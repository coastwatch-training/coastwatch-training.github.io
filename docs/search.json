[
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "History | Create July 2023 | Updated August 2023"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#background",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#background",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Background",
    "text": "Background\nMap projections try to portray the earth’s spherical surface on a flat surface. A coordinate reference system (CRS) defines how the two-dimensional, projected map relates to real places on the earth. Which map projection and CRS to use depends on the region in which you are working and the analysis you will do.\nNOAA PolarWatch distributes gridded and tabular oceanographic data for polar regions.\nMost of the satellite data in the PolarWatch data catalog use a projection based on a Geographic Coordinate Reference System, where the X and Y coordinates are longitude and latitude, respectively. Geographical coordinates work well in many parts of the globe, but within polar regions, features tend to be very distorted. A Polar Stereographic projection often is a better choice for polar regions. For example, the NSIDC’s Polar Stereographic Projections, which were developed to optimize mapping of sea ice, have only a 6% distortion of the grid at the poles and no distortion at 70º, a latitude close to where the marginal ice zones occur. The NOAA NSIDC Sea Ice Concentration Climate Data Record dataset, for example, is in a polar stereographic projection.\nWhen working with satellite datasets with a mix of map projections, it is often necessary to transform all the data to a common projection."
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#objective",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#objective",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Objective",
    "text": "Objective\nIn this tutorial, we will learn to transform dataset coordinates from one projection to another."
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#this-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#this-tutorial-demonstrates-the-following-techniques",
    "title": "Transforming satellite data from one map projection to another",
    "section": "This tutorial demonstrates the following techniques",
    "text": "This tutorial demonstrates the following techniques\n\nDownloading and saving a netCDF file from PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nTransforming coordinates using EPSG codes\nMapping data using the transformed coordinates"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#datasets-used",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#datasets-used",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Datasets used",
    "text": "Datasets used\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, Science Quality, 1978-2022, Monthly\nThe sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Southern Polar Stereographic projection (EPSG:3031). The resolution is 25km, meaning each pixel in this data set represents a value that covers a 25km by 25km area. The dataset can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#import-packages",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#import-packages",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Import packages",
    "text": "Import packages\n\nimport cartopy.crs as ccrs\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nfrom pyproj import CRS\nfrom pyproj import Transformer\nfrom matplotlib import pyplot as plt \nimport cmocean\n\n## Get data from ERDDAP\n\n# request data from polarwatch.noaa.gov erddap and save it to sic.nc file\n\nurl = ''.join([\"https://polarwatch.noaa.gov/erddap/griddap/\",\n               \"nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly\",\n               \"[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)]\", \n               \"[(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]\"\n               ])\n\nurllib.request.urlretrieve(url, \"sic.nc\")\n\n('sic.nc', &lt;http.client.HTTPMessage at 0x1a7e0cca0&gt;)\n\n\n\n# open and assign data from the file to a variable ds using xarray\nds = xr.open_dataset(\"sic.nc\")\n\n# view metadata \nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 1, ygrid: 332, xgrid: 316)\nCoordinates:\n  * time                     (time) datetime64[ns] 2022-12-01\n  * ygrid                    (ygrid) float32 4.338e+06 4.312e+06 ... -3.938e+06\n  * xgrid                    (xgrid) float32 -3.938e+06 -3.912e+06 ... 3.938e+06\nData variables:\n    cdr_seaice_conc_monthly  (time, ygrid, xgrid) float32 ...\nAttributes: (12/65)\n    acknowledgement:                                     This project was sup...\n    cdm_data_type:                                       Grid\n    cdr_variable:                                        cdr_seaice_conc_monthly\n    contributor_name:                                    Walter N. Meier, Flo...\n    contributor_role:                                    principal investigat...\n    Conventions:                                         CF-1.6, ACDD-1.3, CO...\n    ...                                                  ...\n    summary:                                             This data set provid...\n    time_coverage_duration:                              P1M\n    time_coverage_end:                                   2022-12-01T00:00:00Z\n    time_coverage_resolution:                            P1M\n    time_coverage_start:                                 2022-12-01T00:00:00Z\n    title:                                               Sea Ice Concentratio...xarray.DatasetDimensions:time: 1ygrid: 332xgrid: 316Coordinates: (3)time(time)datetime64[ns]2022-12-01_ChunkSizes :1024_CoordinateAxisType :Timeactual_range :[1.6698528e+09 1.6698528e+09]axis :Tioos_category :Timelong_name :ANSI datestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-12-01T00:00:00.000000000'], dtype='datetime64[ns]')ygrid(ygrid)float324.338e+06 4.312e+06 ... -3.938e+06_ChunkSizes :332actual_range :[-3937500.  4337500.]axis :Yioos_category :Locationlong_name :projection_grid_y_centersstandard_name :projection_y_coordinateunits :metersvalid_range :[-3950000.  4350000.]array([ 4337500.,  4312500.,  4287500., ..., -3887500., -3912500., -3937500.],\n      dtype=float32)xgrid(xgrid)float32-3.938e+06 -3.912e+06 ... 3.938e+06_ChunkSizes :316actual_range :[-3937500.  3937500.]axis :Xioos_category :Locationlong_name :projection_grid_x_centersstandard_name :projection_x_coordinateunits :metersvalid_range :[-3950000.  3950000.]array([-3937500., -3912500., -3887500., ...,  3887500.,  3912500.,  3937500.],\n      dtype=float32)Data variables: (1)cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...ancillary_variables :stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthlycolorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole lakes coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Southern Hemisphere Sea Ice Concentrationreferences :https://nsidc.org/data/g02202/versions/4/standard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][104912 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2022-12-01'], dtype='datetime64[ns]', name='time', freq=None))ygridPandasIndexPandasIndex(Index([ 4337500.0,  4312500.0,  4287500.0,  4262500.0,  4237500.0,  4212500.0,\n        4187500.0,  4162500.0,  4137500.0,  4112500.0,\n       ...\n       -3712500.0, -3737500.0, -3762500.0, -3787500.0, -3812500.0, -3837500.0,\n       -3862500.0, -3887500.0, -3912500.0, -3937500.0],\n      dtype='float32', name='ygrid', length=332))xgridPandasIndexPandasIndex(Index([-3937500.0, -3912500.0, -3887500.0, -3862500.0, -3837500.0, -3812500.0,\n       -3787500.0, -3762500.0, -3737500.0, -3712500.0,\n       ...\n        3712500.0,  3737500.0,  3762500.0,  3787500.0,  3812500.0,  3837500.0,\n        3862500.0,  3887500.0,  3912500.0,  3937500.0],\n      dtype='float32', name='xgrid', length=316))Attributes: (65)acknowledgement :This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.cdm_data_type :Gridcdr_variable :cdr_seaice_conc_monthlycontributor_name :Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fishercontributor_role :principal investigator, author, author, software developer, software developer, software developerConventions :CF-1.6, ACDD-1.3, COARDScreator_email :nsidc@nsidc.orgcreator_name :NSIDCcreator_type :institutioncreator_url :https://nsidc.org/date_created :2023-02-22T23:17:53ZdefaultGraphQuery :cdr_seaice_conc_monthly%5Blast%5D%5B(4337500.0):(-3937500.0)%5D%5B(-3937500.0):(3937500.0)%5D&.draw=surfacegrid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3950000.0 25000.0 0 4350000.0 0 -25000.0grid_mapping_grid_boundary_bottom_projected_y :-3950000.0grid_mapping_grid_boundary_left_projected_x :-3950000.0grid_mapping_grid_boundary_right_projected_x :3950000.0grid_mapping_grid_boundary_top_projected_y :4350000.0grid_mapping_latitude_of_projection_origin :-90.0grid_mapping_longitude_of_projection_origin :0.0grid_mapping_name :polar_stereographicgrid_mapping_parent_grid_cell_column_subset_end :316.0grid_mapping_parent_grid_cell_column_subset_start :0.0grid_mapping_parent_grid_cell_row_subset_end :332.0grid_mapping_parent_grid_cell_row_subset_start :0.0grid_mapping_proj4text :+proj=stere +lat_0=-90 +lat_ts=-70 +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_scaling_factor :1.0grid_mapping_semimajor_radius :6378273.0grid_mapping_semiminor_radius :6356889.449grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic South\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",-70],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3412\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3412grid_mapping_standard_parallel :-70.0grid_mapping_straight_vertical_longitude_from_pole :180.0grid_mapping_units :metershistory :Tue Jan  5 13:40:25 2021: ncks -x -v goddard_merged_seaice_conc_monthly ./previous_blank_ncs/S_monthly_blank.nc ./S_monthly_blank.nc\n2023-09-06T03:13:27Z (local files)\n2023-09-06T03:13:27Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]id :https://doi.org/10.7265/sr8p-kc62infoUrl :https://nsidc.org/data/g02202/versions/4/institution :NSIDC &gt; National Snow and Ice Data Centerkeywords :algorithm, area, bellingshausen, bootstrap, cdr_seaice_conc_monthly, center, climate, common, concentration, cryosphere, data, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Polar, Geographic Region &gt; Southern Hemisphere, goddard, gsfc, hemisphere, ice, ice distribution, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Southern Ocean, Ocean &gt; Southern Ocean &gt; Bellingshausen Sea, Ocean &gt; Southern Ocean &gt; Ross Sea, Ocean &gt; Southern Ocean &gt; Weddell Sea, oceans, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, ross, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, southern, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, tdim, team, version, weddellkeywords_vocabulary :GCMD Science Keywordslicense :No constraints on data access or usemetadata_link :https://nsidc.org/data/g02202/versions/4/naming_authority :org.doi.dxNCO :\"4.5.4\"platform :DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17processing_level :NOAA Level 3product_version :v04r00program :NOAA Climate Data Record Programproj_crs_code :EPSG:3412proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.project :NOAA/NSIDC passive microwave sea ice concentration climate data recordreferences :Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7):  15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1sensor :SSMI/S &gt; Special Sensor Microwave Imager/Soundersoftware_version_id :git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897source :ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220701_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220702_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220703_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220704_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220705_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220706_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220707_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220708_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220709_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220710_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220711_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220712_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220713_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220714_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220715_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220716_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220717_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220718_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220719_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220720_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220721_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220722_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220723_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220724_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220725_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220726_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220727_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220728_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220729_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220730_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220731_f17_v04r00.ncsourceUrl :(local files)spatial_resolution :25kmstandard_name_vocabulary :CF Standard Name Table v70summary :This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).time_coverage_duration :P1Mtime_coverage_end :2022-12-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2022-12-01T00:00:00Ztitle :Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-Present, Monthly"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#inspect-crs-definitions-and-the-transformation-function",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#inspect-crs-definitions-and-the-transformation-function",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Inspect CRS definitions and the transformation function",
    "text": "Inspect CRS definitions and the transformation function\nWhen transforming from one CRS to another, it is important to inspect CRS definitions and the transformation function for proper transformation. We will transform from CRS EPSG: 3031 (NSIDC Polar Stereographic South) to EPSG: 4326 (geographic coordinate system) .\nThere are several ways to specify CRS as shown below. For this exercise, we will use EPSG code.\n1. crs = CRS.from_epsg(4326)\n2. crs = CRS.from_string(\"EPSG:4326\")\n3. crs = CRS.from_proj4(\"+proj=latlon\")\nFor this exercise, we will use method 1, the EPSG code.\n\nGet the projection information from the EPSG code\nGeographic\n\ncrs_4326 = CRS.from_epsg(4326)\ncrs_4326\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\nNSIDC Polar Stereographic South\n\ncrs_3031 = CRS.from_epsg(3031)\ncrs_3031\n\n&lt;Projected CRS: EPSG:3031&gt;\nName: WGS 84 / Antarctic Polar Stereographic\nAxis Info [cartesian]:\n- E[north]: Easting (metre)\n- N[north]: Northing (metre)\nArea of Use:\n- name: Antarctica.\n- bounds: (-180.0, -90.0, 180.0, -60.0)\nCoordinate Operation:\n- name: Antarctic Polar Stereographic\n- method: Polar Stereographic (variant B)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n\nInspect CRS definitions\ncrs_4326 * order of axis: latitude first, and longitude in degree * bounds (-180, -90, 180, 90) global coverage\ncrs_3031 * order of axis: X then Y in meter * bounds (-180, -90, 180, -60)\nbased on the crs definitions * transformation input should be in the order of latitude and longitude * transformation input/output should be within the bounds\nNOTE: if you prefer to use lon and lat (or x, y) axis order, you can set transformer parameter always_xy to True\nTransformer.from_crs(crs_3031, crs_4326, always_xy=True)"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#transform-the-data",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#transform-the-data",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Transform the data",
    "text": "Transform the data\n\n# transformer converts lon and lat values to x, y \ntransformer = Transformer.from_crs(crs_3031, crs_4326)\n\n# create a rectangular grid \nx, y = np.meshgrid(ds.xgrid, ds.ygrid)\n\n# pass x and y grid values to transform\nlat, lon = transformer.transform(x,y)"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#add-latitude-and-longitude-values-to-the-dataset",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#add-latitude-and-longitude-values-to-the-dataset",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Add latitude and longitude values to the dataset",
    "text": "Add latitude and longitude values to the dataset\nFor adding the new coordinates to the dataset, create a tuple with its dimension and values then add to the dataset.\n\ncreate a tuple (dimension, value)\nadd to the dataset (ds) ds.coord['name']=(dimension, value)\n\n\nds.coords['lat'] = (ds.cdr_seaice_conc_monthly[0][:].dims, lat)\nds.coords['lon'] = (ds.cdr_seaice_conc_monthly[0][:].dims, lon)\n\nds['cdr_seaice_conc_monthly'] = (ds['cdr_seaice_conc_monthly']\n                                 .where(ds['cdr_seaice_conc_monthly'] &lt;= 1, \n                                        np.nan)\n                                 )"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#plot-data-with-new-coordinates-on-a-global-map",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#plot-data-with-new-coordinates-on-a-global-map",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Plot data with new coordinates on a global map",
    "text": "Plot data with new coordinates on a global map\nBecause the data were in the polar stereographic projection, mapping the data onto a different projection (global map projection) below, doesn’t make the data fit well on the map.\n\n# set the map size\nplt.figure(figsize=(13,5))\n\n# set map projection (PlateCarree(): global map projection)\nax = plt.axes(projection=ccrs.PlateCarree())\n\n# plot data with new coordinates\nds.cdr_seaice_conc_monthly[0][:].plot.pcolormesh('lon', \n                                                 'lat', \n                                                 ax=ax, \n                                                 transform=ccrs.PlateCarree(), \n                                                 cmap=cmocean.cm.ice, \n                                                 add_colorbar=False)\n# add coastlines to the map\nax.coastlines()"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#plot-data-with-new-coordinates-on-a-polar-stereographic-projection-map",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#plot-data-with-new-coordinates-on-a-polar-stereographic-projection-map",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Plot data with new coordinates on a polar stereographic projection map",
    "text": "Plot data with new coordinates on a polar stereographic projection map\n\n# Set map projection \n# SouthPolarStereo(): southern polar stereographic projection)\nax = plt.axes(projection=ccrs.SouthPolarStereo())\n\nds.cdr_seaice_conc_monthly[0][:].plot.pcolormesh('lon', \n                                                 'lat', \n                                                 ax=ax, \n                                                 cmap=cmocean.cm.ice, \n                                                 transform=ccrs.PlateCarree())\n\nax.coastlines()"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#references",
    "href": "tutorials/transform-to-another-map-projection/python/transforming-coords-from-crs-to-crs.html#references",
    "title": "Transforming satellite data from one map projection to another",
    "section": "References",
    "text": "References\nUseful links\n\nNOAA PolarWatch Data Product Page (download, preview)\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)"
  },
  {
    "objectID": "tutorials/seaice-thickness-climatology/python/seaice-thickness-climatology.html",
    "href": "tutorials/seaice-thickness-climatology/python/seaice-thickness-climatology.html",
    "title": "Calculating anomaly and trend with sea ice thickness time series",
    "section": "",
    "text": "In this exercise, we will use the sea ice thickness data in the Arctic region, available through the PolarWatch data server, to study changes in monthly average sea ice thickness values. We will compare the current state of sea ice thickness to the historical mean and also evaluate the long-term trend from the data.\n\nThe exercise demonstrates the following techniques:\n\nLoading twice daily sea ice thickness data of the year 2023 from ERDDAP using xarray and compute monthly average\nLoading multi-year monthly average sea ice thickness data from netCDF file\nCalculating the historical sea ice thickness monthly means\nCalculating anomalies (departures from the historical means)\nCalculating the trend of monthly sea ice thickness means for the climatological reference period of 2006 to 2020 (15 years)\nVisualizing the data\n\n\n\nDatasets used:\n\nSea ice thickness for the Arctic from the NOAA Climate Data Record (CDR) of the Extended Polar Pathfinder cryosphere dataset from NCEI. Twice daily data are available from 1982 to present. https://polarwatch.noaa.gov/catalog/ice-thick-sq-nh-appx/preview/?dataset=daily&var=cdr_sea_ice_thickness&time_min=2024-08-28T14:00:00Z&time_max=2024-08-28T14:00:00Z&proj=epsg3413&colorBar=KT_amp|||0|3|\n25-km sea ice thickess monthly average data from 2006 to 2020.\n\nIn this exercise, monthly means were computed from the 25-km sea ice thickness dataset under the assumption of equal sampling and no missing data. Therefore, no weights were applied in this instance. In cases where data gaps or uneven sampling occur, applying appropriate weights is recommended for more accurate climatological calculations.\n\n\nImport Python packages\n\n# Load packages\nimport xarray as xr\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport pymannkendall as mk\n\n\n\nLoad data from PolarWatch ERDDAP data server\nWe will begin by obtaining the current sea ice thickness data from the PolarWatch ERDDAP data server. The data request is made using a URL that includes the ERDDAP address and a unique dataset ID.\n\n# Define the URL for the PolarWatch sea ice thickness dataset on the ERDDAP server\nerddap_url = \"https://polarwatch.noaa.gov/erddap/griddap/ncei_polarAPPX20_nhem\"  \n\n# Use xarray function to load the dtaset from the EREDDAP URL\nds = xr.open_dataset(erddap_url)   \n\n# Display the dataset metadata \nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 310GB\nDimensions:                                    (time: 29729, rows: 361,\n                                                columns: 361)\nCoordinates:\n  * time                                       (time) datetime64[ns] 238kB 19...\n  * rows                                       (rows) float32 1kB -4.5e+06 .....\n  * columns                                    (columns) float32 1kB -4.525e+...\nData variables: (12/20)\n    cdr_sea_ice_thickness                      (time, rows, columns) float32 15GB ...\n    cdr_surface_temperature                    (time, rows, columns) float32 15GB ...\n    cdr_surface_albedo                         (time, rows, columns) float32 15GB ...\n    cdr_surface_downwelling_shortwave_flux     (time, rows, columns) float32 15GB ...\n    cdr_surface_downwelling_longwave_flux      (time, rows, columns) float32 15GB ...\n    cdr_surface_upwelling_shortwave_flux       (time, rows, columns) float32 15GB ...\n    ...                                         ...\n    cloud_optical_depth                        (time, rows, columns) float32 15GB ...\n    cloud_top_pressure                         (time, rows, columns) float32 15GB ...\n    cloud_top_temperature                      (time, rows, columns) float32 15GB ...\n    cloud_type                                 (time, rows, columns) float32 15GB ...\n    surface_shortwave_cloud_radiative_forcing  (time, rows, columns) float32 15GB ...\n    surface_longwave_cloud_radiative_forcing   (time, rows, columns) float32 15GB ...\nAttributes: (12/44)\n    _NCProperties:              version=2,netcdf=4.8.1,hdf5=1.10.6\n    acknowledgement:            Please acknowledge NCEI, CoastWatch West Coas...\n    cdm_data_type:              Grid\n    cdr_program:                NOAA Climate Data Record Program for satellites\n    cdr_variable:               cdr_surface_temperature, cdr_surface_albedo, ...\n    comment:                    In order to be compliant with the EASE Grid s...\n    ...                         ...\n    spatial_resolution:         25 km\n    standard_name_vocabulary:   CF Standard Name Table (v26, 08 November 2013)\n    summary:                    summary\n    time_coverage_end:          2024-09-19T14:00:00Z\n    time_coverage_start:        1982-01-01T04:00:00Z\n    title:                      Sea Ice Thickness and Multi-variable Extended...xarray.DatasetDimensions:time: 29729rows: 361columns: 361Coordinates: (3)time(time)datetime64[ns]1982-01-01T04:00:00 ... 2024-09-..._ChunkSizes :512_CoordinateAxisType :Timeactual_range :[3.7870560e+08 1.7267544e+09]axis :Tioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1982-01-01T04:00:00.000000000', '1982-01-01T14:00:00.000000000',\n       '1982-01-02T04:00:00.000000000', ..., '2024-09-16T14:00:00.000000000',\n       '2024-09-19T04:00:00.000000000', '2024-09-19T14:00:00.000000000'],\n      dtype='datetime64[ns]')rows(rows)float32-4.5e+06 -4.475e+06 ... 4.525e+06_ChunkSizes :361_CoordinateAxisType :GeoYactual_range :[-4499620.  4524689.]axis :Ycomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid Y Coordinatesstandard_name :projection_y_coordinateunits :metersarray([-4499620.5, -4474553. , -4449485.5, ...,  4474553. ,  4499620.5,\n        4524688.5], dtype=float32)columns(columns)float32-4.525e+06 -4.5e+06 ... 4.5e+06_ChunkSizes :361_CoordinateAxisType :GeoXactual_range :[-4524688.  4499621.]axis :Xcomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid X Coordinatesstandard_name :projection_x_coordinateunits :metersarray([-4524688.5, -4499620.5, -4474553. , ...,  4449485.5,  4474553. ,\n        4499620.5], dtype=float32)Data variables: (20)cdr_sea_ice_thickness(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_icecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Ice Distributionlong_name :NOAA CDR of sea ice thicknessstandard_name :sea_ice_thicknessunits :mvalid_range :[ 0. 10.][3874313009 values with dtype=float32]cdr_surface_temperature(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_thermalcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Temperaturelong_name :NOAA CDR of surface skin temperaturestandard_name :surface_temperatureunits :degree_Kvalid_range :[   0. 1000.][3874313009 values with dtype=float32]cdr_surface_albedo(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of surface broadband albedostandard_name :surface_albedounits :1valid_range :[0. 1.][3874313009 values with dtype=float32]cdr_surface_downwelling_shortwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of surface downwelling shortwave radiative fluxstandard_name :surface_downwelling_shortwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_surface_downwelling_longwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of surface downwelling longwave radiative fluxstandard_name :surface_downwelling_longwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_surface_upwelling_shortwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of surface upwelling shortwave radiative fluxstandard_name :surface_upwelling_shortwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_surface_upwelling_longwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of surface upwelling longwave radiative fluxstandard_name :surface_upwelling_longwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_cloud_binary_mask(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarContinuous :falsecolorBarMaximum :1.5colorBarMinimum :-0.5colorBarNSections :2colorBarPalette :BlackWhitecoverage_content_type :referenceInformationflag_meanings :clear cloudyflag_values :[0 1]grid_mapping :crsioos_category :Identifierlong_name :NOAA CDR of cloud maskunits :1valid_range :[0. 1.][3874313009 values with dtype=float32]cdr_toa_net_downward_shortwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of TOA net downward shortwave radiative fluxstandard_name :toa_net_downward_shortwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_toa_outgoing_shortwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of TOA outgoing shortwave radiative fluxstandard_name :toa_outgoing_shortwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_toa_outgoing_longwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of TOA outgoing longwave radiative fluxstandard_name :toa_outgoing_longwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]surface_type(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarContinuous :falsecolorBarMaximum :5.5colorBarMinimum :-0.5colorBarNSections :6colorBarPalette :KT_graycoverage_content_type :physicalMeasurementflag_meanings :not_land ice snow landflag_values :[  0   3   4 254]grid_mapping :crsioos_category :Meteorologylong_name :surface typeunits :1valid_range :[  0 254][3874313009 values with dtype=float32]cloud_particle_phase(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarContinuous :falsecolorBarMaximum :1.5colorBarMinimum :-0.5colorBarNSections :2colorBarPalette :KT_halinecoverage_content_type :physicalMeasurementflag_meanings :liquid solidflag_values :[0 1]grid_mapping :crsioos_category :Meteorologylong_name :cloud particle phaseunits :1valid_range :[0 1][3874313009 values with dtype=float32]cloud_particle_radius(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_halinecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :cloud particle radiusunits :micronsvalid_range :[  0. 300.][3874313009 values with dtype=float32]cloud_optical_depth(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_deepcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :cloud optical depthunits :1valid_range :[  0. 300.][3874313009 values with dtype=float32]cloud_top_pressure(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_densecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :cloud top pressureunits :hPavalid_range :[   0. 1000.][3874313009 values with dtype=float32]cloud_top_temperature(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_thermalcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :cloud top temperatureunits :Kvalid_range :[   0. 1000.][3874313009 values with dtype=float32]cloud_type(time, rows, columns)float32..._ChunkSizes :[  1 361 361]coverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :cloud typemeanings :Cloud type value has two digits, i.e. XX, the ones place X (the first X from left), representing cloud type from CASPR algorithm, and the tenth place X representing cloud type from CLAVR algorithm. For CLAVR algorithm the tenth place X meanings: 0=clear or partly cloudy,1=fogs,2=liquid,3=mixed phase,4=glaciated,5=cirrus6=cirrus over lower,7=unused,8=unused,9=missing. For CASPR algorithm the ones place X meanings: 0=clear,1=cirrus,2=low stratus,3=warm,4=cold,5=water6=ice,7=Polar stratospheric cloud (PSC),8=unknown,9=missing.units :1valid_range :[ 0 99][3874313009 values with dtype=float32]surface_shortwave_cloud_radiative_forcing(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_densecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :surface shortwave cloud radiative forcingunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]surface_longwave_cloud_radiative_forcing(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_densecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :surface longwave cloud radiative forcingunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1982-01-01 04:00:00', '1982-01-01 14:00:00',\n               '1982-01-02 04:00:00', '1982-01-02 14:00:00',\n               '1982-01-03 04:00:00', '1982-01-03 14:00:00',\n               '1982-01-04 04:00:00', '1982-01-04 14:00:00',\n               '1982-01-05 04:00:00', '1982-01-05 14:00:00',\n               ...\n               '2024-09-13 04:00:00', '2024-09-13 14:00:00',\n               '2024-09-14 04:00:00', '2024-09-14 14:00:00',\n               '2024-09-15 04:00:00', '2024-09-15 14:00:00',\n               '2024-09-16 04:00:00', '2024-09-16 14:00:00',\n               '2024-09-19 04:00:00', '2024-09-19 14:00:00'],\n              dtype='datetime64[ns]', name='time', length=29729, freq=None))rowsPandasIndexPandasIndex(Index([-4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5, -4374283.0,\n       -4349215.5, -4324148.0, -4299080.5, -4274013.0,\n       ...\n        4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,  4424418.0,\n        4449485.5,  4474553.0,  4499620.5,  4524688.5],\n      dtype='float32', name='rows', length=361))columnsPandasIndexPandasIndex(Index([-4524688.5, -4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5,\n       -4374283.0, -4349215.5, -4324148.0, -4299080.5,\n       ...\n        4274013.0,  4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,\n        4424418.0,  4449485.5,  4474553.0,  4499620.5],\n      dtype='float32', name='columns', length=361))Attributes: (44)_NCProperties :version=2,netcdf=4.8.1,hdf5=1.10.6acknowledgement :Please acknowledge NCEI, CoastWatch West Coast Node, and this dataset (doi:10.25921/AE96-0E57).cdm_data_type :Gridcdr_program :NOAA Climate Data Record Program for satellitescdr_variable :cdr_surface_temperature, cdr_surface_albedo, cdr_surface_downwelling_shortwave_flux, cdr_surface_downwelling_longwave_flux, cdr_surface_upwelling_shortwave_flux, cdr_surface_upwelling_longwave_flux, cdr_cloud_binary_mask, cdr_sea_ice_thickness, cdr_toa_net_downward_shortwave_flux, cdr_toa_outgoing_shortwave_flux, cdr_toa_outgoing_longwave_flux,surface_type, cloud_particle_phase, cloud_particle_radius, cloud_optical_depth, cloud_top_pressure, cloud_top_temperature, Cloud_type, surface_shortwave_cloud_radiative_forcing, surface_longwave_cloud_radiative_forcingcomment :In order to be compliant with the EASE Grid specifications, the following modifications were made to the source files: 1) For each data variable plus the latitude and longitude variables, the two dimensional x-y grid was rotated clockwise by 90 degrees, resulting in geographical orientation where the Greenwich Meridian runs parallel to the y (rows)-axis from the North Pole at the grid center to the middle of the x (columns)-axis at the bottom edge of the grid and -90 degree E meridian runs parallel to the x (columns)-axis from the North Pole at the grid center to the middle of the y (rows)-axis at the left edge of the grid.: 2) two coordinate variables (columns and rows) were added that correspond to the columns and rows dimensions (units of m). In addition, the time variable was modified to put all of the files in the dataset on the same base time (seconds since 1970-01-01T00:00:00Z).Conventions :COARDS, CF-1.4, Unidata Dataset Discovery v1.0creator_email :erd.data@noaa.govcreator_name :NOAA/NMFS/SWFSC/ERD and NOAA/NESDIS/CoastWatch West Coast Nodecreator_type :institutiondate_created :2024-09-23defaultGraphQuery :cdr_sea_ice_thickness[(last)][(-4499620.5):(4524688.5)][(-4524688.5):(4499620.5)]&.draw=surfacedoi :doi.org/10.25921/AE96-0E57EPSG :http://epsg.io/3408history :Data files were obtained from NCEI at https://www.ncei.noaa.gov/data/avhrr-polar-pathfinder-extended/access/. For each data variable plus the latitude and longitude variables, the two dimensional x-y grid was rotated clockwise by 90 degrees, resulting in geographical orientation where the Greenwich Meridian runs parallel to the y (rows)-axis from the North Pole at the grid center to the middle of the x (columns)-axis at the bottom edge of the grid and -90 degree E meridian runs parallel to the x (columns)-axis from the North Pole at the grid center to the middle of the y (rows)-axis at the left edge of the grid. To coordinate variables (columns and rows) were added that correspond to the columns and rows dimensions. The coordinate variables have units of meters. The timestamp was made consistent across all files by converting to seconds since 1970-01-01T00:00:00Z. Metadata were alter to be in compliance with CF and ACDD standards.\n2024-10-02T16:55:11Z https://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.ncdc:C00941/html\n2024-10-02T16:55:11Z https://polarwatch.noaa.gov/erddap/griddap/ncei_polarAPPX20_nhem.dasid :Polar-APP-X_v02r00_NheminfoUrl :https://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.ncdc:C00941/htmlinstitution :NOAA/NCEIkeywords :Earth Science &gt; Atmosphere &gt; Atmospheric Radiation &gt; Longwave Radiation, Earth Science &gt; Atmosphere &gt; Atmospheric Radiation &gt; Radiative Flux, Earth Science &gt; Atmosphere &gt; Atmospheric Radiation &gt; Solar Radiation, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Microphysics &gt; Cloud Droplet Concentration(Size), Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Microphysics &gt; Cloud Droplet Phase, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Microphysics &gt; Cloud Optical Depth(Thickness), Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Properties &gt; Cloud Fraction, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Properties &gt; Cloud Top Pressure, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Properties &gt; Cloud Top Temperature, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Properties &gt; Cloud Type, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Radiative Transfer &gt; Cloud Radiative Forcing, Earth Science &gt; Climate Indicators &gt; Cryospheric Indicators &gt; Ice Depth(Thickness), Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Depth(Thickness), Earth Science &gt; Cryosphere &gt; Snow And Ice &gt; Albedo, Earth Science &gt; Cryosphere &gt; Snow And Ice &gt; Snow And Ice Temperature, Earth Science &gt; Land Surface &gt; Land Albedo, Earth Science &gt; Land Surface &gt; Land Temperature, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Depth(Thickness), Earth Science &gt; Terrestrial Hydrosphere &gt; Snow And Ice &gt; Albedo, Earth Science &gt; Terrestrial Hydrosphere &gt; Snow And Ice &gt; Ice Depth(Thickness)keywords_vocabulary :NASA Global Change Master Directory (GCMD) Earth Science Keywords, Version 8license :The data may be used and redistributed for free but is not intended\nfor legal use, since it may contain inaccuracies. Neither the data\nContributor, ERD, NOAA, nor the United States Government, nor any\nof their employees or contractors, makes any warranty, express or\nimplied, including warranties of merchantability and fitness for a\nparticular purpose, or assumes any legal liability for the accuracy,\ncompleteness, or usefulness, of this information.Metadata_Conventions :COARDS, CF-1.6, Unidata Dataset Discovery v1.0metadata_link :https://doi.org/10.25921/AE96-0E57naming_authority :gov.noaa.nceiNCO :netCDF Operators version 5.0.6 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)platform : NOAA polar orbiting satellite 19product_version :V2.0PROJ4 :+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +a=6371228 +b=6371228 +units=m +no_defsproj_crs_code :EPSG:3408proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.proj_units :meterspublisher_email :erd.data@noaa.govpublisher_name :NOAA/NMFS/SWFSC/ERD and NOAA/NESDIS/CoastWatch West Coast Nodepublisher_type :institutionreferences :doi.org/10.25921/AE96-0E57sensor :Advanced Very High Resolution Radiometer (AVHRR)/3source :individual twice daily APP-x datasourceUrl :https://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.ncdc:C00941/htmlspatial_resolution :25 kmstandard_name_vocabulary :CF Standard Name Table (v26, 08 November 2013)summary :summarytime_coverage_end :2024-09-19T14:00:00Ztime_coverage_start :1982-01-01T04:00:00Ztitle :Sea Ice Thickness and Multi-variable Extended AVHRR Polar Pathfinder APP-X NCEI Climate Data Record V2, Arctic, 1982-Present, Twice Daily\n\n\n\n\nLoad 2021 data and compute monthly average\nNote: Running this code snippet may take some time (about 10 minutes), depending on the available resources of your computer. If you encounter any issues running the code, you can load the final dataset, ds_23_monthly.nc, located in the data/ folder to continue with the exercise.\n# Load data from year 2021\nds21 = ds.sel(time=slice('2023-01-01', '2023-12-31'))\n\n# Compute montly average\nds_monthly_mean21 = ds21.groupby(\"time.month\").mean()\n\n# Close dataset to free up memory\nds21.close()\n\n# Load data from year 2021\nds23 = ds['cdr_sea_ice_thickness'].sel(time=slice('2023-01-01', '2023-12-31'))\n\n# Compute montly average\nds_monthly_mean23_2 = ds23.groupby(\"time.month\").mean()\n\n# Close dataset to free up memory\nds23.close()\n\n\n\n# Load already computed monthly mean for 2021\nds_monthly_mean23 = xr.open_dataset('../data/sit_monthly_mean23.nc')\nds_monthly_mean23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 6MB\nDimensions:                (rows: 361, columns: 361, month: 12)\nCoordinates:\n  * rows                   (rows) float32 1kB -4.5e+06 -4.475e+06 ... 4.525e+06\n  * columns                (columns) float32 1kB -4.525e+06 -4.5e+06 ... 4.5e+06\n  * month                  (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\nData variables:\n    cdr_sea_ice_thickness  (month, rows, columns) float32 6MB ...xarray.DatasetDimensions:rows: 361columns: 361month: 12Coordinates: (3)rows(rows)float32-4.5e+06 -4.475e+06 ... 4.525e+06_ChunkSizes :361_CoordinateAxisType :GeoYactual_range :[-4499620.  4524689.]axis :Ycomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid Y Coordinatesstandard_name :projection_y_coordinateunits :metersarray([-4499620.5, -4474553. , -4449485.5, ...,  4474553. ,  4499620.5,\n        4524688.5], dtype=float32)columns(columns)float32-4.525e+06 -4.5e+06 ... 4.5e+06_ChunkSizes :361_CoordinateAxisType :GeoXactual_range :[-4524688.  4499621.]axis :Xcomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid X Coordinatesstandard_name :projection_x_coordinateunits :metersarray([-4524688.5, -4499620.5, -4474553. , ...,  4449485.5,  4474553. ,\n        4499620.5], dtype=float32)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])Data variables: (1)cdr_sea_ice_thickness(month, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_icecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Ice Distributionlong_name :NOAA CDR of sea ice thicknessstandard_name :sea_ice_thicknessunits :mvalid_range :[ 0. 10.][1563852 values with dtype=float32]Indexes: (3)rowsPandasIndexPandasIndex(Index([-4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5, -4374283.0,\n       -4349215.5, -4324148.0, -4299080.5, -4274013.0,\n       ...\n        4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,  4424418.0,\n        4449485.5,  4474553.0,  4499620.5,  4524688.5],\n      dtype='float32', name='rows', length=361))columnsPandasIndexPandasIndex(Index([-4524688.5, -4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5,\n       -4374283.0, -4349215.5, -4324148.0, -4299080.5,\n       ...\n        4274013.0,  4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,\n        4424418.0,  4449485.5,  4474553.0,  4499620.5],\n      dtype='float32', name='columns', length=361))monthPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))Attributes: (0)\n\n\n\n\nVisualizing 2023 January Monthly Average on the Map\n\n# Visualize the January sea ice thickness mean (first time step: index[0])\nds_monthly_mean23['cdr_sea_ice_thickness'][0].plot()\nplt.title(\"2023 Sea ice thickness January Average\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nLoading Monthly Average from 2006 to 2020\nTo do climate analysis such as computing climatology and trend analysis, we will use sea ice thickness monthly average from 2005 to 2020. The monthly averages are already computed and are available in netcdf file.\n\n# Load monthly average data from 2006-2020\nds_monthly = xr.open_dataset('../data/seaice-thickness-monthly2006_2020.nc')\nds_monthly\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 94MB\nDimensions:                (year: 15, month: 12, rows: 361, columns: 361)\nCoordinates:\n  * rows                   (rows) float32 1kB -4.5e+06 -4.475e+06 ... 4.525e+06\n  * columns                (columns) float32 1kB -4.525e+06 -4.5e+06 ... 4.5e+06\n  * month                  (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\n  * year                   (year) int64 120B 2006 2007 2008 ... 2018 2019 2020\nData variables:\n    cdr_sea_ice_thickness  (year, month, rows, columns) float32 94MB ...xarray.DatasetDimensions:year: 15month: 12rows: 361columns: 361Coordinates: (4)rows(rows)float32-4.5e+06 -4.475e+06 ... 4.525e+06_ChunkSizes :361_CoordinateAxisType :GeoYactual_range :[-4499620.  4524689.]axis :Ycomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid Y Coordinatesstandard_name :projection_y_coordinateunits :metersarray([-4499620.5, -4474553. , -4449485.5, ...,  4474553. ,  4499620.5,\n        4524688.5], dtype=float32)columns(columns)float32-4.525e+06 -4.5e+06 ... 4.5e+06_ChunkSizes :361_CoordinateAxisType :GeoXactual_range :[-4524688.  4499621.]axis :Xcomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid X Coordinatesstandard_name :projection_x_coordinateunits :metersarray([-4524688.5, -4499620.5, -4474553. , ...,  4449485.5,  4474553. ,\n        4499620.5], dtype=float32)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])year(year)int642006 2007 2008 ... 2018 2019 2020array([2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n       2018, 2019, 2020])Data variables: (1)cdr_sea_ice_thickness(year, month, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_icecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Ice Distributionlong_name :NOAA CDR of sea ice thicknessstandard_name :sea_ice_thicknessunits :mvalid_range :[ 0. 10.][23457780 values with dtype=float32]Indexes: (4)rowsPandasIndexPandasIndex(Index([-4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5, -4374283.0,\n       -4349215.5, -4324148.0, -4299080.5, -4274013.0,\n       ...\n        4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,  4424418.0,\n        4449485.5,  4474553.0,  4499620.5,  4524688.5],\n      dtype='float32', name='rows', length=361))columnsPandasIndexPandasIndex(Index([-4524688.5, -4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5,\n       -4374283.0, -4349215.5, -4324148.0, -4299080.5,\n       ...\n        4274013.0,  4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,\n        4424418.0,  4449485.5,  4474553.0,  4499620.5],\n      dtype='float32', name='columns', length=361))monthPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))yearPandasIndexPandasIndex(Index([2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n       2018, 2019, 2020],\n      dtype='int64', name='year'))Attributes: (0)\n\n\n\n\nCompute the 15 year historical mean\nUsing ds_monthly dataset, we will compute 15 year historical monthly means.\n\n# Compute monthly mean from annualized data\nhistorical_mean = ds_monthly.mean(dim='year')\nds_monthly.close()\nhistorical_mean\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 6MB\nDimensions:                (month: 12, rows: 361, columns: 361)\nCoordinates:\n  * rows                   (rows) float32 1kB -4.5e+06 -4.475e+06 ... 4.525e+06\n  * columns                (columns) float32 1kB -4.525e+06 -4.5e+06 ... 4.5e+06\n  * month                  (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\nData variables:\n    cdr_sea_ice_thickness  (month, rows, columns) float32 6MB 0.0 0.0 ... 0.0xarray.DatasetDimensions:month: 12rows: 361columns: 361Coordinates: (3)rows(rows)float32-4.5e+06 -4.475e+06 ... 4.525e+06_ChunkSizes :361_CoordinateAxisType :GeoYactual_range :[-4499620.  4524689.]axis :Ycomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid Y Coordinatesstandard_name :projection_y_coordinateunits :metersarray([-4499620.5, -4474553. , -4449485.5, ...,  4474553. ,  4499620.5,\n        4524688.5], dtype=float32)columns(columns)float32-4.525e+06 -4.5e+06 ... 4.5e+06_ChunkSizes :361_CoordinateAxisType :GeoXactual_range :[-4524688.  4499621.]axis :Xcomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid X Coordinatesstandard_name :projection_x_coordinateunits :metersarray([-4524688.5, -4499620.5, -4474553. , ...,  4449485.5,  4474553. ,\n        4499620.5], dtype=float32)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])Data variables: (1)cdr_sea_ice_thickness(month, rows, columns)float320.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0array([[[ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        ...,\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        ...,\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        ...,\n...\n        ...,\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        ...,\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        ...,\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32)Indexes: (3)rowsPandasIndexPandasIndex(Index([-4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5, -4374283.0,\n       -4349215.5, -4324148.0, -4299080.5, -4274013.0,\n       ...\n        4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,  4424418.0,\n        4449485.5,  4474553.0,  4499620.5,  4524688.5],\n      dtype='float32', name='rows', length=361))columnsPandasIndexPandasIndex(Index([-4524688.5, -4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5,\n       -4374283.0, -4349215.5, -4324148.0, -4299080.5,\n       ...\n        4274013.0,  4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,\n        4424418.0,  4449485.5,  4474553.0,  4499620.5],\n      dtype='float32', name='columns', length=361))monthPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))Attributes: (0)\n\n\n\n\nVisualizing monthly historical mean\n\n# Plot the first time step of the sea ice thickness\nhistorical_mean['cdr_sea_ice_thickness'][1].plot()\nplt.title(\"Sea Ice Thickness Historical Month Mean (Feb)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nComputing Anomalies\nTo assess recent changes in sea ice thickness, we can compare the current sea ice thickness for the year 2023 to the 15-year historical mean. An anaomaly is a commonly used metric that represents the difference (or departure) between the current value and the historical average.\n\n# Compute anomaly of 2021 from the mean data\nanom_mean = ds_monthly_mean23['cdr_sea_ice_thickness'] - historical_mean['cdr_sea_ice_thickness']\n\n# Plot Feb and Sep anomaly\nfig, axs = plt.subplots(1, 2, figsize=(12, 5))\nanom_mean[1].plot(ax=axs[0])\nanom_mean[8].plot(ax=axs[1])\n\n# Set the title\nfig.suptitle('2021 Monthly Sea ice thickness Anomalies from 2005-2020 means', fontsize=13)\n\n# Adjust the layout\nplt.tight_layout()\n\n# Display the plots\nplt.show()\n\n\n\n\n\n\n\n\n\n\nComputing Trends\nhttps://www.geeksforgeeks.org/how-to-perform-a-mann-kendall-trend-test-in-python/\nA trend in climatology refers to long-term changes over an extended period. There are several methods to estimate the trends in the time series data. In this exercise, we will use Mann-Kendall regression with mk_slope() function to compute the slope. Mann-Kendall test is a non-parametric method that does not assume data normality, making it suitable for various data distributions.\nNote: The code may take some time to process (approximately 3 minutes).\n\n\n# Define a function to apply the Mann-Kendall test and return the slope\ndef mk_slope(data):\n\n# remove NaN data points\n    clean_data = data[~np.isnan(data)]\n# if data points not enough, return Nan \n    if len(clean_data) &lt; 2:\n            return np.nan     \n    # Apply MK analysis\n    result = mk.original_test(data)\n    # Return only slope\n    return result.slope\n\n# Using xarray.apply_ufunc(), we will apply mk_slope across the 'time' (monthly)  dimension for each grid\n# Apply the function across the 'time' dimension for each pixel\nslopes = xr.apply_ufunc(\n    mk_slope,                # The function to apply\n    ds_monthly,                    # The data \n    input_core_dims=[['year']],  # The dimension over which to apply the function\n    vectorize=True,          # Vectorize to apply across all grid\n    dask='parallelized',     # Enable parallel processing if using Dask\n    output_dtypes=[float]    # The output type (float for slope)\n)\n\n\n\n\nVisualizing the Trends (Slopes) for Each Grid\nThe slopes are calculated for each month and grid over the 15-year-period (2005-2020).\nFor this visualization, we will display the results from the month of September across the grid.\n\nslopes['cdr_sea_ice_thickness'].sel(month=9).plot()\n\nplt.title('Sea Ice Thickness Trend for September')\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "",
    "text": "History | Updated July 2024\n\nIn this exercise you will extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like that produced by an animal telemetry tag, and ship track, or a glider tract.\nPlease note that there may be more efficient ways, more Pythonic ways, to accomplish the tasks in this tutorial. The tutorial was developed to be easier to follow for less experienced users of Python.\n\n\n\nLoading data from a tab- or comma-separated file\nPlotting the latitude/longitude points onto a map\nExtracting satellite data along a track\nSaving results as a CSV file\nPlotting the satellite data onto a map\n\n\n\n\n\nChlorophyll a concentration from the European Space Agency’s Ocean Colour Climate Change Initiative Monthly dataset v6.0\nYellowfin tuna telemetry track data that was developed as part of the Palmyra Bluewater Research (PBR) project (https://portal.atn.ioos.us/?ls=861Wqpd2#metadata/1f877c4c-7b50-49f5-be86-3354664e0cff/project). This example track used in the tutorial is from May 2022 to November 2022 and accessed via the Animal Telemetry Network (ATN) data portal.\n\n\n\n\n\npandas (reading and analyzing data)\n\nnumpy (data analysis, manipulation)\nxarray (multi-dimensional data analysis, manipulation)\nmatplotlib (mapping)\ncartopy (mapping)\ndatetime (date manipulation)"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#overview",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#overview",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "",
    "text": "History | Updated July 2024\n\nIn this exercise you will extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like that produced by an animal telemetry tag, and ship track, or a glider tract.\nPlease note that there may be more efficient ways, more Pythonic ways, to accomplish the tasks in this tutorial. The tutorial was developed to be easier to follow for less experienced users of Python.\n\n\n\nLoading data from a tab- or comma-separated file\nPlotting the latitude/longitude points onto a map\nExtracting satellite data along a track\nSaving results as a CSV file\nPlotting the satellite data onto a map\n\n\n\n\n\nChlorophyll a concentration from the European Space Agency’s Ocean Colour Climate Change Initiative Monthly dataset v6.0\nYellowfin tuna telemetry track data that was developed as part of the Palmyra Bluewater Research (PBR) project (https://portal.atn.ioos.us/?ls=861Wqpd2#metadata/1f877c4c-7b50-49f5-be86-3354664e0cff/project). This example track used in the tutorial is from May 2022 to November 2022 and accessed via the Animal Telemetry Network (ATN) data portal.\n\n\n\n\n\npandas (reading and analyzing data)\n\nnumpy (data analysis, manipulation)\nxarray (multi-dimensional data analysis, manipulation)\nmatplotlib (mapping)\ncartopy (mapping)\ndatetime (date manipulation)"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#import-the-required-python-modules",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#import-the-required-python-modules",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Import the required Python modules",
    "text": "Import the required Python modules\n\nfrom IPython.display import clear_output\nimport pandas as pd\nimport numpy as np\nimport os\nimport warnings\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport matplotlib.pyplot as plt\nimport xarray as xr\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#download-animal-track-data-from-the-atn-website",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#download-animal-track-data-from-the-atn-website",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Download animal track data from the ATN website",
    "text": "Download animal track data from the ATN website\n\nThe data you need for this exercise are already in the GitHub repository\nThe following step are show you how to download the data yourself"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#atn-portal",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#atn-portal",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "ATN Portal",
    "text": "ATN Portal\n\nFollow the link to the ATN website: https://portal.atn.ioos.us/?ls=O6vlufm7#map\nOn the right navigational panel, look for the “Palmyra Bluewater Research (PBR) Megafauna Movement Ecology Project, 2022-2023” tab.\nWithin the tab, scroll to find the telemetry tag labeled “Yellowfin tuna (233568)”.\nClick the search icon (maginifying glass) label next to the label to zoom into the area the area of the animal track.\n\n\n\n\natn_map.png\n\n\nImage of the ATN portal webpage"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#detail-page-for-the-yellowfin-tuna-233568",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#detail-page-for-the-yellowfin-tuna-233568",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Detail page for the Yellowfin tuna (233568)",
    "text": "Detail page for the Yellowfin tuna (233568)\n\nNext click the tag icon to the right of the search icon.\nThis page shows you details about the animal and the track.\n\n\n\n\natn_detail.png\n\n\nImage of the detail page for the Yellowfin Tuna #233568"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#data-download-page",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#data-download-page",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Data Download Page",
    "text": "Data Download Page\n\nPress the “Project Data” tab near the top of the webpage to bring up the data file list.\nSearch for the animal id number (233568).\nClick on the link “THUALB_2022_04-PTT_233568.zip (8.6 MB)” to download the data.\n\n\n\n\natn_data.png\n\n\nData download page"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#the-downloaded-data-file",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#the-downloaded-data-file",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "The Downloaded Data File",
    "text": "The Downloaded Data File\n\nThe download will be a zip file. You will need to unzip it.\nThe unzipped file folder contains many ancillary data files, but the one you are looking for is the CSV file (THUALB_2022_04-233568-4-GPE3.csv).\nYou don’t have to move this file into the data folder for this exercise. It is already there.\nBut if you download the file for a different animal track you would need to put the CSV file into the folder."
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#load-the-track-data-into-a-pandas-data-frame",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#load-the-track-data-into-a-pandas-data-frame",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Load the track data into a Pandas data frame",
    "text": "Load the track data into a Pandas data frame\nBelow, the track data will load using the Pandas “read_csv” method. * Then use the “.head()” method to view the column names and the first few rows of data.\n\ntrack_path = os.path.join('..',\n                          'data',\n                          'THUALB_2022_04-233568-5-GPE3.csv')\n\ntrack_df = pd.read_csv(track_path, skiprows=4)\ntrack_df.head(2)\n\n\n\n\n\n\n\n\nDeployID\nPtt\nDate\nMost Likely Latitude\nMost Likely Longitude\nObservation Type\nObserved SST\nSatellite SST\nObserved Depth\nBathymetry Depth\nObservation LL (MSS)\nObservation Score\nSunrise\nSunset\n\n\n\n\n0\nTHUALB_2022_04\n233568\n31-May-2022 19:00:00\n5.875\n-162.125\nUser\nNaN\nNaN\nNaN\nNaN\nNaN\n68.605853\nNaN\nNaN\n\n\n1\nTHUALB_2022_04\n233568\n01-Jun-2022 00:00:00\n5.875\n-162.100\nNone\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n01-Jun-2022 16:33:04\n02-Jun-2022 04:59:36\n\n\n\n\n\n\n\n## Convert the date strings into the Python datetime date objects * The dates are loaded from the CSV file as strings. * Converting the dates to Python datetime date object gives us flexibility to manipulate the dataframe.\n\ntrack_df['Date'] = pd.to_datetime(track_df['Date'], format='%d-%b-%Y %H:%M:%S')\ntrack_df.head(2)\n\n\n\n\n\n\n\n\nDeployID\nPtt\nDate\nMost Likely Latitude\nMost Likely Longitude\nObservation Type\nObserved SST\nSatellite SST\nObserved Depth\nBathymetry Depth\nObservation LL (MSS)\nObservation Score\nSunrise\nSunset\n\n\n\n\n0\nTHUALB_2022_04\n233568\n2022-05-31 19:00:00\n5.875\n-162.125\nUser\nNaN\nNaN\nNaN\nNaN\nNaN\n68.605853\nNaN\nNaN\n\n\n1\nTHUALB_2022_04\n233568\n2022-06-01 00:00:00\n5.875\n-162.100\nNone\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n01-Jun-2022 16:33:04\n02-Jun-2022 04:59:36"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#clean-up-the-dataframe",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#clean-up-the-dataframe",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Clean up the dataframe",
    "text": "Clean up the dataframe\n\nRemove the columns with non-numerical data.\nRename the “Most Likely Latitude” and “Most Likely Longitude” columns to make the easier to work with.\n\nThe track data has longitude values into -180/+180 format. However, the satellite dataset we are using has longitude values into 0/360 format. So, convert the track data to 0/360 format so that the longitude formats are consistent.\n\n\ndel track_df['DeployID']\ndel track_df['Ptt']\ndel track_df['Sunrise']\ndel track_df['Sunset']\ndel track_df['Observation Type']\n\ntrack_df.rename(columns={\"Most Likely Latitude\": \"Latitude\",\n                         \"Most Likely Longitude\": \"Longitude\"}, inplace=True)\n\n# Convert lontitudes to 0~360 (Re-center map to the dateline)\ntrack_df.Longitude = track_df.Longitude + 360\n\ntrack_df.head(2)\n\n\n\n\n\n\n\n\nDate\nLatitude\nLongitude\nObserved SST\nSatellite SST\nObserved Depth\nBathymetry Depth\nObservation LL (MSS)\nObservation Score\n\n\n\n\n0\n2022-05-31 19:00:00\n5.875\n197.875\nNaN\nNaN\nNaN\nNaN\nNaN\n68.605853\n\n\n1\n2022-06-01 00:00:00\n5.875\n197.900\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#bin-multiple-observations-from-each-day-into-daily-mean-values",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#bin-multiple-observations-from-each-day-into-daily-mean-values",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Bin multiple observations from each day into daily mean values",
    "text": "Bin multiple observations from each day into daily mean values\nThe track data has multiple longitude/latitude/time points for each date. That temporal resolution is much higher than the daily and month satellite datasets that are available. So, let’s reduce the multiple daily values for the animal track data to a single value for each day. The code below creates a new dataframe that bins data for each date and calculates the mean for selected columns. * This process will move the “Date” column to the index column (most left column)\n\ndf = track_df.resample('D', on='Date').mean()\ndf.head()\n\n\n\n\n\n\n\n\nLatitude\nLongitude\nObserved SST\nSatellite SST\nObserved Depth\nBathymetry Depth\nObservation LL (MSS)\nObservation Score\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n2022-05-31\n5.87500\n197.8750\nNaN\nNaN\nNaN\nNaN\nNaN\n68.605853\n\n\n2022-06-01\n5.88500\n198.0000\n28.2\n28.324583\n85.666667\n2908.0\nNaN\n58.239984\n\n\n2022-06-02\n5.92500\n197.9500\n28.3\n28.305416\n64.666667\n3778.0\nNaN\n93.446222\n\n\n2022-06-03\n5.92500\n197.8550\n28.1\n28.310833\n53.666667\n3778.0\nNaN\n71.484871\n\n\n2022-06-04\n5.98125\n197.8125\n28.2\n28.320000\n43.000000\n3778.0\nNaN\n82.962634"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#plot-the-track-on-a-map",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#plot-the-track-on-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot the track on a map",
    "text": "Plot the track on a map\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([180, 221, 0, 26], ccrs.PlateCarree())\n\n# Set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(180, 221, 10), crs=ccrs.PlateCarree())\nax1.set_yticks(range(0, 26, 10), crs=ccrs.PlateCarree())\n\n# Add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# Format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# Bring the lon and lat data into a numpy array \nx, y = df.Longitude.to_numpy(), df.Latitude.to_numpy()\nax1 = plt.plot(x, y, transform=ccrs.PlateCarree(), color='blue')\n# start point in green star\nax1 = plt.plot(x[0], y[0],\n               marker='*',\n               color='g',\n               label='start',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\n# end point in red X\nax1 = plt.plot(x[-1], y[-1],\n               marker='X',\n               color='r',\n               label='end',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\nplt.legend()\nplt.title('Yellowfin Tuna Track (PTT 233568)', fontsize=20)\n\nplt.show()"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Extract data from a satellite dataset corresponding to points on the track",
    "text": "Extract data from a satellite dataset corresponding to points on the track\nWe are going to download data from an ERDDAP server using the following steps: * Select a dataset on an ERDDAP server * Open the dataset using the Xarray module * Loop though the track data and pull out the date, latitude and longitude coordinates from each row * Insert these coordinates into the Xarray open-dataset object to subset and download the satellite data that corresponds to the coordinates. * Add the satellite data to the track dataset.\n\nSelect a dataset\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product that blends data from many ocean color sensors to create a long time series (1997-present) with better spatial coverage than any single sensor.\nIdeally we would use a daily dataset, selecting the day that corresponds to the track data date. However, chlorophyll measurements can have a lot of missing data, primarily due to cloud cover. To reduce data gaps and improve the likelihood of data for our matchups, we can use a dataset that combines all of the data from each month into the monthly average.\nThe ERDDAP URL to the monthly version of the OC-CCI product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\n\n\nOpen the satellite data in Xarray\n\nUse the ERDDAP URL with no extension (e.g. without .html or .graph…). This is the OPeNDAP URL, which allows viewing the dataset metadata and, when you select the data you want, downloading the data.\nUse the Xarray “open_dataset” function then view the metadata\n\n\nerddap_url = '/'.join(['https://oceanwatch.pifsc.noaa.gov',\n                       'erddap',\n                       'griddap',\n                       'esa-cci-chla-monthly-v6-0'])\n\nds = xr.open_dataset(erddap_url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:             (time: 316, latitude: 4320, longitude: 8640)\nCoordinates:\n  * time                (time) datetime64[ns] 1997-09-04 ... 2023-12-01\n  * latitude            (latitude) float64 89.98 89.94 89.9 ... -89.94 -89.98\n  * longitude           (longitude) float64 0.02083 0.0625 ... 359.9 360.0\nData variables:\n    chlor_a             (time, latitude, longitude) float32 ...\n    MERIS_nobs_sum      (time, latitude, longitude) float32 ...\n    MODISA_nobs_sum     (time, latitude, longitude) float32 ...\n    OLCI_A_nobs_sum     (time, latitude, longitude) float32 ...\n    OLCI_B_nobs_sum     (time, latitude, longitude) float32 ...\n    SeaWiFS_nobs_sum    (time, latitude, longitude) float32 ...\n    VIIRS_nobs_sum      (time, latitude, longitude) float32 ...\n    chlor_a_log10_bias  (time, latitude, longitude) float32 ...\n    chlor_a_log10_rmsd  (time, latitude, longitude) float32 ...\n    total_nobs_sum      (time, latitude, longitude) float32 ...\nAttributes: (12/53)\n    cdm_data_type:                     Grid\n    comment:                           See summary attribute\n    Conventions:                       CF-1.7, COARDS, ACDD-1.3\n    creation_date:                     Thu Jan 18 09:04:18 2024\n    creator_email:                     help@esa-oceancolour-cci.org\n    creator_name:                      Plymouth Marine Laboratory\n    ...                                ...\n    time_coverage_end:                 2023-12-01T00:00:00Z\n    time_coverage_resolution:          P1M\n    time_coverage_start:               1997-09-04T00:00:00Z\n    title:                             Chlorophyll a concentration, ESA OC CC...\n    tracking_id:                       abd52a4c-7009-464f-b1eb-958f7d333a1d\n    Westernmost_Easting:               0.020833333333314386xarray.DatasetDimensions:time: 316latitude: 4320longitude: 8640Coordinates: (3)time(time)datetime64[ns]1997-09-04 ... 2023-12-01_CoordinateAxisType :Timeactual_range :[8.7333120e+08 1.7013888e+09]axis :Tioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-04T00:00:00.000000000', '1997-10-01T00:00:00.000000000',\n       '1997-11-01T00:00:00.000000000', ..., '2023-10-01T00:00:00.000000000',\n       '2023-11-01T00:00:00.000000000', '2023-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float6489.98 89.94 89.9 ... -89.94 -89.98_CoordinateAxisType :Latactual_range :[-89.97916667  89.97916667]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.97916666666667valid_min :-89.97916666666666array([ 89.979167,  89.9375  ,  89.895833, ..., -89.895833, -89.9375  ,\n       -89.979167])longitude(longitude)float640.02083 0.0625 ... 359.9 360.0_CoordinateAxisType :Lonactual_range :[2.08333333e-02 3.59979167e+02]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :359.97918701171875valid_min :0.020829999819397926array([2.083333e-02, 6.250000e-02, 1.041667e-01, ..., 3.598958e+02,\n       3.599375e+02, 3.599792e+02])Data variables: (10)chlor_a(time, latitude, longitude)float32...ancillary_variables :chlor_a_log10_rmsd chlor_a_log10_biascolorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll-a concentration in seawater (not log-transformed), generated by as a blended combination of OCI, OCI2, OC2 and OCx algorithms, depending on water class membershipsparameter_vocab_uri :http://vocab.ndg.nerc.ac.uk/term/P011/current/CHLTVOLUstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m-3units_nonstandard :mg m^-3[11794636800 values with dtype=float32]MERIS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the MERIS sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]MODISA_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the MODIS (Aqua) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]OLCI_A_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the OLCI (Sentinel-3a) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]OLCI_B_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the OLCI (Sentinel-3b) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]SeaWiFS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the SeaWiFS (GAC and LAC) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]VIIRS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the VIIRS sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]chlor_a_log10_bias(time, latitude, longitude)float32...colorBarMaximum :0.1colorBarMinimum :-0.1comment :Uncertainty lookups derived from file: /data/datasets/CCI/v6.0-production/stage09b-uncertainty_tables/chlor_a/cci_chla_bias.datioos_category :Statisticslong_name :Bias of log10-transformed chlorophyll-a concentration in seawater.references :https://esa-oceancolour-cci.org/?q=webfm_send/581rel :uncertainty[11794636800 values with dtype=float32]chlor_a_log10_rmsd(time, latitude, longitude)float32...colorBarMaximum :0.002colorBarMinimum :0.0comment :Uncertainty lookups derived from file: /data/datasets/CCI/v6.0-production/stage09b-uncertainty_tables/chlor_a/cci_chla_rmsd.datioos_category :Statisticslong_name :Root-mean-square-difference of log10-transformed chlorophyll-a concentration in seawater.references :https://esa-oceancolour-cci.org/?q=webfm_send/581rel :uncertainty[11794636800 values with dtype=float32]total_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the total number of observations contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-04', '1997-10-01', '1997-11-01', '1997-12-01',\n               '1998-01-01', '1998-02-01', '1998-03-01', '1998-04-01',\n               '1998-05-01', '1998-06-01',\n               ...\n               '2023-03-01', '2023-04-01', '2023-05-01', '2023-06-01',\n               '2023-07-01', '2023-08-01', '2023-09-01', '2023-10-01',\n               '2023-11-01', '2023-12-01'],\n              dtype='datetime64[ns]', name='time', length=316, freq=None))latitudePandasIndexPandasIndex(Float64Index([ 89.97916666666667,            89.9375,  89.89583333333333,\n               89.85416666666667,            89.8125,  89.77083333333333,\n               89.72916666666667,            89.6875,  89.64583333333333,\n               89.60416666666667,\n              ...\n              -89.60416666666666, -89.64583333333331,           -89.6875,\n              -89.72916666666666, -89.77083333333331,           -89.8125,\n              -89.85416666666666, -89.89583333333331,           -89.9375,\n              -89.97916666666666],\n             dtype='float64', name='latitude', length=4320))longitudePandasIndexPandasIndex(Float64Index([0.020833333333314386,               0.0625,  0.10416666666665719,\n               0.14583333333331439,               0.1875,   0.2291666666666572,\n                0.2708333333333144,               0.3125,   0.3541666666666572,\n                0.3958333333333144,\n              ...\n                359.60416666666663,    359.6458333333333,             359.6875,\n                359.72916666666663,    359.7708333333333,             359.8125,\n                359.85416666666663,    359.8958333333333,             359.9375,\n                359.97916666666663],\n             dtype='float64', name='longitude', length=8640))Attributes: (53)cdm_data_type :Gridcomment :See summary attributeConventions :CF-1.7, COARDS, ACDD-1.3creation_date :Thu Jan 18 09:04:18 2024creator_email :help@esa-oceancolour-cci.orgcreator_name :Plymouth Marine Laboratorycreator_url :https://esa-oceancolour-cci.orgdate_created :2022-08-15T22:03:48ZEasternmost_Easting :359.97916666666663geospatial_lat_max :89.97916666666667geospatial_lat_min :-89.97916666666666geospatial_lat_resolution :0.041666666666666664geospatial_lat_units :degrees_northgeospatial_lon_max :359.97916666666663geospatial_lon_min :0.020833333333314386geospatial_lon_resolution :0.041666666666666664geospatial_lon_units :degrees_eastgit_commit_hash :27964270df6ae0b9bdd0af5672529dbebb4e7bd9history :Thu Jan 18 08:21:00 2024: ncatted -O -a geospatial_lon_max,global,o,f,360.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a geospatial_lon_min,global,o,f,0.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a valid_max,lon,o,f,359.9792 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a valid_min,lon,o,f,0.02083 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:20:41 2024: ncap2 -O -s where(lon&lt;0) lon=lon+360 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:20:20 2024: ncks -O --msa_usr_rdr -d lon,0.0,180.0 -d lon,-180.0,0.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0.nc ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nSource data were: ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231201-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231202-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231203-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231204-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231205-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231206-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231207-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231208-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231209-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231210-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231211-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231212-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231213-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231214-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231215-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231216-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231217-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231218-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231219-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231220-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231221-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231222-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231223-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231224-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231225-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231226-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231227-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231228-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231229-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231230-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231231-fv6.0.nc; netcdf_compositor_cci composites  Rrs_412, Rrs_412_bias, Rrs_443, Rrs_443_bias, Rrs_490, Rrs_490_bias, Rrs_510, Rrs_510_bias, Rrs_560, Rrs_560_bias, Rrs_665, Rrs_665_bias, adg_412, adg_412_bias, adg_443, adg_443_bias, adg_490, adg_490_bias, adg_510, adg_510_bias, adg_560, adg_560_bias, adg_665, adg_665_bias, aph_412, aph_412_bias, aph_443, aph_443_bias, aph_490, aph_490_bias, aph_510, aph_510_bias, aph_560, aph_560_bias, aph_665, aph_665_bias, atot_412, atot_443, atot_490, atot_510, atot_560, atot_665, bbp_412, bbp_443, bbp_490, bbp_510, bbp_560, bbp_665, chlor_a, chlor_a_log10_bias, kd_490, kd_490_bias, water_class1, water_class10, water_class11, water_class12, water_class13, water_class14, water_class2, water_class3, water_class4, water_class5, water_class6, water_class7, water_class8, water_class9 with --mean,  Rrs_412_rmsd, Rrs_443_rmsd, Rrs_490_rmsd, Rrs_510_rmsd, Rrs_560_rmsd, Rrs_665_rmsd, adg_412_rmsd, adg_443_rmsd, adg_490_rmsd, adg_510_rmsd, adg_560_rmsd, adg_665_rmsd, aph_412_rmsd, aph_443_rmsd, aph_490_rmsd, aph_510_rmsd, aph_560_rmsd, aph_665_rmsd, chlor_a_log10_rmsd, kd_490_rmsd with --root-mean-square, and  MERIS_nobs, MODISA_nobs, OLCI-A_nobs, OLCI-B_nobs, SeaWiFS_nobs, VIIRS_nobs, total_nobs - with --total\n1705571341 Subsetted from standardised_geo/ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1M_MONTHLY_4km_GEO_PML_OCx_QAA-202312-fv6.0.nc to only include variables MERIS_nobs_sum,MODISA_nobs_sum,OLCI-A_nobs_sum,OLCI-B_nobs_sum,SeaWiFS_nobs_sum,VIIRS_nobs_sum,chlor_a,chlor_a_log10_bias,chlor_a_log10_rmsd,crs,lat,lon,time,total_nobs_sum\n2024-07-31T19:58:44Z (local files)\n2024-07-31T19:58:44Z https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.dasid :ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0.ncinfoUrl :https://esa-oceancolour-cci.org/institution :Plymouth Marine Laboratorykeywords :algorithms, aqua, area, array, array-data, bias, bin, blended, cci, cell, chemistry, chlor_a, chlor_a_log10_bias, chlor_a_log10_rmsd, chlorophyll, chlorophyll-a, class, color, colour, combination, comprehensive, concentration, contributing, count, coverage, data, depending, difference, earth, Earth Science &gt; Oceans &gt; Ocean Chemistry &gt; Chlorophyll, esa, field, field-of-view, gac, generated, global, imager, imager/radiometer, imaging, infrared, laboratory, lac, large, local, log, log-transformed, log10, log10-transformed, marine, mass, mass_concentration_of_chlorophyll_a_in_sea_water, mean, memberships, meris, MERIS_nobs_sum, moderate, modis, MODISA_nobs_sum, not, number, observation, observations, oc2, ocean, ocean color, ocean colour, oceans, oci, oci2, ocx, olci, OLCI-A_nobs_sum, OLCI-B_nobs_sum, plymouth, product, radiometer, resolution, root, root-mean-square-difference, satellite, science, sea, sea-wide, seawater, seawifs, SeaWiFS_nobs_sum, sensor, sentinel, sentinel-3a, sentinel-3b, spectroradiometer, square, statistics, stewardship, suite, system, time, total, total_nobs_sum, transformed, view, viirs, VIIRS_nobs_sum, visible, water, widekeywords_vocabulary :GCMD Science Keywordslicense :ESA CCI Data Policy: free and open access.  When referencing, please use: Ocean Colour Climate Change Initiative dataset, Version &lt;Version Number&gt;, European Space Agency, available online at https://esa-oceancolour-cci.org.  We would also appreciate being notified of publications so that we can list them on the project website at https://esa-oceancolour-cci.org/?q=publicationsnaming_authority :uk.ac.pmlNCO :netCDF Operators version 4.7.5 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)nco_openmp_thread_number :1netcdf_file_type :NETCDF4_CLASSICNorthernmost_Northing :89.97916666666667number_of_bands_used_to_classify :4number_of_files_composited :31number_of_optical_water_types :14platform :Orbview-2,Aqua,Envisat,Suomi-NPP, Sentinel-3a, Sentinel-3bprocessing_level :Level-3product_version :6.0project :Climate Change Initiative - European Space Agencyreferences :https://esa-oceancolour-cci.org/sensor :SeaWiFS,MODIS,MERIS,VIIRS,OLCIsensors_present :OLCIa OLCIbsource :NASA SeaWiFS  L1A and L2 R2018.0 LAC and GAC, MODIS-Aqua L1A and L2 R2018.0, MERIS L1B 3rd reprocessing inc OCL corrections, NASA VIIRS L1A and L2 R2018.0, OLCI L1BsourceUrl :(local files)Southernmost_Northing :-89.97916666666666spatial_resolution :4km nominal at equatorstandard_name_vocabulary :CF Standard Name Table v70summary :Data products generated by the Ocean Colour component of the European Space Agency Climate Change Initiative project. These files are monthly composites of merged sensor (MERIS, Moderate Resolution Imaging Spectroradiometer (MODIS) Aqua, Sea-Wide Field-of-View Sensor (SeaWiFS) Local Area Coverage (LAC) & Global Area Coverage (GAC), Visible and Infrared Imager/Radiometer Suite (VIIRS), OLCI) products.  MODIS Aqua and SeaWiFS were band-shifted and bias-corrected to MERIS bands and values using a temporally and spatially varying scheme based on the overlap years of 2003-2007.  VIIRS was band-shifted and bias-corrected in a second stage against the MODIS Rrs that had already been corrected to MERIS levels, for the overlap period 2012-2014; at the third stage Sentinel-3A OLCI was bias corrected against already corrected MODIS, for overlap period 2016-07-01 to 2019-06-30;  at the fourth stage Sentinel-3B OLCI was bias corrected against already corrected Sentinel-3A OLCI, for overlap period 2018-07-01 to 2021-06-30.  VIIRS, MODIS, SeaWiFS and MERIS Rrs were derived from a combination of NASA's l2gen (for basic sensor geometry corrections, etc) and HYGEOS POLYMER (for atmospheric correction). OLCI Rrs were sourced at L1b (already geometrically corrected) and processed with POLYMER.  The Rrs were binned to a sinusoidal 4km level-3 grid, and later to 4km geographic projection, by Brockmann Consult's SNAP.  Derived products were generally computed with the standard algorithms through SeaDAS.  QAA IOPs were derived using the standard SeaDAS algorithm but with a modified backscattering table to match that used in the bandshifting.  The final chlorophyll is a combination of OCI, OCI2, OC2 and OCx, depending on the water class memberships.  Uncertainty estimates were added using the fuzzy water classifier and uncertainty estimation algorithm of Tim Moore as documented in Jackson et al (2017). and updated according to Jackson et al. (in prep).time_coverage_duration :P1Mtime_coverage_end :2023-12-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :1997-09-04T00:00:00Ztitle :Chlorophyll a concentration, ESA OC CCI - Monthly, 1997-present. v6.0tracking_id :abd52a4c-7009-464f-b1eb-958f7d333a1dWesternmost_Easting :0.020833333333314386\n\n\nOpening the dataset in Xarray lets you look at the dataset metadata.\n* The metadata are listed above. * No data is downloaded until you request it.\nFrom the metadata you can view: * The coordinates (time, latitude and longitude) that you will use to select the data to download. * A list of ten data variables. For this exercise, we want the “chlor_a” variable. If you want, you can find out about each variable with clicking the page icon to the right of each variable name.\nA note on dataset selection\nWe have preselected the OC-CCI monthly dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application.\nYou can find that information above by clicking the right arrow next to “Attribute”. Then look through the list to find: * ‘time_coverage_start’ and ‘time_coverage_end’: the time range * ‘geospatial_lat_min’ and ‘geospatial_lat_max’: the latitude range * ‘geospatial_lon_min’ and ‘geospatial_lon_max’: the longitude range\nThere are a lot of metadata attributes to look through. We can make it easier with a little code to print out the metadata of interest. Then compare these ranges to those found in your track data.\n\nprint('Temporal and spatial ranges of the satellite dataset')\nprint('time range', ds.attrs['time_coverage_start'], \n      ds.attrs['time_coverage_end'])\nprint('latitude range', ds.attrs['geospatial_lat_min'], \n      ds.attrs['geospatial_lat_max'])\nprint('longitude range', ds.attrs['geospatial_lon_min'], \n      ds.attrs['geospatial_lon_max'])\nprint(' ')\nprint('Temporal and spatial ranges of the track data')\nprint('time range', df.index.min(), df.index.max())\nprint('latitude range', \n      round(df.Latitude.min(), 2), round(df.Latitude.max(), 2))\nprint('longitude range', \n      round(df.Longitude.min(), 2), round(df.Longitude.max(), 2))\n\nTemporal and spatial ranges of the satellite dataset\ntime range 1997-09-04T00:00:00Z 2023-12-01T00:00:00Z\nlatitude range -89.97916666666666 89.97916666666667\nlongitude range 0.020833333333314386 359.97916666666663\n \nTemporal and spatial ranges of the track data\ntime range 2022-05-31 00:00:00 2022-11-23 00:00:00\nlatitude range 3.5 17.14\nlongitude range 194.91 201.15\n\n\n\n\nDownload the satellite data that corresponds to each track location\n\nFirst, create new columns in the df dataframe to hold the downloaded data. Fill each row with nan.\n\nDownload the chlorophyll data, time, latitude, and longitude from the ERDDAP satellite dataset.\nConsolidate data adding the downloaded satellite data to the track data (df) dataframe.\n\n\n# Add new columns to the dataframe\ndf[[\"erddap_date\", \"matched_lat\", \"matched_lon\", \"matched_chla\"]] = np.nan\n\n# Subset the satellite data \nfor i in range(0, len(df)):\n    clear_output(wait=True)\n    print(i+1, 'of', len(df))\n    \n    # Download the satellite data and put into a temperary dataframe\n    temp_ds = ds['chlor_a'].sel(time='{0:%Y-%m-%d}'.format(df.index[1]),\n                                latitude=df.loc[df.index[i], 'Latitude'],\n                                longitude=df.loc[df.index[i], 'Longitude'],\n                                method='nearest'\n                                )\n     \n    # Consolidate the data\n    df.loc[df.index[i], [\"erddap_date\", \"matched_lat\",\n               \"matched_lon\", \"matched_chla\"]\n          ] = [temp_ds.time.values,\n               np.round(temp_ds.latitude.values, 5),  # round 5 dec\n               np.round(temp_ds.longitude.values, 5), # round 5 dec\n               np.round(temp_ds.values, 2)  # round 2 decimals\n               ]\n    \n    print(df.loc[df.index[i], [\"erddap_date\", \"matched_lat\",\n               \"matched_lon\", \"matched_chla\"]])\n\n\n177 of 177\nerddap_date     2022-06-01T00:00:00.000000000\nmatched_lat                           4.52083\nmatched_lon                         198.22917\nmatched_chla                             0.22\nName: 2022-11-23 00:00:00, dtype: object\n\n\n\n\nSave your work\n\nSince we moved the Date column to the index, be sure to use index=True\n\n\ndf.to_csv('chl_matchup_tuna233568.csv', index=True, encoding='utf-8')"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#plot-chlorophyll-matchup-data-onto-a-map",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#plot-chlorophyll-matchup-data-onto-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot chlorophyll matchup data onto a map",
    "text": "Plot chlorophyll matchup data onto a map\n\nFirst plot a histogram of the chlorophyll data\n\nprint('Range:', df.matched_chla.min(), df.matched_chla.max())\n_ = df.matched_chla.hist(bins=40)\n\nRange: 0.03999999910593033 0.4699999988079071\n\n\n\n\n\n\n\n\n\nThe range of chlorophyll values can be large, with lots of very low values and a few very high values. Using a linear color bar, most of the lower values would have the same color. * To better visualize the data, we often plot the log or log10 of chlorophyll.\n\n\nPlot a histogram of the log of the chlorophyll data\n\nprint('Range:',\n      np.log(df.matched_chla.min()),\n      np.log(df.matched_chla.max()))\n\n_ = np.log(df.matched_chla).hist(bins=40)\n\nRange: -3.218875847219943 -0.7550225868144006\n\n\n\n\n\n\n\n\n\n\nThe logarithmic transformation displays the range of values across the color bar range (above).\n\n\n\nMap the chlorophyll data\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\n\n# set the projection\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([180, 221, 0, 26], ccrs.PlateCarree())\n\n# Set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(180, 221, 10), crs=ccrs.PlateCarree())\nax1.set_yticks(range(0, 26, 10), crs=ccrs.PlateCarree())\n\n# Add geographical features\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# build and plot coordinates onto map\nx,y = list(df.Longitude), list(df.Latitude)\nax1 = plt.scatter(x, y, transform=ccrs.PlateCarree(),\n                  marker='o',\n                  c=np.log(df.matched_chla),\n                  cmap=plt.get_cmap('jet')\n                  )\nax1=plt.plot(x[0],y[0],marker='*', label='start',transform=ccrs.PlateCarree(), markersize=10)\nax1=plt.plot(x[-1],y[-1],marker='X', label='end',transform=ccrs.PlateCarree(), markersize=10)\n\n\n\n# control color bar values spacing\nlevs2 = np.arange(-3, -1, 0.5)\ncbar=plt.colorbar(ticks=levs2, shrink=0.75, aspect=10)\n#cbar=plt.colorbar(shrink=0.75, aspect=10)\ncbar.set_label(\"Chl a (mg/m^3)\", size=15, labelpad=20)\n\n# set the labels to be exp(levs2) so the label reflect values of chl-a, not log(chl-a)\ncbar.ax.set_yticklabels(np.around(np.exp(levs2), 2), size=10)\n\nplt.legend()\nplt.title(\"Chlorophyll Matchup to Yellowfin Tuna Track (233568)\", size=15)\nplt.show()"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#on-your-own",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#on-your-own",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "On your own!",
    "text": "On your own!\n\nExercise 1:\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the NOAA Geo-polar Blended Analysis SST, GHRSST dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html\n* This dataset is a different ERDDAP; It has a different base URL and dataset ID and variable name. * Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nExercise 2:\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/\n* This dataset will likely be on a different base URL and dataset ID and variable name. * Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nOptional\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v1_0.html"
  },
  {
    "objectID": "tutorials/matchup-polar-data-to-animal-track-locations/python/matchup-polar-data-to-animal-track-locations.html",
    "href": "tutorials/matchup-polar-data-to-animal-track-locations/python/matchup-polar-data-to-animal-track-locations.html",
    "title": "Tracking Penguin in Antarctica",
    "section": "",
    "text": "Modified October 2024"
  },
  {
    "objectID": "tutorials/matchup-polar-data-to-animal-track-locations/python/matchup-polar-data-to-animal-track-locations.html#import-the-required-python-modules",
    "href": "tutorials/matchup-polar-data-to-animal-track-locations/python/matchup-polar-data-to-animal-track-locations.html#import-the-required-python-modules",
    "title": "Tracking Penguin in Antarctica",
    "section": "Import the required Python modules",
    "text": "Import the required Python modules"
  },
  {
    "objectID": "tutorials/matchup-polar-data-to-animal-track-locations/python/matchup-polar-data-to-animal-track-locations.html#packages",
    "href": "tutorials/matchup-polar-data-to-animal-track-locations/python/matchup-polar-data-to-animal-track-locations.html#packages",
    "title": "Tracking Penguin in Antarctica",
    "section": "Packages",
    "text": "Packages\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport xarray as xr\nimport cartopy.crs as ccrs  \nimport cartopy.feature as cfeature\nimport warnings\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nwarnings.filterwarnings(\"ignore\")\n\n\nLoading the sea ice data from PolarWatch ERDDAP\n\n# Get sea ice data by sending data request using xarray to ERDDAP using its unique ID 'nsidcG02202v4shmday'\nds = xr.open_dataset(\"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday\")\n\n\n\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1GB\nDimensions:                           (time: 545, ygrid: 332, xgrid: 316)\nCoordinates:\n  * time                              (time) datetime64[ns] 4kB 1978-11-01 .....\n  * ygrid                             (ygrid) float32 1kB 4.338e+06 ... -3.93...\n  * xgrid                             (xgrid) float32 1kB -3.938e+06 ... 3.93...\nData variables:\n    cdr_seaice_conc_monthly           (time, ygrid, xgrid) float32 229MB ...\n    nsidc_bt_seaice_conc_monthly      (time, ygrid, xgrid) float32 229MB ...\n    nsidc_nt_seaice_conc_monthly      (time, ygrid, xgrid) float32 229MB ...\n    qa_of_cdr_seaice_conc_monthly     (time, ygrid, xgrid) float32 229MB ...\n    stdev_of_cdr_seaice_conc_monthly  (time, ygrid, xgrid) float32 229MB ...\nAttributes: (12/66)\n    _NCProperties:                                       version=2,netcdf=4.8...\n    acknowledgement:                                     This project was sup...\n    cdm_data_type:                                       Grid\n    cdr_variable:                                        cdr_seaice_conc_monthly\n    contributor_name:                                    Walter N. Meier, Flo...\n    contributor_role:                                    principal investigat...\n    ...                                                  ...\n    summary:                                             This data set provid...\n    time_coverage_duration:                              P1M\n    time_coverage_end:                                   2024-03-01T00:00:00Z\n    time_coverage_resolution:                            P1M\n    time_coverage_start:                                 1978-11-01T00:00:00Z\n    title:                                               Sea Ice Concentratio...xarray.DatasetDimensions:time: 545ygrid: 332xgrid: 316Coordinates: (3)time(time)datetime64[ns]1978-11-01 ... 2024-03-01_ChunkSizes :1024_CoordinateAxisType :Timeactual_range :[2.7872640e+08 1.7092512e+09]axis :Tioos_category :Timelong_name :ANSI datestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1978-11-01T00:00:00.000000000', '1978-12-01T00:00:00.000000000',\n       '1979-01-01T00:00:00.000000000', ..., '2024-01-01T00:00:00.000000000',\n       '2024-02-01T00:00:00.000000000', '2024-03-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')ygrid(ygrid)float324.338e+06 4.312e+06 ... -3.938e+06_ChunkSizes :332actual_range :[-3937500.  4337500.]axis :Yioos_category :Locationlong_name :projection_grid_y_centersstandard_name :projection_y_coordinateunits :metersvalid_range :[-3950000.  4350000.]array([ 4337500.,  4312500.,  4287500., ..., -3887500., -3912500., -3937500.],\n      dtype=float32)xgrid(xgrid)float32-3.938e+06 -3.912e+06 ... 3.938e+06_ChunkSizes :316actual_range :[-3937500.  3937500.]axis :Xioos_category :Locationlong_name :projection_grid_x_centersstandard_name :projection_x_coordinateunits :metersvalid_range :[-3950000.  3950000.]array([-3937500., -3912500., -3887500., ...,  3887500.,  3912500.,  3937500.],\n      dtype=float32)Data variables: (5)cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...ancillary_variables :stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthlycolorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole lakes coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Southern Hemisphere Sea Ice Concentrationreferences :https://nsidc.org/data/g02202/versions/4/standard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][57177040 values with dtype=float32]nsidc_bt_seaice_conc_monthly(time, ygrid, xgrid)float32...colorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole unused coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration by Bootstrap algorithm processed by NSIDCstandard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][57177040 values with dtype=float32]nsidc_nt_seaice_conc_monthly(time, ygrid, xgrid)float32...colorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole unused coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration by NASA Team algorithm processed by NSIDCstandard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][57177040 values with dtype=float32]qa_of_cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...colorBarMaximum :120.0colorBarMinimum :0.0datum :+ellps=urn:ogc:def:crs:EPSG::4326flag_masks :[  1.   2.   4.   8.  32.  64. 128.]flag_meanings :Average_concentration_exceeds_0.15 Average_concentration_exceeds_0.30 At_least_half_the_days_have_sea_ice_conc_exceeds_0.15 At_least_half_the_days_have_sea_ice_conc_exceeds_0.30 Region_masked_by_ocean_climatology At_least_one_day_during_month_has_spatial_interpolation At_least_one_day_during_month_has_temporal_interpolationioos_category :Qualitylong_name :Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration QC flagsstandard_name :sea_ice_area_fraction status_flagvalid_range :[ 1 -1][57177040 values with dtype=float32]stdev_of_cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...colorBarMaximum :5.0colorBarMinimum :0.0datum :+ellps=urn:ogc:def:crs:EPSG::4326ioos_category :Statisticslong_name :Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration Source Estimated Standard Deviationvalid_range :[0. 1.][57177040 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1978-11-01', '1978-12-01', '1979-01-01', '1979-02-01',\n               '1979-03-01', '1979-04-01', '1979-05-01', '1979-06-01',\n               '1979-07-01', '1979-08-01',\n               ...\n               '2023-06-01', '2023-07-01', '2023-08-01', '2023-09-01',\n               '2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01',\n               '2024-02-01', '2024-03-01'],\n              dtype='datetime64[ns]', name='time', length=545, freq=None))ygridPandasIndexPandasIndex(Index([ 4337500.0,  4312500.0,  4287500.0,  4262500.0,  4237500.0,  4212500.0,\n        4187500.0,  4162500.0,  4137500.0,  4112500.0,\n       ...\n       -3712500.0, -3737500.0, -3762500.0, -3787500.0, -3812500.0, -3837500.0,\n       -3862500.0, -3887500.0, -3912500.0, -3937500.0],\n      dtype='float32', name='ygrid', length=332))xgridPandasIndexPandasIndex(Index([-3937500.0, -3912500.0, -3887500.0, -3862500.0, -3837500.0, -3812500.0,\n       -3787500.0, -3762500.0, -3737500.0, -3712500.0,\n       ...\n        3712500.0,  3737500.0,  3762500.0,  3787500.0,  3812500.0,  3837500.0,\n        3862500.0,  3887500.0,  3912500.0,  3937500.0],\n      dtype='float32', name='xgrid', length=316))Attributes: (66)_NCProperties :version=2,netcdf=4.8.1,hdf5=1.10.6acknowledgement :This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.cdm_data_type :Gridcdr_variable :cdr_seaice_conc_monthlycontributor_name :Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fishercontributor_role :principal investigator, author, author, software developer, software developer, software developerConventions :CF-1.6, ACDD-1.3, COARDScreator_email :nsidc@nsidc.orgcreator_name :NSIDCcreator_type :institutioncreator_url :https://nsidc.org/date_created :2024-08-05T20:55:49ZdefaultGraphQuery :cdr_seaice_conc_monthly%5Blast%5D%5B(4337500.0):(-3937500.0)%5D%5B(-3937500.0):(3937500.0)%5D&.draw=surfacegrid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3950000.0 25000.0 0 4350000.0 0 -25000.0grid_mapping_grid_boundary_bottom_projected_y :-3950000.0grid_mapping_grid_boundary_left_projected_x :-3950000.0grid_mapping_grid_boundary_right_projected_x :3950000.0grid_mapping_grid_boundary_top_projected_y :4350000.0grid_mapping_latitude_of_projection_origin :-90.0grid_mapping_longitude_of_projection_origin :0.0grid_mapping_name :polar_stereographicgrid_mapping_parent_grid_cell_column_subset_end :316.0grid_mapping_parent_grid_cell_column_subset_start :0.0grid_mapping_parent_grid_cell_row_subset_end :332.0grid_mapping_parent_grid_cell_row_subset_start :0.0grid_mapping_proj4text :+proj=stere +lat_0=-90 +lat_ts=-70 +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_scaling_factor :1.0grid_mapping_semimajor_radius :6378273.0grid_mapping_semiminor_radius :6356889.449grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic South\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",-70],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3412\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3412grid_mapping_standard_parallel :-70.0grid_mapping_straight_vertical_longitude_from_pole :180.0grid_mapping_units :metershistory :Tue Jan  5 13:40:25 2021: ncks -x -v goddard_merged_seaice_conc_monthly ./previous_blank_ncs/S_monthly_blank.nc ./S_monthly_blank.nc\n2024-10-01T21:47:42Z (local files)\n2024-10-01T21:47:42Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.dasid :https://doi.org/10.7265/sr8p-kc62infoUrl :https://nsidc.org/data/g02202/versions/4/institution :NSIDC &gt; National Snow and Ice Data Centerkeywords :algorithm, area, bellingshausen, bootstrap, cdr_seaice_conc_monthly, center, climate, common, concentration, cryosphere, data, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Polar, Geographic Region &gt; Southern Hemisphere, goddard, gsfc, hemisphere, ice, ice distribution, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Southern Ocean, Ocean &gt; Southern Ocean &gt; Bellingshausen Sea, Ocean &gt; Southern Ocean &gt; Ross Sea, Ocean &gt; Southern Ocean &gt; Weddell Sea, oceans, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, ross, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, southern, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, tdim, team, version, weddellkeywords_vocabulary :GCMD Science Keywordslicense :No constraints on data access or usemetadata_link :https://nsidc.org/data/g02202/versions/4/naming_authority :org.doi.dxNCO :\"4.5.4\"platform :DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17processing_level :NOAA Level 3product_version :v04r00program :NOAA Climate Data Record Programproj_crs_code :EPSG:3412proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.project :NOAA/NSIDC passive microwave sea ice concentration climate data recordreferences :Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7):  15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251?2267, https://doi.org/10.1175/JCLI-D-16-0408.1sensor :SSMI/S &gt; Special Sensor Microwave Imager/Soundersoftware_version_id :git@bitbucket.org:nsidc/seaice_cdr.git@a11f275ee7ada7a9cdadada1b3d252de674d624fsource :ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240301_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240302_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240303_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240304_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240305_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240306_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240307_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240308_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240309_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240310_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240311_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240312_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240313_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240314_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240315_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240316_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240317_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240318_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240319_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240320_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240321_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240322_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240323_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240324_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240325_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240326_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240327_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240328_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240329_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240330_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240331_f17_v04r00.ncsourceUrl :(local files)spatial_resolution :25kmstandard_name_vocabulary :CF Standard Name Table v70summary :This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).time_coverage_duration :P1Mtime_coverage_end :2024-03-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :1978-11-01T00:00:00Ztitle :Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\n\n\n\n\nPlotting Sea Ice Data on a Map\n\n# Select sea ice concentration variable of first timestep\nsic = ds['cdr_seaice_conc_monthly'][0]\n\n# Based on the metadata, values above 1 represent variouag flags, therefore we will \n# remove the values greater than 1.\nsic = sic.where(sic &lt;=1, np.nan)\n\n# Set coordinate reference system (crs) based on the projection attribute from ds\npolar_crs = ccrs.SouthPolarStereo(central_longitude=0.0, true_scale_latitude=-70)\n\n# Set figure size\nplt.figure(figsize=(5,5))\n\n# Set the map projection and associated boundaries based on the metadata\nax = plt.axes(projection = polar_crs)\nax.set_extent([-3950000.0, 3950000.0, -3950000.0, 4350000.0], polar_crs)  \nax.coastlines()\nax.add_feature(cfeature.LAND)\n\n# Plot first time-step\ncs = ax.pcolormesh(ds['xgrid'], ds['ygrid'], sic,\n                   cmap=plt.cm.Blues,  transform= polar_crs) #transform default is basemap specs\nplt.colorbar(cs, ax=ax, location='right', shrink =0.8)\nax.set_title('Ice Concentration of timestep 1')\n\nText(0.5, 1.0, 'Ice Concentration of timestep 1')\n\n\n\n\n\n\n\n\n\n\n\nLoading penguin telemetry data in csv\n\n# Load penguin data into pandas data frame\npenguin = pd.read_csv('../data/copa_adpe_ncei.csv')\npenguin.head()\n\n\n\n\n\n\n\n\nBirdId\nSex\nAge\nBreed Stage\nDateGMT\nTimeGMT\nLatitude\nLongitude\nArgosQuality\n\n\n\n\n0\nADPE1\nfemale\nadult\nincubation\n28/10/1997\n7:54:00\n-62.171667\n-58.445000\n2\n\n\n1\nADPE1\nfemale\nadult\nincubation\n28/10/1997\n9:32:00\n-62.173333\n-58.463333\n2\n\n\n2\nADPE1\nfemale\nadult\nincubation\n28/10/1997\n18:15:00\n-62.158333\n-58.426667\n1\n\n\n3\nADPE1\nfemale\nadult\nincubation\n28/10/1997\n19:57:00\n-62.175000\n-58.441667\n2\n\n\n4\nADPE1\nfemale\nadult\nincubation\n28/10/1997\n21:37:00\n-62.171667\n-58.445000\n2\n\n\n\n\n\n\n\n\n\nProcessing Penguin Data\nFor this exercise, we will select ADPE24, female penguin whose track records are highest within the female group, and will follow her journey in the Arctic.\n\n# Find BirdID with the most count by sex\npenguin.groupby('Sex')['BirdId'].apply(lambda x: x.value_counts().idxmax())\n\n# Extract ADPE24 track data\nadpe24 = penguin[penguin['BirdId']=='ADPE24']\n\n# Format Date\nadpe24['DateGMT'] = pd.to_datetime(adpe24['DateGMT'], format='%d/%m/%Y')\nadpe24['Year_Month'] = adpe24['DateGMT'].dt.strftime('%Y-%m')\n\n# unique penguin dates\nadpe_dates = adpe24['Year_Month'].unique()\n\nprint(f\"Date Range: {adpe24['DateGMT'].min()}, {adpe24['DateGMT'].max()}\")\nprint(f\"Unique Month: {adpe24['Year_Month'].unique()}\")\n\nDate Range: 2003-01-16 00:00:00, 2003-03-09 00:00:00\nUnique Month: ['2003-01' '2003-02' '2003-03']\n\n\n\n\nVisualize penguin tracks on sea ice concentration map\n\nadpe_dates\n\narray(['2003-01', '2003-02', '2003-03'], dtype=object)\n\n\n\n# Subset sea ice data based on ADPE24 unique dates\nds_penguin = ds.sel(time=adpe_dates, method='nearest')\n# Process sea ice data\nsic_penguin = ds_penguin['cdr_seaice_conc_monthly']\nsic_penguin = sic_penguin.where(sic_penguin &lt;=1, np.nan)\n\n\n# Penguin Data for Each Month\nadpe24_jan = adpe24[adpe24['DateGMT'].dt.month == 1]\nadpe24_feb = adpe24[adpe24['DateGMT'].dt.month == 2]\nadpe24_mar = adpe24[adpe24['DateGMT'].dt.month == 3]\n\nadpe24_data = [adpe24_jan, adpe24_feb, adpe24_mar]\ntitles = ['January', 'February', 'March']\n\n# set mapping crs to Cartopy's South Polar Stereo graphic\ncrs_epsg = ccrs.SouthPolarStereo(central_longitude=-45)\n\n# Assuming your setup is the same\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 8), subplot_kw={'projection': crs_epsg})\n\nfor i, ax in enumerate(axes):\n    # set basemap with Cartopy PlateCarree() projection\n    ax.add_feature(cfeature.LAND)\n    ax.coastlines(resolution='50m')\n    ax.set_extent([-1500000.0, 500000.0, 2000000.0, 3500000.0], crs_epsg)\n    ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=True)\n\n    cs = ax.pcolormesh(ds_penguin['xgrid'], ds_penguin['ygrid'], sic_penguin[i],\n                       cmap=plt.cm.Blues, transform=ccrs.SouthPolarStereo(true_scale_latitude=-70, central_longitude=0))\n\n    # set the data crs\n    ax.scatter(\n        y=adpe24_data[i][\"Latitude\"],\n        x=adpe24_data[i][\"Longitude\"],\n        color=\"red\",\n        s=3,\n        alpha=1,\n        transform=ccrs.PlateCarree()\n    )\n\n    ax.set_title(titles[i])\n\n #Create a colorbar\ncbar_ax = fig.add_axes([1, 0.15, 0.02, 0.7])  # [left, bottom, width, height]  \nfig.colorbar(cs, cax=cbar_ax, orientation='vertical', label='Sea Ice Concentration')\n\nplt.tight_layout()\nplt.show()\n     \n\n\n\n\n\n\n\n\n\n\nResampling Penguin data to match satellite Date\n\n\nadpe24 = adpe24[[\"DateGMT\", \"Latitude\", \"Longitude\"]]\nadpe24['DateGMT'] = pd.to_datetime(adpe24['DateGMT'], format='%d/%m/%Y')\nadpe24_df = adpe24.resample('D', on='DateGMT').mean()\n\n\n\nTransforming CRS of the penguin locations\n\n\nlatlon_crs = ccrs.PlateCarree() # lat and lon\npolar_crs = ccrs.epsg('3412') # South pole\n\ntransformed_coords = polar_crs.transform_points(latlon_crs, adpe24_df['Longitude'].values, adpe24_df['Latitude'].values)\n\nadpe24_df['xgrid'] = transformed_coords[:, 0]\nadpe24_df['ygrid'] = transformed_coords[:, 1]\n\nadpe24_df.head()\n\n\n\n\n\n\n\n\nLatitude\nLongitude\nerddap_date\nmatched_ygrid\nmatched_xgrid\nmatched_sea_ice_concen\nxgrid\nygrid\n\n\nDateGMT\n\n\n\n\n\n\n\n\n\n\n\n\n2003-01-16\n-62.177000\n-58.452600\nNaN\nNaN\nNaN\nNaN\n-2.618256e+06\n1.607450e+06\n\n\n2003-01-17\n-62.176370\n-58.425000\nNaN\nNaN\nNaN\nNaN\n-2.617543e+06\n1.608749e+06\n\n\n2003-01-18\n-62.339500\n-57.683400\nNaN\nNaN\nNaN\nNaN\n-2.580691e+06\n1.632492e+06\n\n\n2003-01-19\n-62.547353\n-57.539765\nNaN\nNaN\nNaN\nNaN\n-2.556494e+06\n1.626173e+06\n\n\n2003-01-20\n-62.163853\n-58.457471\nNaN\nNaN\nNaN\nNaN\n-2.619678e+06\n1.608017e+06\n\n\n\n\n\n\n\n\n\nExtracting Satellite Data to match penguin track and date\n\n\n# Add new columns to the dataframe\nadpe24_df[[\"erddap_date\", \"matched_ygrid\", \"matched_xgrid\", \"matched_sea_ice_concen\"]] = np.nan\n\n# Subset the satellite data\nfor i in range(0, len(adpe24_df)):\n    # Download the satellite data\n    temp_ds = ds['cdr_seaice_conc_monthly'].sel(time='{0:%Y-%m-%d}'.format(adpe24_df.index[i]),\n                                ygrid=adpe24_df.iloc[i]['ygrid'],\n                                xgrid=adpe24_df.iloc[i]['xgrid'],\n                                method='nearest'\n                                )\n    \n    # Add to the dataframe\n    adpe24_df.loc[adpe24_df.index[i], [\"erddap_date\", \"matched_ygrid\",\n                                 \"matched_xgrid\", \"matched_sea_ice_concen\"]\n          ] = [temp_ds.time.values,\n               np.round(temp_ds.ygrid.values, 5),  # round 5 dec\n               np.round(temp_ds.xgrid.values, 5), # round 5 dec\n               np.round(temp_ds.values, 2)  # round 2 decimals\n               ]\n\n\n\nPlotting Penguin Tracks with Matched Sea Ice Concentration Data\n\nplt.figure(figsize=(14, 10))\n\n\n# set the projection\nax1 = plt.subplot(211, projection=crs_epsg)\n\n# Use the lon and lat ranges to set the extent of the map\nax1.set_extent([-90, -30, -75, -55], ccrs.PlateCarree()) # South Pole\n\n# Add grid line\ngl = ax1.gridlines(draw_labels=True, crs=ccrs.PlateCarree(), linestyle='--')\ngl.xlabels_top = False\ngl.ylabels_right = False\ngl.xformatter = LongitudeFormatter()\ngl.yformatter = LatitudeFormatter()\n\n# Add geographical features\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# build and plot coordinates onto map\nx,y = list(adpe24_df.Longitude), list(adpe24_df.Latitude)\nax1 = plt.scatter(x, y, transform=ccrs.PlateCarree(),\n                  marker='o',\n                  c=adpe24_df.matched_sea_ice_concen,\n                  cmap=plt.get_cmap('Blues'),\n                  edgecolor='Black',\n                  linewidth=0.25\n                  )\nax1=plt.plot(x[0],y[0],marker='*', label='start', color='red', transform=ccrs.PlateCarree(), markersize=10)\nax1=plt.plot(x[-1],y[-1],marker='X', label='end',color='orange', transform=ccrs.PlateCarree(), markersize=10)\n\n\n\n# control color bar values spacing\nlevs2 = np.arange(0, 1, 0.1)\n\ncbar=plt.colorbar()\ncbar.set_label(\"Sea Ice Concentration\", size=12, labelpad=20)\n\n# set the labels to be exp(levs2) so the label reflect values of chl-a, not log(chl-a)\ncbar.ax.set_yticklabels(np.round(levs2, 1), size=10)\n\nplt.legend()\nplt.title(\"Sea Ice Concen Matchup to Penguin Track\", size=15)\nplt.show()"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html",
    "href": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "",
    "text": "History | Updated March 2025"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#objective",
    "href": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#objective",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab daily chlorophyll-a data hosted on an ERDDAP server from Python, how to make temporal composites in Python and how to make some maps and time-series of chlorophyll-a"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nLocating a satellite product in ERDDAP, manually changing the constraints and copying the URL defining the data request\nDownloading the resulting netCDF file\nOpening and examining the netCDF file\nCalculate temporal composites (8Day and monthly)\nSpatially subset the dataset\nMaking basic maps and time series plots"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#datasets-used",
    "href": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#datasets-used",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Datasets used",
    "text": "Datasets used\nLong Island Sound Optimized water quailty datasets from OLCI Products developed by academic collaborators that have partnered with NOAA CoastWatch through a Sea Grant project titled “Actionable satellite water-quality data products in Long Island Sound for improved management and societal benefits”. The dataset includes daily Sentinal-3 OLCI (300 m) water quality indicators: - Chlorophyll-a (Chla “chlor_a”) - Absorption coefficient of Chromophoric Dissolved Organic Material at 300 nm (aCDOM(300) “cdom”) - Dissolved Organic Carbon (DOC “doc”) - Suspended Particulate Matter (SPM “spm”). Chlor_a, cdom and doc are based on Long Island Sound optimized algorithms. Spm retrieved using the Nechad Algorithm.\nThis dataset covers the Long Island Sound region between 40.2° N - 41.5° N and 74° W - 71.8° W\nIn this tutorial we will use the daily Chlorophyll-a dataset The data will be downloaded from the CoastWatch ERRDAP server: https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.html\nfor more information on each product refer to: - Chla: https://www.sciencedirect.com/science/article/pii/S1569843223000456 - CDOM and DOC: https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2023JG007767 - SPM: https://www.sciencedirect.com/science/article/abs/pii/S0034425709003617"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#import-python-modules",
    "href": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#import-python-modules",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Import Python modules",
    "text": "Import Python modules\n\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#download-data-from-erddap-using-python",
    "href": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#download-data-from-erddap-using-python",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "1. Download data from ERDDAP using Python",
    "text": "1. Download data from ERDDAP using Python\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure.\nFor example, the following page allows you to download daily chlorophyll-a (chlor_a) https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.html\n\n\n\nimage.png\n\n\n\nSelect the date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\nIn this specific example, the URL we generated is :\nhttps://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.nc?chlor_a%5B(2022-01-01T00:00:00Z):1:(2022-12-31T00:00:00Z)%5D%5B(41.5):1:(40.204)%5D%5B(-74.0):1:(-71.8049)%5D\n\n\nWith Python, run the following to download the data using the generated URL .\n\nurl = ''.join(['https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.nc?',\n               'chlor_a',\n               '%5B(2022-01-01T00:00:00Z):1:(2022-12-31T00:00:00Z)%5D',\n               '%5B(41.5):1:(40.204)%5D',\n               '%5B(-74.0):1:(-71.8049)%5D'\n               ])\n\nurllib.request.urlretrieve(url, \"chlor_a_2022_LIS_tutorial.nc\")\n\n('chlor_a_2022_LIS_tutorial.nc', &lt;http.client.HTTPMessage at 0x7f0c9c31b220&gt;)"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#loading-netcdf4-data-into-python",
    "href": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#loading-netcdf4-data-into-python",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "2. Loading netCDF4 data into Python",
    "text": "2. Loading netCDF4 data into Python\nNow that we’ve downloaded the data locally, we can load it into Python and extract the variables of interest.\nThe xarray package makes it very convenient to work with NetCDF files. Documentation is available here: http://xarray.pydata.org/en/stable/why-xarray.html\n\nOpen the netCDF file as an xarray dataset object and examine the data structure.\n\nds = xr.open_dataset('chlor_a_2022_LIS_tutorial.nc', decode_cf=True)\n\n\n\nExamine which coordinates and variables are included in the dataset.\n\n# List the coordinates\nprint('The coordinates variables:', list(ds.coords), '\\n')\n\n# List the data variables\nprint('The data variables:', list(ds.data_vars))\n\nThe coordinates variables: ['time', 'latitude', 'longitude'] \n\nThe data variables: ['chlor_a']\n\n\n\n\nExamine the structure of chlor_a.\n\nds.chlor_a.shape\n\n(365, 481, 814)\n\n\nThe dataset is a 3-D array with 365 time steps, each with 481 rows corresponding to latitudes and 814 columns corresponding to longitudes.\n\n\nList the dates for each time step.\nThe dataset has 365 time steps, one for each day between January 2022 and December 2022.\n\nds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 365)&gt; Size: 3kB\narray(['2022-01-01T00:00:00.000000000', '2022-01-02T00:00:00.000000000',\n       '2022-01-03T00:00:00.000000000', ..., '2022-12-29T00:00:00.000000000',\n       '2022-12-30T00:00:00.000000000', '2022-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 3kB 2022-01-01 2022-01-02 ... 2022-12-31\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [1.6409952e+09 1.6724448e+09]\n    axis:                 T\n    ioos_category:        Time\n    long_name:            Start Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00xarray.DataArray'time'time: 3652022-01-01 2022-01-02 2022-01-03 ... 2022-12-29 2022-12-30 2022-12-31array(['2022-01-01T00:00:00.000000000', '2022-01-02T00:00:00.000000000',\n       '2022-01-03T00:00:00.000000000', ..., '2022-12-29T00:00:00.000000000',\n       '2022-12-30T00:00:00.000000000', '2022-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2022-01-01 ... 2022-12-31_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-01T00:00:00.000000000', '2022-01-02T00:00:00.000000000',\n       '2022-01-03T00:00:00.000000000', ..., '2022-12-29T00:00:00.000000000',\n       '2022-12-30T00:00:00.000000000', '2022-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04',\n               '2022-01-05', '2022-01-06', '2022-01-07', '2022-01-08',\n               '2022-01-09', '2022-01-10',\n               ...\n               '2022-12-22', '2022-12-23', '2022-12-24', '2022-12-25',\n               '2022-12-26', '2022-12-27', '2022-12-28', '2022-12-29',\n               '2022-12-30', '2022-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))Attributes: (7)_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00\n\n\n\n\nResample daily data monthly.\nUse Xarray’s resample function to group the data into a monthly dataset (“MS” = Month Start). You can then apply aggregation functions like .mean(), .median(), .sum(), .cumsum(), etc., to compute statistics for each month.\n\nds_mon = ds.resample(time=\"MS\").mean()\n\n\n\nList the dates for each time step after resampling\nThe dataset now has 12 time steps, one for each month between January 2022 and December 2022.\n\nds_mon.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 12)&gt; Size: 96B\narray(['2022-01-01T00:00:00.000000000', '2022-02-01T00:00:00.000000000',\n       '2022-03-01T00:00:00.000000000', '2022-04-01T00:00:00.000000000',\n       '2022-05-01T00:00:00.000000000', '2022-06-01T00:00:00.000000000',\n       '2022-07-01T00:00:00.000000000', '2022-08-01T00:00:00.000000000',\n       '2022-09-01T00:00:00.000000000', '2022-10-01T00:00:00.000000000',\n       '2022-11-01T00:00:00.000000000', '2022-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 96B 2022-01-01 2022-02-01 ... 2022-12-01\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [1.6409952e+09 1.6724448e+09]\n    axis:                 T\n    ioos_category:        Time\n    long_name:            Start Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00xarray.DataArray'time'time: 122022-01-01 2022-02-01 2022-03-01 ... 2022-10-01 2022-11-01 2022-12-01array(['2022-01-01T00:00:00.000000000', '2022-02-01T00:00:00.000000000',\n       '2022-03-01T00:00:00.000000000', '2022-04-01T00:00:00.000000000',\n       '2022-05-01T00:00:00.000000000', '2022-06-01T00:00:00.000000000',\n       '2022-07-01T00:00:00.000000000', '2022-08-01T00:00:00.000000000',\n       '2022-09-01T00:00:00.000000000', '2022-10-01T00:00:00.000000000',\n       '2022-11-01T00:00:00.000000000', '2022-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2022-01-01 ... 2022-12-01_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-01T00:00:00.000000000', '2022-02-01T00:00:00.000000000',\n       '2022-03-01T00:00:00.000000000', '2022-04-01T00:00:00.000000000',\n       '2022-05-01T00:00:00.000000000', '2022-06-01T00:00:00.000000000',\n       '2022-07-01T00:00:00.000000000', '2022-08-01T00:00:00.000000000',\n       '2022-09-01T00:00:00.000000000', '2022-10-01T00:00:00.000000000',\n       '2022-11-01T00:00:00.000000000', '2022-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-01', '2022-02-01', '2022-03-01', '2022-04-01',\n               '2022-05-01', '2022-06-01', '2022-07-01', '2022-08-01',\n               '2022-09-01', '2022-10-01', '2022-11-01', '2022-12-01'],\n              dtype='datetime64[ns]', name='time', freq='MS'))Attributes: (7)_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00\n\n\n\n\nExamine the latitude coordinate variable\nTypically, the latitude coordinate variable will be in ascending order. However, in some datasets the order is reversed, i.e the order is descending.\nBy examining the first and last values on our latitude array (below), we can see that the values are descending.\n* In practice what this means is that when you slice (subset) using latitude later in this tutorial, you will put the largest latitude value first.\n\nprint('First latitude value', ds.latitude[0].item())\nprint('Last latitude value', ds.latitude[-1].item())\n\nFirst latitude value 41.5\nLast latitude value 40.204"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#working-with-the-data",
    "href": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#working-with-the-data",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "3. Working with the data",
    "text": "3. Working with the data\n\nCreating a Faceted Plot of Monthly Mean Chlorophyll-a for 2022\nIn this example, we plot directly from an xarray object using its built-in .plot() method. This is a quick and convenient way to create faceted maps, though it offers limited control over layout and map styling compared to using matplotlib or cartopy directly.\nThe col and col_wrap arguments define which dimension to facet over (in this case, “time”) and how many panels to display per row. The cbar_kwargs dictionary gives access to colorbar customization, such as setting the label and size.\n\nds_mon.chlor_a.plot(col=\"time\",\n                    col_wrap=4,\n                    cmap=\"turbo\",\n                    vmin=0, vmax=20,\n                    figsize=(15, 10),\n                    aspect=1.5,\n                    cbar_kwargs={\n                        'label': 'Chlorophyll-a (mg m$^{-3}$)',\n                        'shrink': 0.7,\n                        }\n                        )"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#creating-a-map-of-average-chlorophyll-a-over-the-year",
    "href": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#creating-a-map-of-average-chlorophyll-a-over-the-year",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Creating a Map of Average Chlorophyll-a Over the Year",
    "text": "Creating a Map of Average Chlorophyll-a Over the Year\n\nCompute the yearly mean for the region\nHere we use NumPy’s mean function to calculate the average chlorophyll-a across the time dimension (axis 0), resulting in a xarray dataarray of yearly mean values.\n\nds_yearly = np.mean(ds_mon.chlor_a, axis=0)\n\n\n\nPlot the map of the 2022 average SST in the region\n\nplt.pcolormesh(ds_yearly.longitude, ds_yearly.latitude, ds_yearly, cmap=\"turbo\", vmin=0, vmax=20)\nplt.colorbar()\nplt.title(\"Mean Chl-a \" \n          + ds_mon.time[0].dt.strftime('%b %Y').item() \n          + ' - '\n          + ds_mon.time[11].dt.strftime('%b %Y').item())\n\nplt.show()"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "href": "tutorials/lis-chlora-dynamics/python/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound",
    "text": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound\nSubset the data - West Long Island Ssound bewteen -73.9o to -73.1o W longitude - East Long Island Ssound bewteen -72.9o to -71.8o W longitude\nWe are going to generate a time series of mean SST within each box.\n\nda_west = ds.sel(longitude=slice(-73.9, -73.1))\nda_east = ds.sel(longitude=slice(-72.9, -71.8))\n\n\nExamine the structure of the subsetted data.\nThe subsets are 3D arrays with 365 time steps, each with 481 rows corresponding to latitudes (full LIS latitudinal extent) and 296 / 406 columns corresponding to longitudes in the West and East, respectively.\n\nprint(f\"West shape: {da_west.chlor_a.shape}\")\nprint(f\"West shape: {da_east.chlor_a.shape}\")\n\nWest shape: (365, 481, 296)\nWest shape: (365, 481, 406)\n\n\n\n\nResmaple each subset to an 8-Day means\nPlotting a daily time series can often be messy, so we compute 8-day averages to smooth the data and highlight seasonal patterns.\n\nda_west = da_west.resample(time=\"8D\").mean()\nda_east = da_east.resample(time=\"8D\").mean()\n\n\n\nCompute a time series\nNow, we will average all data within each subset across the latitude and longitude dimensions to produce a single time series.\n\nwest_TS = da_west.chlor_a.mean(dim=(\"latitude\",\"longitude\"))\neast_TS = da_east.chlor_a.mean(dim=(\"latitude\",\"longitude\"))\n\n\n\nPlot the time-series\n\nplt.figure(figsize=(8, 4))\nplt.plot(west_TS.time, west_TS, label=\"West LIS\", marker=\"o\", c=\"tab:blue\")\nplt.plot(east_TS.time, east_TS, label=\"East LIS\", marker=\"o\", c=\"tab:red\")\n\n\nplt.ylabel('Chlorophyll-a (mg m$^{-3}$)')\nplt.legend()"
  },
  {
    "objectID": "tutorials/gl-timeseries-surface-temp/python/gl-timeseries-surface-temp.html",
    "href": "tutorials/gl-timeseries-surface-temp/python/gl-timeseries-surface-temp.html",
    "title": "Great Lakes longterm water surface temperature plot",
    "section": "",
    "text": "Summary\nIn this example you will see how to extract Great Lakes average water surface temperature data from the ERDDAP server and make a plot of the longterm average water surface temperatue.\n\n\nThe example demonstrates the following techniques:\n\nLoading Great Lakes average water surface temperature data from Great Lakes ERDDAP data server.\nPloting the chart to show the highest and lowest temperature for the specific day.\nPloting the chart using the datetime class as the X axis.\nPloting the chart to show temperature in both degree C and F.\n\n\n\nDatesets used:\n\nGreat Lakes Surface Environmental Analysis (GLSEA): a lakewide average water surface temperauture product.\nWe are using the new developed: ACSPO GLSEA or GLSEA3. ACSPO means Advanced Clear-sky Processor for Oceans.\nThe data files cover from 2007 to current year.\n\n\n\nImport the required Python modules\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n#from PIL import Image\nimport math as m\nfrom datetime import datetime\nimport matplotlib.dates as mdates\n\n\n\n\n\nDefine some function that we need :\nfunction get_366_arry(): Checks to make sure the input array size is 366\n\ndef get_366_arry(t_arry):\n\n    if (t_arry.size &lt; 366):\n        t_arry = np.append(t_arry, np.NAN)\n\n    return t_arry\n\nfunction get_days_arr() takes a year (integer) and reture a list of datetime stamp.\n\ndef get_days_arr(c_yr):\n\n    d = range(1,367)  # range from 1 to 366\n\n    d_list = []\n\n    for i in d:\n\n        d_str = str(c_yr) + ' ' + str(i)\n     \n        d2 = datetime.strptime(d_str, '%Y %j')\n        d_list.append(d2)\n    \n    d_arr = np.array(d_list)\n    #print(d_arr)\n    return d_arr    \n\nfunction draw_plot() takes data array, lake, year Jilian day and years list as input to draw the plat\n\ndef draw_plot(t_all_arry, lake, c_yr, jd,  year_list):\n    \n    begin_day_str = str(c_yr) + '-01-01'  # '2021-01-01'\n    end_day_str = str(c_yr) + '-12-31'    # '2021-12-31'\n    \n    date_marker = [pd.to_datetime(date, format='%Y-%m-%d').date() for date in pd.date_range( begin_day_str, end_day_str, freq=\"ME\")]\n    print(date_marker)\n    \n    days_arr = get_days_arr(c_yr) \n    \n    fig= plt.figure(figsize=(11, 8))\n\n    ax = fig.add_subplot(111)\n\n    number_of_plots = len(year_list) + 1  \n\n    for i, yr4 in enumerate(year_list):\n        ax.plot(days_arr, t_all_arry[i], color='blue', alpha=.1)\n\n    min_v_index_tp = np.where( t_all_arry[:-1,jd] == np.amin(t_all_arry[:-1,jd]))\n    min_v_index = min_v_index_tp[0][0]\n    print(min_v_index)\n    ax.plot(days_arr, t_all_arry[min_v_index], color='green', label=str(year_list[min_v_index]) )\n\n \n    max_v_index_tp = np.where( t_all_arry[:-1,jd] == np.amax(t_all_arry[:-1,jd]))\n\n    max_v_index = max_v_index_tp[0][0]\n    \n    ax.plot(days_arr, t_all_arry[max_v_index], color='red', label=str(year_list[max_v_index]) )\n\n    ax.plot(days_arr, t_all_arry[-1], color='#eb7434', label=str(c_yr) )\n\n    nan_arr = np.empty(366)\n    nan_arr.fill(np.NAN)\n    ax.plot(days_arr, nan_arr, color='blue', alpha=.3, label='Other years' )\n\n    avg_arry = np.nanmean(t_all_arry[:-1], axis=0)\n    \n    ax.plot(days_arr, avg_arry, color='#525150',  label='Average (' + str(year_list[0]) + '-' + str(year_list[-1]) +')' )\n\n    ax.set_ybound(lower=0, upper=30)\n    ax.set_xbound(lower=0, upper=366)\n\n    ax.set_xlim(days_arr[0], days_arr[-1])\n\n    ax.set_xticks(date_marker )\n    dtFmt = mdates.DateFormatter('%b-%d') # define the formatting\n\n    ax.xaxis.set_major_formatter(dtFmt) # apply the format to the desired axis\n\n    ax.set_yticks(range(0,30,2))\n \n    ax.yaxis.set_major_formatter(plt.FuncFormatter('{:.0f}\\u00b0C'.format))  # show degree C char\n\n    ax.set_ylabel('Water Surface Temperature', weight='semibold', fontsize=12)\n    ax.set_xlabel('Months of Year',  weight='semibold', fontsize=12)\n    ax2 = ax.twinx()\n    ax2.set_yticks(range(32,86,4))\n\n    ax2.set_ylim(32, 86)\n\n    ax2.yaxis.set_major_formatter(plt.FuncFormatter('{:.0f}\\u00b0F'.format))  # show degree F char\n \n    ax.grid(True, 'major', 'y', ls='--', lw=.5, c='k', alpha=.3)\n    ax.grid(True, 'major', 'x', ls='--', lw=.5, c='k', alpha=.3)\n\n    fig.suptitle('Lake '  + lake + ' Average GLSEA Surface Water Temperature (' + str(year_list[0]) + ' - ' + str(c_yr) +')', weight='semibold', fontsize=12, ha='center')\n\n    ax.legend(title='YEARS', loc='upper left', ncol=2, fancybox=True)\n\n    plt.figtext(0.1, 0.02, 'NOAA CoastWatch Great Lakes Node', family='sans-serif', style='italic', weight='semibold', size='medium' )\n\n    plt.figtext(0.7, 0.02, datetime.now().strftime(\"%B %d, %Y %H:%M:%S\"), family='sans-serif', style='italic', weight='semibold', size='medium' )\n\n    day = datetime.strptime('{} {}'.format(jd, c_year),'%j %Y')\n    print(day.strftime('%Y %B %d'))\n\n    year_str = '(' + str(year_list[0]) + '-' + str(year_list[-1]) +')'\n\n    plt.figtext(0.20, 0.92, 'The warmest year on ' + day.strftime('%B %d') + ' for the period of record ' + year_str + ' was in ' + str(year_list[max_v_index]) + ' (shown in red)', color='black', fontsize=10 )\n\n    plt.figtext(0.20, 0.90, 'The coldest year on ' + day.strftime('%B %d') + ' for the period of record ' +  year_str + ' was in ' + str(year_list[min_v_index]) + ' (shown in green)', color='black', fontsize=10 )\n \n    plt.show()\n\n\n\nDefine current year and past years range\nGet the current year as an integer number and define a longterm time ranage. In this example, the current year is 2024 and longterm range is 2007 - 2023.\n\nc_year = int(datetime.now().strftime(\"%Y\"))\n \nprint(c_year)\n\nb_year = 2007\n\nyear_list = []\nfor i in range(b_year, c_year):\n    year_list.append(i)\n\nprint(year_list)\n\ntoday = datetime.now()\njd = (today - datetime(today.year, 1, 1)).days \n\n2024\n[2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n\n\n\n\nGet current year’s temperature data from ERDDAP\nThe dataset ID is glsea_avgtemps_3 in the ERDDAP server. The file name of the current year is glsea-temps_1024_3.dat. The file contains 9 lines header information, so we need to skip the first 9 lines when reading the data file. The data in the file are organized in 8 columns, such as Year, Julian day, Lake Superior, Lake Michigan, Lake Huron, Lake Erie, Lake Ontario, and Lake st clr. The file include the average temperature from current day back to 365 days.\neg.\nDaily Lake Average Surface Water Temperature From Great Lakes Surface Environmental Analysis maps\n\n\n\n\n\n\nSurf. Water Temp. (degrees C)\n\n\nYear Day Sup. Mich. Huron Erie Ont. St.Clr\n\n\n\n2023 127 2.24 4.64 4.14 8.87 7.02 9.59 2023 128 2.26 4.81 4.23 9.51 7.33 10.13 …… 2024 125 3.42 6.75 5.10 10.01 6.69 10.38 2024 126 3.47 6.94 5.27 9.99 6.62 10.16\nGet data from ERDDAP server:\n\nc_fn = 'https://apps.glerl.noaa.gov/erddap/files/glsea_avgtemps_3/glsea-temps_1024_3.dat'\nc_df = pd.read_csv(c_fn, skiprows=9,delimiter=r'\\s+', header=None, names=['YEAR', 'JD', 'S', 'M', 'H', 'E', 'O','St'], dtype=np.float64)\n\nprint(c_df.head())\nprint(c_df.info())\n    \nc_yr_list = c_df['YEAR']\n \nbegin_c_yr_index = list(c_yr_list).index(float(c_year))  # find the index of the current year (2024)\nprint('index of begin current year : ', begin_c_yr_index)\n\n\n     YEAR     JD     S     M     H      E     O     St\n0  2023.0  127.0  2.24  4.64  4.14   8.87  7.02   9.59\n1  2023.0  128.0  2.26  4.81  4.23   9.51  7.33  10.13\n2  2023.0  129.0  2.30  4.98  4.37   9.97  7.58  10.81\n3  2023.0  130.0  2.27  5.17  4.50  10.29  7.68  10.95\n4  2023.0  131.0  2.38  5.39  4.64  10.71  7.80  11.01\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 365 entries, 0 to 364\nData columns (total 8 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   YEAR    365 non-null    float64\n 1   JD      365 non-null    float64\n 2   S       365 non-null    float64\n 3   M       365 non-null    float64\n 4   H       365 non-null    float64\n 5   E       365 non-null    float64\n 6   O       365 non-null    float64\n 7   St      365 non-null    float64\ndtypes: float64(8)\nmemory usage: 22.9 KB\nNone\nindex of begin current year :  239\n\n\nGet a sub datafreme of Lake Michigan for current year:\n\nc_df_sub = c_df[begin_c_yr_index:]  # get a sub dataframe that only contains data for 2024\n \n\ncur_m_arry = c_df_sub['M'].values   # get a sub dataframe that only contains data for Lake Michigan\n\nfor i in range(begin_c_yr_index+1):\n    cur_m_arry = np.append(cur_m_arry, np.NAN)\n\nprint(cur_m_arry)\n\n\n[5.63 5.51 5.47 5.43 5.4  5.35 5.32 5.27 5.16 4.71 4.37 4.26 4.1  3.97\n 3.82 3.69 3.62 3.55 3.29 3.24 3.26 3.25 3.37 3.39 3.4  3.47 3.49 3.56\n 3.56 3.61 3.62 3.63 3.65 3.62 3.62 3.6  3.54 3.49 3.48 3.49 3.51 3.47\n 3.47 3.44 3.38 3.33 3.28 3.23 3.24 3.22 3.34 3.38 3.32 3.31 3.18 3.17\n 3.22 3.31 3.31 3.29 3.41 3.5  3.51 3.54 3.63 3.69 3.66 3.7  3.64 3.64\n 3.65 3.67 3.73 3.77 3.8  3.79 3.74 3.64 3.53 3.47 3.42 3.42 3.46 3.42\n 3.53 3.57 3.54 3.51 3.5  3.55 3.6  3.65 3.74 3.9  3.99 4.04 4.1  4.16\n 4.23 4.31 4.38 4.51 4.68 4.82 4.99 5.09 5.1  5.07 5.05 5.1  5.08 5.1\n 5.14 5.25 5.37 5.49 5.56 5.64 5.67 5.76 5.89 6.   6.14 6.48 6.75 6.94\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan]\n\n\n\n\nGet data from 2007 to 2023\nEach year have one data file. The file naming convention is glsea-tempsYYYY_1024_3.dat.\neg. glsea-temps2023_1024.dat.\nThe file format is samilar as the current year’s data file.\nfirst, define an array of (18,366) to hold all data\n\nm_all_arry = np.zeros( (len(year_list)+1,366), dtype=float)   \nprint(m_all_arry.shape)\n\n(18, 366)\n\n\nSecond, get the data from the 2007 to 2023 and put all the data in variable m_all_arry\n\n\nfor i, yr4 in enumerate(year_list):\n    fn = 'https://apps.glerl.noaa.gov/erddap/files/glsea_avgtemps_3/' + str(yr4) + '/glsea-temps' + str(yr4) + '_1024_3.dat'\n    #print(fn)\n    df = pd.read_csv(fn, skiprows=9,delimiter=r'\\s+', header=None, names=['YEAR', 'JD', 'S', 'M', 'H', 'E', 'O','St'], dtype=np.float64)\n\n    m_arry = df['M'].values            # get data for Lake Michigan\n\n    #print(s_arry.size)\n    print(yr4)\n    m_all_arry[i] = get_366_arry(m_arry)   \n\n#print(s_all_arry)\n\nm_all_arry[-1] = cur_m_arry   # last row is current year sst               \n \n\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n\n\nThird, call the function (defined before) to draw the plot.\n\ndraw_plot(m_all_arry, 'Michigan',  c_year, jd, year_list)\n\n[datetime.date(2024, 1, 31), datetime.date(2024, 2, 29), datetime.date(2024, 3, 31), datetime.date(2024, 4, 30), datetime.date(2024, 5, 31), datetime.date(2024, 6, 30), datetime.date(2024, 7, 31), datetime.date(2024, 8, 31), datetime.date(2024, 9, 30), datetime.date(2024, 10, 31), datetime.date(2024, 11, 30), datetime.date(2024, 12, 31)]\n7\n2024 May 05"
  },
  {
    "objectID": "tutorials/gl-ice-plot-timeseries-ice-conc/python/gl-ice-plot-timeseries-ice-conc.html",
    "href": "tutorials/gl-ice-plot-timeseries-ice-conc/python/gl-ice-plot-timeseries-ice-conc.html",
    "title": "Summary",
    "section": "",
    "text": "This example is based on the OceanWatch tutorial meterial edited with Great Lakes satellite data.In this example you will see how to extract Great Lakes ice concentration data from the ERDDAP server and make a ice concentration map, and caculate the monthly\n\nThe example demonstrates the following techniques:\n\nLoading Great Lakes ice concentration data from Great Lakes ERDDAP data server.\nCreate a map of ice concentration.\nCompute the daily mean over the selected region.\n\n\n\nDatesets used:\n\nGreat Lakes ice concentration: Great Lakes ice concentration product.\n\n\n\nImport the required Python modules\n\nimport xarray as xr\nimport pandas as pd\nimport numpy as np\nimport urllib.request\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport warnings\n#warnings.filterwarnings('ignore')\n\n\n\nDownlading data from ERDDAP server\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure. For example, the following link allows you to subset daily ice concentration data from the dataset GL_Ice_Concentration_GCS\nIn this specific example, we will get the SST data from 2023-06-01 to 2023-06-30. the URL we generated is :\nhttps://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5D\nwe extract the data in csv format due to the nc library not available.\n\nurl=\"https://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5D\"\nurllib.request.urlretrieve(url, \"w_e_ice_concentration.nc\")\n\n('w_e_ice_concentration.nc', &lt;http.client.HTTPMessage at 0x1b687bf22d0&gt;)\n\n\n\n\nImporting NetCDF4 data in Python\nNow that we’ve downloaded the data locally, we can import it and extract our variables of interest.\nThe xarray package makes it very convenient to work with NetCDF files. Documentation is available here: http://xarray.pydata.org/en/stable/why-xarray.html\n\nimport xarray as xr\nimport netCDF4 as nc\n\n\n\nOpen the file and load it as an xarray dataset:\n\nds = xr.open_dataset('w_e_ice_concentration.nc',decode_cf=False)\n#ds = xr.open_dataset('e_sst.nc')\n\n\n\nExamine the data structure:\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:            (time: 7146, latitude: 52, longitude: 79)\nCoordinates:\n  * time               (time) float64 7.89e+08 7.89e+08 ... 1.714e+09 1.715e+09\n  * latitude           (latitude) float64 41.38 41.4 41.41 ... 42.07 42.08 42.1\n  * longitude          (longitude) float64 -83.59 -83.58 -83.56 ... -82.51 -82.5\nData variables:\n    ice_concentration  (time, latitude, longitude) float32 ...\nAttributes: (12/28)\n    cdm_data_type:              Grid\n    Conventions:                CF-1.6, COARDS, ACDD-1.3\n    Easternmost_Easting:        -82.496964466524\n    GDAL:                       GDAL 3.4.3, released 2022/04/22\n    geospatial_lat_max:         42.0985561800016\n    geospatial_lat_min:         41.3837647963109\n    ...                         ...\n    standard_name_vocabulary:   CF Standard Name Table v29\n    summary:                    Ice Concentration from Great Lakes Surface En...\n    time_coverage_end:          2024-05-01T12:00:00Z\n    time_coverage_start:        1995-01-01T12:00:00Z\n    title:                      Ice Concentration from Great Lakes Surface En...\n    Westernmost_Easting:        -83.590174818051xarray.DatasetDimensions:time: 7146latitude: 52longitude: 79Coordinates: (3)time(time)float647.89e+08 7.89e+08 ... 1.715e+09_CoordinateAxisType :Timeactual_range :[7.8896160e+08 1.7145648e+09]axis :Tcalendar :Gregorianioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00units :seconds since 1970-01-01T00:00:00Zarray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])latitude(latitude)float6441.38 41.4 41.41 ... 42.08 42.1_CoordinateAxisType :Latactual_range :[41.3837648  42.09855618]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northarray([41.383765, 41.39778 , 41.411796, 41.425811, 41.439827, 41.453842,\n       41.467858, 41.481873, 41.495889, 41.509904, 41.52392 , 41.537935,\n       41.551951, 41.565967, 41.579982, 41.593998, 41.608013, 41.622029,\n       41.636044, 41.65006 , 41.664075, 41.678091, 41.692106, 41.706122,\n       41.720137, 41.734153, 41.748168, 41.762184, 41.776199, 41.790215,\n       41.80423 , 41.818246, 41.832261, 41.846277, 41.860292, 41.874308,\n       41.888323, 41.902339, 41.916354, 41.93037 , 41.944385, 41.958401,\n       41.972417, 41.986432, 42.000448, 42.014463, 42.028479, 42.042494,\n       42.05651 , 42.070525, 42.084541, 42.098556])longitude(longitude)float64-83.59 -83.58 ... -82.51 -82.5_CoordinateAxisType :Lonactual_range :[-83.59017482 -82.49696447]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastarray([-83.590175, -83.576159, -83.562144, -83.548128, -83.534113, -83.520097,\n       -83.506082, -83.492066, -83.478051, -83.464035, -83.45002 , -83.436004,\n       -83.421989, -83.407973, -83.393958, -83.379942, -83.365927, -83.351911,\n       -83.337896, -83.32388 , -83.309864, -83.295849, -83.281833, -83.267818,\n       -83.253802, -83.239787, -83.225771, -83.211756, -83.19774 , -83.183725,\n       -83.169709, -83.155694, -83.141678, -83.127663, -83.113647, -83.099632,\n       -83.085616, -83.071601, -83.057585, -83.04357 , -83.029554, -83.015539,\n       -83.001523, -82.987508, -82.973492, -82.959477, -82.945461, -82.931446,\n       -82.91743 , -82.903414, -82.889399, -82.875383, -82.861368, -82.847352,\n       -82.833337, -82.819321, -82.805306, -82.79129 , -82.777275, -82.763259,\n       -82.749244, -82.735228, -82.721213, -82.707197, -82.693182, -82.679166,\n       -82.665151, -82.651135, -82.63712 , -82.623104, -82.609089, -82.595073,\n       -82.581058, -82.567042, -82.553027, -82.539011, -82.524996, -82.51098 ,\n       -82.496964])Data variables: (1)ice_concentration(time, latitude, longitude)float32..._FillValue :-99999.0colorBarMaximum :100.0colorBarMinimum :0.0colorBarPalette :WhiteBlackgrid_mapping :crsioos_category :Ocean Colorlong_name :Ice Concentrationstandard_name :ice_concentrationunits :percent[29355768 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(Index([ 788961600.0,  789048000.0,  789134400.0,  789220800.0,  789307200.0,\n        789393600.0,  789480000.0,  789566400.0,  789652800.0,  789739200.0,\n       ...\n       1713787200.0, 1713873600.0, 1713960000.0, 1714046400.0, 1714132800.0,\n       1714219200.0, 1714305600.0, 1714392000.0, 1714478400.0, 1714564800.0],\n      dtype='float64', name='time', length=7146))latitudePandasIndexPandasIndex(Index([41.3837647963109, 41.3977803136382, 41.4117958309654, 41.4258113482927,\n         41.43982686562, 41.4538423829472, 41.4678579002745, 41.4818734176018,\n        41.495888934929, 41.5099044522563, 41.5239199695836, 41.5379354869108,\n       41.5519510042381, 41.5659665215654, 41.5799820388927, 41.5939975562199,\n       41.6080130735472, 41.6220285908745, 41.6360441082017,  41.650059625529,\n       41.6640751428563, 41.6780906601835, 41.6921061775108, 41.7061216948381,\n       41.7201372121653, 41.7341527294926, 41.7481682468199, 41.7621837641471,\n       41.7761992814744, 41.7902147988017,  41.804230316129, 41.8182458334562,\n       41.8322613507835, 41.8462768681108,  41.860292385438, 41.8743079027653,\n       41.8883234200926, 41.9023389374198, 41.9163544547471, 41.9303699720744,\n       41.9443854894016, 41.9584010067289, 41.9724165240562, 41.9864320413835,\n       42.0004475587107,  42.014463076038, 42.0284785933653, 42.0424941106925,\n       42.0565096280198, 42.0705251453471, 42.0845406626743, 42.0985561800016],\n      dtype='float64', name='latitude'))longitudePandasIndexPandasIndex(Index([ -83.590174818051, -83.5761593007237, -83.5621437833965,\n       -83.5481282660692, -83.5341127487419, -83.5200972314146,\n       -83.5060817140874, -83.4920661967601, -83.4780506794328,\n       -83.4640351621056, -83.4500196447783,  -83.436004127451,\n       -83.4219886101238, -83.4079730927965, -83.3939575754692,\n       -83.3799420581419, -83.3659265408147, -83.3519110234874,\n       -83.3378955061601, -83.3238799888329, -83.3098644715056,\n       -83.2958489541783, -83.2818334368511, -83.2678179195238,\n       -83.2538024021965, -83.2397868848693,  -83.225771367542,\n       -83.2117558502147, -83.1977403328874, -83.1837248155602,\n       -83.1697092982329, -83.1556937809057, -83.1416782635784,\n       -83.1276627462511, -83.1136472289238, -83.0996317115966,\n       -83.0856161942693,  -83.071600676942, -83.0575851596148,\n       -83.0435696422875, -83.0295541249602,  -83.015538607633,\n       -83.0015230903057, -82.9875075729784, -82.9734920556511,\n       -82.9594765383239, -82.9454610209966, -82.9314455036693,\n       -82.9174299863421, -82.9034144690148, -82.8893989516875,\n       -82.8753834343603,  -82.861367917033, -82.8473523997057,\n       -82.8333368823785, -82.8193213650512, -82.8053058477239,\n       -82.7912903303966, -82.7772748130694, -82.7632592957421,\n       -82.7492437784149, -82.7352282610876, -82.7212127437603,\n        -82.707197226433, -82.6931817091058, -82.6791661917785,\n       -82.6651506744512,  -82.651135157124, -82.6371196397967,\n       -82.6231041224694, -82.6090886051422, -82.5950730878149,\n       -82.5810575704876, -82.5670420531603, -82.5530265358331,\n       -82.5390110185058, -82.5249955011785, -82.5109799838513,\n        -82.496964466524],\n      dtype='float64', name='longitude'))Attributes: (28)cdm_data_type :GridConventions :CF-1.6, COARDS, ACDD-1.3Easternmost_Easting :-82.496964466524GDAL :GDAL 3.4.3, released 2022/04/22geospatial_lat_max :42.0985561800016geospatial_lat_min :41.3837647963109geospatial_lat_resolution :0.014015517327269056geospatial_lat_units :degrees_northgeospatial_lon_max :-82.496964466524geospatial_lon_min :-83.590174818051geospatial_lon_resolution :0.01401551732726889geospatial_lon_units :degrees_easthistory :Ice concentration from Great Lakes Surface Environmental Analysis (GLSEA) asc format to nc fromat\n2024-09-18T16:53:43Z (local files)\n2024-09-18T16:53:43Z https://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5DinfoUrl :https://coastwatch.glerl.noaa.gov/glsea/glsea.htmlinstitution :CoastWatch Great Lakes Nodekeywords :analysis, concentration, data, distribution, environmental, glsea, great, great lakes, ice, ice distribution, ice_concentration, lakes, nic, surface, timelicense :The data may be used and redistributed for free but is not intended\nfor legal use, since it may contain inaccuracies. Neither the data\nContributor, ERD, NOAA, nor the United States Government, nor any\nof their employees or contractors, makes any warranty, express or\nimplied, including warranties of merchantability and fitness for a\nparticular purpose, or assumes any legal liability for the accuracy,\ncompleteness, or usefulness, of this information.NCO :netCDF Operators version 5.0.7 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)Northernmost_Northing :42.0985561800016source :Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-presentsourceUrl :(local files)Southernmost_Northing :41.3837647963109standard_name_vocabulary :CF Standard Name Table v29summary :Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NICtime_coverage_end :2024-05-01T12:00:00Ztime_coverage_start :1995-01-01T12:00:00Ztitle :Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-presentWesternmost_Easting :-83.590174818051\n\n\n\n\nExamine which coordinates and variables are included in the dataset:\n\n ds.dims\n\nFrozen({'time': 7146, 'latitude': 52, 'longitude': 79})\n\n\n\nds.coords\n\nCoordinates:\n  * time       (time) float64 7.89e+08 7.89e+08 ... 1.714e+09 1.715e+09\n  * latitude   (latitude) float64 41.38 41.4 41.41 41.43 ... 42.07 42.08 42.1\n  * longitude  (longitude) float64 -83.59 -83.58 -83.56 ... -82.52 -82.51 -82.5\n\n\n\nds.data_vars\n\nData variables:\n    ice_concentration  (time, latitude, longitude) float32 ...\n\n\n\nds.attrs\n\n{'cdm_data_type': 'Grid',\n 'Conventions': 'CF-1.6, COARDS, ACDD-1.3',\n 'Easternmost_Easting': -82.496964466524,\n 'GDAL': 'GDAL 3.4.3, released 2022/04/22',\n 'geospatial_lat_max': 42.0985561800016,\n 'geospatial_lat_min': 41.3837647963109,\n 'geospatial_lat_resolution': 0.014015517327269056,\n 'geospatial_lat_units': 'degrees_north',\n 'geospatial_lon_max': -82.496964466524,\n 'geospatial_lon_min': -83.590174818051,\n 'geospatial_lon_resolution': 0.01401551732726889,\n 'geospatial_lon_units': 'degrees_east',\n 'history': 'Ice concentration from Great Lakes Surface Environmental Analysis (GLSEA) asc format to nc fromat\\n2024-09-18T16:53:43Z (local files)\\n2024-09-18T16:53:43Z https://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5D',\n 'infoUrl': 'https://coastwatch.glerl.noaa.gov/glsea/glsea.html',\n 'institution': 'CoastWatch Great Lakes Node',\n 'keywords': 'analysis, concentration, data, distribution, environmental, glsea, great, great lakes, ice, ice distribution, ice_concentration, lakes, nic, surface, time',\n 'license': 'The data may be used and redistributed for free but is not intended\\nfor legal use, since it may contain inaccuracies. Neither the data\\nContributor, ERD, NOAA, nor the United States Government, nor any\\nof their employees or contractors, makes any warranty, express or\\nimplied, including warranties of merchantability and fitness for a\\nparticular purpose, or assumes any legal liability for the accuracy,\\ncompleteness, or usefulness, of this information.',\n 'NCO': 'netCDF Operators version 5.0.7 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)',\n 'Northernmost_Northing': 42.0985561800016,\n 'source': 'Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-present',\n 'sourceUrl': '(local files)',\n 'Southernmost_Northing': 41.3837647963109,\n 'standard_name_vocabulary': 'CF Standard Name Table v29',\n 'summary': 'Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC',\n 'time_coverage_end': '2024-05-01T12:00:00Z',\n 'time_coverage_start': '1995-01-01T12:00:00Z',\n 'title': 'Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-present',\n 'Westernmost_Easting': -83.590174818051}\n\n\n\n\nExamine the structure of ice concentration:\n\nds.ice_concentration.shape\n\n(7146, 52, 79)\n\n\nOur dataset is a 3-D array with 52 rows corresponding to latitudes and 79 columns corresponding to longitudes, for each of the 7146 time steps. #### Get the dates for each time step:\n\nds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 7146)&gt;\narray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])\nCoordinates:\n  * time     (time) float64 7.89e+08 7.89e+08 7.891e+08 ... 1.714e+09 1.715e+09\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [7.8896160e+08 1.7145648e+09]\n    axis:                 T\n    calendar:             Gregorian\n    ioos_category:        Time\n    long_name:            Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00\n    units:                seconds since 1970-01-01T00:00:00Zxarray.DataArray'time'time: 71467.89e+08 7.89e+08 7.891e+08 ... 1.714e+09 1.714e+09 1.715e+09array([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])Coordinates: (1)time(time)float647.89e+08 7.89e+08 ... 1.715e+09_CoordinateAxisType :Timeactual_range :[7.8896160e+08 1.7145648e+09]axis :Tcalendar :Gregorianioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00units :seconds since 1970-01-01T00:00:00Zarray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])Indexes: (1)timePandasIndexPandasIndex(Index([ 788961600.0,  789048000.0,  789134400.0,  789220800.0,  789307200.0,\n        789393600.0,  789480000.0,  789566400.0,  789652800.0,  789739200.0,\n       ...\n       1713787200.0, 1713873600.0, 1713960000.0, 1714046400.0, 1714132800.0,\n       1714219200.0, 1714305600.0, 1714392000.0, 1714478400.0, 1714564800.0],\n      dtype='float64', name='time', length=7146))Attributes: (9)_CoordinateAxisType :Timeactual_range :[7.8896160e+08 1.7145648e+09]axis :Tcalendar :Gregorianioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00units :seconds since 1970-01-01T00:00:00Z\n\n\n\nds.time.attrs\n\n{'_CoordinateAxisType': 'Time',\n 'actual_range': array([7.8896160e+08, 1.7145648e+09]),\n 'axis': 'T',\n 'calendar': 'Gregorian',\n 'ioos_category': 'Time',\n 'long_name': 'Time',\n 'standard_name': 'time',\n 'time_origin': '01-JAN-1970 00:00:00',\n 'units': 'seconds since 1970-01-01T00:00:00Z'}\n\n\n\nprint(ds.time)\n\n&lt;xarray.DataArray 'time' (time: 7146)&gt;\narray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])\nCoordinates:\n  * time     (time) float64 7.89e+08 7.89e+08 7.891e+08 ... 1.714e+09 1.715e+09\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [7.8896160e+08 1.7145648e+09]\n    axis:                 T\n    calendar:             Gregorian\n    ioos_category:        Time\n    long_name:            Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00\n    units:                seconds since 1970-01-01T00:00:00Z\n\n\n\n\nThe time units is seconds, we need to convert the seconds to dates.\n\ndates=nc.num2date(ds.time,ds.time.units,only_use_cftime_datetimes=False, \n                        only_use_python_datetimes=True )\ndates\n\narray([real_datetime(1995, 1, 1, 12, 0), real_datetime(1995, 1, 2, 12, 0),\n       real_datetime(1995, 1, 3, 12, 0), ...,\n       real_datetime(2024, 4, 29, 12, 0),\n       real_datetime(2024, 4, 30, 12, 0),\n       real_datetime(2024, 5, 1, 12, 0)], dtype=object)\n\n\n\n\nFind the index of dates for 2019-03-01\n\nfor i, date in enumerate(dates):\n    if date.strftime(\"%Y-%m-%d\") == \"2019-03-01\":\n        print(i, date)\n\n5872 2019-03-01 12:00:00\n\n\n5872 is the index on the array dates for 2019-03-01.\n\n\nCreate a map of ice concentration for March 1, 2019 (our 5872th time step).\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n#np.warnings.filterwarnings('ignore')\n\n#### Examine the values of ice concentration:\n\nprint(ds.ice_concentration.values)\nprint(ds.ice_concentration.shape)\n\n[[[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n ...\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]]\n(7146, 52, 79)\n\n\n\nds.ice_concentration.attrs\n\n{'_FillValue': -99999.0,\n 'colorBarMaximum': 100.0,\n 'colorBarMinimum': 0.0,\n 'colorBarPalette': 'WhiteBlack',\n 'grid_mapping': 'crs',\n 'ioos_category': 'Ocean Color',\n 'long_name': 'Ice Concentration',\n 'standard_name': 'ice_concentration',\n 'units': 'percent'}\n\n\n\nds.ice_concentration.attrs['_FillValue']\n\n-99999.0\n\n\n\n\nMake a new ice concentration DataArray and replace _fillValue with NaN\n\nnan_ice_concentration = ds.ice_concentration.where(ds.ice_concentration.values != ds.ice_concentration.attrs['_FillValue'])\n\nprint(nan_ice_concentration)\n\n&lt;xarray.DataArray 'ice_concentration' (time: 7146, latitude: 52, longitude: 79)&gt;\narray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n...\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)\nCoordinates:\n  * time       (time) float64 7.89e+08 7.89e+08 ... 1.714e+09 1.715e+09\n  * latitude   (latitude) float64 41.38 41.4 41.41 41.43 ... 42.07 42.08 42.1\n  * longitude  (longitude) float64 -83.59 -83.58 -83.56 ... -82.52 -82.51 -82.5\nAttributes:\n    _FillValue:       -99999.0\n    colorBarMaximum:  100.0\n    colorBarMinimum:  0.0\n    colorBarPalette:  WhiteBlack\n    grid_mapping:     crs\n    ioos_category:    Ocean Color\n    long_name:        Ice Concentration\n    standard_name:    ice_concentration\n    units:            percent\n\n\n\n\nSet some color breaks\n\n# find min value in man_sst\nnp.nanmin(nan_ice_concentration)\n\n0.0\n\n\n\nnp.nanmax(nan_ice_concentration)\n\n99.99847\n\n\n\nlevs = np.arange(0, 101, 10)\nlen(levs)\n\n11\n\n\n\n\nDefine a color palette\n\n# init a color list\njet=[\"blue\", \"#007FFF\", \"cyan\",\"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"]\n\n\n\nSet color scale using the jet palette\n\ncm = LinearSegmentedColormap.from_list('my_jet', jet, N=len(levs))\n\n\n\nplot the ice_concentration map\n\nplt.subplots(figsize=(10, 5))\n\n#plot 5872th ice concentration image: nan_ice_concentration[5872 ,:,:]\nplt.contourf(nan_ice_concentration.longitude, nan_ice_concentration.latitude, nan_ice_concentration[5872,:,:], levs,cmap=cm)\n\n#plot the color scale\nplt.colorbar()\n\n#example of how to add points to the map\n#plt.scatter(np.linspace(-82,-80.5,num=4),np.repeat(42,4),c='black')\n\n#example of how to add a contour line\n#step = np.arange(9,26, 1)\n\n#plt.contour(ds.longitude, ds.latitude, ds.sst[0,:,:],levels=step,linewidths=1)\n\n#plot title\nplt.title(\"West Lake Erie Ice Concentration - \" + dates[5872].strftime('%b %d, %Y'))\nplt.show()\n\n\n\n\n\n\n\n\n\n\nLet’s compute the daily mean over the west Lake Erie region:\n\nres=np.nanmean(nan_ice_concentration,axis=(1,2))\nres\n\narray([0., 0., 0., ..., 0., 0., 0.], dtype=float32)\n\n\n\n\nLet’s plot the time-series (from 2019-03-01 to 2019-03-31):\n\nfor i, date in enumerate(dates):\n    if date.strftime(\"%Y-%m-%d\") == \"2019-03-01\":\n        print(i, date)\n    \n    if date.strftime(\"%Y-%m-%d\") == \"2019-03-31\":\n        print(i, date)\n\n5872 2019-03-01 12:00:00\n5902 2019-03-31 12:00:00\n\n\n\nprint(res.shape)\n\n(7146,)\n\n\n\nplt.figure(figsize=(8,4))\n\nplt.scatter(dates[5872:5902+1],res[5872:5902+1])\n\n#degree_sign = u\"\\N{DEGREE SIGN}\"\nplt.ylabel('Ice Concentration (%)')\n\nplt.xlim(dates[5872], dates[5902+1])\n\nplt.xticks(dates[5872:5902+1],rotation=70, fontsize=10 )\nplt.show()\n\n\n\n\n\n\n\n\n\n!jupyter nbconvert --to html GL_python_tutorial4.ipynb\n\n[NbConvertApp] Converting notebook GL_python_tutorial4.ipynb to html\n[NbConvertApp] Writing 313369 bytes to GL_python_tutorial4.html"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html",
    "title": "Extract data within a boundary",
    "section": "",
    "text": "History | Updated Sep 2023"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#background",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#background",
    "title": "Extract data within a boundary",
    "section": "Background",
    "text": "Background\nOne use for satellite observations is to supplement in situ sampling of geographical locations where the timespan or frequency measurements, or spatial dimensions or remoteness of the locations, make physical sampling impossible or impractical. One drawback is that satellite data are often rectangular, whereas geographical locations can have irregular boundaries. Examples of locations with boundaries include Marine Protected Areas or marine physical, biological, and ecological divisions like the Longhurst Marine Provinces."
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#objectives",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#objectives",
    "title": "Extract data within a boundary",
    "section": "Objectives",
    "text": "Objectives\nIn this tutorial we will learn how to download a timeseries of SST satellite data from an ERDDAP server, and then mask the data to retain only the data within an irregular geographical boundary (polygon). We will then plot a yearly seasonal cycle from within the boundary."
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Extract data within a boundary",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data from an ERDDAP data server\nVisualizing data on a map\nMasking satellite data using a shape file"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#datasets-used",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#datasets-used",
    "title": "Extract data within a boundary",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Geo-polar Blended Analysis Sea-Surface Temperature, Global, Monthly, 5km, 2019-Present\nThe NOAA geo-polar blended SST is a high resolution satellite-based sea surface temperature (SST) product that combines SST data from US, Japanese and European geostationary infrared imagers, and low-earth orbiting infrared (U.S. and European) SST data, into a single product. We will use the monthly composite. https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly\nLonghurst Marine Provinces\nThe dataset represents the division of the world oceans into provinces as defined by Longhurst (1995; 1998; 2006). This division has been based on the prevailing role of physical forcing as a regulator of phytoplankton distribution. The Longhurst Marine Provinces dataset is available online (https://www.marineregions.org/downloads.php) and within the shapes folder associated with this repository. For this tutorial we will use the Gulf Stream province (ProvCode: GFST)\n\n\n\n../images/longhurst.png"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#import-packages",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#import-packages",
    "title": "Extract data within a boundary",
    "section": "Import packages",
    "text": "Import packages\nNote: Make sure you have at least version 0.10.0 of regionmask * To install with conda use “conda install -c conda-forge regionmask=0.10.0 cartopy”\n\nimport matplotlib.pyplot as plt\nimport xarray as xr\nimport geopandas\nimport regionmask\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport warnings\nimport os\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#load-the-longhurst-provinces-shape-files-into-a-geopandas-dataframe",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#load-the-longhurst-provinces-shape-files-into-a-geopandas-dataframe",
    "title": "Extract data within a boundary",
    "section": "Load the Longhurst Provinces shape files into a geopandas dataframe",
    "text": "Load the Longhurst Provinces shape files into a geopandas dataframe\n\n#shape_path = '../resources/longhurst_v4_2010/Longhurst_world_v4_2010.shp'\nshape_path = os.path.join('..',\n                          'resources',\n                          'longhurst_v4_2010',\n                          'Longhurst_world_v4_2010.shp'\n                          )\nshapefiles = geopandas.read_file(shape_path)\nshapefiles.head(8)\n\n\n\n\n\n\n\n\nProvCode\nProvDescr\ngeometry\n\n\n\n\n0\nBPLR\nPolar - Boreal Polar Province (POLR)\nMULTIPOLYGON (((-161.18426 63.50000, -161.5000...\n\n\n1\nARCT\nPolar - Atlantic Arctic Province\nMULTIPOLYGON (((-21.51305 64.64409, -21.55945 ...\n\n\n2\nSARC\nPolar - Atlantic Subarctic Province\nMULTIPOLYGON (((11.26472 63.96082, 11.09548 63...\n\n\n3\nNADR\nWesterlies - N. Atlantic Drift Province (WWDR)\nPOLYGON ((-11.50000 57.50000, -11.50000 56.500...\n\n\n4\nGFST\nWesterlies - Gulf Stream Province\nPOLYGON ((-43.50000 43.50000, -43.50000 42.500...\n\n\n5\nNASW\nWesterlies - N. Atlantic Subtropical Gyral Pro...\nPOLYGON ((-39.50000 25.50000, -40.50000 25.500...\n\n\n6\nNATR\nTrades - N. Atlantic Tropical Gyral Province (...\nMULTIPOLYGON (((-72.34673 18.53597, -72.36877 ...\n\n\n7\nWTRA\nTrades - Western Tropical Atlantic Province\nPOLYGON ((-19.50000 -6.50000, -20.50000 -6.500..."
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#isolate-the-gulf-stream-province",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#isolate-the-gulf-stream-province",
    "title": "Extract data within a boundary",
    "section": "Isolate the Gulf Stream Province",
    "text": "Isolate the Gulf Stream Province\nThe Gulf Stream Province can be isolated using its ProvCode (GFST)\n\nProvCode = \"GFST\"\n\n# Locate the row with the ProvCode code\ngulf_stream = shapefiles.loc[shapefiles[\"ProvCode\"] == ProvCode]\ngulf_stream\n\n\n\n\n\n\n\n\nProvCode\nProvDescr\ngeometry\n\n\n\n\n4\nGFST\nWesterlies - Gulf Stream Province\nPOLYGON ((-43.50000 43.50000, -43.50000 42.500..."
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#find-the-coordinates-of-the-bounding-box",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#find-the-coordinates-of-the-bounding-box",
    "title": "Extract data within a boundary",
    "section": "Find the coordinates of the bounding box",
    "text": "Find the coordinates of the bounding box\n\nThe bounding box is the smallest rectangle that will completely enclose the province.\nWe will use the bounding box coordinates to subset the satellite data\n\n\ngs_bnds = gulf_stream.bounds\ngs_bnds\n\n\n\n\n\n\n\n\nminx\nminy\nmaxx\nmaxy\n\n\n\n\n4\n-73.5\n33.5\n-43.5\n43.5"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#open-the-satellite-dataset-into-a-xarray-dataset-object",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#open-the-satellite-dataset-into-a-xarray-dataset-object",
    "title": "Extract data within a boundary",
    "section": "Open the satellite dataset into a xarray dataset object",
    "text": "Open the satellite dataset into a xarray dataset object\n\nerddap_url = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                       'erddap',\n                       'griddap',\n                       'NOAA_DHW_monthly'\n                       ])\n\nds = xr.open_dataset(erddap_url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                          (time: 464, latitude: 3600, longitude: 7200)\nCoordinates:\n  * time                             (time) datetime64[ns] 1985-01-16 ... 202...\n  * latitude                         (latitude) float32 89.97 89.93 ... -89.97\n  * longitude                        (longitude) float32 -180.0 -179.9 ... 180.0\nData variables:\n    sea_surface_temperature          (time, latitude, longitude) float32 ...\n    mask                             (time, latitude, longitude) float32 ...\n    sea_surface_temperature_anomaly  (time, latitude, longitude) float32 ...\nAttributes: (12/66)\n    _NCProperties:                    version=2,netcdf=4.8.1,hdf5=1.12.2\n    acknowledgement:                  NOAA Coral Reef Watch program\n    cdm_data_type:                    Grid\n    comment:                          This is a product of NOAA Coral Reef Wa...\n    contributor_name:                 NOAA Coral Reef Watch program\n    contributor_role:                 Collecting source data and deriving pro...\n    ...                               ...\n    time_coverage_duration:           P1M\n    time_coverage_end:                2023-08-16T00:00:00Z\n    time_coverage_resolution:         P1M\n    time_coverage_start:              1985-01-16T00:00:00Z\n    title:                            SST and SST Anomaly, NOAA Global Coral ...\n    Westernmost_Easting:              -179.975xarray.DatasetDimensions:time: 464latitude: 3600longitude: 7200Coordinates: (3)time(time)datetime64[ns]1985-01-16 ... 2023-08-16_CoordinateAxisType :Timeactual_range :[4.746816e+08 1.692144e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1985-01-16T00:00:00.000000000', '1985-02-16T00:00:00.000000000',\n       '1985-03-16T00:00:00.000000000', ..., '2023-06-16T00:00:00.000000000',\n       '2023-07-16T00:00:00.000000000', '2023-08-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3289.97 89.93 89.88 ... -89.92 -89.97_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([ 89.975   ,  89.92501 ,  89.87501 , ..., -89.875   , -89.924995,\n       -89.975   ], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-179.975  , -179.925  , -179.875  , ...,  179.875  ,  179.92499,\n        179.975  ], dtype=float32)Data variables: (3)sea_surface_temperature(time, latitude, longitude)float32...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[12026880000 values with dtype=float32]mask(time, latitude, longitude)float32...colorBarMaximum :5.0colorBarMinimum :0.0comment :A 2D array, in the same size as the data array in the X and Y directions, the classifies land, ice pixels, and water (data) pixelscoverage_content_type :thematicClassificationflag_meanings :valid-water land missing iceflag_values :[0 1 2 4]ioos_category :Qualitylong_name :Pixel characteristics flag arrayunits :pixel_classification[12026880000 values with dtype=float32]sea_surface_temperature_anomaly(time, latitude, longitude)float32...colorBarMaximum :3.0colorBarMinimum :-3.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :sea surface temperature anomalystandard_name :surface_temperature_anomalyunits :degree_Cvalid_max :15.0valid_min :-15.0[12026880000 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1985-01-16 00:00:00', '1985-02-16 00:00:00',\n               '1985-03-16 00:00:00', '1985-04-16 00:00:00',\n               '1985-05-15 23:00:00', '1985-06-15 23:00:00',\n               '1985-07-15 23:00:00', '1985-08-15 23:00:00',\n               '1985-09-15 23:00:00', '1985-10-15 23:00:00',\n               ...\n               '2022-11-16 00:00:00', '2022-12-16 00:00:00',\n               '2023-01-16 00:00:00', '2023-02-16 00:00:00',\n               '2023-03-16 00:00:00', '2023-04-16 00:00:00',\n               '2023-05-16 00:00:00', '2023-06-16 00:00:00',\n               '2023-07-16 00:00:00', '2023-08-16 00:00:00'],\n              dtype='datetime64[ns]', name='time', length=464, freq=None))latitudePandasIndexPandasIndex(Index([  89.9749984741211,  89.92501068115234,  89.87500762939453,\n        89.82500457763672,   89.7750015258789,   89.7249984741211,\n        89.67501068115234,  89.62500762939453,  89.57500457763672,\n         89.5250015258789,\n       ...\n        -89.5250015258789, -89.57499694824219,            -89.625,\n       -89.67499542236328,  -89.7249984741211,  -89.7750015258789,\n       -89.82499694824219,            -89.875, -89.92499542236328,\n        -89.9749984741211],\n      dtype='float32', name='latitude', length=3600))longitudePandasIndexPandasIndex(Index([-179.97500610351562,  -179.9250030517578,            -179.875,\n       -179.82501220703125, -179.77500915527344, -179.72500610351562,\n        -179.6750030517578,            -179.625, -179.57501220703125,\n       -179.52500915527344,\n       ...\n        179.52499389648438,  179.57501220703125,             179.625,\n        179.67498779296875,  179.72500610351562,  179.77499389648438,\n        179.82501220703125,             179.875,  179.92498779296875,\n        179.97500610351562],\n      dtype='float32', name='longitude', length=7200))Attributes: (66)_NCProperties :version=2,netcdf=4.8.1,hdf5=1.12.2acknowledgement :NOAA Coral Reef Watch programcdm_data_type :Gridcomment :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite Version 3.1, derived from CoralTemp v1.0.contributor_name :NOAA Coral Reef Watch programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archive.Conventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch programcreator_name :NOAA Coral Reef Watch programcreator_type :groupcreator_url :https://coralreefwatch.noaa.govdate_created :2018-03-01T12:00:00Zdate_issued :2019-01-19T20:32:23Zdate_metadata_modified :2018-09-01T12:00:00Zdate_modified :2018-03-01T12:00:00ZEasternmost_Easting :179.975geospatial_bounds :POLYGON((-90.0 180.0, 90.0 180.0, 90.0 -180.0, -90.0 -180.0, -90.0 180.0))geospatial_bounds_crs :EPSG:4326geospatial_lat_max :89.975geospatial_lat_min :-89.975geospatial_lat_units :degrees_northgeospatial_lon_max :179.975geospatial_lon_min :-179.975geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:32663grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Tue Jul 27 10:37:54 2021: ncrename -d lon,longitude -d lat,latitude -v lon,longitude -v lat,latitude -v sea surface temperature anomaly,sea_surface_temperature_anomaly /cwdata/coralreef/work/temp.nc\nMonthly data files for mean sea surface temperature (SST) and sea surface temperature anomaly (SST anomaly) were downloaded from ftp.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1/nc/v1.0/monthly. Monthly files were created that contain both SST and SST anomaly data, and a mask of earth surface classifications.\n2023-09-06T18:39:14Z (local files)\n2023-09-06T18:39:14Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.dasid :Satellite_Global_5km_CoralTemp_SST_SSTA_Monthly_Mean_CompositeinfoUrl :https://coralreefwatch.noaa.gov/product/5km/index.phpinstitution :NOAA/NESDIS/STAR Coral Reef Watch programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, anomaly, array, characteristics, coral, crw, data, earth, Earth Science &gt; Land Surface &gt; Land Temperature &gt; Land Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature Anomaly, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, flag, global, information, infrared, land, latitude, longitude, mask, mean, month, monthly, national, nesdis, noaa, ocean, oceans, pixel, program, quality, reef, satellite, science, sea, sea_surface_temperature, sea_surface_temperature_anomaly, seawater, service, spectral, spectral/engineering, sst, star, surface, surface_temperature_anomaly, temperature, thermal, time, v.3.1, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of the Coral Reef Watch website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/product/5km/index.phpnaming_authority :gov.noaa.coralreefwatchNCO :\"4.6.3\"Northernmost_Northing :89.975platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :Derived from L4 satellite sea surface temperature analysisproduct_version :3.1program :NOAA Coral Reef Watch programproject :NOAA Coral Reef Watch programpublisher_email :erd.data at noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch programpublisher_name :NOAA NMFS SWFSC ERD, CoastWatch West Coast Nodepublisher_type :institutionpublisher_url :https://coralreefwatch.noaa.gov, https://coastwatch.pfeg.noaa.gov/references :https://coralreefwatch.noaa.gov/product/5km/index.php and https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :Coral Reef Watch CoralTemp v1.0sourceUrl :(local files)Southernmost_Northing :-89.975spatial_resolution :0.05 degreestandard_name_vocabulary :CF Standard Name Table v27summary :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite, derived from CoralTemp v1.0.time_coverage_duration :P1Mtime_coverage_end :2023-08-16T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :1985-01-16T00:00:00Ztitle :SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring, 5km, V.3.1, Monthly, 1985-PresentWesternmost_Easting :-179.975"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#subset-the-satellite-data",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#subset-the-satellite-data",
    "title": "Extract data within a boundary",
    "section": "Subset the satellite data",
    "text": "Subset the satellite data\n\nUse the bounding box coordinates for the latitude and longitude slices\nSelect the entire year of 2020\n\n\n# This dataset has latitude in descending order. \n# Therefore use maxy first and miny last to slice latitude\nds_subset = ds['sea_surface_temperature'].sel(time=slice(\"2020-01-16\", \"2020-12-16\"),\n                                              latitude=slice(gs_bnds.maxy.item(), \n                                                             gs_bnds.miny.item()),\n                                              longitude=slice(gs_bnds.minx.item(), \n                                                              gs_bnds.maxx.item())\n                                            )\nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'sea_surface_temperature' (time: 12, latitude: 200,\n                                             longitude: 600)&gt;\n[1440000 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 2020-01-16 2020-02-16 ... 2020-12-16\n  * latitude   (latitude) float32 43.47 43.43 43.38 43.33 ... 33.62 33.58 33.53\n  * longitude  (longitude) float32 -73.47 -73.42 -73.38 ... -43.62 -43.57 -43.53\nAttributes:\n    colorBarMaximum:        32.0\n    colorBarMinimum:        0.0\n    coverage_content_type:  physicalMeasurement\n    ioos_category:          Temperature\n    long_name:              analysed sea surface temperature\n    standard_name:          sea_surface_temperature\n    units:                  degree_C\n    valid_max:              50.0\n    valid_min:              -2.0xarray.DataArray'sea_surface_temperature'time: 12latitude: 200longitude: 600...[1440000 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]2020-01-16 ... 2020-12-16_CoordinateAxisType :Timeactual_range :[4.746816e+08 1.692144e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2020-01-16T00:00:00.000000000', '2020-02-16T00:00:00.000000000',\n       '2020-03-15T23:00:00.000000000', '2020-04-15T23:00:00.000000000',\n       '2020-05-15T23:00:00.000000000', '2020-06-15T23:00:00.000000000',\n       '2020-07-15T23:00:00.000000000', '2020-08-15T23:00:00.000000000',\n       '2020-09-15T23:00:00.000000000', '2020-10-15T23:00:00.000000000',\n       '2020-11-16T00:00:00.000000000', '2020-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3243.47 43.43 43.38 ... 33.58 33.53_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([43.475   , 43.42501 , 43.375008, 43.325005, 43.275   , 43.225   ,\n       43.17501 , 43.125008, 43.075005, 43.025   , 42.975   , 42.92501 ,\n       42.875008, 42.825005, 42.775   , 42.725   , 42.67501 , 42.625008,\n       42.575005, 42.525   , 42.475   , 42.42501 , 42.375008, 42.325005,\n       42.275   , 42.225   , 42.17501 , 42.125008, 42.075005, 42.025   ,\n       41.975   , 41.92501 , 41.875008, 41.825005, 41.775   , 41.725   ,\n       41.67501 , 41.625008, 41.575005, 41.525   , 41.475   , 41.42501 ,\n       41.375008, 41.325005, 41.275   , 41.225   , 41.17501 , 41.125008,\n       41.075005, 41.025   , 40.975   , 40.92501 , 40.875008, 40.825005,\n       40.775   , 40.725   , 40.67501 , 40.625008, 40.575005, 40.525   ,\n       40.475   , 40.42501 , 40.375008, 40.325005, 40.275   , 40.225   ,\n       40.17501 , 40.125008, 40.075005, 40.025   , 39.975   , 39.92501 ,\n       39.875008, 39.825005, 39.775   , 39.725   , 39.67501 , 39.625008,\n       39.575005, 39.525   , 39.475   , 39.42501 , 39.375008, 39.325005,\n       39.275   , 39.225   , 39.17501 , 39.125008, 39.075005, 39.025   ,\n       38.975   , 38.92501 , 38.875008, 38.825005, 38.775   , 38.725   ,\n       38.67501 , 38.625008, 38.575005, 38.525   , 38.475   , 38.42501 ,\n       38.375008, 38.325005, 38.275   , 38.225   , 38.17501 , 38.125008,\n       38.075005, 38.025   , 37.975006, 37.925003, 37.875   , 37.825005,\n       37.775   , 37.725006, 37.675003, 37.625   , 37.575005, 37.525   ,\n       37.475006, 37.425003, 37.375   , 37.325005, 37.275   , 37.225006,\n       37.175003, 37.125   , 37.075005, 37.025   , 36.975006, 36.925003,\n       36.875   , 36.825005, 36.775   , 36.725006, 36.675003, 36.625   ,\n       36.575005, 36.525   , 36.475006, 36.425003, 36.375   , 36.325005,\n       36.275   , 36.225006, 36.175003, 36.125   , 36.075005, 36.025   ,\n       35.975006, 35.925003, 35.875   , 35.825005, 35.775   , 35.725006,\n       35.675003, 35.625   , 35.575005, 35.525   , 35.475006, 35.425003,\n       35.375   , 35.325005, 35.275   , 35.225006, 35.175003, 35.125   ,\n       35.075005, 35.025   , 34.975006, 34.925003, 34.875   , 34.825005,\n       34.775   , 34.725006, 34.675003, 34.625   , 34.575005, 34.525   ,\n       34.475006, 34.425003, 34.375   , 34.325005, 34.275   , 34.225006,\n       34.175003, 34.125   , 34.075005, 34.025   , 33.975006, 33.925003,\n       33.875   , 33.825005, 33.775   , 33.725006, 33.675003, 33.625   ,\n       33.575005, 33.525   ], dtype=float32)longitude(longitude)float32-73.47 -73.42 ... -43.57 -43.53_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-73.475   , -73.424995, -73.375   , ..., -43.624992, -43.57499 ,\n       -43.525   ], dtype=float32)Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2020-01-16 00:00:00', '2020-02-16 00:00:00',\n               '2020-03-15 23:00:00', '2020-04-15 23:00:00',\n               '2020-05-15 23:00:00', '2020-06-15 23:00:00',\n               '2020-07-15 23:00:00', '2020-08-15 23:00:00',\n               '2020-09-15 23:00:00', '2020-10-15 23:00:00',\n               '2020-11-16 00:00:00', '2020-12-16 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))latitudePandasIndexPandasIndex(Index([43.474998474121094, 43.425010681152344,  43.37500762939453,\n        43.32500457763672, 43.275001525878906, 43.224998474121094,\n       43.175010681152344,  43.12500762939453,  43.07500457763672,\n       43.025001525878906,\n       ...\n       33.975006103515625,  33.92500305175781,             33.875,\n        33.82500457763672, 33.775001525878906, 33.725006103515625,\n        33.67500305175781,             33.625,  33.57500457763672,\n       33.525001525878906],\n      dtype='float32', name='latitude', length=200))longitudePandasIndexPandasIndex(Index([  -73.4749984741211,  -73.42499542236328,             -73.375,\n        -73.32499694824219,  -73.27499389648438,   -73.2249984741211,\n        -73.17499542236328,             -73.125,  -73.07499694824219,\n        -73.02499389648438,\n       ...\n       -43.974998474121094,  -43.92499542236328,  -43.87499237060547,\n       -43.824989318847656, -43.775001525878906, -43.724998474121094,\n        -43.67499542236328,  -43.62499237060547, -43.574989318847656,\n       -43.525001525878906],\n      dtype='float32', name='longitude', length=600))Attributes: (9)colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#visualize-the-unmasked-data-on-a-map",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#visualize-the-unmasked-data-on-a-map",
    "title": "Extract data within a boundary",
    "section": "Visualize the unmasked data on a map",
    "text": "Visualize the unmasked data on a map\nThe map shows the full extent of the bounding box\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([260, 350, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nds_subset[0].plot.pcolormesh(ax=ax1, transform=ccrs.PlateCarree(), cmap='jet')\n\nplt.title('Satellite Data Before Masking')\n\nText(0.5, 1.0, 'Satellite Data Before Masking')"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#create-the-region-from-the-shape-file",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#create-the-region-from-the-shape-file",
    "title": "Extract data within a boundary",
    "section": "Create the region from the shape file",
    "text": "Create the region from the shape file\nThe plot shows the shape of the region and its placement along the US East Coast.\n\nregion = regionmask.from_geopandas(gulf_stream)\nregion.plot()"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#mask-the-satellite-data",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#mask-the-satellite-data",
    "title": "Extract data within a boundary",
    "section": "Mask the satellite data",
    "text": "Mask the satellite data\n\n# Create the mask\nmask = region.mask(ds_subset.longitude, ds_subset.latitude)\n\n# Apply mask the the satellite data\nmasked_ds = ds_subset.where(mask == region.numbers[0])"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#visualize-the-masked-data-on-a-map",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#visualize-the-masked-data-on-a-map",
    "title": "Extract data within a boundary",
    "section": "Visualize the masked data on a map",
    "text": "Visualize the masked data on a map\nThese data have been trimmed to contain only values within the Gulf Stream Province\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([260, 350, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nmasked_ds[0].plot.pcolormesh(ax=ax1,\n                             transform=ccrs.PlateCarree(),\n                             cmap='jet')\n\nplt.title('Satellite Data After Masking for Longhurst GFST')\n\n\nText(0.5, 1.0, 'Satellite Data After Masking for Longhurst GFST')"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#plot-the-mean-seasonal-temperature-for-the-province",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#plot-the-mean-seasonal-temperature-for-the-province",
    "title": "Extract data within a boundary",
    "section": "Plot the mean seasonal temperature for the province",
    "text": "Plot the mean seasonal temperature for the province\n\ngulf_stream_mean = masked_ds.mean(dim=['latitude', 'longitude'])\n\n\ngulf_stream_mean\n\nplt.figure(figsize=(10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(gulf_stream_mean.time,\n              gulf_stream_mean, \n              'o', markersize=8, \n              label='gulf stream', c='black', \n              linestyle='-', linewidth=2) \n\nplt.title('Gulf Stream Province Monthly Mean Temperature 2020')\nplt.ylabel('SST(degrees C)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#references",
    "href": "tutorials/extract-satellite-data-within-boundary/python/extract-satellite-data-within-boundary.html#references",
    "title": "Extract data within a boundary",
    "section": "References",
    "text": "References\nThe several CoastWatch Node websites have data catalog containing documentation and links to all the datasets available:\n* https://oceanwatch.pifsc.noaa.gov/doc.html\n* https://coastwatch.pfeg.noaa.gov/data.html\n* https://polarwatch.noaa.gov/catalog/\nSources for marine shape files * https://www.marineregions.org/downloads.php"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html",
    "title": "Make a virtual buoy with satellite data",
    "section": "",
    "text": "History | Updated August 2023 ## Background There are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov) and ARGO floats program (http://www.argo.ucsd.edu). Despite these impressive efforts to monitor environmental conditions, in situ buoy data may not be available for your area of interest. Some locations are hard to access, making deploying and maintaining a buoy impractical. In addition, buoys are expensive to purchase, deploy and maintain. Therefore, limited funding may prevent installation of a buoy or the continued operation of a buoy already in place.\nUsing satellite data to create virtual buoys can provide a solution to monitoring surface environmental conditions at locations where it is not feasible to install a buoy. For example, the University of South Florida has developed a virtual buoy system for locations off the Florida coast (https://optics.marine.usf.edu/projects/vbs.html)."
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#objectives",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#objectives",
    "title": "Make a virtual buoy with satellite data",
    "section": "Objectives",
    "text": "Objectives\nThe following exercise will demonstrate the use of the ERDDAP data server to create a virtual buoy. For the scenario, we will envision that a virtual buoy is needed to continue the datastream for an in situ buoy that was discontinued at the end of 2019. For this exercise we will use the National Data Buoy Center (NDBC) buoy # 46259, which is located off the California coast at 34.767N latitude and -121.497E longitude, and pretend that it was discontinued at the end of 2019. The buoy measures several oceanic variables, but we will continue the sea surface temperature (SST) datastream using NOAA GeoPolar Blended SST satellite dataset."
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#the-tutorial-demonstrates-the-following-skills",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#the-tutorial-demonstrates-the-following-skills",
    "title": "Make a virtual buoy with satellite data",
    "section": "The tutorial demonstrates the following skills:",
    "text": "The tutorial demonstrates the following skills:\n\nThe use of ERDDAP to create a virtual buoy\n\nThe use of the pandas and xarray modules to import and manipulate data\n\nResampling data to bin them into a lower resolution time steps\nGenerating a linear regression and statistics\nPlotting time-series data\n\nCleaning data to remove outlying data points"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#datasets-used",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#datasets-used",
    "title": "Make a virtual buoy with satellite data",
    "section": "Datasets used",
    "text": "Datasets used\nNDBC Buoy Data\nThe National Data Buoy Center (NDBC) distributes meteorological data from moored buoys maintained by NDBC and others. They are deployed in the coastal and offshore waters from the western Atlantic to the Pacific Ocean around Hawaii, and from the Bering Sea to the South Pacific. For this tutorial we will use buoy number 46259. NDBC data are available from the CoastWatch West Coast Node ERDDAP. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#import-required-modules",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#import-required-modules",
    "title": "Make a virtual buoy with satellite data",
    "section": "Import required modules",
    "text": "Import required modules\n\nimport numpy as np\nimport xarray as xr\nfrom datetime import datetime\nimport os\nimport pandas as pd\nimport io\nimport requests\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\nfrom sklearn.metrics import r2_score\n\n# the %matplotlib is a magic function allow displaying results in notebooks\n%matplotlib inline\n\n# some tools for Pandas to work will with matplotlib\nfrom pandas.plotting import register_matplotlib_converters"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#a-note-about-tabledap",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#a-note-about-tabledap",
    "title": "Make a virtual buoy with satellite data",
    "section": "A note about tabledap",
    "text": "A note about tabledap\nMost of our examples in this course use gridded datasets. The NDBC data for this tutorial is a tabular dataset, served via the tabledap part of ERDDAP. The API for tabledap is a little different than for gridded datasets. You can go to the following URL and play around with subsetting. Then push the “Just generate the URL” button, copy the link, put it in a browser. See if you get what you expected. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet\nA quick primer is below\nThe data request URL has three parts: 1. Base URL: https://url/erddap/tabledap/datasetID.fileType? * e.g. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?\n\nA list of variables you want to download that are separated by commas\n\n\n\ne.g. station,longitude,latitude,time,wtmp\n\n\nA list of constraints, each starting with an ampersand (&).\n\n\nThe constraints use =, &gt;, &gt;=, &lt;, and &lt;= to subset the data\ne.g. &station=“46259”, mean station # 46259\ne.g. &time&gt;=2017-01-01T&time&lt;=2020-12-31’, means time between and including Jan. 1, 2017 and Dec. 31, 2020.\n\nThe data request URL we will use for the NDBC data:\nndbc_url = 'https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?station,longitude,latitude,time,wtmp&station=\"46259\"&time&gt;=2017-01-01T&time&lt;=2020-12-31"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#download-the-data-into-a-pandas-dataframe",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#download-the-data-into-a-pandas-dataframe",
    "title": "Make a virtual buoy with satellite data",
    "section": "Download the data into a Pandas dataframe",
    "text": "Download the data into a Pandas dataframe\n\n# Break the url into part and rejoin it so that it is easier to see.\nndbc_url = ''.join(['https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?',\n                    'station,longitude,latitude,time,wtmp',\n                    '&station=\"46259\"&time&gt;=2018-01-01&time&lt;=2019-12-31'\n                    ])\n\nreq = requests.get(ndbc_url).content\nbuoy_df = pd.read_csv(io.StringIO(req.decode('utf-8')), skiprows=[1], parse_dates=['time'])\nbuoy_df.head(2)\n\n\n\n\n\n\n\n\nstation\nlongitude\nlatitude\ntime\nwtmp\n\n\n\n\n0\n46259\n-121.664\n34.732\n2018-01-01 00:22:00+00:00\n14.6\n\n\n1\n46259\n-121.664\n34.732\n2018-01-01 00:52:00+00:00\n14.6\n\n\n\n\n\n\n\n\nExtract the longitude and latitude coordinates for the station\nAfter, clean up the dataframe by deleting unneeded columns.\n\nbuoy_lat = buoy_df.latitude[0]\nbuoy_lon = buoy_df.longitude[0]\n\n# Clean up the dataset by removing unneeded columns\ndel buoy_df['station']\ndel buoy_df['latitude']\ndel buoy_df['longitude'] \n\nprint('latitude', buoy_lat)\nprint('longitude', buoy_lon)\n\nlatitude 34.732\nlongitude -121.664"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#process-the-buoy-data",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#process-the-buoy-data",
    "title": "Make a virtual buoy with satellite data",
    "section": "Process the buoy data",
    "text": "Process the buoy data\nThe measurement rate of the buoy is on the order of minutes. We need to downsample the dataset to the daily resolution of the satellite dataset.\nThere are a few cleanup steps that are needed:\n* The time data are associated with the UTC time zone. Panda operations often don’t like time zones so let’s get rid of it. * Rename the SST variable to something more intuitive\n\nprint('# of timesteps before =', buoy_df.shape[0] )\n\n# The resampling will put time as the df index\nbuoy_df_resampled = buoy_df.resample('D', on='time').mean()\nprint('# of timesteps after =', buoy_df_resampled.shape[0] )\n\n# Remove the timezone (UTC, GMT).\nbuoy_df_resampled = buoy_df_resampled.tz_localize(None)\n\n# Rename the SST variable\nbuoy_df_resampled.rename(columns={\"wtmp\": \"sst_buoy\"}, errors=\"raise\", inplace=True)\nbuoy_df_resampled\n\nbuoy_df_resampled.head(2)\n\n# of timesteps before = 34455\n# of timesteps after = 730\n\n\n\n\n\n\n\n\n\nsst_buoy\n\n\ntime\n\n\n\n\n\n2018-01-01\n14.679167\n\n\n2018-01-02\n14.891489"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#load-the-satellite-data-into-xarray-and-subset",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#load-the-satellite-data-into-xarray-and-subset",
    "title": "Make a virtual buoy with satellite data",
    "section": "Load the satellite data into xarray and subset",
    "text": "Load the satellite data into xarray and subset\n\n# Put satellite data xarray dataset object\nsst_url = 'https://coastwatch.noaa.gov/erddap/griddap/noaacwBLENDEDCsstDaily'\nsst_ds = xr.open_dataset(sst_url)\n\n# Subset the dataset\nsst_ds_subset = sst_ds['analysed_sst'].sel(latitude=buoy_lat,\n                            longitude = buoy_lon, method='nearest'\n                            ).sel(time=slice('2018-01-01', \n                                             '2019-12-31'\n                                             ))\n\nsst_ds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'analysed_sst' (time: 692)&gt;\n[692 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 2018-01-01T12:00:00 ... 2019-12-31T12:00:00\n    latitude   float32 34.72\n    longitude  float32 -121.7\nAttributes:\n    colorBarMaximum:  35.0\n    colorBarMinimum:  0.0\n    comment:          nighttime analysed SST for each ocean grid point\n    ioos_category:    Temperature\n    long_name:        analysed sea surface temperature\n    references:       Fieguth,P.W. et al. \"Mapping Mediterranean altimeter da...\n    standard_name:    sea_surface_foundation_temperature\n    units:            degree_Cxarray.DataArray'analysed_sst'time: 692...[692 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]2018-01-01T12:00:00 ... 2019-12-..._CoordinateAxisType :Timeactual_range :[1.0308816e+09 1.6938288e+09]axis :Tcomment :Nominal time of Level 4 analysisioos_category :Timelong_name :reference time of sst fieldstandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2018-01-01T12:00:00.000000000', '2018-01-02T12:00:00.000000000',\n       '2018-01-03T12:00:00.000000000', ..., '2019-12-29T12:00:00.000000000',\n       '2019-12-30T12:00:00.000000000', '2019-12-31T12:00:00.000000000'],\n      dtype='datetime64[ns]')latitude()float3234.72_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projectionioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array(34.725, dtype=float32)longitude()float32-121.7_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projectionioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array(-121.675, dtype=float32)Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2018-01-01 12:00:00', '2018-01-02 12:00:00',\n               '2018-01-03 12:00:00', '2018-01-04 12:00:00',\n               '2018-01-05 12:00:00', '2018-01-06 12:00:00',\n               '2018-01-07 12:00:00', '2018-01-08 12:00:00',\n               '2018-01-09 12:00:00', '2018-02-09 12:00:00',\n               ...\n               '2019-12-22 12:00:00', '2019-12-23 12:00:00',\n               '2019-12-24 12:00:00', '2019-12-25 12:00:00',\n               '2019-12-26 12:00:00', '2019-12-27 12:00:00',\n               '2019-12-28 12:00:00', '2019-12-29 12:00:00',\n               '2019-12-30 12:00:00', '2019-12-31 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=692, freq=None))Attributes: (8)colorBarMaximum :35.0colorBarMinimum :0.0comment :nighttime analysed SST for each ocean grid pointioos_category :Temperaturelong_name :analysed sea surface temperaturereferences :Fieguth,P.W. et al. \"Mapping Mediterranean altimeter data with a multiresolution optimal interpolation algorithm\", J. Atmos. Ocean Tech, 15\n (2): 535-546, 1998.     Fieguth, P. Multiply-Rooted Multiscale Models for Large-Scale Estimation, IEEE Image Processing, 10(11), 1676-1686, 2001.     Khellah, F., P.W. Fieguth, M.J. M\nurray and M.R. Allen, \"Statistical Processing of Large Image Sequences\", IEEE Transactions on Geoscience and Remote Sensing, 12 (1), 80-93, 2005.standard_name :sea_surface_foundation_temperatureunits :degree_C"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#process-the-satellite-data-to-make-them-compatible-with-the-buoy-data",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#process-the-satellite-data-to-make-them-compatible-with-the-buoy-data",
    "title": "Make a virtual buoy with satellite data",
    "section": "Process the satellite data to make them compatible with the buoy data",
    "text": "Process the satellite data to make them compatible with the buoy data\n\nPut the satellite data into a Pandas dataframe\nResample the data to daily bins: The data are already daily, but resampling them makes the timestamp format the same as for the buoy data, and puts time into the index column of the dataframe.\nRemove the timezone localization from time\n\n\n# Initialize data\nsat_data = {'time': sst_ds_subset.time.values,\n            'sst_sat': sst_ds_subset.to_numpy()\n            }\n\n# Creates pandas DataFrame.\nsat_df = pd.DataFrame(sat_data)\n\n# Resample\nsat_df = sat_df.resample('D', on='time').mean()\n\n# Remove timezone\nsat_df = sat_df.tz_localize(None)\n\n\nsat_df.head(2)\n\n\n\n\n\n\n\n\nsst_sat\n\n\ntime\n\n\n\n\n\n2018-01-01\n14.18\n\n\n2018-01-02\n14.76"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#merge-the-datasets",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#merge-the-datasets",
    "title": "Make a virtual buoy with satellite data",
    "section": "Merge the datasets",
    "text": "Merge the datasets\n\nmerged_df = pd.merge(buoy_df_resampled, \n                     sat_df, \n                     left_index=True, \n                     right_index=True).reset_index()\nmerged_df.head(2)\n\n\n\n\n\n\n\n\ntime\nsst_buoy\nsst_sat\n\n\n\n\n0\n2018-01-01\n14.679167\n14.18\n\n\n1\n2018-01-02\n14.891489\n14.76"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#plot-the-data-along-the-same-time-x-axis",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#plot-the-data-along-the-same-time-x-axis",
    "title": "Make a virtual buoy with satellite data",
    "section": "Plot the data along the same time (x) axis",
    "text": "Plot the data along the same time (x) axis\nThe data from the buoy and satellite seem to track each other very well (below). * You will want to at least run a linear regression to determine how well satellite data reflects the in situ buoy measurements.\n\nplt.figure(figsize = (10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(merged_df.index, merged_df.sst_buoy, \n              'o', markersize=3, \n              label='Buoy', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(merged_df.index, merged_df.sst_sat,  \n              's', markersize=3, \n              label='Satellite', c='blue', \n              linestyle='-', linewidth=1) \n\n#plt.ylim([0, 3])\nplt.ylabel('SST (degrees C)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#clean-up-the-merged-dataset",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#clean-up-the-merged-dataset",
    "title": "Make a virtual buoy with satellite data",
    "section": "Clean up the merged dataset",
    "text": "Clean up the merged dataset\nRegression packages typically do not like nan’s. * Delete rows with nan\nThe data could contain data points that are outliers. Let’s remove those points from the data frame. * Apply a conservative allowable data range. - For the lower end of the range, the freezing point of seawater (ca. -2).\n- For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n\n# Drop nan\nclean_merged_df = merged_df.dropna()\n\n# Drop &lt; -2 and &gt; 45\nclean_merged_df = clean_merged_df.drop(clean_merged_df[(clean_merged_df['sst_sat'] &lt; -2) \n                                       | (clean_merged_df['sst_sat'] &gt; 45)].index)"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#run-the-regression",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#run-the-regression",
    "title": "Make a virtual buoy with satellite data",
    "section": "Run the regression",
    "text": "Run the regression\n\n# Regression packages typically do not like nan's. Delete rows with nan\nclean_merged_df = merged_df.dropna()\n\n# Generate the regression plot\nsns.regplot(x='sst_buoy', y='sst_sat', data=clean_merged_df)\n\n# Calculate the slope and intercept\nslope, intercept = np.polyfit(clean_merged_df[\"sst_buoy\"], clean_merged_df[\"sst_sat\"], 1)\n\n# Calculate R2\nr2 = r2_score(clean_merged_df[\"sst_sat\"], clean_merged_df[\"sst_buoy\"])\n\n# Annotate the plot\nplt.annotate(f\"y = {slope:.2f}x + {intercept:.2f},  R2 = {r2:.2f}\", \n             xy=(12, 18), \n             #xytext=(30, 5), \n             fontsize=12, \n             color=\"black\", \n             ha=\"left\")\n\nprint(slope, intercept)\n\n# To save your data, uncomment the next line\n# clean_merged_df.to_csv(\"virtual_buoy_example.csv\", index=False)\n\n0.9338037509902803 0.9930764222028932"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#it-looks-like-your-virtual-buoy-is-ready-for-operations",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/python/create-virtual-buoy-with-satellite-data.html#it-looks-like-your-virtual-buoy-is-ready-for-operations",
    "title": "Make a virtual buoy with satellite data",
    "section": "It looks like your virtual buoy is ready for operations",
    "text": "It looks like your virtual buoy is ready for operations\n\nThere is essentially a one-to-one relationship between buoy and satellite SST. The slope (0.93) is very close to 1\nThe R2 indicates that 90% of the variability of satellite SST is explained by the regression."
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html",
    "href": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html",
    "title": "Calculating sea ice area and extent",
    "section": "",
    "text": "History | Created Sep 2023"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#background",
    "href": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#background",
    "title": "Calculating sea ice area and extent",
    "section": "Background",
    "text": "Background\nSea ice cover is one of the key components of polar ecological and climatological research. This measurement has gained attention because of the recent decrease in the Arctic sea ice cover. Satellite observations are a key tool in tracking sea ice cover, providing continuous global coverage extending back to 1978. Typically for satellite data, sea ice cover is reported as sea ice concentration, which is the percent areal coverage of ice within a grid cell. Depending on the application, additional parameters of interest can be calculated from sea ice cover:\n* Sea ice area - the sum of the product of ice concentration and area of all grid cells with at least 15% ice concentration.\n* Sea ice extent - the sum of the areas of all grid cells with at least 15% ice concentration"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#objective",
    "href": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#objective",
    "title": "Calculating sea ice area and extent",
    "section": "Objective",
    "text": "Objective\nThis tutorial will demonstrate how to calculate the sea ice area and extent using sea ice concentration and grid cell area data. Please visit the NSIDC website for more detailed descriptions of the calculations."
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#this-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#this-tutorial-demonstrates-the-following-techniques",
    "title": "Calculating sea ice area and extent",
    "section": "This tutorial demonstrates the following techniques",
    "text": "This tutorial demonstrates the following techniques\n\nDownloading and saving a netCDF file from PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nDownloading and adding grid cell area using OPeNDAP web services\nVisualizing data on a map\nComputing sea ice area and extent using sea ice concentration data\nPlotting a time series of sea ice area and extent"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#datasets-used",
    "href": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#datasets-used",
    "title": "Calculating sea ice area and extent",
    "section": "Datasets used",
    "text": "Datasets used\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere\nThe Sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Northern Polar Stereographic projection (EPSG:3413). The resolution is 25km, meaning each grid in this data set represents a value that covers a 25km by 25km area. The dataset is available on the PolarWatch data portal and can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.graph\nPolar Stereographic Ancillary Grid Information\nThis dataset includes area values (m2) of each grid cell in the 25km resolution Northern Polar Stereographic projection (EPSG:3413). The file for this exercise is available in the resources folder or can be downloaded from the NSIDC website at https://nsidc.org/data/nsidc-0771/versions/1. For this tutorial, we will access the dataset directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k\n\nImport packages\n\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#download-the-arctic-sea-ice-concentration-data",
    "href": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#download-the-arctic-sea-ice-concentration-data",
    "title": "Calculating sea ice area and extent",
    "section": "Download the Arctic Sea Ice Concentration Data",
    "text": "Download the Arctic Sea Ice Concentration Data\n\nReview of the ERDDAP data request URL\nFor our first exercise, we will download sea ice concentration data that has been temporally subsetted: * A single month, December 2021\nand spatially subsetted: * Y grid values that have been subsetted from the full range (5337500m to -5337500m) to a reduced range (4843696m to -4858210m).\nThe ERDDAP data request URL for this data subset is presented below.\nhttps://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\"\nThe following table shows the component parts of the ERDDAP data request URL.\n\n\n\n\n\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID for dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nformat of file to download (netCDF)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariable from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)]\nTemporal range (2021-01-01)\n\n\nspatial_range\n[(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\nY and X axes ranges\n\n\n\n\n\nGenerate the ERDDAP data query URL from its component parts\n\nbase_url = 'https://polarwatch.noaa.gov/erddap/griddap/'\ndatasetID = 'nsidcG02202v4nhmday'\nfile_type = '.nc'\nquery_start = '?'\nvariable_name = 'cdr_seaice_conc_monthly'\ndate_range = '[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)]'\nspatial_range = '[(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]'\n\nurl = ''.join([base_url,\n               datasetID,\n               file_type,\n               query_start,\n               variable_name,\n               date_range,\n               spatial_range\n               ])\nurl\n\n'https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]'\n\n\n\n\nDownload the data as a netCDF file and load file data into Python\n\n# Download the data from ERDDAP URL as a netCDF file\nurllib.request.urlretrieve(url, \"sic.nc\")\n\n# Open the netCDF file to create an xarray dataset object\nds = xr.open_dataset(\"sic.nc\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 1, ygrid: 389, xgrid: 304)\nCoordinates:\n  * time                     (time) datetime64[ns] 2021-01-01\n  * ygrid                    (ygrid) float32 4.838e+06 4.812e+06 ... -4.862e+06\n  * xgrid                    (xgrid) float32 -3.838e+06 -3.812e+06 ... 3.738e+06\nData variables:\n    cdr_seaice_conc_monthly  (time, ygrid, xgrid) float32 ...\nAttributes: (12/65)\n    acknowledgement:                                     This project was sup...\n    cdm_data_type:                                       Grid\n    cdr_variable:                                        cdr_seaice_conc_monthly\n    comment:                                             The variable melt_on...\n    contributor_name:                                    Walter N. Meier, Flo...\n    contributor_role:                                    principal investigat...\n    ...                                                  ...\n    summary:                                             This data set provid...\n    time_coverage_duration:                              P1M\n    time_coverage_end:                                   2021-01-01T00:00:00Z\n    time_coverage_resolution:                            P1M\n    time_coverage_start:                                 2021-01-01T00:00:00Z\n    title:                                               Sea Ice Concentratio...xarray.DatasetDimensions:time: 1ygrid: 389xgrid: 304Coordinates: (3)time(time)datetime64[ns]2021-01-01_ChunkSizes :1024_CoordinateAxisType :Timeactual_range :[1.6094592e+09 1.6094592e+09]axis :Tioos_category :Timelong_name :ANSI datestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2021-01-01T00:00:00.000000000'], dtype='datetime64[ns]')ygrid(ygrid)float324.838e+06 4.812e+06 ... -4.862e+06_ChunkSizes :448actual_range :[-4862500.  4837500.]axis :Yioos_category :Locationlong_name :projection_grid_y_centersstandard_name :projection_y_coordinateunits :metersvalid_range :[-5350000.  5850000.]array([ 4837500.,  4812500.,  4787500., ..., -4812500., -4837500., -4862500.],\n      dtype=float32)xgrid(xgrid)float32-3.838e+06 -3.812e+06 ... 3.738e+06_ChunkSizes :304actual_range :[-3837500.  3737500.]axis :Xioos_category :Locationlong_name :projection_grid_x_centersstandard_name :projection_x_coordinateunits :metersvalid_range :[-3850000.  3750000.]array([-3837500., -3812500., -3787500., ...,  3687500.,  3712500.,  3737500.],\n      dtype=float32)Data variables: (1)cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...ancillary_variables :stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthlycolorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole lakes coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Northern Hemisphere Sea Ice Concentrationreferences :https://nsidc.org/data/g02202/versions/4/standard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][118256 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2021-01-01'], dtype='datetime64[ns]', name='time', freq=None))ygridPandasIndexPandasIndex(Float64Index([ 4837500.0,  4812500.0,  4787500.0,  4762500.0,  4737500.0,\n               4712500.0,  4687500.0,  4662500.0,  4637500.0,  4612500.0,\n              ...\n              -4637500.0, -4662500.0, -4687500.0, -4712500.0, -4737500.0,\n              -4762500.0, -4787500.0, -4812500.0, -4837500.0, -4862500.0],\n             dtype='float64', name='ygrid', length=389))xgridPandasIndexPandasIndex(Float64Index([-3837500.0, -3812500.0, -3787500.0, -3762500.0, -3737500.0,\n              -3712500.0, -3687500.0, -3662500.0, -3637500.0, -3612500.0,\n              ...\n               3512500.0,  3537500.0,  3562500.0,  3587500.0,  3612500.0,\n               3637500.0,  3662500.0,  3687500.0,  3712500.0,  3737500.0],\n             dtype='float64', name='xgrid', length=304))Attributes: (65)acknowledgement :This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.cdm_data_type :Gridcdr_variable :cdr_seaice_conc_monthlycomment :The variable melt_onset_day_cdr_seaice_conc_monthly is not available for this month.contributor_name :Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fishercontributor_role :principal investigator, author, author, software developer, software developer, software developerConventions :CF-1.6, ACDD-1.3, COARDScreator_email :nsidc@nsidc.orgcreator_name :NSIDCcreator_type :institutioncreator_url :https://nsidc.org/date_created :2023-02-22T23:18:04ZdefaultGraphQuery :cdr_seaice_conc_monthly[last]%5B(-5337500.0)%5D%5B(3737500.0)%5D&.draw=surfacegrid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3850000.0 25000.0 0 5850000.0 0 -25000.0grid_mapping_grid_boundary_bottom_projected_y :-5350000.0grid_mapping_grid_boundary_left_projected_x :-3850000.0grid_mapping_grid_boundary_right_projected_x :3750000.0grid_mapping_grid_boundary_top_projected_y :5850000.0grid_mapping_latitude_of_projection_origin :90.0grid_mapping_longitude_of_projection_origin :-45.0grid_mapping_name :polar_stereographicgrid_mapping_parent_grid_cell_column_subset_end :304.0grid_mapping_parent_grid_cell_column_subset_start :0.0grid_mapping_parent_grid_cell_row_subset_end :448.0grid_mapping_parent_grid_cell_row_subset_start :0.0grid_mapping_proj4text :+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_scaling_factor :1.0grid_mapping_semimajor_radius :6378273.0grid_mapping_semiminor_radius :6356889.449grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3411\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3411grid_mapping_standard_parallel :70.0grid_mapping_straight_vertical_longitude_from_pole :135.0grid_mapping_units :metershistory :HISTORY_ATTRIBUTE\n2023-09-13T18:20:14Z (local files)\n2023-09-13T18:20:14Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]id :https://doi.org/10.7265/sr8p-kc62infoUrl :https://nsidc.org/data/g02202/versions/4/institution :NSIDC &gt; National Snow and Ice Data Centerkeywords :algorithm, america, arctic, area, atlantic, barents, bay, beaufort, bering, bootstrap, canada, cdr_seaice_conc_monthly, center, chukchi, climate, common, concentration, continent, CONTINENT &gt; NORTH AMERICA &gt; CANADA &gt; HUDSON BAY, Continent &gt; North America &gt; Canada &gt; Hudson Bay, cryosphere, data, davis, day, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Arctic, Geographic Region &gt; Northern Hemisphere, Geographic Region &gt; Polar, goddard, gsfc, gulf, hemisphere, hudson, ice, ice distribution, lawrence, mayen, melt, melt_onset_day_cdr_seaice_conc_monthly, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, north, northern, norwegian, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Arctic Ocean, Ocean &gt; Arctic Ocean &gt; Barents Sea, Ocean &gt; Arctic Ocean &gt; Beaufort Sea, Ocean &gt; Arctic Ocean &gt; Chukchi Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Davis Straight, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; GULF OF ST LAWRENCE, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; North Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Norwegian Sea, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; SVALBARD AND JAN MAYEN, Ocean &gt; Pacific Ocean, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Bering Sea, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Sea Of Okhotsk, oceans, okhotsk, onset, over, pacific, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, straight, svalbard, tdim, team, versionkeywords_vocabulary :GCMD Science Keywordslicense :No constraints on data access or usemetadata_link :https://nsidc.org/data/g02202/versions/4/naming_authority :org.doi.dxplatform :DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17processing_level :NOAA Level 3product_version :v04r00program :NOAA Climate Data Record Programproj_crs_code :EPSG:3411proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.project :NOAA/NSIDC passive microwave sea ice concentration climate data recordreferences :Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7): 15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1sensor :SSMI/S &gt; Special Sensor Microwave Imager/Soundersoftware_version_id :git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897source :ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220901_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220902_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220903_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220904_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220905_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220906_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220907_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220908_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220909_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220910_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220911_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220912_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220913_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220914_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220915_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220916_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220917_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220918_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220919_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220920_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220921_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220922_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220923_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220924_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220925_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220926_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220927_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220928_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220929_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220930_f17_v04r00.ncsourceUrl :(local files)spatial_resolution :25kmstandard_name_vocabulary :CF Standard Name Table v70summary :This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).time_coverage_duration :P1Mtime_coverage_end :2021-01-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2021-01-01T00:00:00Ztitle :Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\n\n\n\n\nDisplay the sea ice cover data as a map\nThe sea ice concentration values range from zero (no ice cover) to 1 (100% ice cover). However, this dataset also includes values above 1 to flag features like lakes, coastline, and land. Therefore, included in the code below is a step to remove those flag values from the mapping workflow.\n\nimg = ds['cdr_seaice_conc_monthly'].squeeze()\n\n# Remove flag values\nimg = img.where(img &lt;= 1)\n\n# Make plot area\nfig, ax = plt.subplots(figsize=(8, 10))\n\n# Set the color palette\ncmap = mpl.cm.get_cmap(\"Blues_r\").copy()\ncmap.set_bad(color='gray')\n\n# show image\nshw = ax.imshow(img, cmap=cmap, vmin=0, vmax=1)\n\n# Make the colorbar\nbar = plt.colorbar(shw, shrink=0.75)\n\n# show plot with labels\nplt.xlabel('X Grid (m)')\nplt.ylabel('Y Grid (m)')\nbar.set_label('Sea Ice Cover (fractional coverage)')\nplt.show()"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#get-area-information-from-the-ancillary-grid-dataset",
    "href": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#get-area-information-from-the-ancillary-grid-dataset",
    "title": "Calculating sea ice area and extent",
    "section": "Get area information from the ancillary grid dataset",
    "text": "Get area information from the ancillary grid dataset\nWhile the resolution of this data set is 25km (25km by 25km grid), the actual area of the grid depends on the grid projection. To obtain area value, we will need to:\n* Subset the Polar Stereographic Ancillary Grid Information dataset to match our SIC dataset and * Extract the area values for each grid cell.\n\nAccess the Ancillary Grid with OPeNDAP web services\nERDDAP allows you to access data using OPeNDAP web services. The OPeNDAP protocol allows you to create the xarray dataset object directly from the remote server, without downloading a data file onto your computer. When you request the subset of the dataset (e.g. the sub_area object below), the data are uploaded directly into an xarray data array.\n\n# Open xarray dataset object via an OPeNDAP connection\ngrid_url = 'https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k'\ngrid_area = xr.open_dataset(grid_url)\n\n# Subset grid area to match SIC data grids\nsub_area = grid_area.sel(x=slice(ds['xgrid'].min(), ds['xgrid'].max()),\n                         y=slice(ds['ygrid'].max(), ds['ygrid'].min())\n                         )\nsub_area\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:    (y: 389, x: 304)\nCoordinates:\n  * y          (y) float64 4.838e+06 4.812e+06 ... -4.838e+06 -4.862e+06\n  * x          (x) float64 -3.838e+06 -3.812e+06 ... 3.712e+06 3.738e+06\nData variables:\n    cell_area  (y, x) float64 ...\nAttributes: (12/52)\n    acknowledgement:                                     These data are produ...\n    cdm_data_type:                                       Grid\n    contributor_name:                                    J. Scott Stewart, Wa...\n    contributor_role:                                    Scientific Programme...\n    Conventions:                                         CF-1.6, ACDD-1.3, CO...\n    creator_name:                                        NASA National Snow a...\n    ...                                                  ...\n    publisher_type:                                      institution\n    publisher_url:                                       https://nsidc.org/daac\n    sourceUrl:                                           (local files)\n    standard_name_vocabulary:                            CF Standard Name Tab...\n    summary:                                             This data set provid...\n    title:                                               Polar Stereographic ...xarray.DatasetDimensions:y: 389x: 304Coordinates: (2)y(y)float644.838e+06 4.812e+06 ... -4.862e+06actual_range :[-5337500.  5837500.]axis :Yioos_category :Locationlong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metersvalid_range :[-5350000.  5850000.]array([ 4837500.,  4812500.,  4787500., ..., -4812500., -4837500., -4862500.])x(x)float64-3.838e+06 -3.812e+06 ... 3.738e+06actual_range :[-3837500.  3737500.]axis :Xioos_category :Locationlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metersvalid_range :[-3850000.  3750000.]array([-3837500., -3812500., -3787500., ...,  3687500.,  3712500.,  3737500.])Data variables: (1)cell_area(y, x)float64...colorBarMaximum :700000000.0colorBarMinimum :300000000.0comment :Surface area of grid cellcoverage_content_type :imageioos_category :Unknownlong_name :Grid Cell areastandard_name :cell_areaunits :meters^2valid_range :[3.82658854e+08 6.64448303e+08][118256 values with dtype=float64]Indexes: (2)yPandasIndexPandasIndex(Float64Index([ 4837500.0,  4812500.0,  4787500.0,  4762500.0,  4737500.0,\n               4712500.0,  4687500.0,  4662500.0,  4637500.0,  4612500.0,\n              ...\n              -4637500.0, -4662500.0, -4687500.0, -4712500.0, -4737500.0,\n              -4762500.0, -4787500.0, -4812500.0, -4837500.0, -4862500.0],\n             dtype='float64', name='y', length=389))xPandasIndexPandasIndex(Float64Index([-3837500.0, -3812500.0, -3787500.0, -3762500.0, -3737500.0,\n              -3712500.0, -3687500.0, -3662500.0, -3637500.0, -3612500.0,\n              ...\n               3512500.0,  3537500.0,  3562500.0,  3587500.0,  3612500.0,\n               3637500.0,  3662500.0,  3687500.0,  3712500.0,  3737500.0],\n             dtype='float64', name='x', length=304))Attributes: (52)acknowledgement :These data are produced and supported by the NASA National Snow and Ice Data Center Distributed Active Archive Center.cdm_data_type :Gridcontributor_name :J. Scott Stewart, Walter N. Meier, Donna J. Scottcontributor_role :Scientific Programmer, Project Scientist, Project LeadConventions :CF-1.6, ACDD-1.3, COARDScreator_name :NASA National Snow and Ice Data Center Distributed Active Archive Centercreator_type :groupcreator_url :https://www.nasa.gov/date_created :2022-03-21date_metadata_modified :2022-03-21date_modified :2022-03-21geospatial_bounds :POLYGON ((-3850000 5850000, 3750000 5850000, 3750000 -5350000, -3850000 -5350000, -3850000 5850000))geospatial_bounds_crs :EPSG:3411geospatial_x_resolution :25000 metersgeospatial_x_units :metersgeospatial_y_resolution :25000 metersgeospatial_y_units :metersgrid_mapping_crs_wkt :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],AUTHORITY[\"EPSG\",\"3411\"]]grid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3850000 25000 0 5850000 0 -25000grid_mapping_inverse_flattening :298.279411123064grid_mapping_latitude_of_projection_origin :90.0grid_mapping_long_name :NSIDC_NH_PolarStereo_25kmgrid_mapping_longitude_of_prime_meridian :0.0grid_mapping_name :polar_stereographicgrid_mapping_proj4text :+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_semi_major_axis :6378273.0grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],AUTHORITY[\"EPSG\",\"3411\"]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3411grid_mapping_standard_parallel :70.0grid_mapping_straight_vertical_longitude_from_pole :-45.0history :2023-09-13T18:20:35Z (local files)\n2023-09-13T18:20:35Z https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k.dasid :10.5067/N6INPBT8Y104infoUrl :https://doi.org/10.5067/N6INPBT8Y104institution :NASA National Snow and Ice Data Center Distributed Active Archive Centerkeywords :active, analysis, ancillary, archive, area, cell, cell_area, center, data, distributed, earth, EARTH SCIENCE SERVICES &gt; DATA ANALYSIS AND VISUALIZATION &gt; GEOGRAPHIC INFORMATION SYSTEMS, geographic, grid, ice, information, nasa, national, nsidc, polar, science, services, snow, stereo, systems, visualizationkeywords_vocabulary :GCMD Science Keywordslicense :Access Constraint: These data are freely, openly, and fully accessible, provided that you are logged into your NASA Earthdata profile (https://urs.earthdata.nasa.gov/);  Use Constraint: These data are freely, openly, and fully available to use without restrictions, provided that you cite the data according to the recommended citation at https://nsidc.org/about/use_copyright.html. For more information on the NASA EOSDIS Data Use Policy, see https://earthdata.nasa.gov/earth-observation-data/data-use-policy.metadata_link :https://doi.org/10.5067/N6INPBT8Y104naming_authority :org.doi.dxproduct_version :1.0program :NASA Earth Science Data and Information System (ESDIS)publisher_email :nsidc@nsidc.orgpublisher_institution :National Snow and Ice Data Center; Cooperative Institute for Research in Environmental Sciences; University of Colorado at Boulder; Boulder, COpublisher_name :NASA National Snow and Ice Data Center Distributed Active Archive Centerpublisher_type :institutionpublisher_url :https://nsidc.org/daacsourceUrl :(local files)standard_name_vocabulary :CF Standard Name Table v70summary :This data set provides the total on-Earth surface area values at the center of each grid cell of 25km polar stereographic gridded data sets (North) distributed by The National Snow and Ice Data Centertitle :Polar Stereographic Grid Cell Area Values of 25km gridded data sets , Polar Stereographic (North), Ancillary Data\n\n\n\n\nCombine the subsetted grid to the SIC dataset\nAdd subsetted area values from grid_area dataset as a new layer in the sea ice concentration dataset.\n\n# Add agrid area to the dataset\nds['area'] = (('ygrid', 'xgrid'), sub_area.cell_area.values)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 1, ygrid: 389, xgrid: 304)\nCoordinates:\n  * time                     (time) datetime64[ns] 2021-01-01\n  * ygrid                    (ygrid) float32 4.838e+06 4.812e+06 ... -4.862e+06\n  * xgrid                    (xgrid) float32 -3.838e+06 -3.812e+06 ... 3.738e+06\nData variables:\n    cdr_seaice_conc_monthly  (time, ygrid, xgrid) float32 ...\n    area                     (ygrid, xgrid) float64 4.266e+08 ... 4.289e+08\nAttributes: (12/65)\n    acknowledgement:                                     This project was sup...\n    cdm_data_type:                                       Grid\n    cdr_variable:                                        cdr_seaice_conc_monthly\n    comment:                                             The variable melt_on...\n    contributor_name:                                    Walter N. Meier, Flo...\n    contributor_role:                                    principal investigat...\n    ...                                                  ...\n    summary:                                             This data set provid...\n    time_coverage_duration:                              P1M\n    time_coverage_end:                                   2021-01-01T00:00:00Z\n    time_coverage_resolution:                            P1M\n    time_coverage_start:                                 2021-01-01T00:00:00Z\n    title:                                               Sea Ice Concentratio...xarray.DatasetDimensions:time: 1ygrid: 389xgrid: 304Coordinates: (3)time(time)datetime64[ns]2021-01-01_ChunkSizes :1024_CoordinateAxisType :Timeactual_range :[1.6094592e+09 1.6094592e+09]axis :Tioos_category :Timelong_name :ANSI datestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2021-01-01T00:00:00.000000000'], dtype='datetime64[ns]')ygrid(ygrid)float324.838e+06 4.812e+06 ... -4.862e+06_ChunkSizes :448actual_range :[-4862500.  4837500.]axis :Yioos_category :Locationlong_name :projection_grid_y_centersstandard_name :projection_y_coordinateunits :metersvalid_range :[-5350000.  5850000.]array([ 4837500.,  4812500.,  4787500., ..., -4812500., -4837500., -4862500.],\n      dtype=float32)xgrid(xgrid)float32-3.838e+06 -3.812e+06 ... 3.738e+06_ChunkSizes :304actual_range :[-3837500.  3737500.]axis :Xioos_category :Locationlong_name :projection_grid_x_centersstandard_name :projection_x_coordinateunits :metersvalid_range :[-3850000.  3750000.]array([-3837500., -3812500., -3787500., ...,  3687500.,  3712500.,  3737500.],\n      dtype=float32)Data variables: (2)cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...ancillary_variables :stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthlycolorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole lakes coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Northern Hemisphere Sea Ice Concentrationreferences :https://nsidc.org/data/g02202/versions/4/standard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][118256 values with dtype=float32]area(ygrid, xgrid)float644.266e+08 4.274e+08 ... 4.289e+08array([[4.26553150e+08, 4.27406844e+08, 4.28257483e+08, ...,\n        4.31628701e+08, 4.30790677e+08, 4.29949439e+08],\n       [4.27630452e+08, 4.28487364e+08, 4.29341214e+08, ...,\n        4.32725186e+08, 4.31883987e+08, 4.31039565e+08],\n       [4.28706202e+08, 4.29566333e+08, 4.30423392e+08, ...,\n        4.33820117e+08, 4.32975743e+08, 4.32128138e+08],\n       ...,\n       [4.27630452e+08, 4.28487364e+08, 4.29341214e+08, ...,\n        4.32725186e+08, 4.31883987e+08, 4.31039565e+08],\n       [4.26553150e+08, 4.27406844e+08, 4.28257483e+08, ...,\n        4.31628701e+08, 4.30790677e+08, 4.29949439e+08],\n       [4.25474341e+08, 4.26324815e+08, 4.27172243e+08, ...,\n        4.30530704e+08, 4.29695856e+08, 4.28857803e+08]])Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2021-01-01'], dtype='datetime64[ns]', name='time', freq=None))ygridPandasIndexPandasIndex(Float64Index([ 4837500.0,  4812500.0,  4787500.0,  4762500.0,  4737500.0,\n               4712500.0,  4687500.0,  4662500.0,  4637500.0,  4612500.0,\n              ...\n              -4637500.0, -4662500.0, -4687500.0, -4712500.0, -4737500.0,\n              -4762500.0, -4787500.0, -4812500.0, -4837500.0, -4862500.0],\n             dtype='float64', name='ygrid', length=389))xgridPandasIndexPandasIndex(Float64Index([-3837500.0, -3812500.0, -3787500.0, -3762500.0, -3737500.0,\n              -3712500.0, -3687500.0, -3662500.0, -3637500.0, -3612500.0,\n              ...\n               3512500.0,  3537500.0,  3562500.0,  3587500.0,  3612500.0,\n               3637500.0,  3662500.0,  3687500.0,  3712500.0,  3737500.0],\n             dtype='float64', name='xgrid', length=304))Attributes: (65)acknowledgement :This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.cdm_data_type :Gridcdr_variable :cdr_seaice_conc_monthlycomment :The variable melt_onset_day_cdr_seaice_conc_monthly is not available for this month.contributor_name :Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fishercontributor_role :principal investigator, author, author, software developer, software developer, software developerConventions :CF-1.6, ACDD-1.3, COARDScreator_email :nsidc@nsidc.orgcreator_name :NSIDCcreator_type :institutioncreator_url :https://nsidc.org/date_created :2023-02-22T23:18:04ZdefaultGraphQuery :cdr_seaice_conc_monthly[last]%5B(-5337500.0)%5D%5B(3737500.0)%5D&.draw=surfacegrid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3850000.0 25000.0 0 5850000.0 0 -25000.0grid_mapping_grid_boundary_bottom_projected_y :-5350000.0grid_mapping_grid_boundary_left_projected_x :-3850000.0grid_mapping_grid_boundary_right_projected_x :3750000.0grid_mapping_grid_boundary_top_projected_y :5850000.0grid_mapping_latitude_of_projection_origin :90.0grid_mapping_longitude_of_projection_origin :-45.0grid_mapping_name :polar_stereographicgrid_mapping_parent_grid_cell_column_subset_end :304.0grid_mapping_parent_grid_cell_column_subset_start :0.0grid_mapping_parent_grid_cell_row_subset_end :448.0grid_mapping_parent_grid_cell_row_subset_start :0.0grid_mapping_proj4text :+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_scaling_factor :1.0grid_mapping_semimajor_radius :6378273.0grid_mapping_semiminor_radius :6356889.449grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3411\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3411grid_mapping_standard_parallel :70.0grid_mapping_straight_vertical_longitude_from_pole :135.0grid_mapping_units :metershistory :HISTORY_ATTRIBUTE\n2023-09-13T18:20:14Z (local files)\n2023-09-13T18:20:14Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]id :https://doi.org/10.7265/sr8p-kc62infoUrl :https://nsidc.org/data/g02202/versions/4/institution :NSIDC &gt; National Snow and Ice Data Centerkeywords :algorithm, america, arctic, area, atlantic, barents, bay, beaufort, bering, bootstrap, canada, cdr_seaice_conc_monthly, center, chukchi, climate, common, concentration, continent, CONTINENT &gt; NORTH AMERICA &gt; CANADA &gt; HUDSON BAY, Continent &gt; North America &gt; Canada &gt; Hudson Bay, cryosphere, data, davis, day, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Arctic, Geographic Region &gt; Northern Hemisphere, Geographic Region &gt; Polar, goddard, gsfc, gulf, hemisphere, hudson, ice, ice distribution, lawrence, mayen, melt, melt_onset_day_cdr_seaice_conc_monthly, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, north, northern, norwegian, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Arctic Ocean, Ocean &gt; Arctic Ocean &gt; Barents Sea, Ocean &gt; Arctic Ocean &gt; Beaufort Sea, Ocean &gt; Arctic Ocean &gt; Chukchi Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Davis Straight, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; GULF OF ST LAWRENCE, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; North Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Norwegian Sea, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; SVALBARD AND JAN MAYEN, Ocean &gt; Pacific Ocean, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Bering Sea, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Sea Of Okhotsk, oceans, okhotsk, onset, over, pacific, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, straight, svalbard, tdim, team, versionkeywords_vocabulary :GCMD Science Keywordslicense :No constraints on data access or usemetadata_link :https://nsidc.org/data/g02202/versions/4/naming_authority :org.doi.dxplatform :DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17processing_level :NOAA Level 3product_version :v04r00program :NOAA Climate Data Record Programproj_crs_code :EPSG:3411proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.project :NOAA/NSIDC passive microwave sea ice concentration climate data recordreferences :Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7): 15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1sensor :SSMI/S &gt; Special Sensor Microwave Imager/Soundersoftware_version_id :git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897source :ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220901_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220902_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220903_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220904_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220905_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220906_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220907_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220908_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220909_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220910_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220911_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220912_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220913_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220914_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220915_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220916_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220917_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220918_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220919_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220920_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220921_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220922_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220923_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220924_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220925_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220926_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220927_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220928_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220929_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220930_f17_v04r00.ncsourceUrl :(local files)spatial_resolution :25kmstandard_name_vocabulary :CF Standard Name Table v70summary :This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).time_coverage_duration :P1Mtime_coverage_end :2021-01-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2021-01-01T00:00:00Ztitle :Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#compute-sea-ice-area-and-extent",
    "href": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#compute-sea-ice-area-and-extent",
    "title": "Calculating sea ice area and extent",
    "section": "Compute sea ice area and extent",
    "text": "Compute sea ice area and extent\nAlthough area and extent may sound the same, they are different measurements. * Sea ice area is the total region covered by ice, i.e. area that is 100% covered by ice. * Sea ice extent is the total region with at least 15 percent sea ice cover.\nTherefore, extent will give higher values than area.\n\n# Subset the dataset to exclude flag values (value &gt; 1)\nseaice_ds = ds.where(ds.cdr_seaice_conc_monthly &lt;= 1)\n\n# Set all cell with &lt; 15% ice cover to zero\n# Leave the other cells unchanged\ncells_15ice_andup = xr.where(seaice_ds.cdr_seaice_conc_monthly.squeeze() &lt; 0.15, \n                             0,  # Set to 0\n                             seaice_ds.cdr_seaice_conc_monthly.squeeze()   # Set to 1\n                             )\n\n# Calculate sea ice area\nicearea = seaice_ds.area * cells_15ice_andup\n\n# Convert the units from m^2 to km^2\nicearea_km = np.sum(icearea) / 1000000\nprint(\"Sea Ice Area (km^2): \", icearea_km.item())\n\n# Compute sea ice extent\n# Find all cells with &lt; 0.15 ice cover and set to 0, Set all other cells to 1\ncells_15ice_andup = xr.where(seaice_ds.cdr_seaice_conc_monthly.squeeze() &lt; 0.15,\n                             0,  # Set to 0\n                             1  # Set to 1\n                             )\n\n# Calculate sea ice extent\nextent = seaice_ds.area * cells_15ice_andup\nextent_km = np.sum(extent)/1000000\nprint(\"Sea Ice Extent (km^2):\", extent_km.item())\n\nSea Ice Area (km^2):  12528341.191722928\nSea Ice Extent (km^2): 13808725.557170859"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#create-a-time-series-with-12-months-of-data",
    "href": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#create-a-time-series-with-12-months-of-data",
    "title": "Calculating sea ice area and extent",
    "section": "Create a time series with 12 months of data",
    "text": "Create a time series with 12 months of data\n\nFor the next exercise, download 12 months of SIC data from 2021. Then, compute sea ice area and extent for each month and plot the time series.\nThe first step is to change our ERDDAP data query URL to request the 12 month time period. To do this, change the second part of the Time coverage component of the URL December of 2021 (see the table below).\n\n\n\n\n\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID for dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nNetCDF (there are many other available file formats)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariables from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]\nTemporal range\n\n\nspatial_range\n[(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\nSpatial range\n\n\n\nThe modified ERDDAP data request URL for this data subset is presented below:\nurl=“https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:( 2021-12-01T00:00:00Z )][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\nWe can generate the URL quickly by changing the “date_range” variable\n* From: date_range = '[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)]'\n* To: date_range = '[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]'\nThen rerunning the code to generate the ERDDAP data query URL.\n\ndate_range = '[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]'\n\nurl = ''.join([base_url,\n               datasetID,\n               file_type,\n               query_start,\n               variable_name,\n               date_range,\n               spatial_range\n               ])\nurl\n\n'https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]'\n\n\n\n\nGenerate the sea ice area and extent time series\n\n# Download 12 months of data\nurllib.request.urlretrieve(url, \"sic12.nc\")\n\n# Open the netCDF file to create an Xarray dataset object\nds = xr.open_dataset(\"sic12.nc\")\n\n# Add grid area to the dataset\ncell_area = sub_area.cell_area.values\nds['area'] = (('ygrid', 'xgrid'), cell_area)\n\n# Subset the dataset to exclude flag values\nseaice_ds = ds.where(ds.cdr_seaice_conc_monthly &lt;= 1)\n\n# Find all cells with &lt; 0.15 ice cover and set to 0.\n# Leave the other cells unchanged\ncells_15ice_andup_ts = xr.where(seaice_ds.cdr_seaice_conc_monthly &lt; 0.15, \n                                0,  # Set to 0\n                                seaice_ds.cdr_seaice_conc_monthly\n                                )\n\n# Calculate sea ice area for each time layer\nicearea_timeseries = seaice_ds.area * cells_15ice_andup_ts\n\n# Sum area for each time step and convert to km^2\nicearea_timeseries_km = icearea_timeseries.sum(dim=['xgrid', 'ygrid']) / 1000000\n\n# Find all cells with &lt; 0.15 ice cover and set to 0. Set all other cells to 1\ncells_15ice_andup_ts = xr.where(seaice_ds.cdr_seaice_conc_monthly &lt; 0.15,\n                                0,  # Set to 0\n                                1  # Set to 1\n                                )\n\n# Calculate sea ice extent by month\nextent_timeseries = seaice_ds.area * cells_15ice_andup_ts\n\n# # Sum extent for each time step and convert units to km^2\nextent_timeseries_km = extent_timeseries.sum(dim=['xgrid', 'ygrid']) / 1000000\n\n\n\nPlot the sea ice area and extent time series\n\n\nfig, ax = plt.subplots(figsize=(10, 4))\n\n# Plot the data as a line\nax.plot(icearea_timeseries_km.time, \n        icearea_timeseries_km,\n        label='Sea ice area',\n        marker='o', \n        linestyle='-')\n\nax.plot(extent_timeseries_km.time,\n        extent_timeseries_km,\n        label='Sea ice extent',\n        marker='s', \n        linestyle='-')\n\n# Add a title and labels\nax.set_title('2021 Monthly Sea ice area and sea ice extent')\nax.set_xlabel('Date')\nax.set_ylabel('Area (km^2)')\n\n# Display the legend\nax.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#references",
    "href": "tutorials/calculating-sea-ice-extent/python/calculating-sea-ice-extent.html#references",
    "title": "Calculating sea ice area and extent",
    "section": "References",
    "text": "References\n\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nPolarWatch Data Catalog\nWhat’s the difference between Sea ice area and extent?\nNSIDC Arctic Sea Ice News & Analysis\nClimate.gov Understanding Climate: sea ice extent\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html",
    "href": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "",
    "text": "History | Updated August 2023"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#objective",
    "href": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#objective",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab data hosted on an ERDDAP server from Python, how to work with NetCDF files in Python and how to make some maps and time-series of sea surface temperature."
  },
  {
    "objectID": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nLocating a satellite product in ERDDAP, manually changing the constraints and copying the URL defining the data request\nDownloading the resulting netCDF file\nOpening and examining the netCDF file\nMaking basic maps and time series plots"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#datasets-used",
    "href": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#datasets-used",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Datasets used",
    "text": "Datasets used\nCoralTemp Sea Surface Temperature product from the NOAA Coral Reef Watch program. The NOAA Coral Reef Watch (CRW) daily global 5km Sea Surface Temperature (SST) product, also known as CoralTemp, shows the nighttime ocean temperature measured at the surface. The SST scale ranges from -2 to 35 °C. The CoralTemp SST data product was developed from two, related reanalysis (reprocessed) SST products and a near real-time SST product. Spanning January 1, 1985 to the present, the CoralTemp SST is one of the best and most internally consistent daily global 5km SST products available. More information about the product: https://coralreefwatch.noaa.gov/product/5km/index_5km_sst.php\nWe will use the monthly composite of this product and download it from the NOAA CoastWatch ERDDAP server: https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.graph"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#import-python-modules",
    "href": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#import-python-modules",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Import Python modules",
    "text": "Import Python modules\n\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#download-data-from-erddap-using-python",
    "href": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#download-data-from-erddap-using-python",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "1. Download data from ERDDAP using Python",
    "text": "1. Download data from ERDDAP using Python\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure.\nFor example, the following page allows you to subset monthly sea surface temperature (SST) https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html\n\n\n\nerddap.png\n\n\n\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\nIn this specific example, the URL we generated is :\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D\n\n\nWith Python, run the following to download the data using the generated URL .\n\n# Below we have broken the url into parts and rejoin the them\n# to allow you to better see the url in the notebook.\nurl = ''.join(['https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?',\n               'sea_surface_temperature',\n               '%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D',\n               '%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D'\n               ])\n\nurllib.request.urlretrieve(url, \"sst.nc\")\n\n('sst.nc', &lt;http.client.HTTPMessage at 0x1ac0e35b0&gt;)"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#loading-netcdf4-data-into-python",
    "href": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#loading-netcdf4-data-into-python",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "2. Loading netCDF4 data into Python",
    "text": "2. Loading netCDF4 data into Python\nNow that we’ve downloaded the data locally, we can load it into Python and extract the variables of interest.\nThe xarray package makes it very convenient to work with NetCDF files. Documentation is available here: http://xarray.pydata.org/en/stable/why-xarray.html\n\nOpen the netCDF file as an xarray dataset object and examine the data structure.\n\nds = xr.open_dataset('sst.nc', decode_cf=True)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 12, latitude: 202, longitude: 201)\nCoordinates:\n  * time                     (time) datetime64[ns] 2022-01-16 ... 2022-12-16\n  * latitude                 (latitude) float32 40.03 39.97 ... 30.02 29.98\n  * longitude                (longitude) float32 -80.02 -79.97 ... -70.07 -70.02\nData variables:\n    sea_surface_temperature  (time, latitude, longitude) float32 ...\nAttributes: (12/65)\n    acknowledgement:                  NOAA Coral Reef Watch program\n    cdm_data_type:                    Grid\n    comment:                          This is a product of NOAA Coral Reef Wa...\n    contributor_name:                 NOAA Coral Reef Watch program\n    contributor_role:                 Collecting source data and deriving pro...\n    Conventions:                      CF-1.6, ACDD-1.3, COARDS\n    ...                               ...\n    time_coverage_duration:           P1M\n    time_coverage_end:                2022-12-16T00:00:00Z\n    time_coverage_resolution:         P1M\n    time_coverage_start:              2022-01-16T00:00:00Z\n    title:                            SST and SST Anomaly, NOAA Global Coral ...\n    Westernmost_Easting:              -80.024994xarray.DatasetDimensions:time: 12latitude: 202longitude: 201Coordinates: (3)time(time)datetime64[ns]2022-01-16 ... 2022-12-16_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3240.03 39.97 39.93 ... 30.02 29.98_CoordinateAxisType :Latactual_range :[29.975004 40.025   ]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([40.025   , 39.975   , 39.92501 , ..., 30.075003, 30.025   , 29.975004],\n      dtype=float32)longitude(longitude)float32-80.02 -79.97 ... -70.07 -70.02_CoordinateAxisType :Lonactual_range :[-80.024994 -70.024994]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-80.024994, -79.975   , -79.924995, ..., -70.125   , -70.075   ,\n       -70.024994], dtype=float32)Data variables: (1)sea_surface_temperature(time, latitude, longitude)float32...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[487224 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-16', '2022-02-16', '2022-03-16', '2022-04-16',\n               '2022-05-16', '2022-06-16', '2022-07-16', '2022-08-16',\n               '2022-09-16', '2022-10-16', '2022-11-16', '2022-12-16'],\n              dtype='datetime64[ns]', name='time', freq=None))latitudePandasIndexPandasIndex(Index([40.025001525878906, 39.974998474121094, 39.925010681152344,\n        39.87500762939453,  39.82500457763672, 39.775001525878906,\n       39.724998474121094, 39.675010681152344,  39.62500762939453,\n        39.57500457763672,\n       ...\n        30.42500114440918, 30.374998092651367, 30.325002670288086,\n       30.274999618530273, 30.225004196166992,  30.17500114440918,\n       30.124998092651367, 30.075002670288086, 30.024999618530273,\n       29.975004196166992],\n      dtype='float32', name='latitude', length=202))longitudePandasIndexPandasIndex(Index([-80.02499389648438,  -79.9749984741211, -79.92499542236328,\n                  -79.875, -79.82499694824219, -79.77499389648438,\n        -79.7249984741211, -79.67499542236328,            -79.625,\n       -79.57499694824219,\n       ...\n        -70.4749984741211, -70.42499542236328,            -70.375,\n       -70.32499694824219, -70.27499389648438,  -70.2249984741211,\n       -70.17499542236328,            -70.125, -70.07499694824219,\n       -70.02499389648438],\n      dtype='float32', name='longitude', length=201))Attributes: (65)acknowledgement :NOAA Coral Reef Watch programcdm_data_type :Gridcomment :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite Version 3.1, derived from CoralTemp v1.0.contributor_name :NOAA Coral Reef Watch programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archive.Conventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch programcreator_name :NOAA Coral Reef Watch programcreator_type :groupcreator_url :https://coralreefwatch.noaa.govdate_created :2018-03-01T12:00:00Zdate_issued :2019-01-19T20:32:23Zdate_metadata_modified :2018-09-01T12:00:00Zdate_modified :2018-03-01T12:00:00ZEasternmost_Easting :-70.024994geospatial_bounds :POLYGON((-90.0 180.0, 90.0 180.0, 90.0 -180.0, -90.0 -180.0, -90.0 180.0))geospatial_bounds_crs :EPSG:4326geospatial_lat_max :40.025geospatial_lat_min :29.975004geospatial_lat_units :degrees_northgeospatial_lon_max :-70.024994geospatial_lon_min :-80.024994geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:32663grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Tue Jul 27 10:37:54 2021: ncrename -d lon,longitude -d lat,latitude -v lon,longitude -v lat,latitude -v sea surface temperature anomaly,sea_surface_temperature_anomaly /cwdata/coralreef/work/temp.nc\nMonthly data files for mean sea surface temperature (SST) and sea surface temperature anomaly (SST anomaly) were downloaded from ftp.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1/nc/v1.0/monthly. Monthly files were created that contain both SST and SST anomaly data, and a mask of earth surface classifications.\n2023-09-06T14:23:22Z (local files)\n2023-09-06T14:23:22Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5Did :Satellite_Global_5km_CoralTemp_SST_SSTA_Monthly_Mean_CompositeinfoUrl :https://coralreefwatch.noaa.gov/product/5km/index.phpinstitution :NOAA/NESDIS/STAR Coral Reef Watch programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, anomaly, array, characteristics, coral, crw, data, earth, Earth Science &gt; Land Surface &gt; Land Temperature &gt; Land Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature Anomaly, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, flag, global, information, infrared, land, latitude, longitude, mask, mean, month, monthly, national, nesdis, noaa, ocean, oceans, pixel, program, quality, reef, satellite, science, sea, sea_surface_temperature, sea_surface_temperature_anomaly, seawater, service, spectral, spectral/engineering, sst, star, surface, surface_temperature_anomaly, temperature, thermal, time, v.3.1, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of the Coral Reef Watch website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/product/5km/index.phpnaming_authority :gov.noaa.coralreefwatchNCO :\"4.6.3\"Northernmost_Northing :40.025platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :Derived from L4 satellite sea surface temperature analysisproduct_version :3.1program :NOAA Coral Reef Watch programproject :NOAA Coral Reef Watch programpublisher_email :erd.data at noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch programpublisher_name :NOAA NMFS SWFSC ERD, CoastWatch West Coast Nodepublisher_type :institutionpublisher_url :https://coralreefwatch.noaa.gov, https://coastwatch.pfeg.noaa.gov/references :https://coralreefwatch.noaa.gov/product/5km/index.php and https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :Coral Reef Watch CoralTemp v1.0sourceUrl :(local files)Southernmost_Northing :29.975004spatial_resolution :0.05 degreestandard_name_vocabulary :CF Standard Name Table v27summary :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite, derived from CoralTemp v1.0.time_coverage_duration :P1Mtime_coverage_end :2022-12-16T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2022-01-16T00:00:00Ztitle :SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring, 5km, V.3.1, Monthly, 1985-PresentWesternmost_Easting :-80.024994\n\n\n\n\nExamine which coordinates and variables are included in the dataset.\n\n# List the coordinates\nprint('The coordinates variables:', list(ds.coords), '\\n')\n\n# List the data variables\nprint('The data variables:', list(ds.data_vars))\n\nThe coordinates variables: ['time', 'latitude', 'longitude'] \n\nThe data variables: ['sea_surface_temperature']\n\n\n\n\nExamine the structure of sea_surface_temperature.\n\nds.sea_surface_temperature.shape\n\n(12, 202, 201)\n\n\nThe dataset is a 3-D array with 12 time steps, each with 202 rows corresponding to latitudes and 201 columns corresponding to longitudes.\n\n\nList the dates for each time step.\nThe dataset has 12 time steps, one for each month between January 2022 and December 2022.\n\nds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 12)&gt;\narray(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 2022-01-16 2022-02-16 ... 2022-12-16\nAttributes:\n    _CoordinateAxisType:    Time\n    actual_range:           [1.6422912e+09 1.6711488e+09]\n    axis:                   T\n    coverage_content_type:  coordinate\n    ioos_category:          Time\n    long_name:              reference time of the last day of the composite t...\n    standard_name:          time\n    time_origin:            01-JAN-1970 00:00:00xarray.DataArray'time'time: 122022-01-16 2022-02-16 2022-03-16 ... 2022-10-16 2022-11-16 2022-12-16array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2022-01-16 ... 2022-12-16_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-16', '2022-02-16', '2022-03-16', '2022-04-16',\n               '2022-05-16', '2022-06-16', '2022-07-16', '2022-08-16',\n               '2022-09-16', '2022-10-16', '2022-11-16', '2022-12-16'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (8)_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00\n\n\n\n\nExamine the latitude coordinate variable\nTypically, the latitude coordinate variable will be in ascending order. However, in some datasets the order is reversed, i.e the order is descending.\nBy examining the first and last values on our latitude array (below), we can see that the values are descending.\n* In practice what this means is that when you slice (subset) using latitude later in this tutorial, you will put the largest latitude value first.\n\nprint('First latitude value', ds.latitude[0].item())\nprint('Last latitude value', ds.latitude[-1].item())\n\nFirst latitude value 40.025001525878906\nLast latitude value 29.975004196166992"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#working-with-the-data",
    "href": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#working-with-the-data",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "3. Working with the data",
    "text": "3. Working with the data\n\nCreating a map for for January 2022 (our first time step)\n\nFind the minimum and maximum SST values.\n\nprint('Minimum SST', np.nanmin(ds.sea_surface_temperature))\nprint('Maximum SST', np.nanmax(ds.sea_surface_temperature))\n\nMinimum SST 2.34\nMaximum SST 29.87\n\n\n\n\nUse the minimum and maximum SST to set some color breaks.\n\n# Sets color breaks from 2 to 30 with 0.05 steps\nlevs = np.arange(2, 30, 0.05)\n\n\n\nDefine a color palette.\n\njet = [\"blue\", \"#007FFF\", \"cyan\", \"#7FFF7F\",\n       \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"]\n\n\n\nSet color scale using the jet palette.\n\ncm = LinearSegmentedColormap.from_list('my_jet', jet, N=len(levs))\n\n\n\nPlot the SST map\nThe code also shows how to annotate the map by: - Adding points to the map (e.g. station locations) - Adding contour lines\n\nplt.contourf(ds.longitude, \n             ds.latitude, \n             ds.sea_surface_temperature[0, :, :], \n             levs,\n             cmap=cm)\n\n# Plot the colorbar\nplt.colorbar()\n\n# Annotation: Example of how to add points to the map\nplt.scatter(range(-74, -71), np.repeat(34, 3), c='black')\n\n# Annotation: Example of how to add a contour line\nplt.contour(ds.longitude, \n            ds.latitude, \n            ds.sea_surface_temperature[0, :, :], \n            levels=[14],\n            linewidths=1)\n\n# Add a title\nplt.title(\"Monthly Sea Surface Temperature - \" \n          + ds.time[0].dt.strftime('%b %Y').item())\nplt.show()"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#plotting-a-time-series",
    "href": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#plotting-a-time-series",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Plotting a time series",
    "text": "Plotting a time series\n\nSubset the following box from the data:\n\n36o to 38oN latitude\n-77o to -75oE longitude\n\nWe are going to generate a time series of mean SST within that box.\n\nFirst, subset the data:\n\nRemember!\nFor this product, latitudes are indexed in descending order (high to low). Therefore when you slice latitude, put the largest value first.\n\nda = ds.sel(latitude=slice(38, 36), longitude=slice(-77, -75))\n\n\n\nExamine the structure of the subsetted data.\nThe subset is a 3-D array with 12 time steps, each with 40 rows corresponding to latitudes and 40 columns corresponding to longitudes.\n\nda.sea_surface_temperature.shape\n\n(12, 40, 40)\n\n\n\n\nPlot the subsetted data\n\nplt.contourf(da.longitude, \n             da.latitude, \n             da.sea_surface_temperature[0, :, :], \n             levs,\n             cmap=cm)\nplt.colorbar()\nplt.title(\"Monthly Sea Surface Temperature \" \n          + ds.time[0].dt.strftime('%b %Y').item())\nplt.show()"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#compute-the-monthly-mean-for-each-month",
    "href": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#compute-the-monthly-mean-for-each-month",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Compute the monthly mean for each month",
    "text": "Compute the monthly mean for each month\n\nres = np.mean(da.sea_surface_temperature, axis=(1, 2))\n\n\nPlot the time-series\n\nplt.figure(figsize=(8, 4))\nplt.scatter(ds.time, res)\nplt.ylabel('SST (ºC)')\n\nText(0, 0.5, 'SST (ºC)')"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#creating-a-map-of-average-sst-over-a-year",
    "href": "tutorials/Tutorial1-basics/python/Tutorial1-basics.html#creating-a-map-of-average-sst-over-a-year",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Creating a map of average SST over a year",
    "text": "Creating a map of average SST over a year\n\nCompute the yearly mean for the region\n\nmean_sst = np.mean(ds.sea_surface_temperature, axis=0)\n\n\n\nPlot the map of the 2022 average SST in the region\n\nplt.contourf(ds.longitude, ds.latitude, mean_sst, levs, cmap=cm)\nplt.colorbar()\nplt.title(\"Mean SST \" \n          + ds.time[0].dt.strftime('%b %Y').item() \n          + ' - '\n          + ds.time[11].dt.strftime('%b %Y').item())\n\nplt.show()"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html",
    "href": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "history | Create July 2023 | Updated August 2023\n\n\n\nMap projections try to portray the earth’s spherical surface on a flat surface. A coordinate reference system (CRS) defines how the two-dimensional, projected map relates to real places on the earth. Which map projection and CRS to use depends on the region in which you are working and the analysis you will do.\nNOAA PolarWatch distributes gridded and tabular oceanographic data for polar regions.\nMost of the satellite data in the PolarWatch data catalog use a projection based on a Geographic Coordinate Reference System, where the X and Y coordinates are longitude and latitude, respectively. Geographical coordinates work well in many parts of the globe, but within polar regions, features tend to be very distorted. A Polar Stereographic projection often is a better choice for polar regions. For example, the NSIDC’s Polar Stereographic Projections, which were developed to optimize mapping of sea ice, have only a 6% distortion of the grid at the poles and no distortion at 70º, a latitude close to where the marginal ice zones occur. The NOAA NSIDC Sea Ice Concentration Climate Data Record dataset, for example, is in a polar stereographic projection.\nWhen working with satellite datasets with a mix of map projections, it is often necessary to transform all the data to a common projection. In this exercise, we will learn to transform coordinates from one projection to another.\n\n\n\nIn this tutorial, we will learn to transform dataset coordinates from one projection to another.\n\n\n\n\nDownloading and saving a netCDF file from PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nConvert the netcdf data into a dataframe\nTransforming coordinates using EPSG codes\nMapping data using the transformed coordinates\n\n\n\n\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-2022, Monthly The sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Southern Polar Stereographic projection (EPSG:3031). The resolution is 25km, meaning each pixel in this data set represents a value that covers a 25km by 25km area. The dataset can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday\n\n\nThis code block will check if required packages are installed, and will install missing packages.\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"ncdf4\" , \"sf\", \"ggplot2\",\"scales\", \"RColorBrewer\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\n# download the sea ice data NetCDF file\nurl &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]\"\n\nsic &lt;- download.file(url, destfile=\"sic.nc\", mode='wb')\n\n# file open\nds &lt;- nc_open('sic.nc')\n\n# print metadata\nprint(ds)\n\n## File sic.nc (NC_FORMAT_CLASSIC):\n## \n##      1 variables (excluding dimension variables):\n##         float cdr_seaice_conc_monthly[xgrid,ygrid,time]   \n##             _FillValue: 2.53999996185303\n##             ancillary_variables: stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthly\n##             colorBarMaximum: 1\n##             colorBarMinimum: 0\n##             colorBarPalette: KT_ice\n##             datum: +ellps=urn:ogc:def:crs:EPSG::4326\n##             flag_meanings: pole_hole lakes coastal land_mask missing_data\n##             flag_values: -5\n##              flag_values: -4\n##              flag_values: -3\n##              flag_values: -2\n##              flag_values: -1\n##             ioos_category: Ice Distribution\n##             long_name: NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration\n##             references: https://nsidc.org/data/g02202/versions/4/\n##             standard_name: sea_ice_area_fraction\n##             units: 1\n##             valid_range: 0\n##              valid_range: 1\n## \n##      3 dimensions:\n##         time  Size:1 \n##             _ChunkSizes: 1024\n##             _CoordinateAxisType: Time\n##             actual_range: 1669852800\n##              actual_range: 1669852800\n##             axis: T\n##             calendar: gregorian\n##             ioos_category: Time\n##             long_name: ANSI date\n##             standard_name: time\n##             time_origin: 01-JAN-1970 00:00:00\n##             units: seconds since 1970-01-01T00:00:00Z\n##         ygrid  Size:332 \n##             _ChunkSizes: 332\n##             actual_range: -3937500\n##              actual_range: 4337500\n##             axis: Y\n##             ioos_category: Location\n##             long_name: projection_grid_y_centers\n##             standard_name: projection_y_coordinate\n##             units: meters\n##             valid_range: -3950000\n##              valid_range: 4350000\n##         xgrid  Size:316 \n##             _ChunkSizes: 316\n##             actual_range: -3937500\n##              actual_range: 3937500\n##             axis: X\n##             ioos_category: Location\n##             long_name: projection_grid_x_centers\n##             standard_name: projection_x_coordinate\n##             units: meters\n##             valid_range: -3950000\n##              valid_range: 3950000\n## \n##     65 global attributes:\n##         acknowledgement: This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.\n##         cdm_data_type: Grid\n##         cdr_variable: cdr_seaice_conc_monthly\n##         contributor_name: Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fisher\n##         contributor_role: principal investigator, author, author, software developer, software developer, software developer\n##         Conventions: CF-1.6, ACDD-1.3, COARDS\n##         creator_email: nsidc@nsidc.org\n##         creator_name: NSIDC\n##         creator_type: institution\n##         creator_url: https://nsidc.org/\n##         date_created: 2023-02-22T23:17:53Z\n##         defaultGraphQuery: cdr_seaice_conc_monthly%5Blast%5D%5B(4337500.0):(-3937500.0)%5D%5B(-3937500.0):(3937500.0)%5D&.draw=surface\n##         grid_mapping_false_easting: 0\n##         grid_mapping_false_northing: 0\n##         grid_mapping_GeoTransform: -3950000.0 25000.0 0 4350000.0 0 -25000.0\n##         grid_mapping_grid_boundary_bottom_projected_y: -3950000\n##         grid_mapping_grid_boundary_left_projected_x: -3950000\n##         grid_mapping_grid_boundary_right_projected_x: 3950000\n##         grid_mapping_grid_boundary_top_projected_y: 4350000\n##         grid_mapping_latitude_of_projection_origin: -90\n##         grid_mapping_longitude_of_projection_origin: 0\n##         grid_mapping_name: polar_stereographic\n##         grid_mapping_parent_grid_cell_column_subset_end: 316\n##         grid_mapping_parent_grid_cell_column_subset_start: 0\n##         grid_mapping_parent_grid_cell_row_subset_end: 332\n##         grid_mapping_parent_grid_cell_row_subset_start: 0\n##         grid_mapping_proj4text: +proj=stere +lat_0=-90 +lat_ts=-70 +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defs\n##         grid_mapping_scaling_factor: 1\n##         grid_mapping_semimajor_radius: 6378273\n##         grid_mapping_semiminor_radius: 6356889.449\n##         grid_mapping_spatial_ref: PROJCS[\"NSIDC Sea Ice Polar Stereographic South\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",-70],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3412\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]\n##         grid_mapping_srid: urn:ogc:def:crs:EPSG::3412\n##         grid_mapping_standard_parallel: -70\n##         grid_mapping_straight_vertical_longitude_from_pole: 180\n##         grid_mapping_units: meters\n##         history: Tue Jan  5 13:40:25 2021: ncks -x -v goddard_merged_seaice_conc_monthly ./previous_blank_ncs/S_monthly_blank.nc ./S_monthly_blank.nc\n## 2023-09-13T19:25:12Z (local files)\n## 2023-09-13T19:25:12Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]\n##         id: https://doi.org/10.7265/sr8p-kc62\n##         infoUrl: https://nsidc.org/data/g02202/versions/4/\n##         institution: NSIDC &gt; National Snow and Ice Data Center\n##         keywords: algorithm, area, bellingshausen, bootstrap, cdr_seaice_conc_monthly, center, climate, common, concentration, cryosphere, data, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Polar, Geographic Region &gt; Southern Hemisphere, goddard, gsfc, hemisphere, ice, ice distribution, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Southern Ocean, Ocean &gt; Southern Ocean &gt; Bellingshausen Sea, Ocean &gt; Southern Ocean &gt; Ross Sea, Ocean &gt; Southern Ocean &gt; Weddell Sea, oceans, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, ross, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, southern, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, tdim, team, version, weddell\n##         keywords_vocabulary: GCMD Science Keywords\n##         license: No constraints on data access or use\n##         metadata_link: https://nsidc.org/data/g02202/versions/4/\n##         naming_authority: org.doi.dx\n##         NCO: \"4.5.4\"\n##         platform: DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17\n##         processing_level: NOAA Level 3\n##         product_version: v04r00\n##         program: NOAA Climate Data Record Program\n##         proj_crs_code: EPSG:3412\n##         proj_crs_code_description: The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.\n##         project: NOAA/NSIDC passive microwave sea ice concentration climate data record\n##         references: Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7):    15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1\n##         sensor: SSMI/S &gt; Special Sensor Microwave Imager/Sounder\n##         software_version_id: git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897\n##         source: ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220701_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220702_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220703_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220704_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220705_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220706_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220707_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220708_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220709_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220710_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220711_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220712_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220713_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220714_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220715_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220716_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220717_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220718_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220719_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220720_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220721_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220722_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220723_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220724_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220725_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220726_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220727_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220728_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220729_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220730_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220731_f17_v04r00.nc\n##         sourceUrl: (local files)\n##         spatial_resolution: 25km\n##         standard_name_vocabulary: CF Standard Name Table v70\n##         summary: This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).\n##         time_coverage_duration: P1M\n##         time_coverage_end: 2022-12-01T00:00:00Z\n##         time_coverage_resolution: P1M\n##         time_coverage_start: 2022-12-01T00:00:00Z\n##         title: Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\n\n# get data into r variables \nxgrid &lt;- ncvar_get(ds, \"xgrid\")\nygrid &lt;- ncvar_get(ds, \"ygrid\")\nsic &lt;- ncvar_get(ds, \"cdr_seaice_conc_monthly\")  #lat and lon\ndim(sic)\n\n## [1] 316 332\n\n# close \nnc_close(ds)\n\n\n\n# create dataframe\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude fillvalue\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels=comma) + \n       scale_x_continuous(labels=comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\")+ggtitle(\"Sea Ice Concentration in Polar Steregraphic projection\")\n\n\n\n\n\nWhen transforming from one CRS to another, it is important to inspect CRS definitions and the transformation function for proper transformation. We will transform from CRS EPSG: 3031 (NSIDC Polar Stereographic South) to EPSG: 4326 (geographic coordinate system)\nxy_sf &lt;- st_as_sf(sicd, coords=c(\"xgrid\", \"ygrid\"), crs=3031)\n\n# st_transform output order: lat , lon\nlatlon_sf &lt;- st_transform(xy_sf, crs=4326)\n\nlatlon_df &lt;- as.data.frame(st_coordinates(latlon_sf))\nnames(latlon_df) &lt;- c(\"Lat\", \"Lon\")\nseaiceconc &lt;- sicd$sic\n# create dataframe and add names\nsicdf_latlon &lt;- data.frame(cbind(latlon_df,seaiceconc))\nhead(na.omit(sicdf_latlon), 5)\n\n##         Lat       Lon seaiceconc\n## 1 -42.23257 -39.49708          0\n## 2 -42.05101 -39.62425          0\n## 3 -41.86840 -39.75110          0\n## 4 -41.68474 -39.87763          0\n## 5 -41.50003 -40.00383          0\n\n\nsic_sf &lt;- st_as_sf(sicdf_latlon, coords = c('Lat', 'Lon'))\nst_crs(sic_sf) = \"4326\"\n\n# plot sea ice concentration on an unprojected map\nggplot(sic_sf) + geom_sf(aes(color = seaiceconc)) + labs(title = \"Sea Ice Concentration of Antarctica\")\n\nBecause the data were in the polar stereographic projection, mapping the data onto a different projection (global map projection) above, doesn’t make the data fit well on the map.\n\n\n\n\n\nNOAA PolarWatch Data Product Page (download, preview)\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#background",
    "href": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#background",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "Map projections try to portray the earth’s spherical surface on a flat surface. A coordinate reference system (CRS) defines how the two-dimensional, projected map relates to real places on the earth. Which map projection and CRS to use depends on the region in which you are working and the analysis you will do.\nNOAA PolarWatch distributes gridded and tabular oceanographic data for polar regions.\nMost of the satellite data in the PolarWatch data catalog use a projection based on a Geographic Coordinate Reference System, where the X and Y coordinates are longitude and latitude, respectively. Geographical coordinates work well in many parts of the globe, but within polar regions, features tend to be very distorted. A Polar Stereographic projection often is a better choice for polar regions. For example, the NSIDC’s Polar Stereographic Projections, which were developed to optimize mapping of sea ice, have only a 6% distortion of the grid at the poles and no distortion at 70º, a latitude close to where the marginal ice zones occur. The NOAA NSIDC Sea Ice Concentration Climate Data Record dataset, for example, is in a polar stereographic projection.\nWhen working with satellite datasets with a mix of map projections, it is often necessary to transform all the data to a common projection. In this exercise, we will learn to transform coordinates from one projection to another."
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#objective",
    "href": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#objective",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "In this tutorial, we will learn to transform dataset coordinates from one projection to another."
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#this-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#this-tutorial-demonstrates-the-following-techniques",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "Downloading and saving a netCDF file from PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nConvert the netcdf data into a dataframe\nTransforming coordinates using EPSG codes\nMapping data using the transformed coordinates"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#dataset-used",
    "href": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#dataset-used",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-2022, Monthly The sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Southern Polar Stereographic projection (EPSG:3031). The resolution is 25km, meaning each pixel in this data set represents a value that covers a 25km by 25km area. The dataset can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday\n\n\nThis code block will check if required packages are installed, and will install missing packages.\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"ncdf4\" , \"sf\", \"ggplot2\",\"scales\", \"RColorBrewer\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\n# download the sea ice data NetCDF file\nurl &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]\"\n\nsic &lt;- download.file(url, destfile=\"sic.nc\", mode='wb')\n\n# file open\nds &lt;- nc_open('sic.nc')\n\n# print metadata\nprint(ds)\n\n## File sic.nc (NC_FORMAT_CLASSIC):\n## \n##      1 variables (excluding dimension variables):\n##         float cdr_seaice_conc_monthly[xgrid,ygrid,time]   \n##             _FillValue: 2.53999996185303\n##             ancillary_variables: stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthly\n##             colorBarMaximum: 1\n##             colorBarMinimum: 0\n##             colorBarPalette: KT_ice\n##             datum: +ellps=urn:ogc:def:crs:EPSG::4326\n##             flag_meanings: pole_hole lakes coastal land_mask missing_data\n##             flag_values: -5\n##              flag_values: -4\n##              flag_values: -3\n##              flag_values: -2\n##              flag_values: -1\n##             ioos_category: Ice Distribution\n##             long_name: NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration\n##             references: https://nsidc.org/data/g02202/versions/4/\n##             standard_name: sea_ice_area_fraction\n##             units: 1\n##             valid_range: 0\n##              valid_range: 1\n## \n##      3 dimensions:\n##         time  Size:1 \n##             _ChunkSizes: 1024\n##             _CoordinateAxisType: Time\n##             actual_range: 1669852800\n##              actual_range: 1669852800\n##             axis: T\n##             calendar: gregorian\n##             ioos_category: Time\n##             long_name: ANSI date\n##             standard_name: time\n##             time_origin: 01-JAN-1970 00:00:00\n##             units: seconds since 1970-01-01T00:00:00Z\n##         ygrid  Size:332 \n##             _ChunkSizes: 332\n##             actual_range: -3937500\n##              actual_range: 4337500\n##             axis: Y\n##             ioos_category: Location\n##             long_name: projection_grid_y_centers\n##             standard_name: projection_y_coordinate\n##             units: meters\n##             valid_range: -3950000\n##              valid_range: 4350000\n##         xgrid  Size:316 \n##             _ChunkSizes: 316\n##             actual_range: -3937500\n##              actual_range: 3937500\n##             axis: X\n##             ioos_category: Location\n##             long_name: projection_grid_x_centers\n##             standard_name: projection_x_coordinate\n##             units: meters\n##             valid_range: -3950000\n##              valid_range: 3950000\n## \n##     65 global attributes:\n##         acknowledgement: This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.\n##         cdm_data_type: Grid\n##         cdr_variable: cdr_seaice_conc_monthly\n##         contributor_name: Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fisher\n##         contributor_role: principal investigator, author, author, software developer, software developer, software developer\n##         Conventions: CF-1.6, ACDD-1.3, COARDS\n##         creator_email: nsidc@nsidc.org\n##         creator_name: NSIDC\n##         creator_type: institution\n##         creator_url: https://nsidc.org/\n##         date_created: 2023-02-22T23:17:53Z\n##         defaultGraphQuery: cdr_seaice_conc_monthly%5Blast%5D%5B(4337500.0):(-3937500.0)%5D%5B(-3937500.0):(3937500.0)%5D&.draw=surface\n##         grid_mapping_false_easting: 0\n##         grid_mapping_false_northing: 0\n##         grid_mapping_GeoTransform: -3950000.0 25000.0 0 4350000.0 0 -25000.0\n##         grid_mapping_grid_boundary_bottom_projected_y: -3950000\n##         grid_mapping_grid_boundary_left_projected_x: -3950000\n##         grid_mapping_grid_boundary_right_projected_x: 3950000\n##         grid_mapping_grid_boundary_top_projected_y: 4350000\n##         grid_mapping_latitude_of_projection_origin: -90\n##         grid_mapping_longitude_of_projection_origin: 0\n##         grid_mapping_name: polar_stereographic\n##         grid_mapping_parent_grid_cell_column_subset_end: 316\n##         grid_mapping_parent_grid_cell_column_subset_start: 0\n##         grid_mapping_parent_grid_cell_row_subset_end: 332\n##         grid_mapping_parent_grid_cell_row_subset_start: 0\n##         grid_mapping_proj4text: +proj=stere +lat_0=-90 +lat_ts=-70 +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defs\n##         grid_mapping_scaling_factor: 1\n##         grid_mapping_semimajor_radius: 6378273\n##         grid_mapping_semiminor_radius: 6356889.449\n##         grid_mapping_spatial_ref: PROJCS[\"NSIDC Sea Ice Polar Stereographic South\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",-70],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3412\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]\n##         grid_mapping_srid: urn:ogc:def:crs:EPSG::3412\n##         grid_mapping_standard_parallel: -70\n##         grid_mapping_straight_vertical_longitude_from_pole: 180\n##         grid_mapping_units: meters\n##         history: Tue Jan  5 13:40:25 2021: ncks -x -v goddard_merged_seaice_conc_monthly ./previous_blank_ncs/S_monthly_blank.nc ./S_monthly_blank.nc\n## 2023-09-13T19:25:12Z (local files)\n## 2023-09-13T19:25:12Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]\n##         id: https://doi.org/10.7265/sr8p-kc62\n##         infoUrl: https://nsidc.org/data/g02202/versions/4/\n##         institution: NSIDC &gt; National Snow and Ice Data Center\n##         keywords: algorithm, area, bellingshausen, bootstrap, cdr_seaice_conc_monthly, center, climate, common, concentration, cryosphere, data, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Polar, Geographic Region &gt; Southern Hemisphere, goddard, gsfc, hemisphere, ice, ice distribution, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Southern Ocean, Ocean &gt; Southern Ocean &gt; Bellingshausen Sea, Ocean &gt; Southern Ocean &gt; Ross Sea, Ocean &gt; Southern Ocean &gt; Weddell Sea, oceans, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, ross, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, southern, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, tdim, team, version, weddell\n##         keywords_vocabulary: GCMD Science Keywords\n##         license: No constraints on data access or use\n##         metadata_link: https://nsidc.org/data/g02202/versions/4/\n##         naming_authority: org.doi.dx\n##         NCO: \"4.5.4\"\n##         platform: DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17\n##         processing_level: NOAA Level 3\n##         product_version: v04r00\n##         program: NOAA Climate Data Record Program\n##         proj_crs_code: EPSG:3412\n##         proj_crs_code_description: The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.\n##         project: NOAA/NSIDC passive microwave sea ice concentration climate data record\n##         references: Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7):    15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1\n##         sensor: SSMI/S &gt; Special Sensor Microwave Imager/Sounder\n##         software_version_id: git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897\n##         source: ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220701_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220702_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220703_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220704_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220705_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220706_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220707_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220708_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220709_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220710_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220711_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220712_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220713_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220714_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220715_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220716_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220717_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220718_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220719_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220720_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220721_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220722_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220723_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220724_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220725_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220726_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220727_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220728_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220729_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220730_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220731_f17_v04r00.nc\n##         sourceUrl: (local files)\n##         spatial_resolution: 25km\n##         standard_name_vocabulary: CF Standard Name Table v70\n##         summary: This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).\n##         time_coverage_duration: P1M\n##         time_coverage_end: 2022-12-01T00:00:00Z\n##         time_coverage_resolution: P1M\n##         time_coverage_start: 2022-12-01T00:00:00Z\n##         title: Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\n\n# get data into r variables \nxgrid &lt;- ncvar_get(ds, \"xgrid\")\nygrid &lt;- ncvar_get(ds, \"ygrid\")\nsic &lt;- ncvar_get(ds, \"cdr_seaice_conc_monthly\")  #lat and lon\ndim(sic)\n\n## [1] 316 332\n\n# close \nnc_close(ds)\n\n\n\n# create dataframe\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude fillvalue\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels=comma) + \n       scale_x_continuous(labels=comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\")+ggtitle(\"Sea Ice Concentration in Polar Steregraphic projection\")"
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#transforming-from-crs-to-crs",
    "href": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#transforming-from-crs-to-crs",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "When transforming from one CRS to another, it is important to inspect CRS definitions and the transformation function for proper transformation. We will transform from CRS EPSG: 3031 (NSIDC Polar Stereographic South) to EPSG: 4326 (geographic coordinate system)\nxy_sf &lt;- st_as_sf(sicd, coords=c(\"xgrid\", \"ygrid\"), crs=3031)\n\n# st_transform output order: lat , lon\nlatlon_sf &lt;- st_transform(xy_sf, crs=4326)\n\nlatlon_df &lt;- as.data.frame(st_coordinates(latlon_sf))\nnames(latlon_df) &lt;- c(\"Lat\", \"Lon\")\nseaiceconc &lt;- sicd$sic\n# create dataframe and add names\nsicdf_latlon &lt;- data.frame(cbind(latlon_df,seaiceconc))\nhead(na.omit(sicdf_latlon), 5)\n\n##         Lat       Lon seaiceconc\n## 1 -42.23257 -39.49708          0\n## 2 -42.05101 -39.62425          0\n## 3 -41.86840 -39.75110          0\n## 4 -41.68474 -39.87763          0\n## 5 -41.50003 -40.00383          0\n\n\nsic_sf &lt;- st_as_sf(sicdf_latlon, coords = c('Lat', 'Lon'))\nst_crs(sic_sf) = \"4326\"\n\n# plot sea ice concentration on an unprojected map\nggplot(sic_sf) + geom_sf(aes(color = seaiceconc)) + labs(title = \"Sea Ice Concentration of Antarctica\")\n\nBecause the data were in the polar stereographic projection, mapping the data onto a different projection (global map projection) above, doesn’t make the data fit well on the map."
  },
  {
    "objectID": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#references",
    "href": "tutorials/transform-to-another-map-projection/r/transforming-coords-from-crs-to-crs.html#references",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "NOAA PolarWatch Data Product Page (download, preview)\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)"
  },
  {
    "objectID": "tutorials/softwarebackground.html",
    "href": "tutorials/softwarebackground.html",
    "title": "Software Information",
    "section": "",
    "text": "This page provides background information on common tools and formats used throughout the CoastWatch training materials, including ERDDAP, NetCDF, NASA Panoply, and the CoastWatch Utilities (CWUtils).\nIf you’re looking for hands-on, step-by-step lessons, go to the Software Code Gallery page.",
    "crumbs": [
      "Training Tutorials",
      "Software Tutorials",
      "Software Information"
    ]
  },
  {
    "objectID": "tutorials/softwarebackground.html#erddap",
    "href": "tutorials/softwarebackground.html#erddap",
    "title": "Software Information",
    "section": "ERDDAP basics: What is ERDDAP?",
    "text": "ERDDAP basics: What is ERDDAP?\nFor many users, obtaining the ocean satellite data they need requires downloading data from several data providers, each with its own file formats, download protocols, subset abilities, and preview abilities.\nA short list of ocean satellite data providers:\n\nJet Propulsion Laboratory (PO.DAAC)\nNASA Ocean Biology (OB.DAAC)\nNASA Goddard Space Flight Center\nNOAA Center for Satellite Applications and Research\nNOAA CoastWatch Central Operations\nNOAA Office of Satellite and Product Operations\nNOAA National Centers for Environmental Information (NCEI)\nNOAA Comprehensive Large Array-data Stewardship System (CLASS)\nEuropean Space Agency (ESA)\nJapan Aerospace Exploration Agency (JAXA)\n\n\nThe goal behind ERDDAP is to make it easier for you to get scientific data. To accomplish that goal, ERDDAP acts as a middleman, selectively channeling datasets from remote and local data sources to a single data portal. With ERDDAP as the single-source portal, you have access to a simple, consistent way to download subsets of gridded and tabular scientific datasets in common file formats, with options and make graphs and maps.\nFeatures of ERDDAP:\n\nData in the common file format of your choice. ERDDAP offers all data as .html table, ESRI .asc and .csv, Google Earth .kml, OPeNDAP binary, .mat, .nc, ODV .txt, .csv, .tsv, .json, and .xhtml\nERDDAP can also return a .png or .pdf image with a customized graph or map\nStandardized dates/times (“seconds since 1970-01-01T00:00:00Z” in UTC)\nA graphical interface for humans with browsers\nRESTful web services for machine-to-machine data exchange and downloading data directly into your software applications (e.g.Matlab, R, Python…) and even into web pages.\n\n\nTutorials on how to use ERDDAP servers\nOn the Software Code Gallery page, you’ll find individual lessons such as:\n\nUsing the ERDDAP Data Catalog\nVisualizing data\nUnderstanding the ERDDAP URL\nCreating a Hovmöller plot\nWorking with wind vectors\nUsing tabular data\nAdditional resources\n\n\n\nCoastWatch ERDDAP servers\nCoastWatch\n\nCoastWatch West Coast Node\nCoastWatch Central Pacific Node\nCoastWatch Gulf of Mexico Node\nCoastWatch Great Lakes Node\nCoastWatch Central\n\nOther organizations\n\nSouthern California Coastal Ocean Observing System (SCCOOS)\nRutgers\nNOAA GEO-IDE UAF\nNCEI\nIFREMER\nMarine Institute Ireland\n\nA more complete list is available here:\nhttps://coastwatch.pfeg.noaa.gov/erddap/download/setup.html#organizations",
    "crumbs": [
      "Training Tutorials",
      "Software Tutorials",
      "Software Information"
    ]
  },
  {
    "objectID": "tutorials/softwarebackground.html#netcdfpanoply",
    "href": "tutorials/softwarebackground.html#netcdfpanoply",
    "title": "Software Information",
    "section": "NetCDF and Panoply",
    "text": "NetCDF and Panoply\n\nNetCDF\nNetCDF (Network Common Data Form) is a file format for storing multidimensional scientific data (variables), including common satellite observations (e.g., sea surface temperature, salinity, chlorophyll, winds). Many organizations and scientific groups in different countries have adopted netCDF as a standard way to represent some forms of scientific data.\nThe NetCDF format has many advantages, the most important of which is that it is self-describing, meaning that software packages can directly read the data and determine its structure, the variable names and essential metadata such as the units. This self-describing aspect of the netCDF file format means that the information needed to ensure accurate work (reduce the incidence of errors) is available within the data itself (no need for additional files). Secondly, it means that different analysis software, like Matlab, R, Python or ArcGIS (among many others), have utilities to read and work with NetCDF files. Thirdly, plotting software (e.g. Ferret, Panoply, ncview) can directly read the netCDF files for visualization.\n \n\n\nNASA Panoply\nNASA developed the Panoply viewer that allows users to view and visualize data held in NetCDF files. Some features the software includes are:\n\nVisualize data from netCDF and HDF files\nView the metadata\nView the data\nDisplay the data in many different map projections\nDownload visualization as images\nCreate animations\nFreeware\n\n\nPanoply is available for download at: https://www.giss.nasa.gov/tools/panoply/ and can be run on Windows, Mac and Linux computers.\nA set of “how to” instructions can be found to the following URL https://www.giss.nasa.gov/tools/panoply/help/ Below are a few examples to try out to get you used to visualizing data with the Panoply Viewer.\n💡 Panoply Version Note: The examples provided in CoastWatch materials are based on Panoply Version 5.3.3 (interfaces may differ slightly across versions).",
    "crumbs": [
      "Training Tutorials",
      "Software Tutorials",
      "Software Information"
    ]
  },
  {
    "objectID": "tutorials/softwarebackground.html#cwutils",
    "href": "tutorials/softwarebackground.html#cwutils",
    "title": "Software Information",
    "section": "CoastWatch Utilities",
    "text": "CoastWatch Utilities\nThe CoastWatch Utilities (CWUtils) are software tools designed to help users work with NOAA/NESDIS CoastWatch satellite data—especially because these scientific data files aren’t meant to be opened in standard image viewers.\n\nWhat CoastWatch Utilities includes\nCWUtils provides both: - Graphical tools for interactive exploration - Command-line tools for scripting and repeatable processing workflows\nThe tools commonly support workflows like: - Information and statistics (inspect file contents, compute summary stats) - Data processing (format conversions, compositing, variable math, sampling) - Graphics and visualization (interactive visualization + batch rendering) - Registration and navigation (resampling between projections; navigation correction)\n\n\nGetting CoastWatch Utilities\nCWUtils is available for Windows, macOS, and Linux. The User’s Guide notes (minimum recommendations): ~400 MB disk (1 GB recommended total workspace) and 4 GB RAM.\nTo download, the guide directs users to the CoastWatch site and to look for CoastWatch Utilities under Data Tools (or search “utilities”).\n\n\nCoastWatch Utilities Online Course\nThe CoastWatch Utilities Online Course is about using the CoastWatch Utilities software package to help with processing satellite imagery and derived data products. The course covers working with data files (i) visually using a graphical user interface, and (ii) by typing commands at the Unix or Windows command prompts. No programming experience is needed, though it can be helpful when automating data processing.",
    "crumbs": [
      "Training Tutorials",
      "Software Tutorials",
      "Software Information"
    ]
  },
  {
    "objectID": "tutorials/seaice-thickness-climatology/r/ice-thickness-climatology.html",
    "href": "tutorials/seaice-thickness-climatology/r/ice-thickness-climatology.html",
    "title": "R Notebook",
    "section": "",
    "text": "Calculating anomaly and trend with sea ice thickness time series\nIn this exercise, we will use the sea ice thickness data in the Arctic region, available through the PolarWatch data server, to study changes in monthly average sea ice thickness values. We will calculate both the long-term trend at each location as well as estimate a changing seasonal.\n\nThe exercise demonstrates the following techniques:\n\nDownloading, as a netcdf file, twice daily sea ice thickness data for a region sdelected at random for the years 1982 to late 2024.\nCalculating a monthly mean from the twice-daily data.\nCalculating the trend and changing seasonal of monthly sea ice thickness means using state-space models\nVisualizing the result of the state-space analysis.\n\n\n\nGetting the data\nFirst we will load the packages that will be used:\n#load needed libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(KFAS)\nlibrary(ncdf4)\nlibrary(tidyr)\nNext the script to download the data (it is advised not to run this because it can take a long time to download and can fail - the resulting file is included), the region selected in projected coordinates was chosen arbitarily:\ndownload_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/ncei_polarAPPX20_nhem.nc?cdr_sea_ice_thickness[(1982-10-31T14:00:00Z):1:(2024-10-31T14:00:00Z)][(-388546.6):1:(338411.6)][(-438681.7):1:(338411.6)]\"\ndownload.file(download_url,  \"ncei_polar.nc\", 'wb')\nThe next step is to read in the netcdf file:\nroot &lt;- nc_open('data/ncei_polar.nc')\ntime &lt;- ncvar_get(root, 'time')\nrows &lt;- ncvar_get(root, 'rows')\ncolumns &lt;- ncvar_get(root, 'columns')\nice_thick &lt;- ncvar_get(root, 'cdr_sea_ice_thickness')\nnc_close(root)\n“time” needs to be converted to an ‘R’ time, and then year and month extracted:\ntime &lt;- as.POSIXlt(time, origin = '1970-01-01', tz = \"GMT\")\nyears &lt;- year(time)\nuniqueYears &lt;- unique(years)\nmonths &lt;- month(time)\nOne solution to calculate the mean time series is to “melt” the data to long form, and then use functions like ‘apply()’ or ‘tapply()’ or any of the appropriate “tidyverse” functions to calculate the mean value for each month. Code below shows how to “melt” the data, but we will not do so because as you will find out you will quickly run out of memory and likely crash your R.\nout &lt;- list(year = years, month = months, rows = rows,  columns = columns)\ndf &lt;- as.data.frame(as.vector(ice_thick))\nmeta  &lt;- expand.grid(out, stringsAsFactors = FALSE)\nalldf &lt;-  cbind(meta, df)\nA simpler, less elegant but more straightforward method (and easier to debug) is to use loops:\nno_years &lt;- length(unique(years))\nmonth_avg &lt;- array(NA, dim = c(length(rows), length(columns), 12, no_years))\nfor (myMonth in 1:12){\n  for (yearCount in 1:length(uniqueYears)){\n    myYear &lt;- uniqueYears[yearCount]\n    data_point &lt;- which((months == myMonth) & (years == myYear))\n    temp_data &lt;- ice_thick[, , data_point]\n    month_avg[, , myMonth, yearCount] &lt;- apply(temp_data, c(1, 2), function(x) mean(x, na.rm = TRUE))\n  }\n}\n# re-from array to be a time-series at each point\nmonth_avg_series &lt;- array(month_avg, dim = c(length(rows), length(columns), 12*length(uniqueYears)))\n#  remove the last two months of 2024 which are missing\nmonth_avg_series &lt;- month_avg_series[, , 1:514]\n# create a date-time object to be used with plotting and other functions\ndate_time &lt;- seq.Date(from = as.Date(\"1982-01-01\"), to = as.Date(\"2024-10-01\"), by = \"month\")\nIn the code above, the “apply()” function applies the function “mean()” elementwise, and ‘month_avg_series’ just flattens the calculated array so that there is a time-series for each time period at each location, rather than being subscripted by month and year.\nIn order to examine the series, we will use a state-space decomposition of the data, which separates the data into a nonparametric trend and plus a seasonal component that can vary in phase and amplitude. This is implemented in the ‘R’ package ‘KFAS’. To start, a function is defined that sets up the state-space model, another that is used with the optimization routine to re-evaluate the function for the new parameters, and a function to call what is needed to do all of the calculation steps:\n\n### define the model in KFAS\nstate_space_decomp &lt;- function(dataSeries){\n  #  set model starting values\n  irreg_init &lt;- 0.5 * log(1)\n  level_init &lt;- 0.5 * log(.01)\n  season_init &lt;-  0.5 * log(.1)\n  modelts_inits &lt;- c(irreg_init, level_init, season_init)\n  # define the state-space model in KFAS\n  model_ice &lt;- SSModel(dataSeries ~ SSMtrend(degree = 1 , Q = list(NA)) +\n                        SSMseasonal(12, Q=NA, sea.type = \"trigonometric\"),  H = matrix(NA))\n  #  fit the model to the data\n  model_ice_Fit &lt;- fitSSM(model = model_ice, inits = modelts_inits, updatefn = update_modelts)\n  # calculate the smoothed values for the optimal parameters\n  smooth_ice &lt;- KFS(model_ice_Fit$model, filtering = \"state\", smoothing = \"state\")\n  # extract the estimated trend and seasonal\n  level &lt;-  signal(smooth_ice, states = 'level')$signal\n  season &lt;- signal(smooth_ice, states = 'season')$signal\n  smooths &lt;- data.frame(level = level, season = season)\n  \n}\n### define the function to update model for the optimization routine \nupdate_modelts &lt;- function(pars, model) {\n  finite_test &lt;- 0.5 * log(.000001)\n  if (pars[1] &lt; finite_test) {\n    pars[1] &lt;- finite_test\n  }\n  model$H[1,1,1] &lt;- exp(2. * pars[1])\n  temp3 &lt;- exp(c(2 * pars[2], rep((2 * pars[3]), 11)))\n  diag(model$Q[,,1]) &lt;-  temp3\n  return(model)\n}\n\nTo get an idea of the output from the state-space model we look at the first series and estimate the model:\ndataSeries &lt;- month_avg_series[1, 1, ]\n# make certain we start at the first actual value in the series\nnobs &lt;- length(na.omit(dataSeries))\nice_decomp &lt;- state_space_decomp(dataSeries)\nIn order to examine the output, some ‘ggplot2’ plotting functions are defined:\nplot_trend_data &lt;- function(dataSeries, level, date_time){\n  df &lt;- data.frame(\n    date_time &lt;- date_time,\n    data = dataSeries,\n    trend = level\n  )\n  \n  p &lt;- ggplot(df, aes(x = date_time)) +\n    geom_line(aes(y = data, color = \"Data\"), linewidth = 0.5) +    # Plot the data\n    geom_line(aes(y = trend, color = \"Trend\"), linewidth = 0.5) +  # Plot the trend\n    labs(title = \"Data and Trend Plot\",\n         x = \"Time\",\n         y = \"Ice Thickness\") +\n    scale_color_manual(values = c(\"Data\" = \"black\", \"Trend\" = \"red\")) +  # Customize colors\n    theme_minimal()\n  return(p)\n}\n\n\nplot_season &lt;- function(season, date_time){\n  df &lt;- data.frame(\n    date_time = date_time,\n    season = season\n  )\n  ggplot(df, aes(x = date_time, y = season)) +\n    geom_line(size = 0.5) +\n    labs(title = \"Ice Thickness Seasonal Component\", x = \"Time\", y = \"Ice Thickness\") +\n    theme_minimal()\n  \n}\n\nplot_season_month  &lt;- function(season, date_time){\n   myMonth &lt;- month(date_time)\n   myYear &lt;- year(date_time)\n   df &lt;- data.frame(\n         month = myMonth,  \n         year = myYear,   \n         season = season\n     )\n   \n     monthly_means &lt;- df %&gt;%\n           group_by(month) %&gt;%\n           summarise(mean_value = mean(season))\n     \n       df &lt;- df %&gt;%\n             left_join(monthly_means, by = \"month\")\n       \n         p &lt;- ggplot(df, aes(x = factor(month), y = season, group = year, color = factor(year))) +\n             geom_line() +\n             geom_line(aes(y = mean_value), color = \"gray\") +\n             labs(x = \"Month\", y = \"Values\", title = \"Monthly Series and Monthly Mean\") +\n             theme_minimal() +\n             theme(legend.title = element_blank())\n       return(p) \n}\n\n\n\nplot_season_polar  &lt;- function(season, date_time){\n  myMonth &lt;- month(date_time)\n  myYear &lt;- year(date_time)\n  df &lt;- data.frame(\n         month = myMonth,  \n         year = myYear,   \n         season = season\n     )\n   p &lt;- ggplot(df, aes(x = factor(month), y = season, group = year)) +\n         geom_line(aes(color = factor(year))) +\n         coord_polar() +\n         labs(x = \"Month\", y = \"Values\", title = \"Polar Plot of Time Series\") +\n         theme_minimal() +\n         theme(legend.position = \"right\") \n    return(p)\n}\nPlot the trend versus the series:\np &lt;- plot_trend_data(dataSeries, ice_decomp$level, date_time)\np\nPlot the seasonal:\np &lt;- plot_season(ice_decomp$season, date_time)\np\nIn interpreting the seasonal plot, even though in theory the seasonal and trend are independent, in practice since the ice thickness has a lower bound of zero, if the trend decreases this limits the amount the seasonal can vary downward.\nPlot each year’s season on one graph:\np &lt;- plot_season_month(ice_decomp$season, date_time)\np\nMake a polar plot of the seasonal:\np &lt;- plot_season_polar(ice_decomp$season, date_time)\np\nWhat can clearly be seen in the seasonal is how it has been slowly but consistently changing over roughly decadal time scales.\nTo examine another location just change the indices in the data array, that is set irow and jcol to the desired values and run the code below:\n    dataSeries &lt;- month_avg_series[irow, jcol, ]\n    # make certain we start at the first actual value in the series\n    ice_decomp &lt;- state_space_decomp(dataSeries)\n    p_trend &lt;- plot_trend_data(dataSeries, ice_decomp$level, date_time)\n    p_season &lt;- plot_season(ice_decomp$season, date_time)\n    p_season_month &lt;- plot_season_month(ice_decomp$season, date_time)\n    p_season_polar &lt;- plot_season_polar(ice_decomp$season, date_time)\n    \nTo get the state-space decomposition for all of the series, just iterate over rows and columns (this can take 5 minutes or there abouts so a good time to stretch you legs):\n#  create arrays of NA to store results\ntrends &lt;- array(NA_real_, dim = c(length(rows), length(columns), length(date_time)))\nseasons &lt;- array(NA_real_, dim = c(length(rows), length(columns), length(date_time)))\n\n# loop over rows and columns\nfor (irow in seq(1, length(rows))) {\n  for (jcol in seq(1, length(columns))) {\n    dataSeries &lt;- month_avg_series[irow, jcol, ]\n    # make certain we start at the first actual value in the series\n    ice_decomp &lt;- state_space_decomp(dataSeries)\n    trends[irow, jcol, ] &lt;- ice_decomp$level\n    seasons[irow, jcol, ] &lt;- ice_decomp$season\n  }\n}\nThis analysis looks at each location separately and can be informative, but a better analysis, beyond the scope of this tutorial, would be to model all the locations jointly, both to take into account spatial correlation as well as the fact that neighboring locations most like will have more similar locations, so some amount of spatial smootiing or regularization would be called for."
  },
  {
    "objectID": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html",
    "href": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html",
    "title": "NetCDF and Panoply tutorial",
    "section": "",
    "text": "Updated March 2024\n\n\n\nNetCDF (Network Common Data Form) is a file format for storing multidimensional scientific data (variables), including satellite observations of variable we wll use in the course such as sea surface temperature, salinity, chlorophyll concentration, and wind speed. Many organizations and scientific groups in different countries have adopted netCDF as a standard way to represent some forms of scientific data.\nThe NetCDF format has many advantages, the most important of which is that it is self-describing, meaning that software packages can directly read the data and determine its structure, the variable names and essential metadata such as the units. This self-describing aspect of the netCDF file format means that the information needed to ensure accurate work (reduce the incidence of errors) is available within the data itself (no need for additional files). Secondly, it means that different analysis software, like Matlab, R, Python or ArcGIS (among many others), have utilities to read and work with NetCDF files. Thirdly, plotting software (e.g. Ferret, Panoply, ncview) can directly read the netCDF files for visualization.\n\n\n\nExample of metadata and data within a NetDCF file\n\n\n\n\n\nExample structure of a NetCDF file containing SST and Sea Ice over 8 time steps\n\n\n\n\n\nNASA developed the Panoply viewer that allows users to view and visualize data held in NetCDF files. Some feature is the software include:\n\nVisualize data from netCDF and HDF files\nView the metadata\nView the data\nDisplay the data in many different map projections\nDownload visualization as images\nCreate animations\nFreeware\n\n\n\n\nPanoply visualization, data, and Metadata interfaces\n\n\nPanoply is available for download at: https://www.giss.nasa.gov/tools/panoply/ and can be run on Windows, Mac and Linux computers.\nA set of “how to” instructions can be found to the following URL\nhttps://www.giss.nasa.gov/tools/panoply/help/\nBelow are a few examples to try out to get you used to visualizing data with the Panoply Viewer.\n\n:bulb: Panoply Version: The examples provided here are based on Panoply Version 5.3.3. Please note that the interface may vary depending on the version you have installed.\n\n\n\n\n\nDownload the a global netCDF file of the NOAA VIIRS, Science Quality Chlorophyll dataset from the West Coast Node ERDDAP by clicking on the link below. The link will open in your default browser and begin the download for the monthly average for March 2021. https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisVHNSQchlaMonthly.nc?chlor_a[(2021-03-01T12:00:00Z)][(0.0)][(89.75625):(-89.75626)][(-179.9812):(179.9813)]&.draw=surface&.vars=longitude|latitude|chlor_a\nLaunch Panoply.\nWhen Panoply opens, it prompts you to open a file. Open the file you just downloaded.\n\nOn the left side, Panoply displays a list of the variables contained within the file, including time, altitude, longitude, latitude, and chlorophyll-a (chlor_a).\nOn the right side, the file’s metadata is presented when you select a variable name from the list on the left. Scroll down to explore additional details about the selected variable.\n\n\n\n\n\nPanoply interface\n\n\n\nYou can visualize the chlor_a variable data.\n\nOn the leftside of the screen, double-click on the chlor_a variable. Keep the default settings and click Create.(this will take a minute, it’s a big file)\nPanoply generates an image of the chlorophyll data contained in the file, and opens a popup window “Plot Controls”.\n\n\n\n\n\nPanoply Create Plot interface\n\n\n\n\n\nPanoply generated an image of the chlorophyll data contained in the file.\n\n\n\nView the Data\n\nAbove the image, click on the “Array 1” tab. This shows you all the values of chlorophyll concentration contained in the file for each longitude/latitude pixel.\n\nAdjust the Plot Scale\n\nNavigate back to the “Plot” tab.\nWithin the Plot Controls popup window, proceed to the “Show” section and select “Scale”\nModify the “Units” setting, changing it from “scalar” to “log10.”\nUpdate the “Range” settings to a minimum of 0.02 and a maximum of 2.0.\nUnder the “Color Table” section, you can explore various color palettes. For visualizing chlorophyll concentration, the “MPL_viridis.rgb” palette is recommended, but feel free to select any palette.\n\n\n\n:bulb: Plot Controls Window In case the “Plot Controls” popup window is not visible, navigate to the “Windows” option in the top menu. There select “Plot Controls” to bring the window back into view.\n\n\nModify the Map projection\n\nWithin the Plot Controls, proceed to the “Show” and select “Map Projection”\nSelect “Mollweide (Oblique)”.\nModify the “Center on”: Lon to 180, and Lat to 0 to center the map on the Pacific ocean.\n\nModify the Map Label\n\nWithin the Plot Controls, proceed to the “Show” and select “Labels”\nModify the Title to “VIIRS SNPP Chlorophyll Concentration, March 2021”\n\nSave the image to your computer\n\nGo to the top menu and choose the “File” option.\nFrom the dropdown menu, select “Save Image” (File &gt; Save Image).\n\n\n\n\n:bulb: Additional Color Palettes Additional Panoply color palettes are available to download at https://www.giss.nasa.gov/tools/panoply/colorbars/\n\n\n\n\n\nDownload data from the West Coast ERDDAP https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisBLENDEDsstDNDaily.nc?analysed_sst%5B(2024-03-16T12:00:00Z):1:(2024-03-16T12:00:00Z)%5D%5B(-89.975):1:(89.975)%5D%5B(-179.975):1:(179.975)%5D ​\nOpen the file in Panoply. Scroll down the list of metadata. You can see it looks different from the metadata for the previous file.\n\nThis is a blended product. Identify the name of the instruments and satellites the data come from. How many satellites were used to create this gap-free SST dataset?\n\nFollowing the same steps as above, create an image of the “analysed_sst” variable with an appropriate color scale. (You do not need to use a log scale for SST though).\n\nChange the units to ºC or ºF.\nClick on “Fit to Data” to adjust the color scale or adjust the range of values manually.\nAdjust the title with the file’s date.\nSave to your computer.\n\n\n\n\n\n\n\nClose any windows showing maps.\nDouble-click on “analysed_sst” again and click ok.\nTo zoom in on a region, push the “Ctrl” key with Windows and the “command” key on Mac. You will see that your cursor changes to a magnifying glass. While keeping the “Ctrl” key down, click and drag over a region of interest. This will generate a plot of SST for that region only.\n\n\n\n\n\n\nDownload monthly wind speed data from the ASCAT instrument on the MetOps satellite for the Alaska region during September through December, 2020.\n\nDownload data from the West Coast ERDDAP using the following URL: https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdQBdivmodmday.nc?mod[(2020-09-16T00:00:00Z):1:(2020-12-16T00:00:00Z)][(10.0):1:(10.0)][(17.75):1:(68.75)][(188.0):1:(239.0)]\n\nOpen the downloaded file in Panoply\nCreate the global map by double clicking on the “mod” variable (“Modulus of Wind Speed). Keep the default settings and click”Create” to create the map.\nZoom in on the region with data by holding down the “Ctrl” key with Windows and the “command” key on Mac. While keeping the “Ctrl” key down, click and drag over the data region in the Gulf of Alaska.\nWithin the Plot Controls, proceed to Show and select “Array”.\n\nSelect a specific date/time to view the data. Try repeatedly clicking on the up arrow next to “Centered time” to animate the Gulf of Alaska entering the windy season.\n\n\n\n\n\nFour months of wind speed data of Gulf of Alaska\n\n\n\n\n\n\n​https://www.giss.nasa.gov/tools/panoply/\n​http://pro.arcgis.com/en/pro-app/help/data/multidimensional/a-quick-tour-of-netcdf-data.htm\n​https://www.nodc.noaa.gov/woce/woce_v3/wocedata_1/cmdac/primer/why.htm"
  },
  {
    "objectID": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#netcdf",
    "href": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#netcdf",
    "title": "NetCDF and Panoply tutorial",
    "section": "",
    "text": "NetCDF (Network Common Data Form) is a file format for storing multidimensional scientific data (variables), including satellite observations of variable we wll use in the course such as sea surface temperature, salinity, chlorophyll concentration, and wind speed. Many organizations and scientific groups in different countries have adopted netCDF as a standard way to represent some forms of scientific data.\nThe NetCDF format has many advantages, the most important of which is that it is self-describing, meaning that software packages can directly read the data and determine its structure, the variable names and essential metadata such as the units. This self-describing aspect of the netCDF file format means that the information needed to ensure accurate work (reduce the incidence of errors) is available within the data itself (no need for additional files). Secondly, it means that different analysis software, like Matlab, R, Python or ArcGIS (among many others), have utilities to read and work with NetCDF files. Thirdly, plotting software (e.g. Ferret, Panoply, ncview) can directly read the netCDF files for visualization.\n\n\n\nExample of metadata and data within a NetDCF file\n\n\n\n\n\nExample structure of a NetCDF file containing SST and Sea Ice over 8 time steps"
  },
  {
    "objectID": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#nasa-panoply",
    "href": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#nasa-panoply",
    "title": "NetCDF and Panoply tutorial",
    "section": "",
    "text": "NASA developed the Panoply viewer that allows users to view and visualize data held in NetCDF files. Some feature is the software include:\n\nVisualize data from netCDF and HDF files\nView the metadata\nView the data\nDisplay the data in many different map projections\nDownload visualization as images\nCreate animations\nFreeware\n\n\n\n\nPanoply visualization, data, and Metadata interfaces\n\n\nPanoply is available for download at: https://www.giss.nasa.gov/tools/panoply/ and can be run on Windows, Mac and Linux computers.\nA set of “how to” instructions can be found to the following URL\nhttps://www.giss.nasa.gov/tools/panoply/help/\nBelow are a few examples to try out to get you used to visualizing data with the Panoply Viewer.\n\n:bulb: Panoply Version: The examples provided here are based on Panoply Version 5.3.3. Please note that the interface may vary depending on the version you have installed."
  },
  {
    "objectID": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#example-1.-make-a-map-of-global-chlorophyll-a-concentration",
    "href": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#example-1.-make-a-map-of-global-chlorophyll-a-concentration",
    "title": "NetCDF and Panoply tutorial",
    "section": "",
    "text": "Download the a global netCDF file of the NOAA VIIRS, Science Quality Chlorophyll dataset from the West Coast Node ERDDAP by clicking on the link below. The link will open in your default browser and begin the download for the monthly average for March 2021. https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisVHNSQchlaMonthly.nc?chlor_a[(2021-03-01T12:00:00Z)][(0.0)][(89.75625):(-89.75626)][(-179.9812):(179.9813)]&.draw=surface&.vars=longitude|latitude|chlor_a\nLaunch Panoply.\nWhen Panoply opens, it prompts you to open a file. Open the file you just downloaded.\n\nOn the left side, Panoply displays a list of the variables contained within the file, including time, altitude, longitude, latitude, and chlorophyll-a (chlor_a).\nOn the right side, the file’s metadata is presented when you select a variable name from the list on the left. Scroll down to explore additional details about the selected variable.\n\n\n\n\n\nPanoply interface\n\n\n\nYou can visualize the chlor_a variable data.\n\nOn the leftside of the screen, double-click on the chlor_a variable. Keep the default settings and click Create.(this will take a minute, it’s a big file)\nPanoply generates an image of the chlorophyll data contained in the file, and opens a popup window “Plot Controls”.\n\n\n\n\n\nPanoply Create Plot interface\n\n\n\n\n\nPanoply generated an image of the chlorophyll data contained in the file.\n\n\n\nView the Data\n\nAbove the image, click on the “Array 1” tab. This shows you all the values of chlorophyll concentration contained in the file for each longitude/latitude pixel.\n\nAdjust the Plot Scale\n\nNavigate back to the “Plot” tab.\nWithin the Plot Controls popup window, proceed to the “Show” section and select “Scale”\nModify the “Units” setting, changing it from “scalar” to “log10.”\nUpdate the “Range” settings to a minimum of 0.02 and a maximum of 2.0.\nUnder the “Color Table” section, you can explore various color palettes. For visualizing chlorophyll concentration, the “MPL_viridis.rgb” palette is recommended, but feel free to select any palette.\n\n\n\n:bulb: Plot Controls Window In case the “Plot Controls” popup window is not visible, navigate to the “Windows” option in the top menu. There select “Plot Controls” to bring the window back into view.\n\n\nModify the Map projection\n\nWithin the Plot Controls, proceed to the “Show” and select “Map Projection”\nSelect “Mollweide (Oblique)”.\nModify the “Center on”: Lon to 180, and Lat to 0 to center the map on the Pacific ocean.\n\nModify the Map Label\n\nWithin the Plot Controls, proceed to the “Show” and select “Labels”\nModify the Title to “VIIRS SNPP Chlorophyll Concentration, March 2021”\n\nSave the image to your computer\n\nGo to the top menu and choose the “File” option.\nFrom the dropdown menu, select “Save Image” (File &gt; Save Image).\n\n\n\n\n:bulb: Additional Color Palettes Additional Panoply color palettes are available to download at https://www.giss.nasa.gov/tools/panoply/colorbars/"
  },
  {
    "objectID": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#example-2.-make-a-map-of-global-sst",
    "href": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#example-2.-make-a-map-of-global-sst",
    "title": "NetCDF and Panoply tutorial",
    "section": "",
    "text": "Download data from the West Coast ERDDAP https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisBLENDEDsstDNDaily.nc?analysed_sst%5B(2024-03-16T12:00:00Z):1:(2024-03-16T12:00:00Z)%5D%5B(-89.975):1:(89.975)%5D%5B(-179.975):1:(179.975)%5D ​\nOpen the file in Panoply. Scroll down the list of metadata. You can see it looks different from the metadata for the previous file.\n\nThis is a blended product. Identify the name of the instruments and satellites the data come from. How many satellites were used to create this gap-free SST dataset?\n\nFollowing the same steps as above, create an image of the “analysed_sst” variable with an appropriate color scale. (You do not need to use a log scale for SST though).\n\nChange the units to ºC or ºF.\nClick on “Fit to Data” to adjust the color scale or adjust the range of values manually.\nAdjust the title with the file’s date.\nSave to your computer."
  },
  {
    "objectID": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#example-3.-zooming-in-on-a-region",
    "href": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#example-3.-zooming-in-on-a-region",
    "title": "NetCDF and Panoply tutorial",
    "section": "",
    "text": "Close any windows showing maps.\nDouble-click on “analysed_sst” again and click ok.\nTo zoom in on a region, push the “Ctrl” key with Windows and the “command” key on Mac. You will see that your cursor changes to a magnifying glass. While keeping the “Ctrl” key down, click and drag over a region of interest. This will generate a plot of SST for that region only."
  },
  {
    "objectID": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#example-4-working-with-time-series-data",
    "href": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#example-4-working-with-time-series-data",
    "title": "NetCDF and Panoply tutorial",
    "section": "",
    "text": "Download monthly wind speed data from the ASCAT instrument on the MetOps satellite for the Alaska region during September through December, 2020.\n\nDownload data from the West Coast ERDDAP using the following URL: https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdQBdivmodmday.nc?mod[(2020-09-16T00:00:00Z):1:(2020-12-16T00:00:00Z)][(10.0):1:(10.0)][(17.75):1:(68.75)][(188.0):1:(239.0)]\n\nOpen the downloaded file in Panoply\nCreate the global map by double clicking on the “mod” variable (“Modulus of Wind Speed). Keep the default settings and click”Create” to create the map.\nZoom in on the region with data by holding down the “Ctrl” key with Windows and the “command” key on Mac. While keeping the “Ctrl” key down, click and drag over the data region in the Gulf of Alaska.\nWithin the Plot Controls, proceed to Show and select “Array”.\n\nSelect a specific date/time to view the data. Try repeatedly clicking on the up arrow next to “Centered time” to animate the Gulf of Alaska entering the windy season.\n\n\n\n\n\nFour months of wind speed data of Gulf of Alaska"
  },
  {
    "objectID": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#references",
    "href": "tutorials/netcdf-panoply/netcdf-panoply-tutorial.html#references",
    "title": "NetCDF and Panoply tutorial",
    "section": "",
    "text": "​https://www.giss.nasa.gov/tools/panoply/\n​http://pro.arcgis.com/en/pro-app/help/data/multidimensional/a-quick-tour-of-netcdf-data.htm\n​https://www.nodc.noaa.gov/woce/woce_v3/wocedata_1/cmdac/primer/why.htm"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "history | Modified Feb 2026\n\n\nThis tutorial will demonstrate how to extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like those produced by an animal telemetry tag, and ship track, or a glider track.\n\n\n\n\nImporting track data in csv file to data frame\nPlotting the latitude/longitude points onto a map\nUsing rerddapXtraco function to extract satellite data from an ERDDAP data server along a track\nPlotting the satellite data onto a map\nSubsetting and analyzing data for individual animals\nComparing satellite-derived environmental conditions across time\n\n\n\n\nChlorophyll a concentration, the European Space Agency’s Ocean Colour Climate Change Initiative (OC-CCI) Monthly dataset v6.0\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nLoggerhead turtle telemetry track data\nThe turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. This dataset has been subsampled to reduce the data requests needed for this tutorial from over 1200 to 25. The track data are stored in the data folder in this project folder.\nDusky shark satellite tag data\nAn extended example uses satellite tag data from dusky sharks provided by Chuck Bangley (Smithsonian Environmental Research Center). This dataset includes daily positions from multiple tagged individuals and demonstrates how the same ERDDAP extraction workflow can be applied to a different species and telemetry format. The shark example highlights additional steps such as data validation, subsetting individual animals, and comparing satellite-derived chlorophyll values across years.\nChlorophyll-a, Aqua MODIS, NPP, L3SMI, Global, 4km, Science Quality, 2003-present (8 Day Composite)\n\n\n\n# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                       \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\n# Import csv file into a data frame\nturtle_df &lt;- read.csv(\"../data/25317_05_subsampled.dat\")\n# Show 3 rows from the data frame\nhead(turtle_df,3)\n##   mean_lon mean_lat year month day\n## 1 176.6194 32.67873 2005     5   4\n## 2 175.8609 35.05773 2005     6  23\n## 3 180.5926 40.40576 2005     8  12\n\n\n\n# Download world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Map turtle tracks\nggplot(turtle_df, aes(mean_lon,mean_lat)) +\n  geom_path(group=1)+\n  geom_point(aes(x=mean_lon,y=mean_lat), pch=1, size=2 )+\n  geom_point(aes(x=mean_lon[1],y=mean_lat[1]),fill=\"green\", shape=24, size=3)+\n  geom_point(aes(x=mean_lon[length(mean_lon)],y=mean_lat[length(mean_lat)]), shape=22, size=3, fill=\"red\")+\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60))+\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with start (green) and end location (red)\")+\n  theme(plot.title=element_text(hjust=0.5), aspect.ratio=1/2)\n\nIn this exercise, two different ways of extracting data from ERDDAP data server along a track of xyt points are demonstrated:\n\nUsing the rerddapXtracto package which was written specifically for this task\nBy manually constructing a URL with the data data request\n\n\n\nWe will use the `rxtracto function of the rerddapXtracto package, which was written to simplify data extraction from ERDDAP servers.\nLet’s use data from the monthly product of the OC-CCI datasets.\nThe ERDDAP URL to the monthly product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-12-01 (at the day of this writing), which covers the track time range of 2005-05-04 to 2008-08-16.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n# Set dataset ID\ndataset &lt;- 'esa-cci-chla-monthly-v6-0'\n\n# Get data information from ERDDAP server\ndataInfo &lt;- rerddap::info(dataset, url= \"https://oceanwatch.pifsc.noaa.gov/erddap\")\n\n\n\n\nrerddap::info returns the metadata of the requested dataset. We can first understand the attributes dataInfo includes then examine each attribute.\n# Display the metadata\ndataInfo\n## &lt;ERDDAP info&gt; esa-cci-chla-monthly-v6-0 \n##  Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-04T00:00:00Z, 2023-12-01T00:00:00Z) \n##      latitude: (-89.97916666666666, 89.97916666666667) \n##      longitude: (0.020833333333314386, 359.97916666666663) \n##  Variables:  \n##      chlor_a: \n##          Units: mg m-3 \n##      chlor_a_log10_bias: \n##      chlor_a_log10_rmsd: \n##      MERIS_nobs_sum: \n##      MODISA_nobs_sum: \n##      OLCI_A_nobs_sum: \n##      OLCI_B_nobs_sum: \n##      SeaWiFS_nobs_sum: \n##      total_nobs_sum: \n##      VIIRS_nobs_sum:\n# Display data attributes\nnames(dataInfo)\n## [1] \"variables\" \"alldata\"   \"base_url\"\n# Examine attribute: variables\ndataInfo$variables\n##         variable_name data_type actual_range\n## 1             chlor_a     float             \n## 2  chlor_a_log10_bias     float             \n## 3  chlor_a_log10_rmsd     float             \n## 4      MERIS_nobs_sum     float             \n## 5     MODISA_nobs_sum     float             \n## 6     OLCI_A_nobs_sum     float             \n## 7     OLCI_B_nobs_sum     float             \n## 8    SeaWiFS_nobs_sum     float             \n## 9      total_nobs_sum     float             \n## 10     VIIRS_nobs_sum     float\n# Distribute attributes of dataInfo$alldata\nnames(dataInfo$alldata)\n##  [1] \"NC_GLOBAL\"          \"time\"               \"latitude\"          \n##  [4] \"longitude\"          \"chlor_a\"            \"MERIS_nobs_sum\"    \n##  [7] \"MODISA_nobs_sum\"    \"OLCI_A_nobs_sum\"    \"OLCI_B_nobs_sum\"   \n## [10] \"SeaWiFS_nobs_sum\"   \"VIIRS_nobs_sum\"     \"chlor_a_log10_bias\"\n## [13] \"chlor_a_log10_rmsd\" \"total_nobs_sum\"\n\n\nFirst we need to define the bounding box within which to search for coordinates. The rxtracto function allows you to set the size of the box used to collect data around the track points using the xlen and ylen arguments. The values for xlen and ylen are in degrees. For our example, we can use 0.2 degrees for both arguments. Note: You can also submit vectors for xlen and ylen, as long as they are the same length as xcoord, ycoord, and tcoord if you want to set a different search radius around each track point.\n# Set the variable we want to extract data from:\nparameter &lt;- 'chlor_a'\n\n# Set xlen, ylen to 0.2 degree\nxlen &lt;- 0.2 \nylen &lt;- 0.2\n\n# Create date column using year, month and day in a format ERDDAP will understand (eg. 2008-12-15)\nturtle_df$date &lt;- as.Date(paste(turtle_df$year, turtle_df$month, turtle_df$day, sep=\"-\"))\n\n# Get variables x, y, t coordinates from turtle track data\nxcoords &lt;- turtle_df$mean_lon\nycoords &lt;- turtle_df$mean_lat\ntcoords &lt;- turtle_df$date\n\n# Extract satellite data using x, y, t coordinates from turtle track data\nchl_track &lt;- rxtracto(dataInfo, \n                  parameter=parameter, \n                  xcoord=xcoords, ycoord=ycoords, \n                  tcoord=tcoords, xlen=xlen, ylen=ylen)\n\n\n\n\n# Check all variables extracted using rxtracto\nchl_track\n## $`mean chlor_a`\n##  [1] 0.26779765 0.12073122 0.30777924 0.31780368 0.28884829 0.36146353\n##  [7] 0.22923882 0.11644071 0.09268904 0.05536651 0.18447913 0.22765385\n## [13] 0.23869553 0.24669819 0.35838123 0.09624625 0.12024124 0.11400095\n## [19] 0.10017463 0.09397742 0.08515869 0.06913812 0.14883095 0.51560753\n## [25] 0.65806269\n## \n## $`stdev chlor_a`\n##  [1] 0.032191816 0.007231171 0.036716832 0.041052758 0.027952051 0.053364804\n##  [7] 0.024394244 0.007282479 0.003880810 0.001490017 0.040774493 0.025363286\n## [13] 0.014782180 0.013523678 0.036640145 0.004842596 0.004098601 0.003910613\n## [19] 0.003537558 0.005928580 0.007001476 0.004942355 0.011980482 0.099209610\n## [25] 0.149563991\n## \n## $n\n##  [1] 36 36 36 27 36 30 36 36 30 30 30 30 36 30 36 30 36 36 36 30 36 30 36 36 36\n## \n## $`satellite date`\n##  [1] \"2005-05-01T00:00:00Z\" \"2005-07-01T00:00:00Z\" \"2005-08-01T00:00:00Z\"\n##  [4] \"2005-10-01T00:00:00Z\" \"2005-12-01T00:00:00Z\" \"2006-01-01T00:00:00Z\"\n##  [7] \"2006-03-01T00:00:00Z\" \"2006-05-01T00:00:00Z\" \"2006-06-01T00:00:00Z\"\n## [10] \"2006-08-01T00:00:00Z\" \"2006-09-01T00:00:00Z\" \"2006-11-01T00:00:00Z\"\n## [13] \"2007-01-01T00:00:00Z\" \"2007-02-01T00:00:00Z\" \"2007-04-01T00:00:00Z\"\n## [16] \"2007-06-01T00:00:00Z\" \"2007-07-01T00:00:00Z\" \"2007-09-01T00:00:00Z\"\n## [19] \"2007-11-01T00:00:00Z\" \"2007-12-01T00:00:00Z\" \"2008-02-01T00:00:00Z\"\n## [22] \"2008-04-01T00:00:00Z\" \"2008-05-01T00:00:00Z\" \"2008-07-01T00:00:00Z\"\n## [25] \"2008-08-01T00:00:00Z\"\n## \n## $`requested lon min`\n##  [1] 176.5194 175.7609 180.4926 183.4102 186.8997 193.2152 198.9158 196.2679\n##  [9] 194.2116 192.7545 193.9788 191.9444 191.6600 194.9631 199.2066 205.5050\n## [17] 210.1805 215.6225 222.9073 225.5386 232.3064 239.4530 245.7716 248.4710\n## [25] 245.6579\n## \n## $`requested lon max`\n##  [1] 176.7194 175.9609 180.6926 183.6102 187.0997 193.4152 199.1158 196.4679\n##  [9] 194.4116 192.9545 194.1788 192.1444 191.8600 195.1631 199.4066 205.7050\n## [17] 210.3805 215.8225 223.1073 225.7386 232.5064 239.6530 245.9716 248.6710\n## [25] 245.8579\n## \n## $`requested lat min`\n##  [1] 32.57873 34.95773 40.30576 41.58480 37.26623 32.03793 32.01126 34.81224\n##  [9] 34.59661 36.99175 41.66933 38.12796 34.63858 31.63964 34.24324 35.02771\n## [17] 38.36083 39.23749 35.76793 30.08540 28.22859 25.88108 24.73662 23.62417\n## [25] 26.68177\n## \n## $`requested lat max`\n##  [1] 32.77873 35.15773 40.50576 41.78480 37.46623 32.23793 32.21126 35.01224\n##  [9] 34.79661 37.19175 41.86933 38.32796 34.83858 31.83964 34.44324 35.22771\n## [17] 38.56083 39.43749 35.96793 30.28540 28.42859 26.08108 24.93662 23.82417\n## [25] 26.88177\n## \n## $`requested z min`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## \n## $`requested z max`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## \n## $`requested date`\n##  [1] \"2005-05-04\" \"2005-06-23\" \"2005-08-12\" \"2005-10-01\" \"2005-11-20\"\n##  [6] \"2006-01-09\" \"2006-02-28\" \"2006-04-19\" \"2006-06-08\" \"2006-07-28\"\n## [11] \"2006-09-16\" \"2006-11-05\" \"2006-12-25\" \"2007-02-13\" \"2007-04-04\"\n## [16] \"2007-05-24\" \"2007-07-13\" \"2007-09-01\" \"2007-10-21\" \"2007-12-10\"\n## [21] \"2008-01-29\" \"2008-03-19\" \"2008-05-08\" \"2008-06-27\" \"2008-08-16\"\n## \n## $`median chlor_a`\n##  [1] 0.26985641 0.11935977 0.31413330 0.31312889 0.28226255 0.35456662\n##  [7] 0.22596541 0.11711950 0.09256660 0.05540323 0.18355133 0.22467585\n## [13] 0.24202415 0.24848759 0.34953472 0.09518800 0.11983451 0.11379882\n## [19] 0.10012896 0.09296544 0.08735247 0.06766215 0.14883141 0.49834299\n## [25] 0.67895702\n## \n## $`mad chlor_a`\n##  [1] 0.030100095 0.008344179 0.039171724 0.027213317 0.023952735 0.049566912\n##  [7] 0.022928175 0.009027836 0.003463391 0.001267676 0.035848973 0.026539111\n## [13] 0.016244819 0.011793729 0.035606685 0.003954114 0.002984454 0.002953619\n## [19] 0.002999692 0.003767908 0.003242842 0.003565519 0.015092995 0.109981245\n## [25] 0.133971250\n## \n## attr(,\"row.names\")\n##  [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n## [16] \"16\" \"17\" \"18\" \"19\" \"20\" \"21\" \"22\" \"23\" \"24\" \"25\"\n## attr(,\"class\")\n## [1] \"list\"          \"rxtractoTrack\"\nrxtracto computes statistics using all the pixels found in the search radius around each track point.\n\n\n\nWe will use the “plotTrack” function to plot the results. “plotTrack” is a function of the “rerddapXtracto” package designed specifically to plot the results of the “rxtracto” function. It provides an easy way to make a quick plot, however it’s not very customizable.\n# Plot tracks with color: algae specifically designed for chlorophyll\nplotTrack(chl_track, xcoords, ycoords, tcoords, size=3, plotColor = 'viridis')\n\n\n\n\nOne of the nice features of the “plotTrack” function is that it is very easy to make an animation of the track data. This will take a minute to run. It creates an animated gif that will display in the Rstudio viewer window once the encoding to gif is done.\n# Animate tracks\n\nmake180 &lt;- function(lon) {\n    ind &lt;- which(lon &gt; 180)\n    lon[ind] &lt;- lon[ind] - 360\n   return(lon)\n}\n\nplotTrack(chl_track, make180(xcoords), ycoords, tcoords, plotColor = 'viridis',\n                    animate = TRUE, cumulative = TRUE)\n## # A tibble: 25 × 7\n##    format width height colorspace matte filesize density\n##    &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n##  1 gif      672    480 sRGB       TRUE         0 72x72  \n##  2 gif      672    480 sRGB       TRUE         0 72x72  \n##  3 gif      672    480 sRGB       TRUE         0 72x72  \n##  4 gif      672    480 sRGB       TRUE         0 72x72  \n##  5 gif      672    480 sRGB       TRUE         0 72x72  \n##  6 gif      672    480 sRGB       TRUE         0 72x72  \n##  7 gif      672    480 sRGB       TRUE         0 72x72  \n##  8 gif      672    480 sRGB       TRUE         0 72x72  \n##  9 gif      672    480 sRGB       TRUE         0 72x72  \n## 10 gif      672    480 sRGB       TRUE         0 72x72  \n## # ℹ 15 more rows\n\n\n\n\n\nIf we to do an customization of the plot, its better to plot the dat ausing ggplot. We will first create a data frame that contains longitudes and latitudes from the turtle and associated satellite chlor-a values.\n# Create a data frame of coords from turtle and chlor_a values \nnew_df &lt;- as.data.frame(cbind(xcoords, ycoords,  \n                              chl_track$`requested lon min`, \n                              chl_track$`requested lon max`, \n                              chl_track$`requested lat min`, \n                              chl_track$`requested lon max`,  \n                              chl_track$`mean chlor_a`))\n\n# Set variable names\nnames(new_df) &lt;- c(\"Lon\", \"Lat\", \"Matchup_Lon_Lower\", \"Matchup_Lon_Upper\", \"Matchup_Lat_Lower\", \"Matchup_Lat_Upper\",  \"Chlor_a\")\nwrite.csv(new_df, \"matchup_df.csv\")\n\n\n\n# Import world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Draw the track positions with associated chlora values\nggplot(new_df) +\n  geom_point(aes(Lon,Lat,color=log(Chlor_a))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nFirst we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\ndata_url = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_1d_2018_0.csv?chlor_a\"\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data is severely affected by clouds (i.e. lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer gaps.\n# Set erddap address\nerddap &lt;- \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0.csv?chlor_a\"\n\n# Get longitude and latitude from turtle track data\nlon &lt;- turtle_df$mean_lon\nlat &lt;- turtle_df$mean_lat\n\n# Get time from turtle track data and convert into ERDDAP date format\ndates &lt;- mdy.date(turtle_df$month,turtle_df$day,turtle_df$year)\ndates2 &lt;- format(as.Date(dates), \"%Y-%m-%d\")\n\n# Initatilize tot variable where data will be downloaded to\ntot &lt;- rep(NA, 4)\n\n# Loop through each turtle track data\nfor (i in 1:dim(turtle_df)[1]) {\n\n   # Create erddap URL by adding lat, lon, dates of each track point \n   url &lt;-  paste(erddap, \"[(\", dates2[i], \"):1:(\", dates2[i], \")][(\", lat[i], \"):1:(\", lat[i], \")][(\", lon[i], \"):1:(\", lon[i], \")]\", sep = \"\")  \n   \n   # Request and load satelite data from ERDDAP\n   new &lt;- read.csv(url, skip=2, header = FALSE) \n   \n   # Append the data\n   tot &lt;- rbind(tot, new)   \n}\n\n# Delete the first row (default column names)\ntot &lt;- tot[-1, ]\n\n# Rename columns\nnames(tot) &lt;- c(\"chlo_date\", \"matched_lat\", \"matched_lon\", \"matched_chl.m\")\n\n# Create data frame combining turtle track data and the chlo-a data\nchl_track2 &lt;- data.frame(turtle_df, tot)\n\n# Write the data frame to csv file\nwrite.csv(chl_track2, 'turtle-track-chl.m.csv', row.names = FALSE)\n\n\n\n# Draw the track positions with associated chlora values\nggplot(chl_track2) +\n  geom_point(aes(mean_lon,mean_lat,color=log(matched_chl.m))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nHow do the chlorophyll values of the turtle track compare to values in the surrounding environment? Meaning does the turtle seem to have a preference for certain chlorophyll values? To look at this we will plot a histograms of the track chl valuesand those of the surrounding area.\nFirst we will get a 3D block of chl data from the region and of the turtle track over the span of time the turtle was in that area. We will use the ‘xtracto_3d’ function of rerddapXtracto to get the data. This data call will take a few minutes.\nchl_grid &lt;- rxtracto_3D(dataInfo, \n                  parameter=parameter, \n                  xcoord=c(min(xcoords),max(xcoords)), \n                  ycoord=c(min(ycoords),max(ycoords)), \n                  tcoord=c(min(tcoords),max(tcoords)))\n\nchl_area &lt;- as.vector(chl_grid$chlor_a) \n\n# remove NA values \nchl_area &lt;- chl_area[!is.na(chl_area)]\n\n# vector or turtle chlorophyll \n\nchl_turtle &lt;- chl_track$`mean chlor_a`\nNow we we plot histograms of all the chlorphyll values in the area, and those of the turtle track. Since we subset the turtletrack, and only have 25 points for this subsampopled dataset the turtle histogram isn’t as useful as it would be with a larger dataset.\nggplot(as.data.frame(chl_area)) + \n      geom_histogram(aes(x=chl_area,y=after_stat(density),color = \"darkgray\",fill='Area'),color='black', bins=50) + \n      geom_histogram(data=as.data.frame(chl_turtle), aes(x=chl_turtle,y=after_stat(density),color='green', fill='Turtle'),color='black',bins=50, alpha=.4) + \n      scale_x_continuous(limits = c(0,.9), expand = c(0, 0)) + \n      scale_y_continuous(limits = c(0,15), expand = c(0, 0)) +\n      labs(x='Chlorophyll values',y='Density') + \n      theme_bw() + \n      scale_fill_manual(values=c(\"darkgray\",\"green\"),'')\n\n\n\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html \\ This dataset is a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name.\n\n\n\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ \\ This dataset will likely be on a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name. \\ Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\n\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorDaily_Lon0360.html"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#objective",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#objective",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "This tutorial will demonstrate how to extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like those produced by an animal telemetry tag, and ship track, or a glider track."
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "Importing track data in csv file to data frame\nPlotting the latitude/longitude points onto a map\nUsing rerddapXtraco function to extract satellite data from an ERDDAP data server along a track\nPlotting the satellite data onto a map\nSubsetting and analyzing data for individual animals\nComparing satellite-derived environmental conditions across time"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#datasets-used",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#datasets-used",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "Chlorophyll a concentration, the European Space Agency’s Ocean Colour Climate Change Initiative (OC-CCI) Monthly dataset v6.0\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nLoggerhead turtle telemetry track data\nThe turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. This dataset has been subsampled to reduce the data requests needed for this tutorial from over 1200 to 25. The track data are stored in the data folder in this project folder.\nDusky shark satellite tag data\nAn extended example uses satellite tag data from dusky sharks provided by Chuck Bangley (Smithsonian Environmental Research Center). This dataset includes daily positions from multiple tagged individuals and demonstrates how the same ERDDAP extraction workflow can be applied to a different species and telemetry format. The shark example highlights additional steps such as data validation, subsetting individual animals, and comparing satellite-derived chlorophyll values across years.\nChlorophyll-a, Aqua MODIS, NPP, L3SMI, Global, 4km, Science Quality, 2003-present (8 Day Composite)"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#install-required-packages-and-load-libraries",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#install-required-packages-and-load-libraries",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                       \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#import-the-track-data-into-a-data-frame",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#import-the-track-data-into-a-data-frame",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Import csv file into a data frame\nturtle_df &lt;- read.csv(\"../data/25317_05_subsampled.dat\")\n# Show 3 rows from the data frame\nhead(turtle_df,3)\n##   mean_lon mean_lat year month day\n## 1 176.6194 32.67873 2005     5   4\n## 2 175.8609 35.05773 2005     6  23\n## 3 180.5926 40.40576 2005     8  12"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Download world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Map turtle tracks\nggplot(turtle_df, aes(mean_lon,mean_lat)) +\n  geom_path(group=1)+\n  geom_point(aes(x=mean_lon,y=mean_lat), pch=1, size=2 )+\n  geom_point(aes(x=mean_lon[1],y=mean_lat[1]),fill=\"green\", shape=24, size=3)+\n  geom_point(aes(x=mean_lon[length(mean_lon)],y=mean_lat[length(mean_lat)]), shape=22, size=3, fill=\"red\")+\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60))+\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with start (green) and end location (red)\")+\n  theme(plot.title=element_text(hjust=0.5), aspect.ratio=1/2)\n\nIn this exercise, two different ways of extracting data from ERDDAP data server along a track of xyt points are demonstrated:\n\nUsing the rerddapXtracto package which was written specifically for this task\nBy manually constructing a URL with the data data request\n\n\n\nWe will use the `rxtracto function of the rerddapXtracto package, which was written to simplify data extraction from ERDDAP servers.\nLet’s use data from the monthly product of the OC-CCI datasets.\nThe ERDDAP URL to the monthly product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-12-01 (at the day of this writing), which covers the track time range of 2005-05-04 to 2008-08-16.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n# Set dataset ID\ndataset &lt;- 'esa-cci-chla-monthly-v6-0'\n\n# Get data information from ERDDAP server\ndataInfo &lt;- rerddap::info(dataset, url= \"https://oceanwatch.pifsc.noaa.gov/erddap\")"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#examine-metadata",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#examine-metadata",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "rerddap::info returns the metadata of the requested dataset. We can first understand the attributes dataInfo includes then examine each attribute.\n# Display the metadata\ndataInfo\n## &lt;ERDDAP info&gt; esa-cci-chla-monthly-v6-0 \n##  Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-04T00:00:00Z, 2023-12-01T00:00:00Z) \n##      latitude: (-89.97916666666666, 89.97916666666667) \n##      longitude: (0.020833333333314386, 359.97916666666663) \n##  Variables:  \n##      chlor_a: \n##          Units: mg m-3 \n##      chlor_a_log10_bias: \n##      chlor_a_log10_rmsd: \n##      MERIS_nobs_sum: \n##      MODISA_nobs_sum: \n##      OLCI_A_nobs_sum: \n##      OLCI_B_nobs_sum: \n##      SeaWiFS_nobs_sum: \n##      total_nobs_sum: \n##      VIIRS_nobs_sum:\n# Display data attributes\nnames(dataInfo)\n## [1] \"variables\" \"alldata\"   \"base_url\"\n# Examine attribute: variables\ndataInfo$variables\n##         variable_name data_type actual_range\n## 1             chlor_a     float             \n## 2  chlor_a_log10_bias     float             \n## 3  chlor_a_log10_rmsd     float             \n## 4      MERIS_nobs_sum     float             \n## 5     MODISA_nobs_sum     float             \n## 6     OLCI_A_nobs_sum     float             \n## 7     OLCI_B_nobs_sum     float             \n## 8    SeaWiFS_nobs_sum     float             \n## 9      total_nobs_sum     float             \n## 10     VIIRS_nobs_sum     float\n# Distribute attributes of dataInfo$alldata\nnames(dataInfo$alldata)\n##  [1] \"NC_GLOBAL\"          \"time\"               \"latitude\"          \n##  [4] \"longitude\"          \"chlor_a\"            \"MERIS_nobs_sum\"    \n##  [7] \"MODISA_nobs_sum\"    \"OLCI_A_nobs_sum\"    \"OLCI_B_nobs_sum\"   \n## [10] \"SeaWiFS_nobs_sum\"   \"VIIRS_nobs_sum\"     \"chlor_a_log10_bias\"\n## [13] \"chlor_a_log10_rmsd\" \"total_nobs_sum\"\n\n\nFirst we need to define the bounding box within which to search for coordinates. The rxtracto function allows you to set the size of the box used to collect data around the track points using the xlen and ylen arguments. The values for xlen and ylen are in degrees. For our example, we can use 0.2 degrees for both arguments. Note: You can also submit vectors for xlen and ylen, as long as they are the same length as xcoord, ycoord, and tcoord if you want to set a different search radius around each track point.\n# Set the variable we want to extract data from:\nparameter &lt;- 'chlor_a'\n\n# Set xlen, ylen to 0.2 degree\nxlen &lt;- 0.2 \nylen &lt;- 0.2\n\n# Create date column using year, month and day in a format ERDDAP will understand (eg. 2008-12-15)\nturtle_df$date &lt;- as.Date(paste(turtle_df$year, turtle_df$month, turtle_df$day, sep=\"-\"))\n\n# Get variables x, y, t coordinates from turtle track data\nxcoords &lt;- turtle_df$mean_lon\nycoords &lt;- turtle_df$mean_lat\ntcoords &lt;- turtle_df$date\n\n# Extract satellite data using x, y, t coordinates from turtle track data\nchl_track &lt;- rxtracto(dataInfo, \n                  parameter=parameter, \n                  xcoord=xcoords, ycoord=ycoords, \n                  tcoord=tcoords, xlen=xlen, ylen=ylen)"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#check-the-output-of-the-rxtracto-function",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#check-the-output-of-the-rxtracto-function",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Check all variables extracted using rxtracto\nchl_track\n## $`mean chlor_a`\n##  [1] 0.26779765 0.12073122 0.30777924 0.31780368 0.28884829 0.36146353\n##  [7] 0.22923882 0.11644071 0.09268904 0.05536651 0.18447913 0.22765385\n## [13] 0.23869553 0.24669819 0.35838123 0.09624625 0.12024124 0.11400095\n## [19] 0.10017463 0.09397742 0.08515869 0.06913812 0.14883095 0.51560753\n## [25] 0.65806269\n## \n## $`stdev chlor_a`\n##  [1] 0.032191816 0.007231171 0.036716832 0.041052758 0.027952051 0.053364804\n##  [7] 0.024394244 0.007282479 0.003880810 0.001490017 0.040774493 0.025363286\n## [13] 0.014782180 0.013523678 0.036640145 0.004842596 0.004098601 0.003910613\n## [19] 0.003537558 0.005928580 0.007001476 0.004942355 0.011980482 0.099209610\n## [25] 0.149563991\n## \n## $n\n##  [1] 36 36 36 27 36 30 36 36 30 30 30 30 36 30 36 30 36 36 36 30 36 30 36 36 36\n## \n## $`satellite date`\n##  [1] \"2005-05-01T00:00:00Z\" \"2005-07-01T00:00:00Z\" \"2005-08-01T00:00:00Z\"\n##  [4] \"2005-10-01T00:00:00Z\" \"2005-12-01T00:00:00Z\" \"2006-01-01T00:00:00Z\"\n##  [7] \"2006-03-01T00:00:00Z\" \"2006-05-01T00:00:00Z\" \"2006-06-01T00:00:00Z\"\n## [10] \"2006-08-01T00:00:00Z\" \"2006-09-01T00:00:00Z\" \"2006-11-01T00:00:00Z\"\n## [13] \"2007-01-01T00:00:00Z\" \"2007-02-01T00:00:00Z\" \"2007-04-01T00:00:00Z\"\n## [16] \"2007-06-01T00:00:00Z\" \"2007-07-01T00:00:00Z\" \"2007-09-01T00:00:00Z\"\n## [19] \"2007-11-01T00:00:00Z\" \"2007-12-01T00:00:00Z\" \"2008-02-01T00:00:00Z\"\n## [22] \"2008-04-01T00:00:00Z\" \"2008-05-01T00:00:00Z\" \"2008-07-01T00:00:00Z\"\n## [25] \"2008-08-01T00:00:00Z\"\n## \n## $`requested lon min`\n##  [1] 176.5194 175.7609 180.4926 183.4102 186.8997 193.2152 198.9158 196.2679\n##  [9] 194.2116 192.7545 193.9788 191.9444 191.6600 194.9631 199.2066 205.5050\n## [17] 210.1805 215.6225 222.9073 225.5386 232.3064 239.4530 245.7716 248.4710\n## [25] 245.6579\n## \n## $`requested lon max`\n##  [1] 176.7194 175.9609 180.6926 183.6102 187.0997 193.4152 199.1158 196.4679\n##  [9] 194.4116 192.9545 194.1788 192.1444 191.8600 195.1631 199.4066 205.7050\n## [17] 210.3805 215.8225 223.1073 225.7386 232.5064 239.6530 245.9716 248.6710\n## [25] 245.8579\n## \n## $`requested lat min`\n##  [1] 32.57873 34.95773 40.30576 41.58480 37.26623 32.03793 32.01126 34.81224\n##  [9] 34.59661 36.99175 41.66933 38.12796 34.63858 31.63964 34.24324 35.02771\n## [17] 38.36083 39.23749 35.76793 30.08540 28.22859 25.88108 24.73662 23.62417\n## [25] 26.68177\n## \n## $`requested lat max`\n##  [1] 32.77873 35.15773 40.50576 41.78480 37.46623 32.23793 32.21126 35.01224\n##  [9] 34.79661 37.19175 41.86933 38.32796 34.83858 31.83964 34.44324 35.22771\n## [17] 38.56083 39.43749 35.96793 30.28540 28.42859 26.08108 24.93662 23.82417\n## [25] 26.88177\n## \n## $`requested z min`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## \n## $`requested z max`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## \n## $`requested date`\n##  [1] \"2005-05-04\" \"2005-06-23\" \"2005-08-12\" \"2005-10-01\" \"2005-11-20\"\n##  [6] \"2006-01-09\" \"2006-02-28\" \"2006-04-19\" \"2006-06-08\" \"2006-07-28\"\n## [11] \"2006-09-16\" \"2006-11-05\" \"2006-12-25\" \"2007-02-13\" \"2007-04-04\"\n## [16] \"2007-05-24\" \"2007-07-13\" \"2007-09-01\" \"2007-10-21\" \"2007-12-10\"\n## [21] \"2008-01-29\" \"2008-03-19\" \"2008-05-08\" \"2008-06-27\" \"2008-08-16\"\n## \n## $`median chlor_a`\n##  [1] 0.26985641 0.11935977 0.31413330 0.31312889 0.28226255 0.35456662\n##  [7] 0.22596541 0.11711950 0.09256660 0.05540323 0.18355133 0.22467585\n## [13] 0.24202415 0.24848759 0.34953472 0.09518800 0.11983451 0.11379882\n## [19] 0.10012896 0.09296544 0.08735247 0.06766215 0.14883141 0.49834299\n## [25] 0.67895702\n## \n## $`mad chlor_a`\n##  [1] 0.030100095 0.008344179 0.039171724 0.027213317 0.023952735 0.049566912\n##  [7] 0.022928175 0.009027836 0.003463391 0.001267676 0.035848973 0.026539111\n## [13] 0.016244819 0.011793729 0.035606685 0.003954114 0.002984454 0.002953619\n## [19] 0.002999692 0.003767908 0.003242842 0.003565519 0.015092995 0.109981245\n## [25] 0.133971250\n## \n## attr(,\"row.names\")\n##  [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n## [16] \"16\" \"17\" \"18\" \"19\" \"20\" \"21\" \"22\" \"23\" \"24\" \"25\"\n## attr(,\"class\")\n## [1] \"list\"          \"rxtractoTrack\"\nrxtracto computes statistics using all the pixels found in the search radius around each track point."
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#plotting-the-results-using-plottrack",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#plotting-the-results-using-plottrack",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "We will use the “plotTrack” function to plot the results. “plotTrack” is a function of the “rerddapXtracto” package designed specifically to plot the results of the “rxtracto” function. It provides an easy way to make a quick plot, however it’s not very customizable.\n# Plot tracks with color: algae specifically designed for chlorophyll\nplotTrack(chl_track, xcoords, ycoords, tcoords, size=3, plotColor = 'viridis')"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#animating-the-track",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#animating-the-track",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "One of the nice features of the “plotTrack” function is that it is very easy to make an animation of the track data. This will take a minute to run. It creates an animated gif that will display in the Rstudio viewer window once the encoding to gif is done.\n# Animate tracks\n\nmake180 &lt;- function(lon) {\n    ind &lt;- which(lon &gt; 180)\n    lon[ind] &lt;- lon[ind] - 360\n   return(lon)\n}\n\nplotTrack(chl_track, make180(xcoords), ycoords, tcoords, plotColor = 'viridis',\n                    animate = TRUE, cumulative = TRUE)\n## # A tibble: 25 × 7\n##    format width height colorspace matte filesize density\n##    &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n##  1 gif      672    480 sRGB       TRUE         0 72x72  \n##  2 gif      672    480 sRGB       TRUE         0 72x72  \n##  3 gif      672    480 sRGB       TRUE         0 72x72  \n##  4 gif      672    480 sRGB       TRUE         0 72x72  \n##  5 gif      672    480 sRGB       TRUE         0 72x72  \n##  6 gif      672    480 sRGB       TRUE         0 72x72  \n##  7 gif      672    480 sRGB       TRUE         0 72x72  \n##  8 gif      672    480 sRGB       TRUE         0 72x72  \n##  9 gif      672    480 sRGB       TRUE         0 72x72  \n## 10 gif      672    480 sRGB       TRUE         0 72x72  \n## # ℹ 15 more rows"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#plotting-the-results-using-ggplot",
    "href": "tutorials/matchup-satellite-data-to-track-locations/r/matchup-satellite-data-to-track-locations.html#plotting-the-results-using-ggplot",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "If we to do an customization of the plot, its better to plot the dat ausing ggplot. We will first create a data frame that contains longitudes and latitudes from the turtle and associated satellite chlor-a values.\n# Create a data frame of coords from turtle and chlor_a values \nnew_df &lt;- as.data.frame(cbind(xcoords, ycoords,  \n                              chl_track$`requested lon min`, \n                              chl_track$`requested lon max`, \n                              chl_track$`requested lat min`, \n                              chl_track$`requested lon max`,  \n                              chl_track$`mean chlor_a`))\n\n# Set variable names\nnames(new_df) &lt;- c(\"Lon\", \"Lat\", \"Matchup_Lon_Lower\", \"Matchup_Lon_Upper\", \"Matchup_Lat_Lower\", \"Matchup_Lat_Upper\",  \"Chlor_a\")\nwrite.csv(new_df, \"matchup_df.csv\")\n\n\n\n# Import world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Draw the track positions with associated chlora values\nggplot(new_df) +\n  geom_point(aes(Lon,Lat,color=log(Chlor_a))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nFirst we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\ndata_url = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_1d_2018_0.csv?chlor_a\"\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data is severely affected by clouds (i.e. lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer gaps.\n# Set erddap address\nerddap &lt;- \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0.csv?chlor_a\"\n\n# Get longitude and latitude from turtle track data\nlon &lt;- turtle_df$mean_lon\nlat &lt;- turtle_df$mean_lat\n\n# Get time from turtle track data and convert into ERDDAP date format\ndates &lt;- mdy.date(turtle_df$month,turtle_df$day,turtle_df$year)\ndates2 &lt;- format(as.Date(dates), \"%Y-%m-%d\")\n\n# Initatilize tot variable where data will be downloaded to\ntot &lt;- rep(NA, 4)\n\n# Loop through each turtle track data\nfor (i in 1:dim(turtle_df)[1]) {\n\n   # Create erddap URL by adding lat, lon, dates of each track point \n   url &lt;-  paste(erddap, \"[(\", dates2[i], \"):1:(\", dates2[i], \")][(\", lat[i], \"):1:(\", lat[i], \")][(\", lon[i], \"):1:(\", lon[i], \")]\", sep = \"\")  \n   \n   # Request and load satelite data from ERDDAP\n   new &lt;- read.csv(url, skip=2, header = FALSE) \n   \n   # Append the data\n   tot &lt;- rbind(tot, new)   \n}\n\n# Delete the first row (default column names)\ntot &lt;- tot[-1, ]\n\n# Rename columns\nnames(tot) &lt;- c(\"chlo_date\", \"matched_lat\", \"matched_lon\", \"matched_chl.m\")\n\n# Create data frame combining turtle track data and the chlo-a data\nchl_track2 &lt;- data.frame(turtle_df, tot)\n\n# Write the data frame to csv file\nwrite.csv(chl_track2, 'turtle-track-chl.m.csv', row.names = FALSE)\n\n\n\n# Draw the track positions with associated chlora values\nggplot(chl_track2) +\n  geom_point(aes(mean_lon,mean_lat,color=log(matched_chl.m))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nHow do the chlorophyll values of the turtle track compare to values in the surrounding environment? Meaning does the turtle seem to have a preference for certain chlorophyll values? To look at this we will plot a histograms of the track chl valuesand those of the surrounding area.\nFirst we will get a 3D block of chl data from the region and of the turtle track over the span of time the turtle was in that area. We will use the ‘xtracto_3d’ function of rerddapXtracto to get the data. This data call will take a few minutes.\nchl_grid &lt;- rxtracto_3D(dataInfo, \n                  parameter=parameter, \n                  xcoord=c(min(xcoords),max(xcoords)), \n                  ycoord=c(min(ycoords),max(ycoords)), \n                  tcoord=c(min(tcoords),max(tcoords)))\n\nchl_area &lt;- as.vector(chl_grid$chlor_a) \n\n# remove NA values \nchl_area &lt;- chl_area[!is.na(chl_area)]\n\n# vector or turtle chlorophyll \n\nchl_turtle &lt;- chl_track$`mean chlor_a`\nNow we we plot histograms of all the chlorphyll values in the area, and those of the turtle track. Since we subset the turtletrack, and only have 25 points for this subsampopled dataset the turtle histogram isn’t as useful as it would be with a larger dataset.\nggplot(as.data.frame(chl_area)) + \n      geom_histogram(aes(x=chl_area,y=after_stat(density),color = \"darkgray\",fill='Area'),color='black', bins=50) + \n      geom_histogram(data=as.data.frame(chl_turtle), aes(x=chl_turtle,y=after_stat(density),color='green', fill='Turtle'),color='black',bins=50, alpha=.4) + \n      scale_x_continuous(limits = c(0,.9), expand = c(0, 0)) + \n      scale_y_continuous(limits = c(0,15), expand = c(0, 0)) +\n      labs(x='Chlorophyll values',y='Density') + \n      theme_bw() + \n      scale_fill_manual(values=c(\"darkgray\",\"green\"),'')\n\n\n\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html \\ This dataset is a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name.\n\n\n\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ \\ This dataset will likely be on a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name. \\ Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\n\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorDaily_Lon0360.html"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "history | Modified July 2024\n\n\nThis tutorial will demonstrate how to extract satellite data around a set of points defined by longitude, latitude, and time coordinates from an animal telemetry tag that was acquired from the Animal Telemetry Network (https://ioos.noaa.gov/project/atn/).\n\n\n\n\nImporting track data in csv file to data frame\nPlotting the latitude/longitude points onto a map\nUsing rerddapXtraco function to extract satellite data from an ERDDAP data server along a track\nPlotting the satellite data onto a map\n\n\n\n\nChlorophyll a concentration, the European Space Agency’s Ocean Colour Climate Change Initiative (OC-CCI) Monthly dataset v6.0\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nYellowfin tuna telemetry track data\nMarine protected areas (MPAs) in pelagic regions is also called Blue Water. The Palmyra Bluewater Research (PBR) project seeks to understand the impact of MPAs on species and ecosystems by tracking at-sea movements of ten marine animal species at Palmyra Atoll (part of the U.S. Pacific Remote Islands Marine National Monument). All data were being collected from adult individuals between May 2022 and June 2023. They can be accessed via the Animal Telemetry Network (ATN) data portal for the PBR project under “Project Data”: (https://portal.atn.ioos.us/?ls=861Wqpd2#metadata/1f877c4c-7b50-49f5-be86-3354664e0cff/project/files)\nThe yellowfin tuna geolocation data is developed as part of the PBR project. This example track used in the tutorial is from May 2022 to November 2022. The track data has been previously downloaded, extracted, and stored in the data folder of this training module.\n\n\n\n# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                       \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\", \"stringr\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\n\nThe data you need for this exercise are already in the GitHub repository\nThe following step are show you how to download the data yourself\n\n\n\n\nFollow the link to the ATN website: https://portal.atn.ioos.us/?ls=O6vlufm7#map\n\nOn the right navigational panel, look for the “Palmyra Bluewater Research (PBR) Megafauna Movement Ecology Project, 2022-2023” tab.\nWithin the tab, scroll to find the telemetry tag labeled “Yellowfin tuna (233568)”.\nClick the search icon (maginifying glass) label next to the label to zoom into the area the area of the animal track.\n\n\n\n\nImage of the ATN portal webpage\n\n\n\n\n\n\nNext click the tag icon to the right of the search icon.\nThis page shows you details about the animal and the track.\n\n\n\n\nImage of the detail page for the Yellowfin Tuna #233568\n\n\n\n\n\n\nPress the “Project Data” tab near the top of the webpage to bring up the data file list.\nSearch for the animal id number (233568).\nClick on the link “THUALB_2022_04-PTT_233568.zip (8.6 MB)” to download the data.\n\n\n\n\nData download page\n\n\n\n\n\n\nThe download will be a zip file. You will need to unzip it.\nThe unzipped file folder contains many ancillary data files, but the one you are looking for is the CSV file (THUALB_2022_04-233568-4-GPE3.csv).\nYou don’t have to move this file into the data folder for this exercise. It is already there.\n\nBut if you download the file for a different animal track you would need to put the CSV file into the folder.\n\n\n\n\n\n# Import csv file into a data frame\nfile = \"../data/THUALB_2022_04-233568-5-GPE3.csv\"\npre_tuna_df &lt;- read.csv(file, skip = 5)\n\n# Show 3 rows from the data frame\nhead(pre_tuna_df, 3)\n##         DeployID    Ptt                 Date Most.Likely.Latitude\n## 1 THUALB_2022_04 233568 31-May-2022 19:00:00                5.875\n## 2 THUALB_2022_04 233568 01-Jun-2022 00:00:00                5.875\n## 3 THUALB_2022_04 233568 01-Jun-2022 04:56:15                5.850\n##   Most.Likely.Longitude Observation.Type Observed.SST Satellite.SST\n## 1              -162.125             User           NA            NA\n## 2              -162.100             None           NA            NA\n## 3              -161.975     Light - Dusk           NA            NA\n##   Observed.Depth Bathymetry.Depth Observation.LL..MSS. Observation.Score\n## 1             NA               NA                   NA          68.60585\n## 2             NA               NA                   NA                NA\n## 3            144             2908                   NA          43.16747\n##                Sunrise               Sunset\n## 1                                          \n## 2 01-Jun-2022 16:33:04 02-Jun-2022 04:59:36\n## 3\n# Convert longitudes to 0~360 (Re-center map to the dateline)\npre_tuna_df['Most.Likely.Longitude'] &lt;- pre_tuna_df['Most.Likely.Longitude'] + 360\n# Show converted data frame\nhead(pre_tuna_df, 3)\n##         DeployID    Ptt                 Date Most.Likely.Latitude\n## 1 THUALB_2022_04 233568 31-May-2022 19:00:00                5.875\n## 2 THUALB_2022_04 233568 01-Jun-2022 00:00:00                5.875\n## 3 THUALB_2022_04 233568 01-Jun-2022 04:56:15                5.850\n##   Most.Likely.Longitude Observation.Type Observed.SST Satellite.SST\n## 1               197.875             User           NA            NA\n## 2               197.900             None           NA            NA\n## 3               198.025     Light - Dusk           NA            NA\n##   Observed.Depth Bathymetry.Depth Observation.LL..MSS. Observation.Score\n## 1             NA               NA                   NA          68.60585\n## 2             NA               NA                   NA                NA\n## 3            144             2908                   NA          43.16747\n##                Sunrise               Sunset\n## 1                                          \n## 2 01-Jun-2022 16:33:04 02-Jun-2022 04:59:36\n## 3\n\n\n\npre_tuna_df$Date &lt;- as.Date(pre_tuna_df$Date, format = \"%d-%b-%Y\")\nhead(pre_tuna_df)\n##         DeployID    Ptt       Date Most.Likely.Latitude Most.Likely.Longitude\n## 1 THUALB_2022_04 233568 2022-05-31                5.875               197.875\n## 2 THUALB_2022_04 233568 2022-06-01                5.875               197.900\n## 3 THUALB_2022_04 233568 2022-06-01                5.850               198.025\n## 4 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n## 5 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n## 6 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n##   Observation.Type Observed.SST Satellite.SST Observed.Depth Bathymetry.Depth\n## 1             User           NA            NA             NA               NA\n## 2             None           NA            NA             NA               NA\n## 3     Light - Dusk           NA            NA            144             2908\n## 4             None           NA            NA             NA               NA\n## 5              SST         28.2      28.32458              1             2908\n## 6     Light - Dawn           NA            NA            112             2908\n##   Observation.LL..MSS. Observation.Score              Sunrise\n## 1                   NA          68.60585                     \n## 2                   NA                NA 01-Jun-2022 16:33:04\n## 3                   NA          43.16747                     \n## 4                   NA                NA                     \n## 5                   NA          76.62995                     \n## 6                   NA          54.92253                     \n##                 Sunset\n## 1                     \n## 2 02-Jun-2022 04:59:36\n## 3                     \n## 4                     \n## 5                     \n## 6\n\n\n\nThe track data has multiple longitude/latitude/time points for each date. That temporal resolution is much higher than the daily and month satellite datasets that are available. So, let’s reduce the multiple daily values for the animal track data to a single value for each day. The code below creates a new dataframe that bins data for each date and calculates the mean for selected columns.\nlibrary(dplyr)\ntuna_df &lt;- pre_tuna_df %&gt;% group_by(Date) %&gt;% summarize(Most.Likely.Latitude = mean(Most.Likely.Latitude),\n                                         Most.Likely.Longitude = mean(Most.Likely.Longitude),\n                                         Satellite.SST = mean(Satellite.SST, na.rm=TRUE),\n                                         Observed.SST = mean(Observed.SST, na.rm=TRUE),\n                                         Observed.Depth = mean(Observed.Depth, na.rm=TRUE),\n                                         Bathymetry.Depth = mean(Bathymetry.Depth, na.rm=TRUE),\n                                         )\n\ntuna_df\n## # A tibble: 177 × 7\n##    Date       Most.Likely.Latitude Most.Likely.Longitude Satellite.SST\n##    &lt;date&gt;                    &lt;dbl&gt;                 &lt;dbl&gt;         &lt;dbl&gt;\n##  1 2022-05-31                 5.88                  198.         NaN  \n##  2 2022-06-01                 5.88                  198           28.3\n##  3 2022-06-02                 5.92                  198.          28.3\n##  4 2022-06-03                 5.92                  198.          28.3\n##  5 2022-06-04                 5.98                  198.          28.3\n##  6 2022-06-05                 6.11                  198.          28.4\n##  7 2022-06-06                 6.28                  198.          28.3\n##  8 2022-06-07                 6.45                  197.          28.3\n##  9 2022-06-08                 6.51                  197.          28.2\n## 10 2022-06-09                 6.78                  197.          28.2\n## # ℹ 167 more rows\n## # ℹ 3 more variables: Observed.SST &lt;dbl&gt;, Observed.Depth &lt;dbl&gt;,\n## #   Bathymetry.Depth &lt;dbl&gt;\n\n\n\n# Download world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Map tuna tracks\nggplot(tuna_df, aes(Most.Likely.Longitude,Most.Likely.Latitude)) +\n  geom_path(group=1)+\n  geom_point(aes(x=Most.Likely.Longitude,y=Most.Likely.Latitude), pch=1, size=2 )+\n  geom_point(aes(x=Most.Likely.Longitude[1],y=Most.Likely.Latitude[1]),fill=\"green\", shape=24, size=3)+\n  geom_point(aes(x=Most.Likely.Longitude[length(Most.Likely.Longitude)],y=Most.Likely.Latitude[length(Most.Likely.Latitude)]), shape=22, size=3, fill=\"red\")+\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26))+\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with start (green) and end location (red)\")+\n  theme(plot.title=element_text(hjust=0.5), aspect.ratio=0.6)\n\nIn this exercise, two different ways of extracting data from ERDDAP data server along a track of xyt points are demonstrated:\n\nUsing the rerddapXtracto package which was written specifically for this task\nFor those who want to know what goes on “under the hood”, we will show how to manually construct ERDDAP data-request URLs to download the data.\n\n\n\nWe will use the `rxtracto function of the rerddapXtracto package, which was written to simplify data extraction from ERDDAP servers.\nLet’s use data from the monthly product of the OC-CCI datasets.\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data are severely affected by clouds (i.e. lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer data gaps.\nThe ERDDAP URL to the monthly product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-12-01 (at the day of this writing), which covers the track time range of 2022-05-30 to 2023-01-18.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n# Set dataset ID\ndataset &lt;- 'esa-cci-chla-monthly-v6-0'\n\n# Get data information from ERDDAP server\ndataInfo &lt;- rerddap::info(dataset, url= \"https://oceanwatch.pifsc.noaa.gov/erddap\")\n\n\n\n\nrerddap::info returns the metadata of the requested dataset. We can first understand the attributes dataInfo includes then examine each attribute.\n# Display the metadata\ndataInfo\n## &lt;ERDDAP info&gt; esa-cci-chla-monthly-v6-0 \n##  Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-04T00:00:00Z, 2023-12-01T00:00:00Z) \n##      latitude: (-89.97916666666666, 89.97916666666667) \n##      longitude: (0.020833333333314386, 359.97916666666663) \n##  Variables:  \n##      chlor_a: \n##          Units: mg m-3 \n##      chlor_a_log10_bias: \n##      chlor_a_log10_rmsd: \n##      MERIS_nobs_sum: \n##      MODISA_nobs_sum: \n##      OLCI_A_nobs_sum: \n##      OLCI_B_nobs_sum: \n##      SeaWiFS_nobs_sum: \n##      total_nobs_sum: \n##      VIIRS_nobs_sum:\n# Display data attributes\nnames(dataInfo)\n## [1] \"variables\" \"alldata\"   \"base_url\"\n# Examine attribute: variables\ndataInfo$variables\n##         variable_name data_type actual_range\n## 1             chlor_a     float             \n## 2  chlor_a_log10_bias     float             \n## 3  chlor_a_log10_rmsd     float             \n## 4      MERIS_nobs_sum     float             \n## 5     MODISA_nobs_sum     float             \n## 6     OLCI_A_nobs_sum     float             \n## 7     OLCI_B_nobs_sum     float             \n## 8    SeaWiFS_nobs_sum     float             \n## 9      total_nobs_sum     float             \n## 10     VIIRS_nobs_sum     float\n# Distribute attributes of dataInfo$alldata\nnames(dataInfo$alldata)\n##  [1] \"NC_GLOBAL\"          \"time\"               \"latitude\"          \n##  [4] \"longitude\"          \"chlor_a\"            \"MERIS_nobs_sum\"    \n##  [7] \"MODISA_nobs_sum\"    \"OLCI_A_nobs_sum\"    \"OLCI_B_nobs_sum\"   \n## [10] \"SeaWiFS_nobs_sum\"   \"VIIRS_nobs_sum\"     \"chlor_a_log10_bias\"\n## [13] \"chlor_a_log10_rmsd\" \"total_nobs_sum\"\n\n\nFirst we need to define the bounding box within which to search for coordinates. The rxtracto function allows you to set the size of the box used to collect data around the track points using the xlen and ylen arguments. The values for xlen and ylen are in degrees. For our example, we can use 0.2 degrees for both arguments. Note: You can also submit vectors for xlen and ylen, as long as they are the same length as xcoord, ycoord, and tcoord if you want to set a different search radius around each track point.\n# Set the variable we want to extract data from:\nparameter &lt;- 'chlor_a'\n\n# Set xlen, ylen to 0.2 degree\nxlen &lt;- 0.2 \nylen &lt;- 0.2\n\n# Create date column using year, month and day in a format ERDDAP will understand (eg. 2008-12-15)\n#tuna_df$date &lt;-as.Date(tuna_df$Date, format = \"%d-%b-%Y\")\n\n# Get variables x, y, t coordinates from tuna track data\nxcoords &lt;- tuna_df$Most.Likely.Longitude\nycoords &lt;- tuna_df$Most.Likely.Latitude\ntcoords &lt;- tuna_df$Date\n\n# Extract satellite data using x, y, t coordinates from tuna track data\nchl_track &lt;- rxtracto(dataInfo, \n                  parameter=parameter, \n                  xcoord=xcoords, ycoord=ycoords, \n                  tcoord=tcoords, xlen=xlen, ylen=ylen)\n\n\n\n\n# Check all variables extracted using rxtracto\nstr(chl_track)\n## List of 13\n##  $ mean chlor_a     : num [1:177] 0.35 0.34 0.349 0.367 0.276 ...\n##  $ stdev chlor_a    : num [1:177] 0.373 0.372 0.373 0.407 0.154 ...\n##  $ n                : int [1:177] 36 36 36 30 25 36 30 36 36 30 ...\n##  $ satellite date   : chr [1:177] \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" ...\n##  $ requested lon min: num [1:177] 198 198 198 198 198 ...\n##  $ requested lon max: num [1:177] 198 198 198 198 198 ...\n##  $ requested lat min: num [1:177] 5.78 5.79 5.83 5.83 5.88 ...\n##  $ requested lat max: num [1:177] 5.97 5.98 6.02 6.02 6.08 ...\n##  $ requested z min  : logi [1:177] NA NA NA NA NA NA ...\n##  $ requested z max  : logi [1:177] NA NA NA NA NA NA ...\n##  $ requested date   : chr [1:177] \"2022-05-31\" \"2022-06-01\" \"2022-06-02\" \"2022-06-03\" ...\n##  $ median chlor_a   : num [1:177] 0.235 0.227 0.232 0.236 0.232 ...\n##  $ mad chlor_a      : num [1:177] 0.017 0.0148 0.0172 0.0151 0.0192 ...\n##  - attr(*, \"row.names\")= chr [1:177] \"1\" \"2\" \"3\" \"4\" ...\n##  - attr(*, \"class\")= chr [1:2] \"list\" \"rxtractoTrack\"\n##  - attr(*, \"base_url\")= chr \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\n##  - attr(*, \"datasetid\")= chr \"esa-cci-chla-monthly-v6-0\"\nrxtracto computes statistics using all the pixels found in the search radius around each track point.\n\n\n\nWe will use the “plotTrack” function to plot the results. “plotTrack” is a function of the “rerddapXtracto” package designed specifically to plot the results of the “rxtracto” function. It provides an easy way to make a quick plot, however it’s not very customizable.\n# Plot tracks with color: algae specifically designed for chlorophyll\nplotTrack(chl_track, xcoords, ycoords, tcoords, size=3, plotColor = 'viridis')\n\n\n\n\nOne of the nice features of the “plotTrack” function is that it is very easy to make an animation of the track data. This will take a minute to run. It creates an animated gif that will display in the Rstudio viewer window once the encoding to gif is done. Note: this works with but doesn’t require the latest versions of R Studio or rerddapXtracto package (e.g., it works with R Studio Version 2023.12.1+402 and rerddapXtracto version 1.1.5).\n# Animate tracks\n\nmake180 &lt;- function(lon) {\n    ind &lt;- which(lon &gt; 180)\n    lon[ind] &lt;- lon[ind] - 360\n   return(lon)\n}\n\nplotTrack(chl_track,\n          make180(xcoords),\n          ycoords, tcoords,\n          plotColor = 'viridis',\n          animate = TRUE,\n          cumulative = TRUE)\n## # A tibble: 177 × 7\n##    format width height colorspace matte filesize density\n##    &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n##  1 gif      672    480 sRGB       TRUE         0 72x72  \n##  2 gif      672    480 sRGB       TRUE         0 72x72  \n##  3 gif      672    480 sRGB       TRUE         0 72x72  \n##  4 gif      672    480 sRGB       TRUE         0 72x72  \n##  5 gif      672    480 sRGB       TRUE         0 72x72  \n##  6 gif      672    480 sRGB       TRUE         0 72x72  \n##  7 gif      672    480 sRGB       TRUE         0 72x72  \n##  8 gif      672    480 sRGB       TRUE         0 72x72  \n##  9 gif      672    480 sRGB       TRUE         0 72x72  \n## 10 gif      672    480 sRGB       TRUE         0 72x72  \n## # ℹ 167 more rows\n\n\n\n\n\nIf we to do an customization of the plot, its better to plot the data using ggplot. We will first create a data frame that contains longitudes and latitudes from the tuna and associated satellite chlor-a values.\n# Create a data frame of coords from tuna and chlor_a values \nnew_df &lt;- as.data.frame(cbind(xcoords, ycoords,  \n                              chl_track$`requested lon min`, \n                              chl_track$`requested lon max`, \n                              chl_track$`requested lat min`, \n                              chl_track$`requested lon max`,  \n                              chl_track$`mean chlor_a`)\n                        )\n\n# Set variable names\nnames(new_df) &lt;- c(\"Lon\", \n                   \"Lat\", \n                   \"Matchup_Lon_Lower\",\n                   \"Matchup_Lon_Upper\",\n                   \"Matchup_Lat_Lower\",\n                   \"Matchup_Lat_Upper\", \n                   \"Chlor_a\")\n\nwrite.csv(new_df, \"tuna_matchup_df.csv\")\n\n\n\n# Import world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Draw the track positions with associated chlora values\nggplot(new_df) +\n  geom_point(aes(Lon,Lat,color=log(Chlor_a))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with chlor-a values\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nFirst we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\ndata_url = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a\"\nFor a refresher of how to construct an ERDDAP data-request URL, please review the ERDDAP tutorial “04-Erddapurl.md” at the following link: https://github.com/coastwatch-training/CoastWatch-Tutorials/blob/main/ERDDAP-basics/lessons/\n# Set erddap address\nerddap_base_url &lt;- \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a\"\n\n# Get longitude and latitude from tuna track data\nlon &lt;- tuna_df$Most.Likely.Longitude\nlat &lt;- tuna_df$Most.Likely.Latitude\n\n# Get time from tuna track data and convert into ERDDAP date format\ndates2 &lt;- as.Date(tuna_df$Date, format = \"%d-%b-%Y\")\n\n# Initatilize tot variable where data will be downloaded to\ntot &lt;- rep(NA, 4)\n\n# Loop through each tuna track data\nfor (i in 1:dim(tuna_df)[1]) {\n\n  # follow the progress of the loop\n  cat(\"\\014\")\n  cat(\" Loop \", i, \" of \", dim(tuna_df)[1])\n  \n  # Create erddap URL by adding lat, lon, dates of each track point \n   url &lt;-  paste(erddap_base_url,\n                 \"[(\", dates2[i], \"):1:(\", dates2[i],\n                 \")][(\", lat[i], \"):1:(\", lat[i],\n                 \")][(\", lon[i], \"):1:(\", lon[i], \")]\", sep = \"\")  \n   \n   # Request and load satelite data from ERDDAP\n   new &lt;- read.csv(url, skip=2, header = FALSE) \n   \n   # Append the data\n   tot &lt;- rbind(tot, new)   \n   \n}\n## \f Loop  1  of  177\f Loop  2  of  177\f Loop  3  of  177\f Loop  4  of  177\f Loop  5  of  177\f Loop  6  of  177\f Loop  7  of  177\f Loop  8  of  177\f Loop  9  of  177\f Loop  10  of  177\f Loop  11  of  177\f Loop  12  of  177\f Loop  13  of  177\f Loop  14  of  177\f Loop  15  of  177\f Loop  16  of  177\f Loop  17  of  177\f Loop  18  of  177\f Loop  19  of  177\f Loop  20  of  177\f Loop  21  of  177\f Loop  22  of  177\f Loop  23  of  177\f Loop  24  of  177\f Loop  25  of  177\f Loop  26  of  177\f Loop  27  of  177\f Loop  28  of  177\f Loop  29  of  177\f Loop  30  of  177\f Loop  31  of  177\f Loop  32  of  177\f Loop  33  of  177\f Loop  34  of  177\f Loop  35  of  177\f Loop  36  of  177\f Loop  37  of  177\f Loop  38  of  177\f Loop  39  of  177\f Loop  40  of  177\f Loop  41  of  177\f Loop  42  of  177\f Loop  43  of  177\f Loop  44  of  177\f Loop  45  of  177\f Loop  46  of  177\f Loop  47  of  177\f Loop  48  of  177\f Loop  49  of  177\f Loop  50  of  177\f Loop  51  of  177\f Loop  52  of  177\f Loop  53  of  177\f Loop  54  of  177\f Loop  55  of  177\f Loop  56  of  177\f Loop  57  of  177\f Loop  58  of  177\f Loop  59  of  177\f Loop  60  of  177\f Loop  61  of  177\f Loop  62  of  177\f Loop  63  of  177\f Loop  64  of  177\f Loop  65  of  177\f Loop  66  of  177\f Loop  67  of  177\f Loop  68  of  177\f Loop  69  of  177\f Loop  70  of  177\f Loop  71  of  177\f Loop  72  of  177\f Loop  73  of  177\f Loop  74  of  177\f Loop  75  of  177\f Loop  76  of  177\f Loop  77  of  177\f Loop  78  of  177\f Loop  79  of  177\f Loop  80  of  177\f Loop  81  of  177\f Loop  82  of  177\f Loop  83  of  177\f Loop  84  of  177\f Loop  85  of  177\f Loop  86  of  177\f Loop  87  of  177\f Loop  88  of  177\f Loop  89  of  177\f Loop  90  of  177\f Loop  91  of  177\f Loop  92  of  177\f Loop  93  of  177\f Loop  94  of  177\f Loop  95  of  177\f Loop  96  of  177\f Loop  97  of  177\f Loop  98  of  177\f Loop  99  of  177\f Loop  100  of  177\f Loop  101  of  177\f Loop  102  of  177\f Loop  103  of  177\f Loop  104  of  177\f Loop  105  of  177\f Loop  106  of  177\f Loop  107  of  177\f Loop  108  of  177\f Loop  109  of  177\f Loop  110  of  177\f Loop  111  of  177\f Loop  112  of  177\f Loop  113  of  177\f Loop  114  of  177\f Loop  115  of  177\f Loop  116  of  177\f Loop  117  of  177\f Loop  118  of  177\f Loop  119  of  177\f Loop  120  of  177\f Loop  121  of  177\f Loop  122  of  177\f Loop  123  of  177\f Loop  124  of  177\f Loop  125  of  177\f Loop  126  of  177\f Loop  127  of  177\f Loop  128  of  177\f Loop  129  of  177\f Loop  130  of  177\f Loop  131  of  177\f Loop  132  of  177\f Loop  133  of  177\f Loop  134  of  177\f Loop  135  of  177\f Loop  136  of  177\f Loop  137  of  177\f Loop  138  of  177\f Loop  139  of  177\f Loop  140  of  177\f Loop  141  of  177\f Loop  142  of  177\f Loop  143  of  177\f Loop  144  of  177\f Loop  145  of  177\f Loop  146  of  177\f Loop  147  of  177\f Loop  148  of  177\f Loop  149  of  177\f Loop  150  of  177\f Loop  151  of  177\f Loop  152  of  177\f Loop  153  of  177\f Loop  154  of  177\f Loop  155  of  177\f Loop  156  of  177\f Loop  157  of  177\f Loop  158  of  177\f Loop  159  of  177\f Loop  160  of  177\f Loop  161  of  177\f Loop  162  of  177\f Loop  163  of  177\f Loop  164  of  177\f Loop  165  of  177\f Loop  166  of  177\f Loop  167  of  177\f Loop  168  of  177\f Loop  169  of  177\f Loop  170  of  177\f Loop  171  of  177\f Loop  172  of  177\f Loop  173  of  177\f Loop  174  of  177\f Loop  175  of  177\f Loop  176  of  177\f Loop  177  of  177\n# Delete the first row (default column names)\ntot &lt;- tot[-1, ]\n\n# Rename columns\nnames(tot) &lt;- c(\"chlo_date\", \"matched_lat\", \"matched_lon\", \"matched_chl.m\")\n\n# Create data frame combining tuna track data and the chlo-a data\nchl_track2 &lt;- data.frame(tuna_df, tot)\n\n# Write the data frame to csv file\nwrite.csv(chl_track2, 'tuna-track-chl.m.csv', row.names = FALSE)\n\n\n\n# Draw the track positions with associated chlora values\nggplot(chl_track2) +\n  geom_point(aes(Most.Likely.Longitude,Most.Likely.Latitude,color=log(matched_chl.m))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nHow do the chlorophyll values of the tuna track compare to values in the surrounding environment? Meaning does the tuna seem to have a preference for certain chlorophyll values? To look at this we will plot a histograms of the track chl valuesand those of the surrounding area.\nFirst we will get a 3D block of chl data from the region and of the tuna track over the span of time the tuna was in that area. We will use the ‘xtracto_3d’ function of rerddapXtracto to get the data. This data call will take a few minutes.\nchl_grid &lt;- rxtracto_3D(dataInfo, \n                  parameter=parameter, \n                  xcoord=c(min(xcoords),max(xcoords)), \n                  ycoord=c(min(ycoords),max(ycoords)), \n                  tcoord=c(min(tcoords),max(tcoords)))\n\nchl_area &lt;- as.vector(chl_grid$chlor_a) \n\n# remove NA values \nchl_area &lt;- chl_area[!is.na(chl_area)]\n\n# vector or tuna chlorophyll \n\nchl_tuna &lt;- chl_track$`mean chlor_a`\nNow we we plot histograms of all the chlorphyll values in the area, and those of the tuna track.\nggplot(as.data.frame(chl_area)) + \n      geom_histogram(aes(x=chl_area,y=after_stat(density),color = \"darkgray\",fill='Area'),color='black', bins=50) + \n      geom_histogram(data=as.data.frame(chl_tuna), aes(x=chl_tuna,y=after_stat(density),color='green', fill='Tuna'),color='black',bins=50, alpha=.4) + \n      scale_x_continuous(limits = c(0,.9), expand = c(0, 0)) + \n      scale_y_continuous(limits = c(0,15), expand = c(0, 0)) +\n      labs(x='Chlorophyll values',y='Density') + \n      theme_bw() + \n      scale_fill_manual(values=c(\"darkgray\",\"green\"),'')\n\n\n\nRepeat the steps above with a different satellite dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html \\ This dataset is a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name.\n\n\n\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ \\ This dataset will likely be on a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name. \\ Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\n\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorDaily_Lon0360.html"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#objective",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#objective",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "This tutorial will demonstrate how to extract satellite data around a set of points defined by longitude, latitude, and time coordinates from an animal telemetry tag that was acquired from the Animal Telemetry Network (https://ioos.noaa.gov/project/atn/)."
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "Importing track data in csv file to data frame\nPlotting the latitude/longitude points onto a map\nUsing rerddapXtraco function to extract satellite data from an ERDDAP data server along a track\nPlotting the satellite data onto a map"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#datasets-used-in-this-exercise",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#datasets-used-in-this-exercise",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "Chlorophyll a concentration, the European Space Agency’s Ocean Colour Climate Change Initiative (OC-CCI) Monthly dataset v6.0\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nYellowfin tuna telemetry track data\nMarine protected areas (MPAs) in pelagic regions is also called Blue Water. The Palmyra Bluewater Research (PBR) project seeks to understand the impact of MPAs on species and ecosystems by tracking at-sea movements of ten marine animal species at Palmyra Atoll (part of the U.S. Pacific Remote Islands Marine National Monument). All data were being collected from adult individuals between May 2022 and June 2023. They can be accessed via the Animal Telemetry Network (ATN) data portal for the PBR project under “Project Data”: (https://portal.atn.ioos.us/?ls=861Wqpd2#metadata/1f877c4c-7b50-49f5-be86-3354664e0cff/project/files)\nThe yellowfin tuna geolocation data is developed as part of the PBR project. This example track used in the tutorial is from May 2022 to November 2022. The track data has been previously downloaded, extracted, and stored in the data folder of this training module."
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#install-required-packages-and-load-libraries",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#install-required-packages-and-load-libraries",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                       \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\", \"stringr\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#download-animal-track-data-from-the-atn-website",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#download-animal-track-data-from-the-atn-website",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "The data you need for this exercise are already in the GitHub repository\nThe following step are show you how to download the data yourself\n\n\n\n\nFollow the link to the ATN website: https://portal.atn.ioos.us/?ls=O6vlufm7#map\n\nOn the right navigational panel, look for the “Palmyra Bluewater Research (PBR) Megafauna Movement Ecology Project, 2022-2023” tab.\nWithin the tab, scroll to find the telemetry tag labeled “Yellowfin tuna (233568)”.\nClick the search icon (maginifying glass) label next to the label to zoom into the area the area of the animal track.\n\n\n\n\nImage of the ATN portal webpage\n\n\n\n\n\n\nNext click the tag icon to the right of the search icon.\nThis page shows you details about the animal and the track.\n\n\n\n\nImage of the detail page for the Yellowfin Tuna #233568\n\n\n\n\n\n\nPress the “Project Data” tab near the top of the webpage to bring up the data file list.\nSearch for the animal id number (233568).\nClick on the link “THUALB_2022_04-PTT_233568.zip (8.6 MB)” to download the data.\n\n\n\n\nData download page\n\n\n\n\n\n\nThe download will be a zip file. You will need to unzip it.\nThe unzipped file folder contains many ancillary data files, but the one you are looking for is the CSV file (THUALB_2022_04-233568-4-GPE3.csv).\nYou don’t have to move this file into the data folder for this exercise. It is already there.\n\nBut if you download the file for a different animal track you would need to put the CSV file into the folder."
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#import-the-track-data-into-a-data-frame",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#import-the-track-data-into-a-data-frame",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Import csv file into a data frame\nfile = \"../data/THUALB_2022_04-233568-5-GPE3.csv\"\npre_tuna_df &lt;- read.csv(file, skip = 5)\n\n# Show 3 rows from the data frame\nhead(pre_tuna_df, 3)\n##         DeployID    Ptt                 Date Most.Likely.Latitude\n## 1 THUALB_2022_04 233568 31-May-2022 19:00:00                5.875\n## 2 THUALB_2022_04 233568 01-Jun-2022 00:00:00                5.875\n## 3 THUALB_2022_04 233568 01-Jun-2022 04:56:15                5.850\n##   Most.Likely.Longitude Observation.Type Observed.SST Satellite.SST\n## 1              -162.125             User           NA            NA\n## 2              -162.100             None           NA            NA\n## 3              -161.975     Light - Dusk           NA            NA\n##   Observed.Depth Bathymetry.Depth Observation.LL..MSS. Observation.Score\n## 1             NA               NA                   NA          68.60585\n## 2             NA               NA                   NA                NA\n## 3            144             2908                   NA          43.16747\n##                Sunrise               Sunset\n## 1                                          \n## 2 01-Jun-2022 16:33:04 02-Jun-2022 04:59:36\n## 3\n# Convert longitudes to 0~360 (Re-center map to the dateline)\npre_tuna_df['Most.Likely.Longitude'] &lt;- pre_tuna_df['Most.Likely.Longitude'] + 360\n# Show converted data frame\nhead(pre_tuna_df, 3)\n##         DeployID    Ptt                 Date Most.Likely.Latitude\n## 1 THUALB_2022_04 233568 31-May-2022 19:00:00                5.875\n## 2 THUALB_2022_04 233568 01-Jun-2022 00:00:00                5.875\n## 3 THUALB_2022_04 233568 01-Jun-2022 04:56:15                5.850\n##   Most.Likely.Longitude Observation.Type Observed.SST Satellite.SST\n## 1               197.875             User           NA            NA\n## 2               197.900             None           NA            NA\n## 3               198.025     Light - Dusk           NA            NA\n##   Observed.Depth Bathymetry.Depth Observation.LL..MSS. Observation.Score\n## 1             NA               NA                   NA          68.60585\n## 2             NA               NA                   NA                NA\n## 3            144             2908                   NA          43.16747\n##                Sunrise               Sunset\n## 1                                          \n## 2 01-Jun-2022 16:33:04 02-Jun-2022 04:59:36\n## 3"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#convert-date-string-to-a-date-object",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#convert-date-string-to-a-date-object",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "pre_tuna_df$Date &lt;- as.Date(pre_tuna_df$Date, format = \"%d-%b-%Y\")\nhead(pre_tuna_df)\n##         DeployID    Ptt       Date Most.Likely.Latitude Most.Likely.Longitude\n## 1 THUALB_2022_04 233568 2022-05-31                5.875               197.875\n## 2 THUALB_2022_04 233568 2022-06-01                5.875               197.900\n## 3 THUALB_2022_04 233568 2022-06-01                5.850               198.025\n## 4 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n## 5 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n## 6 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n##   Observation.Type Observed.SST Satellite.SST Observed.Depth Bathymetry.Depth\n## 1             User           NA            NA             NA               NA\n## 2             None           NA            NA             NA               NA\n## 3     Light - Dusk           NA            NA            144             2908\n## 4             None           NA            NA             NA               NA\n## 5              SST         28.2      28.32458              1             2908\n## 6     Light - Dawn           NA            NA            112             2908\n##   Observation.LL..MSS. Observation.Score              Sunrise\n## 1                   NA          68.60585                     \n## 2                   NA                NA 01-Jun-2022 16:33:04\n## 3                   NA          43.16747                     \n## 4                   NA                NA                     \n## 5                   NA          76.62995                     \n## 6                   NA          54.92253                     \n##                 Sunset\n## 1                     \n## 2 02-Jun-2022 04:59:36\n## 3                     \n## 4                     \n## 5                     \n## 6"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#bin-multiple-observations-from-each-day-into-daily-mean-values",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#bin-multiple-observations-from-each-day-into-daily-mean-values",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "The track data has multiple longitude/latitude/time points for each date. That temporal resolution is much higher than the daily and month satellite datasets that are available. So, let’s reduce the multiple daily values for the animal track data to a single value for each day. The code below creates a new dataframe that bins data for each date and calculates the mean for selected columns.\nlibrary(dplyr)\ntuna_df &lt;- pre_tuna_df %&gt;% group_by(Date) %&gt;% summarize(Most.Likely.Latitude = mean(Most.Likely.Latitude),\n                                         Most.Likely.Longitude = mean(Most.Likely.Longitude),\n                                         Satellite.SST = mean(Satellite.SST, na.rm=TRUE),\n                                         Observed.SST = mean(Observed.SST, na.rm=TRUE),\n                                         Observed.Depth = mean(Observed.Depth, na.rm=TRUE),\n                                         Bathymetry.Depth = mean(Bathymetry.Depth, na.rm=TRUE),\n                                         )\n\ntuna_df\n## # A tibble: 177 × 7\n##    Date       Most.Likely.Latitude Most.Likely.Longitude Satellite.SST\n##    &lt;date&gt;                    &lt;dbl&gt;                 &lt;dbl&gt;         &lt;dbl&gt;\n##  1 2022-05-31                 5.88                  198.         NaN  \n##  2 2022-06-01                 5.88                  198           28.3\n##  3 2022-06-02                 5.92                  198.          28.3\n##  4 2022-06-03                 5.92                  198.          28.3\n##  5 2022-06-04                 5.98                  198.          28.3\n##  6 2022-06-05                 6.11                  198.          28.4\n##  7 2022-06-06                 6.28                  198.          28.3\n##  8 2022-06-07                 6.45                  197.          28.3\n##  9 2022-06-08                 6.51                  197.          28.2\n## 10 2022-06-09                 6.78                  197.          28.2\n## # ℹ 167 more rows\n## # ℹ 3 more variables: Observed.SST &lt;dbl&gt;, Observed.Depth &lt;dbl&gt;,\n## #   Bathymetry.Depth &lt;dbl&gt;"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#plot-the-track-on-a-map",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#plot-the-track-on-a-map",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Download world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Map tuna tracks\nggplot(tuna_df, aes(Most.Likely.Longitude,Most.Likely.Latitude)) +\n  geom_path(group=1)+\n  geom_point(aes(x=Most.Likely.Longitude,y=Most.Likely.Latitude), pch=1, size=2 )+\n  geom_point(aes(x=Most.Likely.Longitude[1],y=Most.Likely.Latitude[1]),fill=\"green\", shape=24, size=3)+\n  geom_point(aes(x=Most.Likely.Longitude[length(Most.Likely.Longitude)],y=Most.Likely.Latitude[length(Most.Likely.Latitude)]), shape=22, size=3, fill=\"red\")+\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26))+\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with start (green) and end location (red)\")+\n  theme(plot.title=element_text(hjust=0.5), aspect.ratio=0.6)\n\nIn this exercise, two different ways of extracting data from ERDDAP data server along a track of xyt points are demonstrated:\n\nUsing the rerddapXtracto package which was written specifically for this task\nFor those who want to know what goes on “under the hood”, we will show how to manually construct ERDDAP data-request URLs to download the data.\n\n\n\nWe will use the `rxtracto function of the rerddapXtracto package, which was written to simplify data extraction from ERDDAP servers.\nLet’s use data from the monthly product of the OC-CCI datasets.\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data are severely affected by clouds (i.e. lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer data gaps.\nThe ERDDAP URL to the monthly product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-12-01 (at the day of this writing), which covers the track time range of 2022-05-30 to 2023-01-18.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n# Set dataset ID\ndataset &lt;- 'esa-cci-chla-monthly-v6-0'\n\n# Get data information from ERDDAP server\ndataInfo &lt;- rerddap::info(dataset, url= \"https://oceanwatch.pifsc.noaa.gov/erddap\")"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#examine-metadata",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#examine-metadata",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "rerddap::info returns the metadata of the requested dataset. We can first understand the attributes dataInfo includes then examine each attribute.\n# Display the metadata\ndataInfo\n## &lt;ERDDAP info&gt; esa-cci-chla-monthly-v6-0 \n##  Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-04T00:00:00Z, 2023-12-01T00:00:00Z) \n##      latitude: (-89.97916666666666, 89.97916666666667) \n##      longitude: (0.020833333333314386, 359.97916666666663) \n##  Variables:  \n##      chlor_a: \n##          Units: mg m-3 \n##      chlor_a_log10_bias: \n##      chlor_a_log10_rmsd: \n##      MERIS_nobs_sum: \n##      MODISA_nobs_sum: \n##      OLCI_A_nobs_sum: \n##      OLCI_B_nobs_sum: \n##      SeaWiFS_nobs_sum: \n##      total_nobs_sum: \n##      VIIRS_nobs_sum:\n# Display data attributes\nnames(dataInfo)\n## [1] \"variables\" \"alldata\"   \"base_url\"\n# Examine attribute: variables\ndataInfo$variables\n##         variable_name data_type actual_range\n## 1             chlor_a     float             \n## 2  chlor_a_log10_bias     float             \n## 3  chlor_a_log10_rmsd     float             \n## 4      MERIS_nobs_sum     float             \n## 5     MODISA_nobs_sum     float             \n## 6     OLCI_A_nobs_sum     float             \n## 7     OLCI_B_nobs_sum     float             \n## 8    SeaWiFS_nobs_sum     float             \n## 9      total_nobs_sum     float             \n## 10     VIIRS_nobs_sum     float\n# Distribute attributes of dataInfo$alldata\nnames(dataInfo$alldata)\n##  [1] \"NC_GLOBAL\"          \"time\"               \"latitude\"          \n##  [4] \"longitude\"          \"chlor_a\"            \"MERIS_nobs_sum\"    \n##  [7] \"MODISA_nobs_sum\"    \"OLCI_A_nobs_sum\"    \"OLCI_B_nobs_sum\"   \n## [10] \"SeaWiFS_nobs_sum\"   \"VIIRS_nobs_sum\"     \"chlor_a_log10_bias\"\n## [13] \"chlor_a_log10_rmsd\" \"total_nobs_sum\"\n\n\nFirst we need to define the bounding box within which to search for coordinates. The rxtracto function allows you to set the size of the box used to collect data around the track points using the xlen and ylen arguments. The values for xlen and ylen are in degrees. For our example, we can use 0.2 degrees for both arguments. Note: You can also submit vectors for xlen and ylen, as long as they are the same length as xcoord, ycoord, and tcoord if you want to set a different search radius around each track point.\n# Set the variable we want to extract data from:\nparameter &lt;- 'chlor_a'\n\n# Set xlen, ylen to 0.2 degree\nxlen &lt;- 0.2 \nylen &lt;- 0.2\n\n# Create date column using year, month and day in a format ERDDAP will understand (eg. 2008-12-15)\n#tuna_df$date &lt;-as.Date(tuna_df$Date, format = \"%d-%b-%Y\")\n\n# Get variables x, y, t coordinates from tuna track data\nxcoords &lt;- tuna_df$Most.Likely.Longitude\nycoords &lt;- tuna_df$Most.Likely.Latitude\ntcoords &lt;- tuna_df$Date\n\n# Extract satellite data using x, y, t coordinates from tuna track data\nchl_track &lt;- rxtracto(dataInfo, \n                  parameter=parameter, \n                  xcoord=xcoords, ycoord=ycoords, \n                  tcoord=tcoords, xlen=xlen, ylen=ylen)"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#check-the-output-of-the-rxtracto-function",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#check-the-output-of-the-rxtracto-function",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Check all variables extracted using rxtracto\nstr(chl_track)\n## List of 13\n##  $ mean chlor_a     : num [1:177] 0.35 0.34 0.349 0.367 0.276 ...\n##  $ stdev chlor_a    : num [1:177] 0.373 0.372 0.373 0.407 0.154 ...\n##  $ n                : int [1:177] 36 36 36 30 25 36 30 36 36 30 ...\n##  $ satellite date   : chr [1:177] \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" ...\n##  $ requested lon min: num [1:177] 198 198 198 198 198 ...\n##  $ requested lon max: num [1:177] 198 198 198 198 198 ...\n##  $ requested lat min: num [1:177] 5.78 5.79 5.83 5.83 5.88 ...\n##  $ requested lat max: num [1:177] 5.97 5.98 6.02 6.02 6.08 ...\n##  $ requested z min  : logi [1:177] NA NA NA NA NA NA ...\n##  $ requested z max  : logi [1:177] NA NA NA NA NA NA ...\n##  $ requested date   : chr [1:177] \"2022-05-31\" \"2022-06-01\" \"2022-06-02\" \"2022-06-03\" ...\n##  $ median chlor_a   : num [1:177] 0.235 0.227 0.232 0.236 0.232 ...\n##  $ mad chlor_a      : num [1:177] 0.017 0.0148 0.0172 0.0151 0.0192 ...\n##  - attr(*, \"row.names\")= chr [1:177] \"1\" \"2\" \"3\" \"4\" ...\n##  - attr(*, \"class\")= chr [1:2] \"list\" \"rxtractoTrack\"\n##  - attr(*, \"base_url\")= chr \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\n##  - attr(*, \"datasetid\")= chr \"esa-cci-chla-monthly-v6-0\"\nrxtracto computes statistics using all the pixels found in the search radius around each track point."
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#plotting-the-results-using-plottrack",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#plotting-the-results-using-plottrack",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "We will use the “plotTrack” function to plot the results. “plotTrack” is a function of the “rerddapXtracto” package designed specifically to plot the results of the “rxtracto” function. It provides an easy way to make a quick plot, however it’s not very customizable.\n# Plot tracks with color: algae specifically designed for chlorophyll\nplotTrack(chl_track, xcoords, ycoords, tcoords, size=3, plotColor = 'viridis')"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#animating-the-track",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#animating-the-track",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "One of the nice features of the “plotTrack” function is that it is very easy to make an animation of the track data. This will take a minute to run. It creates an animated gif that will display in the Rstudio viewer window once the encoding to gif is done. Note: this works with but doesn’t require the latest versions of R Studio or rerddapXtracto package (e.g., it works with R Studio Version 2023.12.1+402 and rerddapXtracto version 1.1.5).\n# Animate tracks\n\nmake180 &lt;- function(lon) {\n    ind &lt;- which(lon &gt; 180)\n    lon[ind] &lt;- lon[ind] - 360\n   return(lon)\n}\n\nplotTrack(chl_track,\n          make180(xcoords),\n          ycoords, tcoords,\n          plotColor = 'viridis',\n          animate = TRUE,\n          cumulative = TRUE)\n## # A tibble: 177 × 7\n##    format width height colorspace matte filesize density\n##    &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n##  1 gif      672    480 sRGB       TRUE         0 72x72  \n##  2 gif      672    480 sRGB       TRUE         0 72x72  \n##  3 gif      672    480 sRGB       TRUE         0 72x72  \n##  4 gif      672    480 sRGB       TRUE         0 72x72  \n##  5 gif      672    480 sRGB       TRUE         0 72x72  \n##  6 gif      672    480 sRGB       TRUE         0 72x72  \n##  7 gif      672    480 sRGB       TRUE         0 72x72  \n##  8 gif      672    480 sRGB       TRUE         0 72x72  \n##  9 gif      672    480 sRGB       TRUE         0 72x72  \n## 10 gif      672    480 sRGB       TRUE         0 72x72  \n## # ℹ 167 more rows"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#plotting-the-results-using-ggplot",
    "href": "tutorials/matchup-satellite-data-to-ATN-animal-tracks/r/matchup-satellite-data-to-ATN_track-locations.html#plotting-the-results-using-ggplot",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "If we to do an customization of the plot, its better to plot the data using ggplot. We will first create a data frame that contains longitudes and latitudes from the tuna and associated satellite chlor-a values.\n# Create a data frame of coords from tuna and chlor_a values \nnew_df &lt;- as.data.frame(cbind(xcoords, ycoords,  \n                              chl_track$`requested lon min`, \n                              chl_track$`requested lon max`, \n                              chl_track$`requested lat min`, \n                              chl_track$`requested lon max`,  \n                              chl_track$`mean chlor_a`)\n                        )\n\n# Set variable names\nnames(new_df) &lt;- c(\"Lon\", \n                   \"Lat\", \n                   \"Matchup_Lon_Lower\",\n                   \"Matchup_Lon_Upper\",\n                   \"Matchup_Lat_Lower\",\n                   \"Matchup_Lat_Upper\", \n                   \"Chlor_a\")\n\nwrite.csv(new_df, \"tuna_matchup_df.csv\")\n\n\n\n# Import world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Draw the track positions with associated chlora values\nggplot(new_df) +\n  geom_point(aes(Lon,Lat,color=log(Chlor_a))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with chlor-a values\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nFirst we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\ndata_url = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a\"\nFor a refresher of how to construct an ERDDAP data-request URL, please review the ERDDAP tutorial “04-Erddapurl.md” at the following link: https://github.com/coastwatch-training/CoastWatch-Tutorials/blob/main/ERDDAP-basics/lessons/\n# Set erddap address\nerddap_base_url &lt;- \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a\"\n\n# Get longitude and latitude from tuna track data\nlon &lt;- tuna_df$Most.Likely.Longitude\nlat &lt;- tuna_df$Most.Likely.Latitude\n\n# Get time from tuna track data and convert into ERDDAP date format\ndates2 &lt;- as.Date(tuna_df$Date, format = \"%d-%b-%Y\")\n\n# Initatilize tot variable where data will be downloaded to\ntot &lt;- rep(NA, 4)\n\n# Loop through each tuna track data\nfor (i in 1:dim(tuna_df)[1]) {\n\n  # follow the progress of the loop\n  cat(\"\\014\")\n  cat(\" Loop \", i, \" of \", dim(tuna_df)[1])\n  \n  # Create erddap URL by adding lat, lon, dates of each track point \n   url &lt;-  paste(erddap_base_url,\n                 \"[(\", dates2[i], \"):1:(\", dates2[i],\n                 \")][(\", lat[i], \"):1:(\", lat[i],\n                 \")][(\", lon[i], \"):1:(\", lon[i], \")]\", sep = \"\")  \n   \n   # Request and load satelite data from ERDDAP\n   new &lt;- read.csv(url, skip=2, header = FALSE) \n   \n   # Append the data\n   tot &lt;- rbind(tot, new)   \n   \n}\n## \f Loop  1  of  177\f Loop  2  of  177\f Loop  3  of  177\f Loop  4  of  177\f Loop  5  of  177\f Loop  6  of  177\f Loop  7  of  177\f Loop  8  of  177\f Loop  9  of  177\f Loop  10  of  177\f Loop  11  of  177\f Loop  12  of  177\f Loop  13  of  177\f Loop  14  of  177\f Loop  15  of  177\f Loop  16  of  177\f Loop  17  of  177\f Loop  18  of  177\f Loop  19  of  177\f Loop  20  of  177\f Loop  21  of  177\f Loop  22  of  177\f Loop  23  of  177\f Loop  24  of  177\f Loop  25  of  177\f Loop  26  of  177\f Loop  27  of  177\f Loop  28  of  177\f Loop  29  of  177\f Loop  30  of  177\f Loop  31  of  177\f Loop  32  of  177\f Loop  33  of  177\f Loop  34  of  177\f Loop  35  of  177\f Loop  36  of  177\f Loop  37  of  177\f Loop  38  of  177\f Loop  39  of  177\f Loop  40  of  177\f Loop  41  of  177\f Loop  42  of  177\f Loop  43  of  177\f Loop  44  of  177\f Loop  45  of  177\f Loop  46  of  177\f Loop  47  of  177\f Loop  48  of  177\f Loop  49  of  177\f Loop  50  of  177\f Loop  51  of  177\f Loop  52  of  177\f Loop  53  of  177\f Loop  54  of  177\f Loop  55  of  177\f Loop  56  of  177\f Loop  57  of  177\f Loop  58  of  177\f Loop  59  of  177\f Loop  60  of  177\f Loop  61  of  177\f Loop  62  of  177\f Loop  63  of  177\f Loop  64  of  177\f Loop  65  of  177\f Loop  66  of  177\f Loop  67  of  177\f Loop  68  of  177\f Loop  69  of  177\f Loop  70  of  177\f Loop  71  of  177\f Loop  72  of  177\f Loop  73  of  177\f Loop  74  of  177\f Loop  75  of  177\f Loop  76  of  177\f Loop  77  of  177\f Loop  78  of  177\f Loop  79  of  177\f Loop  80  of  177\f Loop  81  of  177\f Loop  82  of  177\f Loop  83  of  177\f Loop  84  of  177\f Loop  85  of  177\f Loop  86  of  177\f Loop  87  of  177\f Loop  88  of  177\f Loop  89  of  177\f Loop  90  of  177\f Loop  91  of  177\f Loop  92  of  177\f Loop  93  of  177\f Loop  94  of  177\f Loop  95  of  177\f Loop  96  of  177\f Loop  97  of  177\f Loop  98  of  177\f Loop  99  of  177\f Loop  100  of  177\f Loop  101  of  177\f Loop  102  of  177\f Loop  103  of  177\f Loop  104  of  177\f Loop  105  of  177\f Loop  106  of  177\f Loop  107  of  177\f Loop  108  of  177\f Loop  109  of  177\f Loop  110  of  177\f Loop  111  of  177\f Loop  112  of  177\f Loop  113  of  177\f Loop  114  of  177\f Loop  115  of  177\f Loop  116  of  177\f Loop  117  of  177\f Loop  118  of  177\f Loop  119  of  177\f Loop  120  of  177\f Loop  121  of  177\f Loop  122  of  177\f Loop  123  of  177\f Loop  124  of  177\f Loop  125  of  177\f Loop  126  of  177\f Loop  127  of  177\f Loop  128  of  177\f Loop  129  of  177\f Loop  130  of  177\f Loop  131  of  177\f Loop  132  of  177\f Loop  133  of  177\f Loop  134  of  177\f Loop  135  of  177\f Loop  136  of  177\f Loop  137  of  177\f Loop  138  of  177\f Loop  139  of  177\f Loop  140  of  177\f Loop  141  of  177\f Loop  142  of  177\f Loop  143  of  177\f Loop  144  of  177\f Loop  145  of  177\f Loop  146  of  177\f Loop  147  of  177\f Loop  148  of  177\f Loop  149  of  177\f Loop  150  of  177\f Loop  151  of  177\f Loop  152  of  177\f Loop  153  of  177\f Loop  154  of  177\f Loop  155  of  177\f Loop  156  of  177\f Loop  157  of  177\f Loop  158  of  177\f Loop  159  of  177\f Loop  160  of  177\f Loop  161  of  177\f Loop  162  of  177\f Loop  163  of  177\f Loop  164  of  177\f Loop  165  of  177\f Loop  166  of  177\f Loop  167  of  177\f Loop  168  of  177\f Loop  169  of  177\f Loop  170  of  177\f Loop  171  of  177\f Loop  172  of  177\f Loop  173  of  177\f Loop  174  of  177\f Loop  175  of  177\f Loop  176  of  177\f Loop  177  of  177\n# Delete the first row (default column names)\ntot &lt;- tot[-1, ]\n\n# Rename columns\nnames(tot) &lt;- c(\"chlo_date\", \"matched_lat\", \"matched_lon\", \"matched_chl.m\")\n\n# Create data frame combining tuna track data and the chlo-a data\nchl_track2 &lt;- data.frame(tuna_df, tot)\n\n# Write the data frame to csv file\nwrite.csv(chl_track2, 'tuna-track-chl.m.csv', row.names = FALSE)\n\n\n\n# Draw the track positions with associated chlora values\nggplot(chl_track2) +\n  geom_point(aes(Most.Likely.Longitude,Most.Likely.Latitude,color=log(matched_chl.m))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nHow do the chlorophyll values of the tuna track compare to values in the surrounding environment? Meaning does the tuna seem to have a preference for certain chlorophyll values? To look at this we will plot a histograms of the track chl valuesand those of the surrounding area.\nFirst we will get a 3D block of chl data from the region and of the tuna track over the span of time the tuna was in that area. We will use the ‘xtracto_3d’ function of rerddapXtracto to get the data. This data call will take a few minutes.\nchl_grid &lt;- rxtracto_3D(dataInfo, \n                  parameter=parameter, \n                  xcoord=c(min(xcoords),max(xcoords)), \n                  ycoord=c(min(ycoords),max(ycoords)), \n                  tcoord=c(min(tcoords),max(tcoords)))\n\nchl_area &lt;- as.vector(chl_grid$chlor_a) \n\n# remove NA values \nchl_area &lt;- chl_area[!is.na(chl_area)]\n\n# vector or tuna chlorophyll \n\nchl_tuna &lt;- chl_track$`mean chlor_a`\nNow we we plot histograms of all the chlorphyll values in the area, and those of the tuna track.\nggplot(as.data.frame(chl_area)) + \n      geom_histogram(aes(x=chl_area,y=after_stat(density),color = \"darkgray\",fill='Area'),color='black', bins=50) + \n      geom_histogram(data=as.data.frame(chl_tuna), aes(x=chl_tuna,y=after_stat(density),color='green', fill='Tuna'),color='black',bins=50, alpha=.4) + \n      scale_x_continuous(limits = c(0,.9), expand = c(0, 0)) + \n      scale_y_continuous(limits = c(0,15), expand = c(0, 0)) +\n      labs(x='Chlorophyll values',y='Density') + \n      theme_bw() + \n      scale_fill_manual(values=c(\"darkgray\",\"green\"),'')\n\n\n\nRepeat the steps above with a different satellite dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html \\ This dataset is a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name.\n\n\n\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ \\ This dataset will likely be on a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name. \\ Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\n\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorDaily_Lon0360.html"
  },
  {
    "objectID": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html",
    "href": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "In this exercise, you will combine satellite and buoy data by extracting satellite measurements around specific points defined by buoy locations and dates.\n- The focus of this exercise is on matching two data sources from different projections.\n- Similar tutorials for mid to lower latitudes can be found at https://github.com/coastwatch-training/CoastWatch-Tutorials.\n\n\n\nUsing ERDDAP to retrieve buoy data in CSV format and satellite data in netCDF format\nImporting and manipulating data with the pandas and xarray libraries\nResampling data to lower-resolution time steps\nConverting latitude and longitude coordinates to the polar stereographic projection\n\n\n\n\nIce Surface Temperature, NOAA-20 VIIRS, Near Real-Time, Polar Stereographic (North), 4-day\nThis dataset provides VIIRS sea ice surface temperature for the Arctic at a 750m resolution, collected by the NOAA-20 satellite. It includes near-real-time daily data and 4-day composites for the past three weeks. For this exercise, we will use 4-day composites data. This dataset is in a polar stereographic projection.\nInternational Arctic Buoy Programme (IABP) Buoy Data, Daily\nThis dataset is from the US International Arctic Buoy Programme and includes meteorological and oceanographic data from buoys. Dataset is updated daily and includes multiple variables. For this exercise, we will extract surface temperature data.\nSatellite Ice Surface Temperature (IST) is measured by the Visible Infrared Imaging Radiometer Suite (VIIRS) and captures the temperature of the surface layer of ice.\nBuoy Surface Temperature (Ts) is measured from the bottom of the buoy hull. If the buoy is floating, the reported temperature is of the sea surface. If the buoy is frozen into the ice or sitting on top of it, the reported temperature is of the ground or ice. The freezing temperature of seawater is about -1.8°C, so temperature readings below this indicate ground or ice temperatures.\nMore details can be found in the metadata section of the data products (click on the data links above).\n\n\n\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE)\n    if(!require(x,character.only = TRUE)) stop(\"Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ncdf4\", \"rerddap\", \"plotdap\", \"httr\",\n                       \"lubridate\", \"gridGraphics\",  \"mapdata\",\n                       \"ggplot2\", \"RColorBrewer\", \"grid\", \"PBSmapping\", \n                       \"rerddapXtracto\",\"dplyr\",\"viridis\",\"cmocean\", \"sf\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\n\n\nUse the info function from the rerddap package. The variable surface_temp will be used for this exercise.\nERDDAP_Node = \"https://polarwatch.noaa.gov/erddap\"\n\nNDBC_id = 'iabpv2_buoys'\nNDBC_info=info(datasetid = NDBC_id,url = ERDDAP_Node)\n\nprint(NDBC_info)\n## &lt;ERDDAP info&gt; iabpv2_buoys \n##  Base URL: https://polarwatch.noaa.gov/erddap \n##  Dataset Type: tabledap \n##  Variables:  \n##      air_temp: \n##          Range: -90.0, 44.78 \n##          Units: degree_C \n##      bp: \n##          Range: 850.0, 1185.9 \n##          Units: mBars \n##      buoy_id: \n##      buoy_owner: \n##      buoy_type: \n##      day_of_year: \n##          Range: 6.0E-4, 366.999 \n##      has_air_temp: \n##      has_bp: \n##      has_surface_temp: \n##      hemisphere: \n##      hour: \n##          Range: 0.0, 24.0 \n##      latitude: \n##          Range: -90.0, 90.0 \n##          Units: degrees_north \n##      logistics: \n##      longitude: \n##          Range: -180.0, 180.0 \n##          Units: degrees_east \n##      minute: \n##          Range: 0.0, 59.0 \n##      surface_temp: \n##          Range: -72.88, 45.0 \n##          Units: degree_C \n##      time: \n##          Range: 1.189717571E9, 1.729396802E9 \n##          Units: seconds since 1970-01-01T00:00:00Z \n##      year: \n##          Range: 2007.0, 2024.0\n\n\n\nbuoy &lt;- rerddap::tabledap(url = ERDDAP_Node, NDBC_id,\n                           fields=c('buoy_id', 'latitude',  'longitude', 'time', 'surface_temp', \n                           'has_surface_temp'), 'time&gt;=2023-08-01',   'time&lt;=2023-09-30'\n)\n\n# Create data frame with the downloaded data\nbuoy.df &lt;-data.frame(buoy_id=as.character(buoy$buoy_id),\n                     longitude=as.numeric(buoy$longitude),\n                     latitude=as.numeric(buoy$latitude),\n                     time=as.POSIXct(buoy$time, \"%Y-%m-%dT%H:%M:%S\", tz=\"UTC\"),\n                     surface_temp=as.numeric(buoy$surface_temp))\n\nsummary(buoy.df)\n##    buoy_id            longitude          latitude     \n##  Length:471572      Min.   :-180.00   Min.   :-74.00  \n##  Class :character   1st Qu.:-129.15   1st Qu.: 73.93  \n##  Mode  :character   Median : -25.04   Median : 82.74  \n##                     Mean   : -21.90   Mean   : 72.16  \n##                     3rd Qu.:  97.57   3rd Qu.: 85.20  \n##                     Max.   : 180.00   Max.   : 90.00  \n##                                                       \n##       time                         surface_temp   \n##  Min.   :2023-08-01 00:00:00.00   Min.   :-60.00  \n##  1st Qu.:2023-08-21 16:00:02.00   1st Qu.: -0.95  \n##  Median :2023-09-06 15:00:00.00   Median :  0.30  \n##  Mean   :2023-09-04 05:39:11.03   Mean   :  1.96  \n##  3rd Qu.:2023-09-18 17:00:23.00   3rd Qu.:  2.69  \n##  Max.   :2023-09-30 00:00:00.00   Max.   : 40.00  \n##                                   NA's   :144689\nhead(buoy.df)\n##           buoy_id longitude latitude                time surface_temp\n## 1 300234066034140  -28.5226  55.0168 2023-08-01 00:00:00         13.5\n## 2 300234066034140  -28.5226  55.0168 2023-08-01 01:00:02         13.4\n## 3 300234066034140  -28.5226  55.0168 2023-08-01 01:59:57         13.4\n## 4 300234066034140  -28.5618  55.0032 2023-08-01 03:00:00         13.4\n## 5 300234066034140  -28.5618  55.0032 2023-08-01 04:00:02         13.3\n## 6 300234066034140  -28.5618  55.0032 2023-08-01 04:59:57         13.3\n\n\n\n\nWe will first select one buoy (buoy id = “300534062897730”). The buoy records measurements at intervals of minutes, resulting in a high-resolution dataset. To align it with the daily resolution of the satellite dataset, we will downsample the buoy data.\n\n\nCheck the number of timesteps\n# Select one buoy (buoy id = \"300534062897730\")\ntarget.buoy &lt;- buoy.df %&gt;% filter(buoy_id == \"300534062897730\")\n\n# Print the number of timestamps before resampling\n# cat(\"# of timesteps before =\", nrow(target.buoy), \"\\n\")\n#print(c(\"# of timesteps before =\", nrow(target.buoy.daily)))\nsteps_before &lt;- length(buoy.df$time)\n\n# Resample to daily mean by averaging surface_temp values for each day\n# And rename surface_temp to temp_buoy\ntarget.buoy.daily &lt;- target.buoy %&gt;%\n  mutate(time = as.Date(time)) %&gt;% \n  group_by(time) %&gt;%\n  summarize(\n    buoy_id = first(buoy_id),\n    longitude = first(longitude),\n    latitude = first(latitude),\n    temp_buoy = mean(surface_temp, na.rm = TRUE))\n\n# Print the number of timesteps after resampling\n# cat(\"# of timesteps before =\", nrow(target.buoy.daily), \"\\n\")\nsteps_after &lt;- length(target.buoy.daily$time)\n\n\nhead(target.buoy.daily)\n## # A tibble: 6 × 5\n##   time       buoy_id         longitude latitude temp_buoy\n##   &lt;date&gt;     &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n## 1 2023-08-01 300534062897730     -144.     86.4     2.19 \n## 2 2023-08-02 300534062897730     -144.     86.4     1.52 \n## 3 2023-08-03 300534062897730     -142.     86.3     0.803\n## 4 2023-08-04 300534062897730     -142.     86.3     0.542\n## 5 2023-08-05 300534062897730     -142.     86.4     0.475\n## 6 2023-08-06 300534062897730     -142.     86.5     0.522\n\n\n\ncat(\"# of timesteps before =\", steps_before, \"# of timesteps after =\", steps_after)\n## # of timesteps before = 471572 # of timesteps after = 60\n#length(buoy.df$time)\n\n\n\n\nThe buoy locations are provided in latitude and longitude coordinates, whereas the satellite data are in a polar stereographic projection with locations in units of meters. We will convert the buoy locations from latitude and longitude to the corresponding columns and rows in the polar projection.\n# Define the projection using the PROJ4 string format\nproj4text &lt;- \"+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n\n# Convert the dataframe into an sf object (Spatial Dataframe)\ntarget.buoy.sf &lt;- st_as_sf(target.buoy.daily, coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\n# Reproject the data to the Polar Stereographic projection using the PROJ4 string\ntarget.buoy.projected &lt;- st_transform(target.buoy.sf, crs = proj4text)\n\n# Extract the projected coordinates\ntarget.buoy.projected$cols &lt;- st_coordinates(target.buoy.projected)[,1] # X (columns)\ntarget.buoy.projected$rows &lt;- st_coordinates(target.buoy.projected)[,2] # Y (rows)\n\n# Show the first 2 rows to verify that the 'cols' and 'rows' columns were added\nhead(target.buoy.projected, 2)\n## Simple feature collection with 2 features and 5 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -389549.6 ymin: 58944.53 xmax: -385824.4 ymax: 59121.58\n## Projected CRS: +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\n## # A tibble: 2 × 6\n##   time       buoy_id         temp_buoy             geometry     cols   rows\n##   &lt;date&gt;     &lt;chr&gt;               &lt;dbl&gt;          &lt;POINT [m]&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n## 1 2023-08-01 300534062897730      2.19 (-385824.4 58944.53) -385824. 58945.\n## 2 2023-08-02 300534062897730      1.52 (-389549.6 59121.58) -389550. 59122.\n# Select the first buoy location to pull corresponding satellite data\ntarget.buoy.cols &lt;- target.buoy.projected$cols[1]\ntarget.buoy.rows &lt;- target.buoy.projected$rows[1]\n\n# Verify the data\nprint(target.buoy.cols)\n## [1] -385824.4\nprint(target.buoy.rows)\n## [1] 58944.53\n\n\nLook at the metadata to check the metadata Note that the temperature is in degrees Kelvin.\nNDBC_id_2 = 'noaacwVIIRSn20icesrftempNP06Daily4Day'\nNDBC_info_2=info(datasetid = NDBC_id_2,url = ERDDAP_Node)\n\nprint(NDBC_info_2)\n## &lt;ERDDAP info&gt; noaacwVIIRSn20icesrftempNP06Daily4Day \n##  Base URL: https://polarwatch.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (2021-04-13T00:00:00Z, 2024-10-15T00:00:00Z) \n##      altitude: (0.0, 0.0) \n##      rows: (-3434002.5, 3434002.5) \n##      cols: (-3434002.5, 3434002.5) \n##  Variables:  \n##      IceSrfTemp: \n##          Units: Kelvin(K)\n\n\n\n\nUse the rxtracto function from the rerddapXtracto package\nzpos &lt;- rep(0., length(target.buoy.projected$time))\n\nsat_data &lt;- rxtracto(NDBC_info_2,\n                    xName=\"cols\",\n                    yName=\"rows\",\n                    tName=\"time\",\n                    zName=\"altitude\",\n                    parameter=\"IceSrfTemp\",\n                    xcoord = target.buoy.projected$cols,\n                    ycoord = target.buoy.projected$rows,\n                    tcoord = target.buoy.projected$time,\n                    zcoord = zpos\n                    )\nhead(sat_data)\n## $`mean IceSrfTemp`\n##  [1] 272.9286      NaN      NaN      NaN      NaN      NaN 271.0790 270.2815\n##  [9]      NaN      NaN      NaN 272.5218      NaN 271.7425 272.3054 270.4868\n## [17] 270.3914 273.3692 273.4933 272.3756 273.1550 273.1486 273.4222      NaN\n## [25]      NaN      NaN      NaN 269.4200 268.0554 267.6486 268.2197      NaN\n## [33]      NaN      NaN      NaN      NaN 266.4402 268.3176 268.0433 267.8826\n## [41] 268.3053      NaN      NaN      NaN      NaN      NaN      NaN 270.8179\n## [49]      NaN      NaN      NaN      NaN 264.4946 263.8606      NaN      NaN\n## [57] 256.9289      NaN      NaN      NaN\n## \n## $`stdev IceSrfTemp`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [51] NA NA NA NA NA NA NA NA NA NA\n## \n## $n\n##  [1] 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1\n## [39] 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0\n## \n## $`satellite date`\n##  [1] \"2023-08-01T00:00:00Z\" \"2023-08-02T00:00:00Z\" \"2023-08-03T00:00:00Z\"\n##  [4] \"2023-08-04T00:00:00Z\" \"2023-08-05T00:00:00Z\" \"2023-08-06T00:00:00Z\"\n##  [7] \"2023-08-07T00:00:00Z\" \"2023-08-08T00:00:00Z\" \"2023-08-09T00:00:00Z\"\n## [10] \"2023-08-10T00:00:00Z\" \"2023-08-11T00:00:00Z\" \"2023-08-12T00:00:00Z\"\n## [13] \"2023-08-13T00:00:00Z\" \"2023-08-14T00:00:00Z\" \"2023-08-15T00:00:00Z\"\n## [16] \"2023-08-16T00:00:00Z\" \"2023-08-17T00:00:00Z\" \"2023-08-18T00:00:00Z\"\n## [19] \"2023-08-19T00:00:00Z\" \"2023-08-20T00:00:00Z\" \"2023-08-21T00:00:00Z\"\n## [22] \"2023-08-22T00:00:00Z\" \"2023-08-23T00:00:00Z\" \"2023-08-24T00:00:00Z\"\n## [25] \"2023-08-25T00:00:00Z\" \"2023-08-26T00:00:00Z\" \"2023-08-27T00:00:00Z\"\n## [28] \"2023-08-28T00:00:00Z\" \"2023-08-29T00:00:00Z\" \"2023-08-30T00:00:00Z\"\n## [31] \"2023-08-31T00:00:00Z\" \"2023-09-01T00:00:00Z\" \"2023-09-02T00:00:00Z\"\n## [34] \"2023-09-03T00:00:00Z\" \"2023-09-04T00:00:00Z\" \"2023-09-05T00:00:00Z\"\n## [37] \"2023-09-06T00:00:00Z\" \"2023-09-07T00:00:00Z\" \"2023-09-08T00:00:00Z\"\n## [40] \"2023-09-09T00:00:00Z\" \"2023-09-10T00:00:00Z\" \"2023-09-11T00:00:00Z\"\n## [43] \"2023-09-12T00:00:00Z\" \"2023-09-13T00:00:00Z\" \"2023-09-14T00:00:00Z\"\n## [46] \"2023-09-15T00:00:00Z\" \"2023-09-16T00:00:00Z\" \"2023-09-17T00:00:00Z\"\n## [49] \"2023-09-18T00:00:00Z\" \"2023-09-19T00:00:00Z\" \"2023-09-20T00:00:00Z\"\n## [52] \"2023-09-21T00:00:00Z\" \"2023-09-22T00:00:00Z\" \"2023-09-23T00:00:00Z\"\n## [55] \"2023-09-24T00:00:00Z\" \"2023-09-25T00:00:00Z\" \"2023-09-26T00:00:00Z\"\n## [58] \"2023-09-27T00:00:00Z\" \"2023-09-28T00:00:00Z\" \"2023-09-29T00:00:00Z\"\n## \n## $`requested x min`\n##  [1] -385824.4 -389549.6 -398253.9 -399928.2 -383575.3 -376519.9 -373178.9\n##  [8] -369485.9 -364101.8 -358053.1 -344667.3 -339413.6 -325379.7 -308859.0\n## [15] -297005.5 -290218.6 -283776.4 -280170.8 -271276.3 -263223.8 -263830.1\n## [22] -269754.9 -268728.9 -262726.0 -258730.5 -262527.7 -277050.1 -274674.6\n## [29] -261436.0 -250715.5 -248618.1 -253833.2 -247254.1 -241801.9 -248913.6\n## [36] -253308.9 -253242.1 -259535.5 -256109.5 -263955.3 -260399.8 -254873.5\n## [43] -244906.9 -239308.2 -230283.9 -227856.9 -220466.8 -213128.6 -205585.0\n## [50] -194830.9 -185590.9 -183007.2 -178188.9 -176271.0 -179406.9 -180725.3\n## [57] -176656.0 -171027.2 -162577.7 -149611.3\n## \n## $`requested x max`\n##  [1] -385824.4 -389549.6 -398253.9 -399928.2 -383575.3 -376519.9 -373178.9\n##  [8] -369485.9 -364101.8 -358053.1 -344667.3 -339413.6 -325379.7 -308859.0\n## [15] -297005.5 -290218.6 -283776.4 -280170.8 -271276.3 -263223.8 -263830.1\n## [22] -269754.9 -268728.9 -262726.0 -258730.5 -262527.7 -277050.1 -274674.6\n## [29] -261436.0 -250715.5 -248618.1 -253833.2 -247254.1 -241801.9 -248913.6\n## [36] -253308.9 -253242.1 -259535.5 -256109.5 -263955.3 -260399.8 -254873.5\n## [43] -244906.9 -239308.2 -230283.9 -227856.9 -220466.8 -213128.6 -205585.0\n## [50] -194830.9 -185590.9 -183007.2 -178188.9 -176271.0 -179406.9 -180725.3\n## [57] -176656.0 -171027.2 -162577.7 -149611.3\n\n\n#sftemp_ds_subset$temp_sat &lt;- sftemp_ds_subset$IceSrfTemp - 273.15\ntemp_sat &lt;- sat_data$mean - 273.15\ntemp_sat\n##  [1]  -0.221441650           NaN           NaN           NaN           NaN\n##  [6]           NaN  -2.070959473  -2.868536377           NaN           NaN\n## [11]           NaN  -0.628179932           NaN  -1.407537842  -0.844641113\n## [16]  -2.663214111  -2.758581543   0.219171143   0.343347168  -0.774359131\n## [21]   0.004998779  -0.001409912   0.272210693           NaN           NaN\n## [26]           NaN           NaN  -3.729956055  -5.094610596  -5.501409912\n## [31]  -4.930303955           NaN           NaN           NaN           NaN\n## [36]           NaN  -6.709814453  -4.832434082  -5.106665039  -5.267431641\n## [41]  -4.844671631           NaN           NaN           NaN           NaN\n## [46]           NaN           NaN  -2.332067871           NaN           NaN\n## [51]           NaN           NaN  -8.655371094  -9.289373779           NaN\n## [56]           NaN -16.221136475           NaN           NaN           NaN\n#extract$mean\n\n\n\nAdd the satellite ice temperature to the buoy dataset. Not all buoy dates have corresponding satellite data. Any unmatched dates will be filled with NaN values.\ntarget.buoy.projected$temp_sat &lt;- temp_sat\nhead(target.buoy.projected)\n## Simple feature collection with 6 features and 6 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -399928.2 ymin: 46312.22 xmax: -376519.9 ymax: 59121.58\n## Projected CRS: +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\n## # A tibble: 6 × 7\n##   time       buoy_id temp_buoy             geometry     cols   rows temp_sat\n##   &lt;date&gt;     &lt;chr&gt;       &lt;dbl&gt;          &lt;POINT [m]&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n## 1 2023-08-01 300534…     2.19  (-385824.4 58944.53) -385824. 58945.   -0.221\n## 2 2023-08-02 300534…     1.52  (-389549.6 59121.58) -389550. 59122.  NaN    \n## 3 2023-08-03 300534…     0.803 (-398253.9 50891.54) -398254. 50892.  NaN    \n## 4 2023-08-04 300534…     0.542 (-399928.2 48358.67) -399928. 48359.  NaN    \n## 5 2023-08-05 300534…     0.475 (-383575.3 49983.71) -383575. 49984.  NaN    \n## 6 2023-08-06 300534…     0.522 (-376519.9 46312.22) -376520. 46312.  NaN\n\n\n\nVisualize the matched buoy and satellite datasets to assess the data alignment.\n# Create the plot\nggplot(target.buoy.projected, aes(x = time)) +\n  # Plot the buoy data\n  geom_point(aes(y = temp_buoy, color = 'Buoy Surface Temperature'), size =3) +\n  geom_line(aes(y = temp_buoy, color = 'Buoy Surface Temperature'), linewidth = 1, na.rm = TRUE) +\n  \n  # Plot the satellite (VIIRS Sea Ice Surface Temperature) data\n  geom_point(aes(y = temp_sat, color = 'VIIRS Sea Ice Surface Temperature'), shape = 15, size = 3) +\n  geom_line(aes(y = temp_sat, color = 'VIIRS Sea Ice Surface Temperature'), linewidth = 1, na.rm = TRUE) +\n  \n  # Set the y-axis limits\n  ylim(-20, 5) +\n  \n  # Labels and theme\n  labs(x = 'Time', y = 'Temperature (degrees C)', color = 'Legend') +\n  scale_color_manual(values = c('Buoy Surface Temperature' = 'red',\n                                'VIIRS Sea Ice Surface Temperature' = 'blue')) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#this-exercise-demonstrates-the-following-techniques",
    "href": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#this-exercise-demonstrates-the-following-techniques",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "Using ERDDAP to retrieve buoy data in CSV format and satellite data in netCDF format\nImporting and manipulating data with the pandas and xarray libraries\nResampling data to lower-resolution time steps\nConverting latitude and longitude coordinates to the polar stereographic projection"
  },
  {
    "objectID": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#data-used-in-this-exercise",
    "href": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#data-used-in-this-exercise",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "Ice Surface Temperature, NOAA-20 VIIRS, Near Real-Time, Polar Stereographic (North), 4-day\nThis dataset provides VIIRS sea ice surface temperature for the Arctic at a 750m resolution, collected by the NOAA-20 satellite. It includes near-real-time daily data and 4-day composites for the past three weeks. For this exercise, we will use 4-day composites data. This dataset is in a polar stereographic projection.\nInternational Arctic Buoy Programme (IABP) Buoy Data, Daily\nThis dataset is from the US International Arctic Buoy Programme and includes meteorological and oceanographic data from buoys. Dataset is updated daily and includes multiple variables. For this exercise, we will extract surface temperature data.\nSatellite Ice Surface Temperature (IST) is measured by the Visible Infrared Imaging Radiometer Suite (VIIRS) and captures the temperature of the surface layer of ice.\nBuoy Surface Temperature (Ts) is measured from the bottom of the buoy hull. If the buoy is floating, the reported temperature is of the sea surface. If the buoy is frozen into the ice or sitting on top of it, the reported temperature is of the ground or ice. The freezing temperature of seawater is about -1.8°C, so temperature readings below this indicate ground or ice temperatures.\nMore details can be found in the metadata section of the data products (click on the data links above)."
  },
  {
    "objectID": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#load-packages",
    "href": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#load-packages",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "pkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE)\n    if(!require(x,character.only = TRUE)) stop(\"Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ncdf4\", \"rerddap\", \"plotdap\", \"httr\",\n                       \"lubridate\", \"gridGraphics\",  \"mapdata\",\n                       \"ggplot2\", \"RColorBrewer\", \"grid\", \"PBSmapping\", \n                       \"rerddapXtracto\",\"dplyr\",\"viridis\",\"cmocean\", \"sf\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#load-buoy-data-iabp-from-polarwatch-erddap-data-server",
    "href": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#load-buoy-data-iabp-from-polarwatch-erddap-data-server",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "Use the info function from the rerddap package. The variable surface_temp will be used for this exercise.\nERDDAP_Node = \"https://polarwatch.noaa.gov/erddap\"\n\nNDBC_id = 'iabpv2_buoys'\nNDBC_info=info(datasetid = NDBC_id,url = ERDDAP_Node)\n\nprint(NDBC_info)\n## &lt;ERDDAP info&gt; iabpv2_buoys \n##  Base URL: https://polarwatch.noaa.gov/erddap \n##  Dataset Type: tabledap \n##  Variables:  \n##      air_temp: \n##          Range: -90.0, 44.78 \n##          Units: degree_C \n##      bp: \n##          Range: 850.0, 1185.9 \n##          Units: mBars \n##      buoy_id: \n##      buoy_owner: \n##      buoy_type: \n##      day_of_year: \n##          Range: 6.0E-4, 366.999 \n##      has_air_temp: \n##      has_bp: \n##      has_surface_temp: \n##      hemisphere: \n##      hour: \n##          Range: 0.0, 24.0 \n##      latitude: \n##          Range: -90.0, 90.0 \n##          Units: degrees_north \n##      logistics: \n##      longitude: \n##          Range: -180.0, 180.0 \n##          Units: degrees_east \n##      minute: \n##          Range: 0.0, 59.0 \n##      surface_temp: \n##          Range: -72.88, 45.0 \n##          Units: degree_C \n##      time: \n##          Range: 1.189717571E9, 1.729396802E9 \n##          Units: seconds since 1970-01-01T00:00:00Z \n##      year: \n##          Range: 2007.0, 2024.0\n\n\n\nbuoy &lt;- rerddap::tabledap(url = ERDDAP_Node, NDBC_id,\n                           fields=c('buoy_id', 'latitude',  'longitude', 'time', 'surface_temp', \n                           'has_surface_temp'), 'time&gt;=2023-08-01',   'time&lt;=2023-09-30'\n)\n\n# Create data frame with the downloaded data\nbuoy.df &lt;-data.frame(buoy_id=as.character(buoy$buoy_id),\n                     longitude=as.numeric(buoy$longitude),\n                     latitude=as.numeric(buoy$latitude),\n                     time=as.POSIXct(buoy$time, \"%Y-%m-%dT%H:%M:%S\", tz=\"UTC\"),\n                     surface_temp=as.numeric(buoy$surface_temp))\n\nsummary(buoy.df)\n##    buoy_id            longitude          latitude     \n##  Length:471572      Min.   :-180.00   Min.   :-74.00  \n##  Class :character   1st Qu.:-129.15   1st Qu.: 73.93  \n##  Mode  :character   Median : -25.04   Median : 82.74  \n##                     Mean   : -21.90   Mean   : 72.16  \n##                     3rd Qu.:  97.57   3rd Qu.: 85.20  \n##                     Max.   : 180.00   Max.   : 90.00  \n##                                                       \n##       time                         surface_temp   \n##  Min.   :2023-08-01 00:00:00.00   Min.   :-60.00  \n##  1st Qu.:2023-08-21 16:00:02.00   1st Qu.: -0.95  \n##  Median :2023-09-06 15:00:00.00   Median :  0.30  \n##  Mean   :2023-09-04 05:39:11.03   Mean   :  1.96  \n##  3rd Qu.:2023-09-18 17:00:23.00   3rd Qu.:  2.69  \n##  Max.   :2023-09-30 00:00:00.00   Max.   : 40.00  \n##                                   NA's   :144689\nhead(buoy.df)\n##           buoy_id longitude latitude                time surface_temp\n## 1 300234066034140  -28.5226  55.0168 2023-08-01 00:00:00         13.5\n## 2 300234066034140  -28.5226  55.0168 2023-08-01 01:00:02         13.4\n## 3 300234066034140  -28.5226  55.0168 2023-08-01 01:59:57         13.4\n## 4 300234066034140  -28.5618  55.0032 2023-08-01 03:00:00         13.4\n## 5 300234066034140  -28.5618  55.0032 2023-08-01 04:00:02         13.3\n## 6 300234066034140  -28.5618  55.0032 2023-08-01 04:59:57         13.3"
  },
  {
    "objectID": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#select-one-buoy-and-process-data",
    "href": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#select-one-buoy-and-process-data",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "We will first select one buoy (buoy id = “300534062897730”). The buoy records measurements at intervals of minutes, resulting in a high-resolution dataset. To align it with the daily resolution of the satellite dataset, we will downsample the buoy data.\n\n\nCheck the number of timesteps\n# Select one buoy (buoy id = \"300534062897730\")\ntarget.buoy &lt;- buoy.df %&gt;% filter(buoy_id == \"300534062897730\")\n\n# Print the number of timestamps before resampling\n# cat(\"# of timesteps before =\", nrow(target.buoy), \"\\n\")\n#print(c(\"# of timesteps before =\", nrow(target.buoy.daily)))\nsteps_before &lt;- length(buoy.df$time)\n\n# Resample to daily mean by averaging surface_temp values for each day\n# And rename surface_temp to temp_buoy\ntarget.buoy.daily &lt;- target.buoy %&gt;%\n  mutate(time = as.Date(time)) %&gt;% \n  group_by(time) %&gt;%\n  summarize(\n    buoy_id = first(buoy_id),\n    longitude = first(longitude),\n    latitude = first(latitude),\n    temp_buoy = mean(surface_temp, na.rm = TRUE))\n\n# Print the number of timesteps after resampling\n# cat(\"# of timesteps before =\", nrow(target.buoy.daily), \"\\n\")\nsteps_after &lt;- length(target.buoy.daily$time)\n\n\nhead(target.buoy.daily)\n## # A tibble: 6 × 5\n##   time       buoy_id         longitude latitude temp_buoy\n##   &lt;date&gt;     &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n## 1 2023-08-01 300534062897730     -144.     86.4     2.19 \n## 2 2023-08-02 300534062897730     -144.     86.4     1.52 \n## 3 2023-08-03 300534062897730     -142.     86.3     0.803\n## 4 2023-08-04 300534062897730     -142.     86.3     0.542\n## 5 2023-08-05 300534062897730     -142.     86.4     0.475\n## 6 2023-08-06 300534062897730     -142.     86.5     0.522\n\n\n\ncat(\"# of timesteps before =\", steps_before, \"# of timesteps after =\", steps_after)\n## # of timesteps before = 471572 # of timesteps after = 60\n#length(buoy.df$time)"
  },
  {
    "objectID": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#transform-buoy-coordinates-to-polar-projection",
    "href": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#transform-buoy-coordinates-to-polar-projection",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "The buoy locations are provided in latitude and longitude coordinates, whereas the satellite data are in a polar stereographic projection with locations in units of meters. We will convert the buoy locations from latitude and longitude to the corresponding columns and rows in the polar projection.\n# Define the projection using the PROJ4 string format\nproj4text &lt;- \"+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n\n# Convert the dataframe into an sf object (Spatial Dataframe)\ntarget.buoy.sf &lt;- st_as_sf(target.buoy.daily, coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\n# Reproject the data to the Polar Stereographic projection using the PROJ4 string\ntarget.buoy.projected &lt;- st_transform(target.buoy.sf, crs = proj4text)\n\n# Extract the projected coordinates\ntarget.buoy.projected$cols &lt;- st_coordinates(target.buoy.projected)[,1] # X (columns)\ntarget.buoy.projected$rows &lt;- st_coordinates(target.buoy.projected)[,2] # Y (rows)\n\n# Show the first 2 rows to verify that the 'cols' and 'rows' columns were added\nhead(target.buoy.projected, 2)\n## Simple feature collection with 2 features and 5 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -389549.6 ymin: 58944.53 xmax: -385824.4 ymax: 59121.58\n## Projected CRS: +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\n## # A tibble: 2 × 6\n##   time       buoy_id         temp_buoy             geometry     cols   rows\n##   &lt;date&gt;     &lt;chr&gt;               &lt;dbl&gt;          &lt;POINT [m]&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n## 1 2023-08-01 300534062897730      2.19 (-385824.4 58944.53) -385824. 58945.\n## 2 2023-08-02 300534062897730      1.52 (-389549.6 59121.58) -389550. 59122.\n# Select the first buoy location to pull corresponding satellite data\ntarget.buoy.cols &lt;- target.buoy.projected$cols[1]\ntarget.buoy.rows &lt;- target.buoy.projected$rows[1]\n\n# Verify the data\nprint(target.buoy.cols)\n## [1] -385824.4\nprint(target.buoy.rows)\n## [1] 58944.53\n\n\nLook at the metadata to check the metadata Note that the temperature is in degrees Kelvin.\nNDBC_id_2 = 'noaacwVIIRSn20icesrftempNP06Daily4Day'\nNDBC_info_2=info(datasetid = NDBC_id_2,url = ERDDAP_Node)\n\nprint(NDBC_info_2)\n## &lt;ERDDAP info&gt; noaacwVIIRSn20icesrftempNP06Daily4Day \n##  Base URL: https://polarwatch.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (2021-04-13T00:00:00Z, 2024-10-15T00:00:00Z) \n##      altitude: (0.0, 0.0) \n##      rows: (-3434002.5, 3434002.5) \n##      cols: (-3434002.5, 3434002.5) \n##  Variables:  \n##      IceSrfTemp: \n##          Units: Kelvin(K)"
  },
  {
    "objectID": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#extract-the-satellite-ice-surface-temperture-timeseries",
    "href": "tutorials/matchup-polar-satellite-data-to-buoy-data/r/matchup-polar-satellite-data-to-buoy-data.html#extract-the-satellite-ice-surface-temperture-timeseries",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "Use the rxtracto function from the rerddapXtracto package\nzpos &lt;- rep(0., length(target.buoy.projected$time))\n\nsat_data &lt;- rxtracto(NDBC_info_2,\n                    xName=\"cols\",\n                    yName=\"rows\",\n                    tName=\"time\",\n                    zName=\"altitude\",\n                    parameter=\"IceSrfTemp\",\n                    xcoord = target.buoy.projected$cols,\n                    ycoord = target.buoy.projected$rows,\n                    tcoord = target.buoy.projected$time,\n                    zcoord = zpos\n                    )\nhead(sat_data)\n## $`mean IceSrfTemp`\n##  [1] 272.9286      NaN      NaN      NaN      NaN      NaN 271.0790 270.2815\n##  [9]      NaN      NaN      NaN 272.5218      NaN 271.7425 272.3054 270.4868\n## [17] 270.3914 273.3692 273.4933 272.3756 273.1550 273.1486 273.4222      NaN\n## [25]      NaN      NaN      NaN 269.4200 268.0554 267.6486 268.2197      NaN\n## [33]      NaN      NaN      NaN      NaN 266.4402 268.3176 268.0433 267.8826\n## [41] 268.3053      NaN      NaN      NaN      NaN      NaN      NaN 270.8179\n## [49]      NaN      NaN      NaN      NaN 264.4946 263.8606      NaN      NaN\n## [57] 256.9289      NaN      NaN      NaN\n## \n## $`stdev IceSrfTemp`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [51] NA NA NA NA NA NA NA NA NA NA\n## \n## $n\n##  [1] 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1\n## [39] 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0\n## \n## $`satellite date`\n##  [1] \"2023-08-01T00:00:00Z\" \"2023-08-02T00:00:00Z\" \"2023-08-03T00:00:00Z\"\n##  [4] \"2023-08-04T00:00:00Z\" \"2023-08-05T00:00:00Z\" \"2023-08-06T00:00:00Z\"\n##  [7] \"2023-08-07T00:00:00Z\" \"2023-08-08T00:00:00Z\" \"2023-08-09T00:00:00Z\"\n## [10] \"2023-08-10T00:00:00Z\" \"2023-08-11T00:00:00Z\" \"2023-08-12T00:00:00Z\"\n## [13] \"2023-08-13T00:00:00Z\" \"2023-08-14T00:00:00Z\" \"2023-08-15T00:00:00Z\"\n## [16] \"2023-08-16T00:00:00Z\" \"2023-08-17T00:00:00Z\" \"2023-08-18T00:00:00Z\"\n## [19] \"2023-08-19T00:00:00Z\" \"2023-08-20T00:00:00Z\" \"2023-08-21T00:00:00Z\"\n## [22] \"2023-08-22T00:00:00Z\" \"2023-08-23T00:00:00Z\" \"2023-08-24T00:00:00Z\"\n## [25] \"2023-08-25T00:00:00Z\" \"2023-08-26T00:00:00Z\" \"2023-08-27T00:00:00Z\"\n## [28] \"2023-08-28T00:00:00Z\" \"2023-08-29T00:00:00Z\" \"2023-08-30T00:00:00Z\"\n## [31] \"2023-08-31T00:00:00Z\" \"2023-09-01T00:00:00Z\" \"2023-09-02T00:00:00Z\"\n## [34] \"2023-09-03T00:00:00Z\" \"2023-09-04T00:00:00Z\" \"2023-09-05T00:00:00Z\"\n## [37] \"2023-09-06T00:00:00Z\" \"2023-09-07T00:00:00Z\" \"2023-09-08T00:00:00Z\"\n## [40] \"2023-09-09T00:00:00Z\" \"2023-09-10T00:00:00Z\" \"2023-09-11T00:00:00Z\"\n## [43] \"2023-09-12T00:00:00Z\" \"2023-09-13T00:00:00Z\" \"2023-09-14T00:00:00Z\"\n## [46] \"2023-09-15T00:00:00Z\" \"2023-09-16T00:00:00Z\" \"2023-09-17T00:00:00Z\"\n## [49] \"2023-09-18T00:00:00Z\" \"2023-09-19T00:00:00Z\" \"2023-09-20T00:00:00Z\"\n## [52] \"2023-09-21T00:00:00Z\" \"2023-09-22T00:00:00Z\" \"2023-09-23T00:00:00Z\"\n## [55] \"2023-09-24T00:00:00Z\" \"2023-09-25T00:00:00Z\" \"2023-09-26T00:00:00Z\"\n## [58] \"2023-09-27T00:00:00Z\" \"2023-09-28T00:00:00Z\" \"2023-09-29T00:00:00Z\"\n## \n## $`requested x min`\n##  [1] -385824.4 -389549.6 -398253.9 -399928.2 -383575.3 -376519.9 -373178.9\n##  [8] -369485.9 -364101.8 -358053.1 -344667.3 -339413.6 -325379.7 -308859.0\n## [15] -297005.5 -290218.6 -283776.4 -280170.8 -271276.3 -263223.8 -263830.1\n## [22] -269754.9 -268728.9 -262726.0 -258730.5 -262527.7 -277050.1 -274674.6\n## [29] -261436.0 -250715.5 -248618.1 -253833.2 -247254.1 -241801.9 -248913.6\n## [36] -253308.9 -253242.1 -259535.5 -256109.5 -263955.3 -260399.8 -254873.5\n## [43] -244906.9 -239308.2 -230283.9 -227856.9 -220466.8 -213128.6 -205585.0\n## [50] -194830.9 -185590.9 -183007.2 -178188.9 -176271.0 -179406.9 -180725.3\n## [57] -176656.0 -171027.2 -162577.7 -149611.3\n## \n## $`requested x max`\n##  [1] -385824.4 -389549.6 -398253.9 -399928.2 -383575.3 -376519.9 -373178.9\n##  [8] -369485.9 -364101.8 -358053.1 -344667.3 -339413.6 -325379.7 -308859.0\n## [15] -297005.5 -290218.6 -283776.4 -280170.8 -271276.3 -263223.8 -263830.1\n## [22] -269754.9 -268728.9 -262726.0 -258730.5 -262527.7 -277050.1 -274674.6\n## [29] -261436.0 -250715.5 -248618.1 -253833.2 -247254.1 -241801.9 -248913.6\n## [36] -253308.9 -253242.1 -259535.5 -256109.5 -263955.3 -260399.8 -254873.5\n## [43] -244906.9 -239308.2 -230283.9 -227856.9 -220466.8 -213128.6 -205585.0\n## [50] -194830.9 -185590.9 -183007.2 -178188.9 -176271.0 -179406.9 -180725.3\n## [57] -176656.0 -171027.2 -162577.7 -149611.3\n\n\n#sftemp_ds_subset$temp_sat &lt;- sftemp_ds_subset$IceSrfTemp - 273.15\ntemp_sat &lt;- sat_data$mean - 273.15\ntemp_sat\n##  [1]  -0.221441650           NaN           NaN           NaN           NaN\n##  [6]           NaN  -2.070959473  -2.868536377           NaN           NaN\n## [11]           NaN  -0.628179932           NaN  -1.407537842  -0.844641113\n## [16]  -2.663214111  -2.758581543   0.219171143   0.343347168  -0.774359131\n## [21]   0.004998779  -0.001409912   0.272210693           NaN           NaN\n## [26]           NaN           NaN  -3.729956055  -5.094610596  -5.501409912\n## [31]  -4.930303955           NaN           NaN           NaN           NaN\n## [36]           NaN  -6.709814453  -4.832434082  -5.106665039  -5.267431641\n## [41]  -4.844671631           NaN           NaN           NaN           NaN\n## [46]           NaN           NaN  -2.332067871           NaN           NaN\n## [51]           NaN           NaN  -8.655371094  -9.289373779           NaN\n## [56]           NaN -16.221136475           NaN           NaN           NaN\n#extract$mean\n\n\n\nAdd the satellite ice temperature to the buoy dataset. Not all buoy dates have corresponding satellite data. Any unmatched dates will be filled with NaN values.\ntarget.buoy.projected$temp_sat &lt;- temp_sat\nhead(target.buoy.projected)\n## Simple feature collection with 6 features and 6 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -399928.2 ymin: 46312.22 xmax: -376519.9 ymax: 59121.58\n## Projected CRS: +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\n## # A tibble: 6 × 7\n##   time       buoy_id temp_buoy             geometry     cols   rows temp_sat\n##   &lt;date&gt;     &lt;chr&gt;       &lt;dbl&gt;          &lt;POINT [m]&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n## 1 2023-08-01 300534…     2.19  (-385824.4 58944.53) -385824. 58945.   -0.221\n## 2 2023-08-02 300534…     1.52  (-389549.6 59121.58) -389550. 59122.  NaN    \n## 3 2023-08-03 300534…     0.803 (-398253.9 50891.54) -398254. 50892.  NaN    \n## 4 2023-08-04 300534…     0.542 (-399928.2 48358.67) -399928. 48359.  NaN    \n## 5 2023-08-05 300534…     0.475 (-383575.3 49983.71) -383575. 49984.  NaN    \n## 6 2023-08-06 300534…     0.522 (-376519.9 46312.22) -376520. 46312.  NaN\n\n\n\nVisualize the matched buoy and satellite datasets to assess the data alignment.\n# Create the plot\nggplot(target.buoy.projected, aes(x = time)) +\n  # Plot the buoy data\n  geom_point(aes(y = temp_buoy, color = 'Buoy Surface Temperature'), size =3) +\n  geom_line(aes(y = temp_buoy, color = 'Buoy Surface Temperature'), linewidth = 1, na.rm = TRUE) +\n  \n  # Plot the satellite (VIIRS Sea Ice Surface Temperature) data\n  geom_point(aes(y = temp_sat, color = 'VIIRS Sea Ice Surface Temperature'), shape = 15, size = 3) +\n  geom_line(aes(y = temp_sat, color = 'VIIRS Sea Ice Surface Temperature'), linewidth = 1, na.rm = TRUE) +\n  \n  # Set the y-axis limits\n  ylim(-20, 5) +\n  \n  # Labels and theme\n  labs(x = 'Time', y = 'Temperature (degrees C)', color = 'Legend') +\n  scale_color_manual(values = c('Buoy Surface Temperature' = 'red',\n                                'VIIRS Sea Ice Surface Temperature' = 'blue')) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "Updated March 2024 \n\nRemotely sensed ocean color algorithms are calibrated for optically-deep waters, where the signal received by the satellite sensor originates from the water column without any bottom contribution.\nOptically shallow waters are those in which light reflected off the seafloor contributes significantly to the water-leaving signal, such as coral reefs, atolls, lagoons. This is known to affect geophysical variables derived by ocean-color algorithms, often leading to biased values in chlorophyll-a concentration for example.\nIn the tropical Pacific, optically-deep waters are typically deeper than 15 – 30 m. It is recommended to remove shallow-pixels, i.e., ocean color pixels that contain a portion (e.g., more than 5%) of shallow water area (less than 30m depth), from the study area before computing ocean color metrics (Couch et al., 2023).\n\n\nIn this tutorial, we demonstrate how to create a mask to remove ocean color pixels in the coastal shallow water that are contaminated by bottom reflectance.\n\n\n\n\nAccessing and Downloading satellite data from ERDDAP data server\nVisualizing the datasets\nMatching coarse-resolution ocean color data with fine-resolution bathymetry data\nCalculating percentage of shallow water area in each ocean color pixel\nCreating and applying value mask to datasets\nCalculating long-term climatology from monthly data\nOutputing dataset into netCDF format\n\n\n\n\nBathymetry data, ETOPO Global Relief Model integrates topography, bathymetry, and shoreline data, version 2022, 15 arc-second resolution\nOcean color data, ESA CCI chlorophyll-a concentration, 1998-2022, monthly\n\n\n\nCouch CS, Oliver TA, Dettloff K, Huntington B, Tanaka KR and Vargas-Ángel B (2023) Ecological and environmental predictors of juvenile coral density across the central and western Pacific. Front. Mar. Sci. 10:1192102.  doi: 10.3389/fmars.2023.1192102 \n\n\n\n# Load libraries\nlibrary(rerddap)\nlibrary(raster) \nlibrary(sp) \nlibrary(cmocean)\nlibrary(here)\nlibrary(ncdf4)\n\n\n\n# This is where the data are and where the plots will go\nDir &lt;- here()\n\n\n\nWe will access the ETOPO2022 bathymetry data and the monthly ESA CCI chlorophyll-a concentration data (1/1998-12/2022) for the island of Oahu from the OceanWatch ERDDAP server. We will also download the chlorophyll-a data and save it to local for future use.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\nWe will utilize the ’‘’rerddap’’’ R package to engage with the ERDDAP data server. The ’‘’rerddap’’’ package, created by Roy Mendelssohn (SWFSC) and Scott Chamberlain, is designed to simplify the process of importing data into R.\n# Bounding box for Oahu:\nlon_range = c(-158.39+360, -157.55+360)\nlat_range = c(21.14, 21.8)\n\n# Set ERDDAP URL\nERDDAP_Node = \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\n\n# Download bathymetry data with its unique ID \nETOPO_id = 'ETOPO_2022_v1_15s'\nETOPO_info=info(datasetid = ETOPO_id,url = ERDDAP_Node)\nbathy =  griddap(url = ERDDAP_Node, ETOPO_id, \n                 latitude = lat_range, longitude = lon_range)\n\n# Download ocean color data with its unique ID\nCCI_id = 'esa-cci-chla-monthly-v6-0'\nCCI_info=info(datasetid = CCI_id,url = ERDDAP_Node)\nvar=CCI_info$variable$variable_name\nchl = griddap(url = ERDDAP_Node, CCI_id, \n                   time = c('1998-01-01', '2022-12-01'),\n                   latitude = lat_range, longitude = lon_range,\n                   fields = var[1],\n                   store=disk('chl_data'))\n\n\n\nWe convert bathymetry and chlorophyll-a data to rasters for visulization.\n# Convert the data into a raster layer\nr_bathy=raster(bathy$summary$filename)\n\nplot(r_bathy,main=\"ETOPO Bathymetry (m)\")\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n# Convert the data into a raster layer\nr_chl=raster(chl$summary$filename,varname=var[1]) \n\nplot(log(r_chl),main=\"ESA CCI Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n\n\n\nThe ocean color data has coarser resolution (~4km) compared with the bathymetry data (~500m). We will calculate how much area (percentage) within each ocean color pixel is in shallow water (&lt;30m depth).\n#Convert raster bathymetry to SpatialPoints dataframe for counting\ndf_bathy = data.frame(rasterToPoints(r_bathy))\ncoordinates(df_bathy) &lt;- ~x+y\ncrs(df_bathy) = crs(r_chl[[1]])\n\n# Define a function to calculate the percentage of (smaller) bathymetry pixels in each (larger) Chl-a pixel that are shallow\npercent_shallow_pixels=function(depths,threshold=-30, na.rm=F){ \n  return(length(which(depths&gt;threshold))/length(depths)) \n} \n  \n# Build a raster of the chl-a grid, using the function to generate the shallow water area percentage to consider a pixel necessary to mask\nper_shallow =  rasterize(x = df_bathy,y=r_chl,fun=percent_shallow_pixels)[[2]]\nplot(per_shallow,main=\"% Shallow water\", col=cmocean('amp')(50))\n\n\n\n\n# Set a percentage threshold to create the shallow pixel mask\npercent_threshold = 0.05\ndepth_mask = r_chl/r_chl\ndepth_mask[,]= 1\ndepth_mask[per_shallow&gt;= percent_threshold]= NA\nplot(depth_mask,main=\"Shallow pixel mask\")\n\n\n\n\n# Read in the files previousely downloaded\nfiles = list.files('chl_data/', full.names = T)\n# Read the file into R and make it to rasterstack\nstack_chl = stack(files)\n# Convert raster data to dataframe for calculating climatology\ndf_chl = as.data.frame(rasterToPoints(stack_chl))\ndf_chl$z = rowMeans(df_chl[,3:dim(df_chl)[2]], na.rm = T)\n# Convert dataframe to raster for mapping\nr_chl_clim = rasterFromXYZ(df_chl[,c(\"x\", \"y\", \"z\")])\n# Map unmasked climatology\nplot(log(r_chl_clim),main=\"Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n# Apply Mask, calculate climatology and map\nr_chl_masked = mask(x = stack_chl, mask = depth_mask)\n# Convert masked raster data to dataframe for calculating climatology\ndf_chl_masked = as.data.frame(rasterToPoints(r_chl_masked))\ndf_chl_masked$z = rowMeans(df_chl_masked[,3:dim(df_chl_masked)[2]], na.rm = T)\n# Convert dataframe to raster for mapping\nr_chl_masked_clim = rasterFromXYZ(df_chl_masked[,c(\"x\", \"y\", \"z\")])\n# Map masked climatology\nplot(log(r_chl_masked_clim),main=\"Masked Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n\n\n\n# Grab var name and unit from unmasked nc file\nnc = nc_open(paste0(files))\nvariable_name = as.character(nc$var[[1]][2])\nvariable_unit = as.character(nc$var[[1]][8])\nx_name = nc$dim$longitude$name\ny_name = nc$dim$latitude$name\nz_name = nc$dim$time$name\nz_unit = nc$dim$time$units\nnc_close(nc)\n# Set a file name and output path for the masked data\nmasked_fln = 'esa_cci_monthly_chl-a_masked.nc'\nmask_path = paste0(Dir,  \"/output/\")\nif (!dir.exists(mask_path)) {\n  dir.create(mask_path)\n}\n# Write out masked nc.file\nwriteRaster(r_chl_masked,\n            paste0(mask_path, masked_fln),\n            overwrite = T,\n            varname = variable_name,\n            varunit = variable_unit,\n            xname = x_name,\n            yname = y_name,\n            zname = z_name,\n            zunit = z_unit)\n\n\n\nSpecial thanks to Kisei Tanaka from NOAA’s Pacific Islands Fisheries Science Center (PIFSC) for his contributions to this tutorial, which is adapted from the scripts he developed. Additionally, portions of this tutorial have been revised based on a previous version created by Melanie Abecassis and Thomas Oliver."
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#objective",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#objective",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "In this tutorial, we demonstrate how to create a mask to remove ocean color pixels in the coastal shallow water that are contaminated by bottom reflectance."
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "Accessing and Downloading satellite data from ERDDAP data server\nVisualizing the datasets\nMatching coarse-resolution ocean color data with fine-resolution bathymetry data\nCalculating percentage of shallow water area in each ocean color pixel\nCreating and applying value mask to datasets\nCalculating long-term climatology from monthly data\nOutputing dataset into netCDF format"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#datasets-used",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#datasets-used",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "Bathymetry data, ETOPO Global Relief Model integrates topography, bathymetry, and shoreline data, version 2022, 15 arc-second resolution\nOcean color data, ESA CCI chlorophyll-a concentration, 1998-2022, monthly"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#references",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#references",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "Couch CS, Oliver TA, Dettloff K, Huntington B, Tanaka KR and Vargas-Ángel B (2023) Ecological and environmental predictors of juvenile coral density across the central and western Pacific. Front. Mar. Sci. 10:1192102.  doi: 10.3389/fmars.2023.1192102"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#load-libraries",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#load-libraries",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "# Load libraries\nlibrary(rerddap)\nlibrary(raster) \nlibrary(sp) \nlibrary(cmocean)\nlibrary(here)\nlibrary(ncdf4)"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#set-work-directory",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#set-work-directory",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "# This is where the data are and where the plots will go\nDir &lt;- here()"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#access-and-download-satellite-data",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#access-and-download-satellite-data",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "We will access the ETOPO2022 bathymetry data and the monthly ESA CCI chlorophyll-a concentration data (1/1998-12/2022) for the island of Oahu from the OceanWatch ERDDAP server. We will also download the chlorophyll-a data and save it to local for future use.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\nWe will utilize the ’‘’rerddap’’’ R package to engage with the ERDDAP data server. The ’‘’rerddap’’’ package, created by Roy Mendelssohn (SWFSC) and Scott Chamberlain, is designed to simplify the process of importing data into R.\n# Bounding box for Oahu:\nlon_range = c(-158.39+360, -157.55+360)\nlat_range = c(21.14, 21.8)\n\n# Set ERDDAP URL\nERDDAP_Node = \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\n\n# Download bathymetry data with its unique ID \nETOPO_id = 'ETOPO_2022_v1_15s'\nETOPO_info=info(datasetid = ETOPO_id,url = ERDDAP_Node)\nbathy =  griddap(url = ERDDAP_Node, ETOPO_id, \n                 latitude = lat_range, longitude = lon_range)\n\n# Download ocean color data with its unique ID\nCCI_id = 'esa-cci-chla-monthly-v6-0'\nCCI_info=info(datasetid = CCI_id,url = ERDDAP_Node)\nvar=CCI_info$variable$variable_name\nchl = griddap(url = ERDDAP_Node, CCI_id, \n                   time = c('1998-01-01', '2022-12-01'),\n                   latitude = lat_range, longitude = lon_range,\n                   fields = var[1],\n                   store=disk('chl_data'))"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#visualize-bathymetry-and-chlorophyll-a-data",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#visualize-bathymetry-and-chlorophyll-a-data",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "We convert bathymetry and chlorophyll-a data to rasters for visulization.\n# Convert the data into a raster layer\nr_bathy=raster(bathy$summary$filename)\n\nplot(r_bathy,main=\"ETOPO Bathymetry (m)\")\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n# Convert the data into a raster layer\nr_chl=raster(chl$summary$filename,varname=var[1]) \n\nplot(log(r_chl),main=\"ESA CCI Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE)"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#match-two-datasets-and-calculate-percentage-of-shallow-water-area-in-each-ocean-color-pixel",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#match-two-datasets-and-calculate-percentage-of-shallow-water-area-in-each-ocean-color-pixel",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "The ocean color data has coarser resolution (~4km) compared with the bathymetry data (~500m). We will calculate how much area (percentage) within each ocean color pixel is in shallow water (&lt;30m depth).\n#Convert raster bathymetry to SpatialPoints dataframe for counting\ndf_bathy = data.frame(rasterToPoints(r_bathy))\ncoordinates(df_bathy) &lt;- ~x+y\ncrs(df_bathy) = crs(r_chl[[1]])\n\n# Define a function to calculate the percentage of (smaller) bathymetry pixels in each (larger) Chl-a pixel that are shallow\npercent_shallow_pixels=function(depths,threshold=-30, na.rm=F){ \n  return(length(which(depths&gt;threshold))/length(depths)) \n} \n  \n# Build a raster of the chl-a grid, using the function to generate the shallow water area percentage to consider a pixel necessary to mask\nper_shallow =  rasterize(x = df_bathy,y=r_chl,fun=percent_shallow_pixels)[[2]]\nplot(per_shallow,main=\"% Shallow water\", col=cmocean('amp')(50))"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#create-a-mask-for-shallow-pixels",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#create-a-mask-for-shallow-pixels",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "# Set a percentage threshold to create the shallow pixel mask\npercent_threshold = 0.05\ndepth_mask = r_chl/r_chl\ndepth_mask[,]= 1\ndepth_mask[per_shallow&gt;= percent_threshold]= NA\nplot(depth_mask,main=\"Shallow pixel mask\")"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#calculate-long-term-climatology-and-compare-unmasked-and-masked-maps",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#calculate-long-term-climatology-and-compare-unmasked-and-masked-maps",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "# Read in the files previousely downloaded\nfiles = list.files('chl_data/', full.names = T)\n# Read the file into R and make it to rasterstack\nstack_chl = stack(files)\n# Convert raster data to dataframe for calculating climatology\ndf_chl = as.data.frame(rasterToPoints(stack_chl))\ndf_chl$z = rowMeans(df_chl[,3:dim(df_chl)[2]], na.rm = T)\n# Convert dataframe to raster for mapping\nr_chl_clim = rasterFromXYZ(df_chl[,c(\"x\", \"y\", \"z\")])\n# Map unmasked climatology\nplot(log(r_chl_clim),main=\"Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n# Apply Mask, calculate climatology and map\nr_chl_masked = mask(x = stack_chl, mask = depth_mask)\n# Convert masked raster data to dataframe for calculating climatology\ndf_chl_masked = as.data.frame(rasterToPoints(r_chl_masked))\ndf_chl_masked$z = rowMeans(df_chl_masked[,3:dim(df_chl_masked)[2]], na.rm = T)\n# Convert dataframe to raster for mapping\nr_chl_masked_clim = rasterFromXYZ(df_chl_masked[,c(\"x\", \"y\", \"z\")])\n# Map masked climatology\nplot(log(r_chl_masked_clim),main=\"Masked Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE)"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#output-masked-chlorophyll-a-data-to-a-netcdf-file",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#output-masked-chlorophyll-a-data-to-a-netcdf-file",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "# Grab var name and unit from unmasked nc file\nnc = nc_open(paste0(files))\nvariable_name = as.character(nc$var[[1]][2])\nvariable_unit = as.character(nc$var[[1]][8])\nx_name = nc$dim$longitude$name\ny_name = nc$dim$latitude$name\nz_name = nc$dim$time$name\nz_unit = nc$dim$time$units\nnc_close(nc)\n# Set a file name and output path for the masked data\nmasked_fln = 'esa_cci_monthly_chl-a_masked.nc'\nmask_path = paste0(Dir,  \"/output/\")\nif (!dir.exists(mask_path)) {\n  dir.create(mask_path)\n}\n# Write out masked nc.file\nwriteRaster(r_chl_masked,\n            paste0(mask_path, masked_fln),\n            overwrite = T,\n            varname = variable_name,\n            varunit = variable_unit,\n            xname = x_name,\n            yname = y_name,\n            zname = z_name,\n            zunit = z_unit)"
  },
  {
    "objectID": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#acknowledgements",
    "href": "tutorials/mask-shallow-ocean-color/r/mask-shallow-ocean-color.html#acknowledgements",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "Special thanks to Kisei Tanaka from NOAA’s Pacific Islands Fisheries Science Center (PIFSC) for his contributions to this tutorial, which is adapted from the scripts he developed. Additionally, portions of this tutorial have been revised based on a previous version created by Melanie Abecassis and Thomas Oliver."
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "",
    "text": "History | Updated Apr 2025"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#objective",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#objective",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab daily chlorophyll-a data hosted on an ERDDAP server using the griddap function in the rerrdap package, how to make temporal composites in R and how to make some maps and time-series of chlorophyll-a."
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "The tutorial demonstrates the following techniques:",
    "text": "The tutorial demonstrates the following techniques:\n\nAccessing gridded satellite data from an ERDDAP server using the rerddap package.\nSubsetting spatial and temporal data using latitude, longitude, and date ranges.\nConverting gridded data to tidy format for analysis using dplyr and lubridate.\nCalculating monthly and annual spatial averages of chlorophyll-a concentrations.\nCreating faceted maps of monthly chlorophyll-a using ggplot2 and viridis color scales.\nCreating an 8-day time series to analyze seasonal chlorophyll-a patterns.\nComparing chlorophyll-a seasonal cycles between regions (West vs. East Long Island Sound)."
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#datasets-used",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#datasets-used",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Datasets used",
    "text": "Datasets used\nLong Island Sound Optimized water quailty datasets from OLCI Products developed by academic collaborators that have partnered with NOAA CoastWatch through a Sea Grant project titled “Actionable satellite water-quality data products in Long Island Sound for improved management and societal benefits”. The dataset includes daily Sentinal-3 OLCI (300 m) water quality indicators:\n\nChlorophyll-a (Chla “chlor_a”)\nAbsorption coefficient of Chromophoric Dissolved Organic Material at 300 nm (aCDOM(300) “cdom”)\nDissolved Organic Carbon (DOC “doc”)\nSuspended Particulate Matter (SPM “spm”). Chlor_a, cdom and doc are based on Long Island Sound optimized algorithms. Spm retrieved using the Nechad Algorithm.\n\nThis dataset covers the Long Island Sound region between 40.2° N - 41.5° N and 74° W - 71.8° W\nIn this tutorial we will use the daily Chlorophyll-a dataset. The data will be downloaded from the CoastWatch ERRDAP server: https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.html\nFor more information on each product refer to:\n\nChla: https://www.sciencedirect.com/science/article/pii/S1569843223000456\nCDOM and DOC: https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2023JG007767\nSPM: https://www.sciencedirect.com/science/article/abs/pii/S0034425709003617"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#install-and-load-packages",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#install-and-load-packages",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Install and load packages",
    "text": "Install and load packages\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"tidyverse\", \"lubridate\", \"viridis\", \"ggplot2\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#select-the-satellite-dataset",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#select-the-satellite-dataset",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Select the satellite dataset",
    "text": "Select the satellite dataset\nWe will load the daily Chlorophyll-a dataset from the CoastWatch ERDDAP server. The dataset ID is noaacwappsS3ABcolorLISDaily.\nWe will use the info function from the rerddap package to first obtain information about the dataset of interest, then we will import the data.\n# Set the ERDDAP URL\nerddap_url &lt;- \"https://coastwatch.noaa.gov/erddap\"\n\n# Set the dataset ID\ndataset_id &lt;- \"noaacwappsS3ABcolorLISDaily\"\n\n# Obtain data info using the erddap url and dataset ID\ndataInfo &lt;- rerddap::info(dataset_id,url=erddap_url)  \n\n# Examine the metadata dataset info\ndataInfo\n## &lt;ERDDAP info&gt; noaacwappsS3ABcolorLISDaily \n## Base URL: https://coastwatch.noaa.gov/erddap \n## Dataset Type: griddap \n## Dimensions (range):  \n##     time: (2017-01-01T00:00:00Z, 2025-02-28T00:00:00Z) \n##     latitude: (40.204, 41.5) \n##     longitude: (-74.0, -71.8049) \n## Variables:  \n##     cdom: \n##         Units: m^-1 \n##     chlor_a: \n##         Units: mg m^-3 \n##     doc: \n##         Units: Âµmole/liter \n##     spm: \n##         Units: mg L^-1"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#subset-the-data",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#subset-the-data",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Subset the data",
    "text": "Subset the data\nFor this tutorial, we will be focusing on chloropyhll-a throughout 2022 in the Long Island Sound Range.\n# Set the time range\ntime_range &lt;- c(\"2022-01-01\", \"2022-12-31\")\n\n# Set the ranges for latitude and longitude\nlat_range &lt;- c(40.204, 41.5)\nlon_range &lt;- c(-74.0, -71.8049)\n\n# Set the parameter\nparameter &lt;- 'chlor_a'"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#extract-the-dataset",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#extract-the-dataset",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Extract the dataset",
    "text": "Extract the dataset\n# Download the chlorophyll-a data\nchlor_data &lt;- griddap(\n  datasetx = dataset_id,\n  url = erddap_url,\n  time = time_range,\n  latitude = lat_range,       \n  longitude = lon_range,\n  fields = parameter\n)\n\n# View the data\nhead(chlor_data)"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#convert-to-a-tibble-and-add-datemonth-columns",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#convert-to-a-tibble-and-add-datemonth-columns",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Convert to a tibble and add date/month columns",
    "text": "Convert to a tibble and add date/month columns\nConverting to a tibble makes the dataset tidy-verse friendly, so we can manipulate the data without headaches.\n# Convert to tibble and add date/month columns\ndf &lt;- chlor_data$data %&gt;%\n  as_tibble() %&gt;%\n  mutate(\n    time = as.Date(time),\n    month = floor_date(time, \"month\")\n  )\n\n# View the data\nprint(df)"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#calculate-monthly-mean-chlorophyll-a",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#calculate-monthly-mean-chlorophyll-a",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Calculate monthly mean chlorophyll-a",
    "text": "Calculate monthly mean chlorophyll-a\nWe group the data by month, latitude, and longitude and compute the average chlorophyll-a for each pixel for each month. We also remove any missing values.\n# Calculate monthly mean chlor_a\nmonthly_mean &lt;- df %&gt;%\n  group_by(month, latitude, longitude) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\")\n\n# View the data\nprint(monthly_mean)"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#list-the-dates-for-each-time-step-after-calculating-the-monthly-means",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#list-the-dates-for-each-time-step-after-calculating-the-monthly-means",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "List the dates for each time step after calculating the monthly means",
    "text": "List the dates for each time step after calculating the monthly means\nThe dataset now has 12 time steps, one for each month between January 2022 and December 2022.\nunique(monthly_mean$month)\n##[1] \"2022-01-01\" \"2022-02-01\" \"2022-03-01\" \"2022-04-01\" \"2022-05-01\" \"2022-06-01\" \n##\"2022-07-01\" \"2022-08-01\" \"2022-09-01\" \"2022-10-01\" \"2022-11-01\"\n##[12] \"2022-12-01\""
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#create-a-faceted-plot-of-monthly-mean-chlorophyll-a-for-2022",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#create-a-faceted-plot-of-monthly-mean-chlorophyll-a-for-2022",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Create a faceted plot of monthly mean chlorophyll-a for 2022",
    "text": "Create a faceted plot of monthly mean chlorophyll-a for 2022\nUsing ggplot, we create a faceted spatial plot of chlorophyll-a with tiles colored by value, and one map per month of 2022.\nfacet_wrap tells ggplot to split the plot in 12 facets (one for each month) and ncol = 4 puts the 12 plots into 3 rows and 4 columns.\nggplot(monthly_mean, aes(x = longitude, y = latitude, fill = chlor_a)) +\n  geom_tile() +\n  scale_fill_viridis(\n    name = bquote(\"Chlorophyll-a (mg \"*m^{-3}*\")\"),\n    option = \"turbo\",\n    limits = c(0, 20),\n    na.value = \"transparent\"\n  ) +\n  scale_x_continuous(\n    breaks = c(-74, -73, -72),\n    labels = c(\"-74\", \"-73\", \"-72\")\n  ) +\n  coord_equal() +\n  facet_wrap(~format(month, \"%Y-%m-%d\"), ncol = 4) +\n  labs(x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal(base_size = 12) +\n  theme(strip.text = element_text(size = 10))\n\n\n\nimages"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#compute-the-annual-average-for-the-region",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#compute-the-annual-average-for-the-region",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Compute the annual average for the region",
    "text": "Compute the annual average for the region\nCalculate the annual average chlorophyll-a at each pixel by grouping the monthly data by latitude and longitude, then taking the mean across all months. We also remove any missing values.\nyearly_mean &lt;- monthly_mean %&gt;%\n  group_by(latitude, longitude) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\")"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#plot-the-map-of-the-2022-average-chlorophyll-a-in-the-region",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#plot-the-map-of-the-2022-average-chlorophyll-a-in-the-region",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Plot the map of the 2022 average chlorophyll-a in the region",
    "text": "Plot the map of the 2022 average chlorophyll-a in the region\nggplot(yearly_mean, aes(x = longitude, y = latitude, fill = chlor_a)) +\n  geom_tile() +\n  scale_fill_viridis(\n    name = bquote(\"Chlorophyll-a (mg \"*m^{-3}*\")\"),\n    option = \"turbo\",\n    limits = c(0, 20),\n    na.value = \"transparent\"\n  ) +\n  coord_equal() +\n  labs(\n    title = \"Mean Chlorophyll-a\\nJan 2022 – Dec 2022\",\n    x = \"Longitude\", y = \"Latitude\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\nimages"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound",
    "text": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound\nSubset the data\n\nWest Long Island Sound between -73.9° to -73.1° W longitude\nEast Long Island Sound between -72.9° to -71.8° W longitude\n\nWe are going to generate a time series of mean chlorophyll-a within each box.\n# Subset West Long Island\nwest_df &lt;- df %&gt;%\n  filter(longitude &gt;= -73.9, longitude &lt;= -73.1)\n\n# Subset East Long Island\neast_df &lt;- df %&gt;%\n  filter(longitude &gt;= -72.9, longitude &lt;= -71.8)"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#examine-the-structure-of-the-subsetted-data",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#examine-the-structure-of-the-subsetted-data",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Examine the structure of the subsetted data",
    "text": "Examine the structure of the subsetted data\nstr(west_df)\n\nstr(east_df)"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#resample-each-subset-to-8-day-means",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#resample-each-subset-to-8-day-means",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Resample each subset to 8-day means",
    "text": "Resample each subset to 8-day means\n# Resample west_df\nwest_df &lt;- west_df %&gt;%\n  mutate(\n    period = as.Date(\"2022-01-01\") +\n      floor(as.numeric(difftime(time, as.Date(\"2022-01-01\"), units = \"days\")) / 8) * 8\n  )\n\n# Resample east_df\neast_df &lt;- east_df %&gt;%\n  mutate(\n    period = as.Date(\"2022-01-01\") +\n      floor(as.numeric(difftime(time, as.Date(\"2022-01-01\"), units = \"days\")) / 8) * 8\n  )"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#compute-a-time-series",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#compute-a-time-series",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Compute a time series",
    "text": "Compute a time series\nNow, we will average all data within each subset across the latitude and longitude dimensions to produce a single time series.\nwest_ts &lt;- west_df %&gt;%\n  group_by(period) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(region = \"West LIS\")\n\neast_ts &lt;- east_df %&gt;%\n  group_by(period) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(region = \"East LIS\")"
  },
  {
    "objectID": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#plot-the-time-series",
    "href": "tutorials/lis-chlora-dynamics/r/lis-chlora-dynamics.html#plot-the-time-series",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Plot the time series",
    "text": "Plot the time series\n# Combine for plotting\nts_combined &lt;- bind_rows(west_ts, east_ts)\n\n# Plot the time series\nggplot(ts_combined, aes(x = period, y = chlor_a, color = region)) +\n  geom_line() +\n  geom_point(size = 1) +\n  scale_color_manual(values = c(\"West LIS\" = \"blue\", \"East LIS\" = \"red\")) +\n  labs(\n    title = \"Seasonal Cycle of Chlorophyll-a in Long Island Sound (2022)\",\n    x = \"Date\",\n    y = bquote(\"Chlorophyll-a (mg \"*m^{-3}*\")\"),\n    color = \"Region\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\nimages"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html",
    "href": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html",
    "title": "Extract data within a boundary",
    "section": "",
    "text": "history | Updated August 2023"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#background",
    "href": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#background",
    "title": "Extract data within a boundary",
    "section": "Background",
    "text": "Background\nOne use for satellite observations is to supplement in situ sampling of geographical locations where the timespan, frequency measurements, spatial dimensions or remoteness of the locations, make physical sampling impossible or impractical. One drawback is that satellite data are often rectangular, whereas geographical locations can have irregular boundaries. Examples of boundaries include marine protected areas or marine physical, biological, and ecological divisions like the Longhurst Marine Provinces."
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#objectives",
    "href": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#objectives",
    "title": "Extract data within a boundary",
    "section": "Objectives",
    "text": "Objectives\nIn this tutorial we will learn how to download a timeseries of SST satellite data from an ERDDAP server, and then mask the data to retain only the data within an irregular geographical boundary (polygon). We will then plot a yearly seasonal cycle from within the boundary."
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Extract data within a boundary",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data from an ERDDAP data server for a non-rectangular region using the rerddapXtracto package\nVisualizing data on a map\nPlotting a time-series of mean SST"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#datasets-used",
    "href": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#datasets-used",
    "title": "Extract data within a boundary",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Geo-polar Blended Analysis Sea-Surface Temperature, Global, Monthlyly, 5km, 2019-Present\nThe NOAA geo-polar blended SST is a high resolution satellite-based gap-free sea surface temperature (SST) product that combines SST data from US, Japanese and European geostationary infrared imagers, and low-earth orbiting infrared (U.S. and European) SST data, into a single product. We will use the monthly composite. https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly\nLonghurst Marine Provinces\nThe dataset represents the division of the world oceans into provinces as defined by Longhurst (1995; 1998; 2006). This division has been based on the prevailing role of physical forcing as a regulator of phytoplankton distribution. The Longhurst Marine Provinces dataset is available online (https://www.marineregions.org/downloads.php) and within the shapes folder associated with this repository. For this tutorial we will use the Gulf Stream province (ProvCode: GFST)\n\n\n\n../images/longhurst.png"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#install-packages-and-load-libraries",
    "href": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#install-packages-and-load-libraries",
    "title": "Extract data within a boundary",
    "section": "Install packages and load libraries",
    "text": "Install packages and load libraries\npkges = installed.packages()[,\"Package\"]\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n# create list of required packages\nlist.of.packages &lt;- c(\"ncdf4\", \"rerddap\",\"plotdap\", \"parsedate\", \n                      \"sp\", \"ggplot2\", \"RColorBrewer\", \"sf\", \n                      \"reshape2\", \"maps\", \"mapdata\", \n                      \"jsonlite\", \"rerddapXtracto\")\n\n# Run install and load function\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#load-boundary-coordinates",
    "href": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#load-boundary-coordinates",
    "title": "Extract data within a boundary",
    "section": "Load boundary coordinates",
    "text": "Load boundary coordinates\nThe shapefile for the Longhurst marine provinces includes a list of regions. For this exercise, we will only use the boundary of one province, the Gulf Stream region (“GFST”).\n# Set directory path\ndir_path &lt;- '../resources/longhurst_v4_2010/'\n\n# Import shape files (Longhurst coordinates)\nshapes &lt;- read_sf(dsn = dir_path, layer = \"Longhurst_world_v4_2010\")\n\n# Example List of all the province names\nshapes$ProvCode\n##  [1] \"BPLR\" \"ARCT\" \"SARC\" \"NADR\" \"GFST\" \"NASW\" \"NATR\" \"WTRA\" \"ETRA\" \"SATL\"\n## [11] \"NECS\" \"CNRY\" \"GUIN\" \"GUIA\" \"NWCS\" \"MEDI\" \"CARB\" \"NASE\" \"BRAZ\" \"FKLD\"\n## [21] \"BENG\" \"MONS\" \"ISSG\" \"EAFR\" \"REDS\" \"ARAB\" \"INDE\" \"INDW\" \"AUSW\" \"BERS\"\n## [31] \"PSAE\" \"PSAW\" \"KURO\" \"NPPF\" \"NPSW\" \"TASM\" \"SPSG\" \"NPTG\" \"PNEC\" \"PEQD\"\n## [41] \"WARM\" \"ARCH\" \"ALSK\" \"CCAL\" \"CAMR\" \"CHIL\" \"CHIN\" \"SUND\" \"AUSE\" \"NEWZ\"\n## [51] \"SSTC\" \"SANT\" \"ANTA\" \"APLR\"\n# Get boundary coordinates for Gulf Stream region (GFST)\nGFST &lt;- shapes[shapes$ProvCode == \"GFST\",]\n\nxcoord &lt;- st_coordinates(GFST)[,1]\nycoord &lt;- st_coordinates(GFST)[,2]"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#select-the-satellite-dataset",
    "href": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#select-the-satellite-dataset",
    "title": "Extract data within a boundary",
    "section": "Select the satellite dataset",
    "text": "Select the satellite dataset\nWe will load the sea surface temperature data from the geo-polar blended SST satellite data product hosted on the CoastWatch ERDDAP. The dataset ID for this data product is nesdisBLENDEDsstDNDaily.\nWe will use the info function from the rerddap package to first obtain information about the dataset of interest, then we will import the data.\n# Set ERDDAP URL\nerd_url = \"http://coastwatch.pfeg.noaa.gov/erddap/\"\n\n# Obtain data info using the erddap url and dataset ID\ndataInfo &lt;- rerddap::info('NOAA_DHW_monthly',url=erd_url)  \n\n# Examine the metadata dataset info\ndataInfo\n## &lt;ERDDAP info&gt; NOAA_DHW_monthly \n##  Base URL: http://coastwatch.pfeg.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1985-01-16T00:00:00Z, 2023-08-16T00:00:00Z) \n##      latitude: (-89.975, 89.975) \n##      longitude: (-179.975, 179.975) \n##  Variables:  \n##      mask: \n##          Units: pixel_classification \n##      sea_surface_temperature: \n##          Units: degree_C \n##      sea_surface_temperature_anomaly: \n##          Units: degree_C"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#set-the-options-for-the-polygon-data-extract",
    "href": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#set-the-options-for-the-polygon-data-extract",
    "title": "Extract data within a boundary",
    "section": "Set the options for the polygon data extract",
    "text": "Set the options for the polygon data extract\nUsing the rxtractogon function, we will import the satellite data from erddap. The rxtractogon function takes the variable(s) of interest and the coordinates as input.\n\nFor the coordinates: determine the range of x, y, z, and time.\ntime coordinate: select the entire year of 2020\n\n# set the parameter to extract\nparameter &lt;- 'sea_surface_temperature'\n# set the time range\ntcoord &lt;- c(\"2020-01-16\", \"2020-12-16\")\n\n# We already extracted the xcoord (longitude) and ycoord (latitude) from the shapefiles \n# The dummy code below is just a placeholder indicating it is necessary to define what the longitude and latitude vectors are that make up the boundary of the polygon.\nxcoord &lt;- xcoord\nycoord &lt;- ycoord"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#extract-data-and-mask-it-using-rxtractogon",
    "href": "tutorials/extract-satellite-data-within-boundary/r/extract-satellite-data-within-boundary.html#extract-data-and-mask-it-using-rxtractogon",
    "title": "Extract data within a boundary",
    "section": "Extract data and mask it using rxtractogon",
    "text": "Extract data and mask it using rxtractogon\n\nthe rxtractogon function automatically extracts data from the satellite dataset and masks out any data outside the polygon boundary.\n\nList the data\n\n## Request the data\nsatdata &lt;- rxtractogon(dataInfo, parameter=parameter, xcoord=xcoord, ycoord=ycoord,tcoord=tcoord)\n\n## List the returned data\nstr(satdata)\n## List of 6\n##  $ sea_surface_temperature: num [1:601, 1:202, 1:12] NA NA NA NA NA NA NA NA NA NA ...\n##  $ datasetname            : chr \"NOAA_DHW_monthly\"\n##  $ longitude              : num [1:601(1d)] -73.5 -73.5 -73.4 -73.4 -73.3 ...\n##  $ latitude               : num [1:202(1d)] 33.5 33.5 33.6 33.6 33.7 ...\n##  $ altitude               : logi NA\n##  $ time                   : POSIXlt[1:12], format: \"2020-01-16 00:00:00\" \"2020-02-16 00:00:00\" ...\n##  - attr(*, \"class\")= chr [1:2] \"list\" \"rxtracto3D\"\n\nPlot the data\n\nUse the plotBBox function in the rerddapXtracto package to quickly plot the data\n\nplotBBox(satdata, plotColor = 'thermal',maxpixels=1000000)\n\n\n\nPlot the mean seasonal temperature for the province\nsst_mean=apply(satdata$sea_surface_temperature,3,mean,na.rm=TRUE)\nplot(satdata$time,sst_mean,main='Gulf Stream Province Monthly Mean Temperature 2020',ylab='SSt (ºC)',xlab='',type='b')"
  },
  {
    "objectID": "tutorials/define_marine_habitat/r/define_marine_habitat.html",
    "href": "tutorials/define_marine_habitat/r/define_marine_habitat.html",
    "title": "Define a marine habitat",
    "section": "",
    "text": "notebook filename | define_marine_habitat.Rmd"
  },
  {
    "objectID": "tutorials/define_marine_habitat/r/define_marine_habitat.html#install-required-packages-and-load-libraries",
    "href": "tutorials/define_marine_habitat/r/define_marine_habitat.html#install-required-packages-and-load-libraries",
    "title": "Define a marine habitat",
    "section": "Install required packages and load libraries",
    "text": "Install required packages and load libraries\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ncdf4\", \"rerddap\", \"plotdap\", \"RCurl\",  \n                       \"raster\", \"colorRamps\", \"maps\", \"mapdata\",\n                       \"ggplot2\", \"RColorBrewer\", \"rerddapXtracto\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/define_marine_habitat/r/define_marine_habitat.html#select-the-satellite-data",
    "href": "tutorials/define_marine_habitat/r/define_marine_habitat.html#select-the-satellite-data",
    "title": "Define a marine habitat",
    "section": "Select the Satellite Data",
    "text": "Select the Satellite Data\n\nUse the CoralTemp SST dataset (ID CRW_sst_v3_1) from the OceanWatch ERDDAP server (https://oceanwatch.pifsc.noaa.gov/erddap/index.html)\n\nGather information about the dataset (metadata) using rerddap\n\nDisplay the information\n\n# Let's look at the metadata\n\n\nurl = \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\ndataInfo &lt;- rerddap::info('CRW_sst_v3_1',url=url)\nparameter &lt;- 'analysed_sst'\ndataInfo\n## &lt;ERDDAP info&gt; CRW_sst_v3_1 \n##  Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1985-01-01T12:00:00Z, 2023-09-09T12:00:00Z) \n##      latitude: (-89.975, 89.975) \n##      longitude: (0.025, 359.975) \n##  Variables:  \n##      analysed_sst: \n##          Units: degree_C \n##      sea_ice_fraction: \n##          Units: 1"
  },
  {
    "objectID": "tutorials/define_marine_habitat/r/define_marine_habitat.html#get-satellite-data",
    "href": "tutorials/define_marine_habitat/r/define_marine_habitat.html#get-satellite-data",
    "title": "Define a marine habitat",
    "section": "Get Satellite Data",
    "text": "Get Satellite Data\n\nSelect an area of the central North Pacific where the fishery operates: longitude range of 185 to 235 east and latitude range of 20 to 45 north\n\nSelect a date in the first quarter of the year when bycatch typically occurs: tcoord=c('2023-01-06', '2023-01-06')). tcoord needs to be a vector even if we are pulling only one day of data.\n\n# latitude and longitude of the vertices\nylim&lt;-c(20,45)\nxlim&lt;-c(185,235)\n\n# Extract the data\nSST &lt;- rxtracto_3D(dataInfo,xcoord=xlim,ycoord=ylim,parameter=parameter, \n                   tcoord=c('2023-01-06','2023-01-06'))\n\n# Drop command needed to reduce SST from a 3D variable to a 2D  one  \nSST$analysed_sst &lt;- drop(SST$analysed_sst)"
  },
  {
    "objectID": "tutorials/define_marine_habitat/r/define_marine_habitat.html#make-a-quick-plot-using-plotbbox",
    "href": "tutorials/define_marine_habitat/r/define_marine_habitat.html#make-a-quick-plot-using-plotbbox",
    "title": "Define a marine habitat",
    "section": "Make a quick plot using plotBBox",
    "text": "Make a quick plot using plotBBox\nplotBBox(SST, plotColor = 'thermal')\n\n         #,maxpixels=1000000)"
  },
  {
    "objectID": "tutorials/define_marine_habitat/r/define_marine_habitat.html#define-and-plot-the-turtlewatch-temperature-band",
    "href": "tutorials/define_marine_habitat/r/define_marine_habitat.html#define-and-plot-the-turtlewatch-temperature-band",
    "title": "Define a marine habitat",
    "section": "Define and plot the TurtleWatch temperature band",
    "text": "Define and plot the TurtleWatch temperature band\nSet the temperature band to 17.5-18.5 degrees C, as determined by the TurtleWatch program.\n## Define turtle temperature range\nmin.temp &lt;- 17.5\nmax.temp &lt;- 18.5\nCreate another variable for habitat temperature\nSet the habitat temperature to equal NA\nSST2 &lt;- SST\nSST2$analysed_sst[SST2$analysed_sst &gt;= min.temp & SST2$analysed_sst &lt;= max.temp] &lt;- NA\nplotBBox(SST2, plotColor = 'thermal')\n\nIt would be nicer to color in the TurtleWatch band (the NA values) with a different color. If you want to customize graphs, it’s better to use ggplot than the plotBBox that comes with the rerrdapXtracto package. Here we will use ggplot to plot the data. But first the data is reformatted for use in ggplot.\nRestructure the data\ndims &lt;- dim(SST2$analysed_sst)\nSST2.lf &lt;- expand.grid(x=SST$longitude,y=SST$latitude)\nSST2.lf$sst&lt;-array(SST2$analysed_sst,dims[1]*dims[2])"
  },
  {
    "objectID": "tutorials/define_marine_habitat/r/define_marine_habitat.html#plot-the-data-using-ggplot",
    "href": "tutorials/define_marine_habitat/r/define_marine_habitat.html#plot-the-data-using-ggplot",
    "title": "Define a marine habitat",
    "section": "Plot the Data using ‘ggplot’",
    "text": "Plot the Data using ‘ggplot’\ncoast &lt;- map_data(\"worldHires\", ylim = ylim, xlim = xlim)\n\npar(mar=c(3,3,.5,.5), las=1, font.axis=10)\n\nmyplot&lt;-ggplot(data = SST2.lf, aes(x = x, y = y, fill = sst)) +\n  geom_tile(na.rm=T) +\n  geom_polygon(data = coast, aes(x=long, y = lat, group = group), fill = \"grey80\") +\n  theme_bw(base_size = 15) + ylab(\"Latitude\") + xlab(\"Longitude\") +\n  coord_fixed(1.3,xlim = xlim, ylim = ylim) +\n  ggtitle(unique(as.Date(SST2$time))) +\n  scale_fill_gradientn(colours = rev(rainbow(12)),limits=c(5,30),na.value = \"firebrick4\") \n\nmyplot"
  },
  {
    "objectID": "tutorials/codegallery.html",
    "href": "tutorials/codegallery.html",
    "title": "Code Gallery",
    "section": "",
    "text": "The Code Gallery provides a collection of coding-based tutorials that demonstrate how to access, analyze, and visualize CoastWatch satellite data using common programming languages. These tutorials focus on reproducible, hands-on workflows and are intended for users who want to work directly with data through code.\nMany tutorials are available in multiple software languages, such as Python, R, and MATLAB, allowing users to follow the same workflow using the tools they prefer.\nEach tutorial presents a complete example workflow, including data access (for example through ERDDAP), basic data processing and quality control steps, and the generation of common outputs such as maps, time series, or summary statistics.\nThe Code Gallery is designed to support exploration, comparison, and reuse of coding workflows. Users are encouraged to adapt the example code to their own research, educational, or operational needs.\nClick the eye icon to view the tutorial, box icon to view the required resources, or download to get directed to the source file.\n\n\n\n\n\n\n\n  \n    Category\n    \n      All\n      Data Access & SubsettingERDDAP BasicsSpatial Analysis & MappingTime Series\n    \n  \n\n  \n    Software\n\n    \n      Python ×\n    \n\n    \n      R ×\n    \n\n    \n      Matlab ×\n    \n\n    \n      Clear\n    \n  \n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nCategory\nPreview\nResources\nPython ↓\nR ↓\nMatlab ↓\n\n\n\n\nBasics of working with satellite data\nERDDAP Basics\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompare time series from different sensors\nTime Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMake a virtual buoy with satellite data\nTime Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nCalculating sea ice area and extent\nSpatial Analysis & Mapping\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n—\n\n\nWorking with data that crosses the antimeridian\nSpatial Analysis & Mapping\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nDefine a marine habitat\nSpatial Analysis & Mapping\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n—\n\n\nExtract data within a boundary\nData Access & Subsetting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to work with satellite data in Matlab in the Great Lakes\nERDDAP Basics\n\n\n\n\n\n—\n—\n—\n\n\n\n\n\n\n\nWorking with Great Lakes Surface Temperature Data\nData Access & Subsetting\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nAnalyze Great Lakes Ice Concentration\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nMulti-Sensor chlorophyll time series analysis for Lake Erie\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nLong-term lake surface temperature variability from Great Lakes Satellite Records\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nVisualizing JPSS Sea Ice Concentration products using Google Colab\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nLong Island Sound Chlorophyll-a Dynamics\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n—\n\n\nMap geographical and polarstereographic data on a projected map\nSpatial Analysis & Mapping\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nMask shallow pixels for satellite ocean color datasets\nSpatial Analysis & Mapping\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n—\n\n\nMatching polar data to animal track locations\nSpatial Analysis & Mapping\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nMatching satellite and buoy surface temperature data in polar regions\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n—\n\n\nComparing satellite and buoy sea surface temperature observations\nTime Series\n\n\n\n\n\n—\n—\n\n\n\n\n\n—\n\n\nMatchup satellite data to ship, glider, or animal tracks\nSpatial Analysis & Mapping\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nMatching satellite chlorophyll to animal telemetry tracks\nSpatial Analysis & Mapping\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalculating anomaly and trend with sea ice thickness time series\nTime Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nSubset data in polar stereographic projection using a shapefile\nData Access & Subsetting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nTransforming satellite data from one map to another\nSpatial Analysis & Mapping\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n    \n      Basics of working with satellite data\n      Access and analyze satellite-derived sea surface temperature using ERDDAP and NetCDF-based workflows. This tutorial demonstrates how to locate and subset a satellite SST product in ERDDAP, download gridded NetCDF data, examine its structure, and create basic spatial maps and regional time series. Users work with the NOAA Coral Reef Watch CoralTemp monthly sea surface temperature product to explore coordinate conventions, generate SST maps, compute regional averages, and visualize temporal variability.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature in the western North Atlantic Ocean along the US East Coast in 2022.\n          \n          \n          \n            \n              \n            \n            Map of the 2022 average sea surface temperature in the western North Atlantic Ocean along the US East Coast.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature in the western North Atlantic Ocean along the US East Coast in 2022.\n          \n          \n          \n            \n              \n            \n            Map of the 2022 average sea surface temperature in the western North Atlantic Ocean along the US East Coast.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature around the Hawaiian Islands in 2018.\n          \n          \n          \n            \n              \n            \n            Map of the 2018 average sea surface temperature in the Hawaiian Islands.\n          \n            ◀  1 / 2  ▶\n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      Compare time series from different sensors\n      Compare satellite chlorophyll-a time series from multiple ocean color sensors to understand differences during overlapping observation periods. This tutorial demonstrates how to use ERDDAP to extract spatially averaged chlorophyll-a time series from a defined region, examine dataset metadata, handle differences in coordinate conventions, and compare measurements across sensors through visualization. Monthly chlorophyll-a data from SeaWiFS, MODIS Aqua, NOAA VIIRS S-NPP, and the ESA Ocean Colour Climate Change Initiative (OC-CCI) are used to evaluate consistency and variability among sensors from 1997 to the present.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          \n            \n              \n            \n            Mean log-transformed chlorophyll-a concentration for the Gulf of Mexico region derived from SeaWiFS, MODIS Aqua, NOAA VIIRS S-NPP, and the ESA OC-CCI blended dataset.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      Make a virtual buoy with satellite data\n      Create a virtual ocean buoy using satellite data to extend or replace discontinued in situ observations. This tutorial demonstrates how to use ERDDAP to extract satellite sea surface temperature at a fixed location, build and clean a virtual buoy time series, resample the data to a lower temporal resolution, and analyze trends through visualization and linear regression. Data from NDBC Buoy 46259 are used alongside the NOAA GeoPolar Blended SST satellite dataset.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            National Data Buoy Center buoy 46259 matched up with sea surface temperature data.\n          \n          \n          \n            \n              \n            \n             Trend analysis of buoy and satellite data.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            National Data Buoy Center buoy 46259 matched up with sea surface temperature data.\n          \n          \n          \n            \n              \n            \n             Trend analysis of buoy and satellite data.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Calculating sea ice area and extent\n      Calculate sea ice area and extent from satellite-derived sea ice concentration to quantify seasonal and interannual variability in Arctic ice cover. This tutorial demonstrates how to use PolarWatch ERDDAP to retrieve gridded sea ice concentration data, incorporate grid cell area information, and apply standard concentration thresholds to compute sea ice area and extent. Users visualize sea ice concentration maps and generate monthly time series to examine changes in Arctic sea ice over time. Data from the NOAA/NSIDC Sea Ice Concentration Climate Data Record (Version 4) and a polar stereographic grid cell area dataset are used to perform the calculations for the Northern Hemisphere.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly mean sea ice concentration in the Northern Hemisphere derived from the NOAA/NSIDC Sea Ice Concentration Climate Data Record.\n          \n          \n          \n            \n              \n            \n            Monthly time series of Arctic sea ice area and sea ice extent computed from satellite-derived sea ice concentration using a 15% concentration threshold.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly mean sea ice concentration for the Arctic in 2021 shown in a Northern Polar Stereographic projection.\n          \n          \n          \n            \n              \n            \n            Monthly time series of Arctic sea ice area and sea ice extent for 2021 computed from satellite-derived sea ice concentration using a 15% concentration threshold.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Working with data that crosses the antimeridian\n      Work with satellite datasets that span the antimeridian by correcting longitude discontinuities for analysis and visualization. This tutorial demonstrates how to retrieve gridded satellite data defined on a −180° to +180° longitude system, subset regions that cross the antimeridian, convert longitude coordinates to a 0–360° system, and reorder the longitude axis to create a continuous spatial domain. The corrected data are then visualized on a map and saved for downstream analysis. Chlorophyll-a data from the NOAA gap-filled blended VIIRS ocean color dataset are used to illustrate antimeridian handling in the Bering Sea region.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Subset of satellite chlorophyll-a data crossing the antimeridian plotted using a −180° to +180° longitude convention. The map shows a visible discontinuity where data from opposite sides of the antimeridian are split and displayed at opposite edges of the domain.\n          \n          \n          \n            \n              \n            \n            The same satellite chlorophyll-a data after converting longitudes to a 0–360° convention and reordering the longitude axis. The antimeridian discontinuity is removed, resulting in a continuous spatial representation suitable for mapping and analysis.\n          \n            ◀  1 / 2  ▶\n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Define a marine habitat\n      Define a marine habitat using satellite sea surface temperature to identify regions associated with species–environment interactions. This tutorial demonstrates how to retrieve satellite SST from ERDDAP, subset data for a region and time of interest, and apply temperature-based thresholds to delineate a habitat band. The resulting temperature contours are visualized on a map to highlight areas associated with increased likelihood of interaction. Sea surface temperature data from the NOAA Coral Reef Watch CoralTemp product are used to illustrate habitat definition in the central North Pacific as part of the TurtleWatch framework.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature map with the TurtleWatch habitat band highlighted. The red band marks SST values between 17.5 °C and 18.5 °C, identifying regions associated with increased loggerhead sea turtle interactions based on the TurtleWatch framework.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature map with the TurtleWatch habitat band highlighted. The red band marks SST values between 17.5 °C and 18.5 °C, identifying regions associated with increased loggerhead sea turtle interactions based on the TurtleWatch framework.\n          \n          \n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Extract data within a boundary\n      Extract and analyze satellite data within an irregular geographic boundary to better represent real-world marine regions. This tutorial demonstrates how to download sea surface temperature data from ERDDAP, subset it using a bounding box, and apply a polygon mask to retain values only within a defined boundary. The masked data are then used to compute and visualize a seasonal temperature cycle for the region of interest. Sea surface temperature data from the NOAA Geo-Polar Blended SST product are combined with Longhurst Marine Province boundaries to illustrate region-based satellite analysis.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature masked to the Gulf Stream Longhurst Province (GFST).\n          \n          \n          \n            \n              \n            \n            Monthly mean sea surface temperature within the Gulf Stream Province for 2020.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature masked to the Gulf Stream Longhurst Province (GFST).\n          \n          \n          \n            \n              \n            \n            Monthly mean sea surface temperature within the Gulf Stream Province for 2020.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Monthly sea surface temperature within the Papahānaumokuākea Marine National Monument (PMNM) for April 2015.\n          \n          \n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      How to work with satellite data in Matlab in the Great Lakes\n      Access and analyze satellite sea surface temperature data in MATLAB using ERDDAP and NetCDF workflows. This tutorial demonstrates how to construct ERDDAP download URLs, read NetCDF variables directly into MATLAB, convert time coordinates, and subset data spatially and temporally. The workflow includes creating daily SST maps, generating regional mean time series, and computing average SST over a selected period. Satellite sea surface temperature data from NOAA CoastWatch are used to illustrate spatial and temporal analysis across the Great Lakes region.\n\n      \n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Daily satellite sea surface temperature (SST) across the Great Lakes on 21 July 2021, extracted from ERDDAP and visualized in a Mercator projection.\n          \n          \n          \n            \n              \n            \n            Time series of mean SST within a Lake Superior subregion showing daily temperature variability from 21–28 July 2021.\n          \n          \n          \n            \n              \n            \n            Mean satellite SST across the Great Lakes averaged over 21–28 July 2021, illustrating spatial temperature patterns derived from ERDDAP data.\n          \n            ◀  1 / 3  ▶\n          \n            View Matlab tutorial\n          \n        \n        \n      \n\n      Close\n    \n    \n    \n      Working with Great Lakes Surface Temperature Data\n      Access and analyze Great Lakes surface temperature using satellite observations in Python. This tutorial demonstrates how to download water surface temperature data from an ERDDAP server, open and inspect NetCDF files using xarray, and convert time variables into usable date formats. The extracted data are used to generate spatial maps of surface temperature, compute regional averages within user-defined bounding boxes, and visualize temporal variability through daily time series and monthly mean maps. Water surface temperature data from the Great Lakes Surface Environmental Analysis (GLSEA) ACSPO dataset are used to illustrate satellite-based analysis of Lake Erie.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Spatial subset of Lake Erie water surface temperature on June 1, 2023, extracted from ERDDAP and visualized for a focused region of interest.\n          \n          \n          \n            \n              \n            \n            Daily mean water surface temperature time series for a selected Lake Erie subregion during June 2023, illustrating short-term temporal variability.\n          \n          \n          \n            \n              \n            \n            Monthly mean water surface temperature across Lake Erie for June 2023, computed from daily satellite observations downloaded via ERDDAP.\n          \n            ◀  1 / 3  ▶\n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Analyze Great Lakes Ice Concentration \n      Extract and summarize satellite-derived ice concentration to characterize seasonal ice conditions in the Great Lakes. This tutorial demonstrates how to download ice concentration data from ERDDAP, subset the data spatially and temporally for a region of interest, and handle missing values in NetCDF files. The extracted data are used to generate maps of ice concentration for specific dates and to compute regional daily mean ice concentration time series. Ice concentration data from the NOAA Great Lakes Surface Environmental Analysis (GLSEA) product are used to illustrate regional ice variability in western Lake Erie.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Spatial distribution of ice concentration (%) in western Lake Erie on March 1, 2019, derived from the Great Lakes Ice Concentration product and visualized after subsetting the ERDDAP dataset to the region of interest.\n          \n          \n          \n            \n              \n            \n            Time series of daily mean ice concentration (%) for western Lake Erie during March 2019, calculated by averaging satellite-derived ice concentration over the selected spatial domain.\n          \n            ◀  1 / 2  ▶\n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Multi-Sensor chlorophyll time series analysis for Lake Erie\n      Analyze long-term changes in lake chlorophyll concentrations by combining satellite observations from multiple sensors. This tutorial demonstrates how to download chlorophyll-a data from ERDDAP for Lake Erie, process daily observations from MODIS (2002–2017) and VIIRS (2018–2023), and compute spatially averaged monthly and daily time series. The workflow shows how to handle fill values, aggregate data across space and time, and visualize chlorophyll variability across the sensor transition. By merging MODIS and VIIRS records, the tutorial provides a practical approach for creating a continuous multi-sensor time series to support long-term water quality analysis in the Great Lakes.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly mean chlorophyll-a concentration across Lake Erie for August 2009, illustrating the spatial distribution of phytoplankton biomass derived from satellite observations.\n          \n          \n          \n            \n              \n            \n            Spatially averaged monthly chlorophyll-a time series for Lake Erie from 2002–2017, showing seasonal variability and interannual changes captured by the MODIS sensor.\n          \n          \n          \n            \n              \n            \n            Daily spatially averaged chlorophyll-a concentrations for Lake Erie in 2023, highlighting short-term variability and bloom dynamics observed by the VIIRS sensor.\n          \n            ◀  1 / 3  ▶\n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Long-term lake surface temperature variability from Great Lakes Satellite Records\n      Analyze long-term patterns in Great Lakes water surface temperature using lakewide satellite-derived averages. This tutorial demonstrates how to retrieve daily average surface temperature data from ERDDAP, assemble a multi-year record spanning 2007 to the present, and visualize seasonal temperature variability across years. Daily temperature records are aligned by day of year to highlight the warmest, coldest, and average conditions for a given date, with the current year shown in context of the historical record. Using Great Lakes Surface Environmental Analysis (GLSEA) satellite products, the workflow illustrates how long-term lake temperature climatologies can be used to assess seasonal extremes and interannual variability across the Great Lakes.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Seasonal evolution of Lake Michigan average surface water temperature from 2007–2024, showing the current year in context of the long-term mean and highlighting the historically warmest and coldest years for the selected calendar day based on GLSEA satellite records.\n          \n          \n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Visualizing JPSS Sea Ice Concentration products using Google Colab\n      Visualize polar sea ice conditions by converting JPSS Sea Ice Concentration files into mapped images for quick inspection and reporting. This tutorial demonstrates how to obtain either Level-2 swath VIIRS ice concentration data or Level-3 daily gridded blended sea ice concentration products, load them into an analysis environment, and generate publication-ready maps for the Arctic or Antarctic. The workflow resamples swath observations onto a common polar grid when needed, applies consistent color scaling in percent ice concentration, and exports the final figures as PNGs.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Blended JPSS sea ice concentration for the Arctic on October 5, 2024, showing the spatial extent and intensity of ice cover derived from combined satellite observations and mapped onto a polar projection with ice concentration expressed as percent.\n          \n          \n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Long Island Sound Chlorophyll-a Dynamics\n      Analyze seasonal and spatial patterns in coastal chlorophyll-a by working with daily satellite observations from Long Island Sound. This tutorial demonstrates how to download chlorophyll-a data from ERDDAP, generate temporal composites at monthly and 8-day intervals, and subset the data to compare regional variability within the Sound. The workflow illustrates how to examine gridded satellite datasets, compute spatial averages, and visualize chlorophyll dynamics through maps and time-series plots. Chlorophyll-a data from Sentinel-3 OLCI, processed with Long Island Sound–optimized algorithms, are used to highlight differences between western and eastern regions and to explore seasonal water-quality variability in a complex coastal environment.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly mean chlorophyll-a concentrations in Long Island Sound during 2022, illustrating the seasonal evolution of phytoplankton biomass derived from daily Sentinel-3 OLCI observations.\n          \n          \n          \n            \n              \n            \n            Spatial distribution of mean chlorophyll-a concentration in Long Island Sound averaged over January–December 2022, highlighting persistent regional gradients across the estuary.\n          \n          \n          \n            \n              \n            \n            Eight-day averaged chlorophyll-a time series comparing western and eastern Long Island Sound, showing contrasting seasonal cycles and peak bloom timing during 2022.\n          \n            ◀  1 / 3  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly mean chlorophyll-a concentrations in Long Island Sound during 2022, illustrating the seasonal evolution of phytoplankton biomass derived from daily Sentinel-3 OLCI observations.\n          \n          \n          \n            \n              \n            \n            Spatial distribution of mean chlorophyll-a concentration in Long Island Sound averaged over January–December 2022, highlighting persistent regional gradients across the estuary.\n          \n          \n          \n            \n              \n            \n            Eight-day averaged chlorophyll-a time series comparing western and eastern Long Island Sound, showing contrasting seasonal cycles and peak bloom timing during 2022.\n          \n            ◀  1 / 3  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Map geographical and polarstereographic data on a projected map\n      Plot polar satellite data correctly by working across coordinate systems and projections. This tutorial demonstrates how to access polar sea ice concentration data from an ERDDAP server, interpret the dataset’s polar stereographic metadata (or EPSG code), and display the gridded x–y product on a matching projected basemap. It then shows how to overlay a second dataset provided in geographic coordinates (latitude/longitude) here, polar bear GPS tracks by transforming those points into the same map projection for direct visual comparison with the sea ice field.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Sea ice concentration from the NOAA/NSIDC Climate Data Record is displayed on a North Polar Stereographic map using the dataset’s native EPSG:3411 projection.\n          \n          \n          \n            \n              \n            \n            Monthly sea ice concentration is shown on a polar stereographic basemap with overlaid polar bear GPS locations in latitude–longitude coordinates.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Sea ice concentration from the NOAA/NSIDC Climate Data Record is displayed on a Polar Stereographic projection, illustrating how gridded polar satellite data are mapped in projected x–y coordinates.\n          \n          \n          \n            \n              \n            \n             Sea ice concentration mapped on a Polar Stereographic projection with polar bear GPS tracks overlaid.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Mask shallow pixels for satellite ocean color datasets\n      Remove optically shallow-water contamination from satellite ocean color data to improve the accuracy of derived biogeochemical metrics. This tutorial demonstrates how to download bathymetry and monthly chlorophyll-a data from ERDDAP, quantify the fraction of shallow water within each ocean color pixel, and construct a threshold-based mask to exclude pixels affected by bottom reflectance. The masked and unmasked datasets are then used to compute and compare long-term chlorophyll-a climatologies. By combining high-resolution bathymetry with coarse-resolution ocean color observations, the workflow illustrates a practical approach for preparing satellite datasets for robust analysis in coastal and reef-adjacent regions.\n\n      \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            High-resolution ETOPO bathymetry for the Oʻahu region showing depth contours used to distinguish optically shallow and deep waters.\n          \n          \n          \n            \n              \n            \n            Percentage of shallow water (&lt;30 m depth) contained within each coarse-resolution ocean color pixel, calculated by matching bathymetry to the chlorophyll grid.\n          \n          \n          \n            \n              \n            \n            Binary mask identifying ocean color pixels dominated by shallow water based on a user-defined shallow-area threshold.\n          \n          \n          \n            \n              \n            \n            Log-scaled chlorophyll-a climatology after applying the shallow-water mask, illustrating the removal of bottom-contaminated coastal pixels.\n          \n            ◀  1 / 4  ▶\n          \n            View R tutorial\n          \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Matching polar data to animal track locations\n      Extract and analyze satellite sea ice conditions along animal movement tracks in polar regions. This tutorial demonstrates how to combine satellite sea ice concentration data with animal telemetry observations to examine environmental conditions encountered along a tracked path. Using monthly sea ice concentration records from NOAA PolarWatch, the workflow shows how to subset gridded satellite data in polar stereographic coordinates, align it temporally and spatially with penguin telemetry locations, and extract coincident sea ice values along the track. The tutorial also illustrates how to visualize animal movement overlaid on sea ice maps and how to generate matched time series of satellite-derived sea ice concentration at each observation point.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly Antarctic sea ice concentration from the NOAA/NSIDC Climate Data Record is shown on a south polar stereographic map for the first available timestep.\n          \n          \n          \n            \n              \n            \n            Monthly sea ice concentration maps for January, February, and March are overlaid with Adelie penguin telemetry tracks.\n          \n          \n          \n            \n              \n            \n            Penguin track locations are colored by collocated sea ice concentration values extracted from the satellite dataset.\n          \n            ◀  1 / 3  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly sea ice concentration from the NOAA/NSIDC Climate Data Record is mapped for the first available time step to illustrate the polar stereographic satellite grid used for Antarctic matchups.\n          \n          \n          \n            \n              \n            \n            The Adelie penguin telemetry track is plotted in geographic coordinates, highlighting the start and end points used to extract satellite sea ice values along the animal’s path.\n          \n          \n          \n            \n              \n            \n            The penguin track is colored by the extracted monthly sea ice concentration at each location and date, showing how satellite conditions are sampled along a moving trajectory in Antarctica.\n          \n            ◀  1 / 3  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Matching satellite and buoy surface temperature data in polar regions\n      Combine satellite ice surface temperature composites with in situ buoy observations by matching satellite pixels to buoy locations and dates in the Arctic. This tutorial walks through how to query buoy surface temperature records from ERDDAP in tabular format, download polar-projected satellite Ice Surface Temperature (IST) data in NetCDF, and resample the buoy time series to comparable time steps. It then demonstrates how to convert buoy latitude/longitude positions into the satellite’s polar stereographic coordinate system, extract the nearest satellite IST values at each buoy time and location, and merge the two datasets for side-by-side comparison and visualization.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Time series comparison of buoy-measured surface temperature and collocated VIIRS ice surface temperature.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Time series comparison of buoy-measured surface temperature and collocated VIIRS ice surface temperature.\n          \n          \n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Comparing satellite and buoy sea surface temperature observations \n      This tutorial demonstrates how to match satellite-derived sea surface temperature (SST) with in situ buoy observations to evaluate satellite data accuracy. Using ERDDAP-hosted datasets, the workflow shows how to download and process buoy measurements, extract collocated satellite SST values, and compare the two datasets through statistical analysis and visualization.\n\n      \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Daily averaged buoy sea surface temperatures are compared with colocated satellite SST values along the California coast from August 1–10, 2023.\n          \n          \n          \n            \n              \n            \n            Satellite sea surface temperature fields for July 31, 2023 are shown with overlaid buoy locations colored by observed temperature.\n          \n            ◀  1 / 2  ▶\n          \n            View R tutorial\n          \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Matchup satellite data to ship, glider, or animal tracks\n      Extract and analyze satellite-derived environmental variables along moving platforms such as ship tracks, gliders, or animal telemetry paths. This tutorial demonstrates how to load track data defined by latitude, longitude, and time, visualize trajectories on a map, and retrieve colocated satellite observations from ERDDAP for each track position. Using a yellowfin tuna telemetry record as an example, satellite chlorophyll-a data from the ESA Ocean Colour Climate Change Initiative are matched to daily track locations, saved to a tabular format, and visualized to explore spatial and temporal variability along the track.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Chlorophyll-a concentrations extracted from satellite observations along a Yellowfin tuna telemetry track, with points colored by matched monthly chlorophyll values and symbols indicating the start and end of the track.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Yellowfin tuna track locations colored by the log of satellite-derived chlorophyll-a values extracted from the ESA OC-CCI monthly dataset.\n          \n          \n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Matching satellite chlorophyll to animal telemetry tracks\n      This tutorial demonstrates how to match satellite chlorophyll data to animal, ship, or glider tracks using longitude, latitude, and time coordinates. Examples include a loggerhead turtle track using nearest-pixel matchups and a dusky shark telemetry dataset that applies spatial averaging within a local window to better represent environmental conditions along movement tracks.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Chlorophyll-a concentrations from the ESA OC-CCI monthly product matched to locations along animal track #25317, with points colored by satellite-derived chlorophyll values and start/end positions indicated along the track.\n          \n          \n          \n            \n              \n            \n            Plot of the locations of all tagged dusky sharks and color each detection by the mean satellite-derived chlorophyll-a concentration matched to that location and date.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Loggerhead turtle track locations colored by log-transformed ESA OC-CCI monthly chlorophyll-a values extracted from ERDDAP at each subsampled track point (May 2005–Aug 2008).\n          \n          \n          \n            \n              \n            \n            Plot of the locations of all tagged dusky sharks and color each detection by the mean satellite-derived chlorophyll-a concentration matched to that location and date.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Loggerhead turtle (#25317) track colored by log-transformed monthly chlorophyll-a averaged within ±0.1° of each tag location using ERDDAP matchup requests.\n          \n          \n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      Calculating anomaly and trend with sea ice thickness time series\n      This tutorial demonstrates how to analyze variability and long-term change in Arctic sea ice thickness using gridded satellite data. Monthly mean sea ice thickness fields are derived from twice-daily observations accessed through the PolarWatch ERDDAP server, then compared against a multi-year climatological baseline to quantify anomalies. A 15-year reference period (2006–2020) is used to compute historical monthly means, which serve as the basis for anomaly calculations and trend assessment. Long-term trends in monthly sea ice thickness are estimated at each grid cell using the non-parametric Mann–Kendall method, allowing robust slope estimation without assumptions of normality.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly sea ice thickness anomalies for February (left) and September (right) in 2021, calculated as departures from the 2005–2020 climatological mean using Arctic sea ice thickness data from the NOAA CDR Extended Polar Pathfinder dataset.\n          \n          \n          \n            \n              \n            \n            Spatial distribution of the long-term September sea ice thickness trend across the Arctic, estimated for the 2006–2020 climatological period using a Mann–Kendall trend analysis applied to monthly mean sea ice thickness data.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          No preview image\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Subset data in polar stereographic projection using a shapefile\n      This exercise demonstrates how to subset satellite data provided in a polar stereographic projection using a lake boundary defined in a different coordinate reference system. The workflow includes downloading polar satellite data from PolarWatch ERDDAP, transforming a shapefile to match the satellite projection, and clipping the dataset to the extent of Lake Iliamna in Alaska. The results are visualized to illustrate projection handling and spatial subsetting of polar remote sensing data\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            IMS Snow and Ice Analysis data from PolarWatch for 30 July 2024 shown in its native polar stereographic projection, illustrating categorical surface conditions across the Northern Hemisphere.\n          \n          \n          \n            \n              \n            \n            Subset of the IMS Snow and Ice Analysis clipped to the Lake Iliamna region after transforming the lake shapefile into the satellite data’s polar stereographic projection, demonstrating successful reprojection and spatial subsetting.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            IMS Snow and Ice Analysis data for November 1, 2019 shown in its native polar stereographic projection. Colors represent categorical surface classes from the IMS product, including open water, land, ice, and snow-covered land across the Arctic domain.\n          \n          \n          \n            \n              \n            \n            Subset of the IMS Snow and Ice Analysis raster after cropping and masking to the Lake Iliamna shapefile. Only grid cells intersecting the lake boundary are retained, illustrating how polar-projected satellite data can be spatially subset using vector geometries.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Transforming satellite data from one map to another\n      This exercise demonstrates how to transform satellite data coordinates from one map projection to another in order to work consistently with datasets that use different coordinate reference systems. It walks through downloading sea ice concentration data from PolarWatch ERDDAP, inspecting CRS definitions, applying EPSG-based coordinate transformations, and adding the transformed coordinates back into a NetCDF dataset.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly mean sea ice concentration for December 2022 from the NOAA/NSIDC Climate Data Record, displayed using transformed latitude–longitude coordinates on a global (Plate Carrée) map projection.\n          \n          \n          \n            \n              \n            \n            The same December 2022 sea ice concentration data visualized on a Southern Hemisphere polar stereographic projection.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly mean sea ice concentration for December 2022 from the NOAA/NSIDC Climate Data Record, displayed using transformed latitude–longitude coordinates on a global (Plate Carrée) map projection.\n          \n          \n          \n            \n              \n            \n            The same December 2022 sea ice concentration data visualized on a Southern Hemisphere polar stereographic projection, illustrating the improved representation of Antarctic sea ice when using a projection optimized for polar regions.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n\n\n\n\n\n\n✕",
    "crumbs": [
      "Training Tutorials",
      "Code Gallery"
    ]
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "A tidyverse/ggplot version is also available here: https://github.com/jebyrnes/noaa_coastwatch_tutorial_1/blob/main/tutorial2-1.md Links to an external site.\ncourtesy of Jarrett Byrnes from UMass Boston - http://byrneslab.net (Thank you Jarrett!!)"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#background",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#background",
    "title": "CoastWatch Training",
    "section": "Background",
    "text": "Background\nSeveral ocean color sensors have been launched since 1997 to provide continuous global coverage for ocean color data. The sensors have differences in design and calibration, and different algorithms may be applied to generate chlorophyll values. Consequently, chlorophyll-a values can vary among the sensors during periods where measurements overlap.\nTo examine this phenomenon, we will download and plot time-series of chlorophyll-a concentrations from various sensors from 1997 to the present and see how the measurements compare during periods of overlap."
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#objective",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#objective",
    "title": "CoastWatch Training",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show how to extract a time-series from four different monthly satellite chlorophyll datasets for the period that each was in operation between 1997-present. It will showcase the use of the rerddap and rerddapXtracto packages, which have been developed to make it easier to interact with ERDDAP servers from R.\nMore information about the rerddap package can be found here: https://cran.r-project.org/web/packages/rerddap/index.html\nand here: https://cran.r-project.org/web/packages/rerddap/vignettes/Using_rerddap.html\nMore information about the rerddapXtracto package can be found here: https://cran.r-project.org/web/packages/rerddapXtracto/index.html\nand here: https://cran.r-project.org/web/packages/rerddapXtracto/vignettes/UsingrerddapXtracto.html"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "CoastWatch Training",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nUsing rerddapXtracto package to extract data from a rectangular area of the ocean over time\nUsing rerddap to retrieving information about a dataset from ERDDAP\nComparing results from different sensors\nAveraging data spatially\nProducing timeseries plots\nDrawing maps with satellite data"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "title": "CoastWatch Training",
    "section": "Datasets used",
    "text": "Datasets used\nSeaWiFS Chlorophyll-a, V.2018, Monthly, Global, 4km, 1997-2012 https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nMODIS Aqua, Chlorophyll-a, V.2022, Monthly, Global, 4km, 2002-present https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022SQ\nNOAA VIIRS S-NPP, Chlorophyll-a, Monthly, Global, 4km, 2012-present https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisVHNSQchlaMonthly\nESA CCI Ocean Colour Dataset, v6.0, Monthly, Global, 4km, 1997-Present This dataset was developed by the European Space Agency’s Climate Change Initiative. The dataset merges data from multiple sensors (MERIS, MODIS, VIIRS and SeaWiFS) to create a long timeseries (1997 to present) with better spatial coverage than any single sensor. Parameters include chlorophyll-a, remote sensing reflectance, diffuse attenuation coefficients, absorption coefficients, backscatter coefficients, and water classification. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorMonthly"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#load-packages",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#load-packages",
    "title": "CoastWatch Training",
    "section": "Load packages",
    "text": "Load packages\npackages &lt;- c( \"ncdf4\",\"plyr\",\"lubridate\",\"rerddap\",\"ggplot2\",\"plotdap\",\n               \"rerddapXtracto\",\"maps\", \"mapdata\",\"grid\", \"reshape2\", \"gridExtra\")\n\n# Install packages not yet installed\ninstalled_packages &lt;- packages %in% rownames(installed.packages())\n\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages])\n}\n\n# Load packages \ninvisible(lapply(packages, library, character.only = TRUE))"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "title": "CoastWatch Training",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nFirst we define the longitude-latitude boundaries of the region. The coordinates used here, between -95 to -90°W longitude and 25-30°N latitude, define an area in teh Gulf of Mexico.\nxcoord &lt;- c(-95,-90)\nycoord &lt;- c(25,30)"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#get-information-about-the-dataset-we-will-be-downloading",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/r/Tutorial2-timeseries-compare-sensors.html#get-information-about-the-dataset-we-will-be-downloading",
    "title": "CoastWatch Training",
    "section": "Get information about the dataset we will be downloading",
    "text": "Get information about the dataset we will be downloading\nDefine the URL of the ERDDAP we will be using:\nERDDAP_Node &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/\"\n\nGet monthly SeaWiFS data, which starts in 1997.\nGo to ERDDAP to find the name of the dataset for monthly SeaWIFS data: erdSW2018chlamday\nYou should always examine the dataset in ERDDAP to check the date range, names of the variables and dataset ID, to make sure your griddap calls are correct: https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nFirst we need to know what our variable is called. Let’s retrieve some metadata using the info function of the rerddap package:\ndataInfo &lt;- rerddap::info('erdSW2018chlamday', url=ERDDAP_Node)\nvar &lt;- dataInfo$variable$variable_name\n\n# Display the dataset metadata\ndataInfo\n\n## &lt;ERDDAP info&gt; erdSW2018chlamday \n##  Base URL: https://coastwatch.pfeg.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-16T00:00:00Z, 2010-12-16T00:00:00Z) \n##      latitude: (-89.95834, 89.95834) \n##      longitude: (-179.9583, 179.9584) \n##  Variables:  \n##      chlorophyll: \n##          Units: mg m^-3\n\n\nExtract satellite data with rxtracto_3D\nFor each dataset, we will extract satellite data for the entire length of the available timeseries.\n\nDates must be defined separately for each dataset. rxtracto_3D will crash if dates are entered that are not part of the timeseries.\n\nThe beginning (earliest) date to use in timeseries is obtained from the information returned in dataInfo.\n\nTo get the end (most recent) date to use in the timeseries, use the last option for time.\nThe variable name can change between datasets. For this dataset, the chloropyll variable is called chlorophyll, as seen in the metadata returned by dataInfo\n\n\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n# Set the altitude coordinate to zero\nzcoord &lt;- 0.\n\n# Extract the beginning and ending dates of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntcoord &lt;- c(tt[2],\"last\")\n** Run the SeaWiFS data extraction with rxtracto_3D:\n# Extract the timeseries data using rxtracto_3D\nchlSeaWiFS&lt;-rxtracto_3D(dataInfo,\n                        parameter=parameter,\n                        tcoord=tcoord,\n                        xcoord=xcoord,\n                        ycoord=ycoord)\n\n\nPlot data to show where it is in the world\nWe will use the plotBBox function of the rerddapXtracto package to make a quick map of the data\nmyFunc &lt;- function(x) log(x)\nplotBBox(chlSeaWiFS, plotColor = 'algae', myFunc = myFunc)\n\n\n\nGet monthly MODIS data, which starts in 2002.\ndataInfo &lt;- rerddap::info('erdMH1chlamday_R2022SQ', url=ERDDAP_Node)\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n#Extract the start and end times of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\n#Run rxtracto_3D\nchlMODIS&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord)\n\n\nGet monthly VIIRS data, which starts in 2012.\ndataInfo &lt;- rerddap::info('nesdisVHNSQchlaMonthly', url=ERDDAP_Node)\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n#Extract the start and end times of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\n\n# This dataset has an altitude dimensionm, so must include zcoord as an argument in the rxtracto_3D function Set the altitude coordinate to zero\nzcoord &lt;- 0.\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\n#Run rxtracto_3D\nchlVIIRS &lt;- rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord,\n                      zcoord=zcoord)\n\n# Remove extraneous zcoord dimension for chlorophyll \nchlVIIRS$chlor_a &lt;- drop(chlVIIRS$chlor_a)\n\n\nAverage data spatially and temporally\n\nspatially averages data for each time step within the area boundaries for each dataset.\n\ntemporally averages data for data in each timeseries onto a map, for each dataset.\n\n\n## Spatially average all the data within the box for each dataset.\n## The c(3) indicates the dimension to keep - in this case time \nchlSeaWiFS$avg &lt;- apply(chlSeaWiFS$chlorophyll, c(3),function(x) mean(x,na.rm=TRUE))\nchlMODIS$avg &lt;- apply(chlMODIS$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\nchlVIIRS$avg &lt;- apply(chlVIIRS$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\n\n## Temporally average all of the data into one map \n## The c(1,2) indicates the dimensions to keep - in this case latitude and longitude  \nchlSeaWiFS$avgmap &lt;- apply(chlSeaWiFS$chlorophyll,c(1,2),function(x) mean(x,na.rm=TRUE))\nchlMODIS$avgmap &lt;- apply(chlMODIS$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\nchlVIIRS$avgmap &lt;- apply(chlVIIRS$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\n\n\nPlot time series for the three datasets\nplot(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg, type='l', col=2,lwd=2, \n     xlab=\"\", xlim=as.Date(c(\"1997-12-01\",\"2024-06-01\")), \n     ylim=c(0.5,3.5), ylab=\"CHL\")\naxis(2)\npoints(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg,pch=20,col=2)\n\nlines(as.Date(chlMODIS$time), chlMODIS$avg, col=4, lwd=2)\npoints(as.Date(chlMODIS$time), chlMODIS$avg,pch=20,col=4)\n\nlines(as.Date(chlVIIRS$time), chlVIIRS$avg, col=3, lwd=2)\npoints(as.Date(chlVIIRS$time), chlVIIRS$avg,pch=20,col=3)\n\nlegend('topleft',legend=c('SeaWiFS','MODIS','VIIRS'),cex=0.6,col=c(2,4,3),lwd=2)\n\nYou can see that the values of chl-a concentration doesn’t always match between sensors.\n\n\nGet OC-CCI data (September 1997 to Dec 2022)\nIf you needed a single time series from 1997 to present, you would have to use the plot above to devise some method to reconcile the difference in values where two datasets overlap. Alternatively, you could use the ESA OC-CCI (ocean color climate change initiative) dataset, which blends data from many satellite missions into a single dataset, including data from SeaWiFS, MODIS, and VIIRS.\nAdd the ESA OC-CCI dataset to the plot above to see how it compares with data from the individual satellite missions.\ndataInfo &lt;- rerddap::info('pmlEsaCCI60OceanColorMonthly', url=ERDDAP_Node)\n\n# This identifies the parameter to choose - there are &gt; 60 in this dataset!\nparameter &lt;- 'chlor_a'\n\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\nchlOCCCI&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord)\n\n# Now spatially average the data into a timeseries\nchlOCCCI$avg &lt;- apply(chlOCCCI$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\n\n# Now temporally average the data into one map \nchlOCCCI$avgmap &lt;- apply(chlOCCCI$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\n\n\nMake another plot with CCI as well to compare\nplot(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg, type='l', col=2,lwd=2, \n     xlab=\"\", xlim=as.Date(c(\"1997-12-01\",\"2024-06-01\")), \n     ylim=c(0.5,3.5), ylab=\"CHL\")\naxis(2)\npoints(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg,pch=20,col=2)\npoints(as.Date(chlMODIS$time), chlMODIS$avg,pch=20,col=4)\npoints(as.Date(chlVIIRS$time), chlVIIRS$avg,pch=20,col=3)\nlines(as.Date(chlOCCCI$time),chlOCCCI$avg,lwd=2)\n\nlegend('topleft',legend=c('SeaWiFS','MODIS','VIIRS','OC-CCI'),cex=0.6,col=c(2,4,3,1),\n       pch=c(20,20,20,NA),lty=c(NA,NA,NA,1),lwd=2)\n\ncoast &lt;- map_data(\"worldHires\", ylim = ycoord, xlim = xcoord)\n\n# Put arrays into format for ggplot\nmelt_map &lt;- function(lon,lat,var) {\n  dimnames(var) &lt;- list(Longitude=lon, Latitude=lat)\n  ret &lt;- melt(var,value.name=\"Chl\")\n}\n\n# Loop for making 4 maps\ndatasetnames &lt;- c(\"SeaWiFS\",\"MODIS\",\"VIIRS\",\"OC-CCI\")\n\nplot_list = list()\n\nfor(i in 1:4) {\n  \n  if(i == 1) chl &lt;- chlSeaWiFS\n  if(i == 2) chl &lt;- chlMODIS\n  if(i == 3) chl &lt;- chlVIIRS\n  if(i == 4) chl &lt;- chlOCCCI\n  \n   chlmap &lt;- melt_map(chl$longitude, chl$latitude, chl$avgmap)\n\n   p = ggplot(\n     data = chlmap, \n     aes(x = Longitude, y = Latitude, fill = log(Chl))) +\n         geom_tile(na.rm=T) +\n         geom_polygon(data = coast, aes(x=long, y = lat, group = group), fill = \"grey80\") +\n         theme_bw(base_size = 12) + ylab(\"Latitude\") + xlab(\"Longitude\") +\n         coord_fixed(1.3, xlim = c(-95,-90), ylim = ycoord) +\n         scale_fill_viridis_c(limits=c(-2.5,3)) +\n         ggtitle(paste(\"Average\", datasetnames[i])\n      ) \n\n  plot_list[[i]] = p\n}\n\n# Now print out maps into a png file.  Can't use par function with **ggplpot** to get \n# multiple plots per page.  Here using a function in the **grid** package\n\ngrid.arrange(plot_list[[1]],plot_list[[2]],plot_list[[3]],plot_list[[4]], nrow = 2)"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html",
    "href": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "A tidyverse/ggplot version is also available here: https://github.com/jebyrnes/noaa_coastwatch_tutorial_1/blob/main/tutorial1-1.md\ncourtesy of Jarrett Byrnes from UMass Boston - http://byrneslab.net (Thank you Jarrett!!)"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#objective",
    "href": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#objective",
    "title": "CoastWatch Training",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab data hosted on an ERDDAP server from R, how to work with NetCDF files in R and how to make some maps and time-series of sea surface temperature."
  },
  {
    "objectID": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "CoastWatch Training",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nLocating a satellite product in ERDDAP, manually changing the constraints and copying the URL defining the data request\nDownloading the resulting NetCDF file\nOpening and examining the NetCDF file\nMaking basic maps and time series plots"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#datasets-used",
    "href": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#datasets-used",
    "title": "CoastWatch Training",
    "section": "Datasets used",
    "text": "Datasets used\nCoralTemp Sea Surface Temperature product from the NOAA Coral Reef Watch program. The NOAA Coral Reef Watch (CRW) daily global 5km Sea Surface Temperature (SST) product, also known as CoralTemp, shows the nighttime ocean temperature measured at the surface. The SST scale ranges from -2 to 35 °C. The CoralTemp SST data product was developed from two, related reanalysis (reprocessed) SST products and a near real-time SST product. Spanning January 1, 1985 to the present, the CoralTemp SST is one of the best and most internally consistent daily global 5km SST products available. More information about the product: https://coralreefwatch.noaa.gov/product/5km/index_5km_sst.php\nWe will use the monthly composite of this product and download it from the NOAA CoastWatch ERDDAP server: https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.graph\n# Package names\npackages &lt;- c( \"ncdf4\",\"httr\")\n\n# Install packages not yet installed\ninstalled_packages &lt;- packages %in% rownames(installed.packages())\n\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages])\n}\n\n# Load packages \ninvisible(lapply(packages, library, character.only = TRUE))"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#downloading-data-from-r",
    "href": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#downloading-data-from-r",
    "title": "CoastWatch Training",
    "section": "1. Downloading data from R",
    "text": "1. Downloading data from R\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from R using the URL structure.\nFor example, the following page allows you to subset monthly sea surface temperature (SST) https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n NOTE: Notice that the latitudes are indexed from North to South (negative spacing)\nIn this specific example, the URL we generated is : https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D\nYou can also edit this URL manually.\nIn R, run the following to download the data using the generated URL (you need to copy it from your browser):\njunk &lt;- GET('https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D', write_disk(\"sst.nc\", overwrite=TRUE))"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#importing-the-downloaded-file-in-r",
    "href": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#importing-the-downloaded-file-in-r",
    "title": "CoastWatch Training",
    "section": "2. Importing the downloaded file in R",
    "text": "2. Importing the downloaded file in R\nNow that we’ve downloaded the data locally, we can import it and extract our variables of interest:\n\nopen the file\n\n\nnc &lt;- nc_open('sst.nc')\n\nexamine which variables are included in the dataset:\n\n\nnames(nc$var)\n\n## [1] \"sea_surface_temperature\"\n\nExtract sea_surface_temperature:\n\n\nv1 &lt;- nc$var[[1]]\nsst &lt;- ncvar_get(nc,v1)\n\nexamine the structure of sst:\n\n\ndim(sst)\n\n## [1] 201 202  12\nOur dataset is a 3-D array with 201 rows corresponding to longitudes, 202 columns corresponding to latitudes for each of the 12 time steps.\n\nget the dates for each time step:\n\n\ndates &lt;- as.POSIXlt(v1$dim[[3]]$vals,origin='1970-01-01',tz='GMT')\ndates\n\n##  [1] \"2022-01-16 GMT\" \"2022-02-16 GMT\" \"2022-03-16 GMT\" \"2022-04-16 GMT\"\n##  [5] \"2022-05-16 GMT\" \"2022-06-16 GMT\" \"2022-07-16 GMT\" \"2022-08-16 GMT\"\n##  [9] \"2022-09-16 GMT\" \"2022-10-16 GMT\" \"2022-11-16 GMT\" \"2022-12-16 GMT\"\n\nget the longitude and latitude values\n\n\nlon &lt;- v1$dim[[1]]$vals\nlat &lt;- v1$dim[[2]]$vals\n\nClose the netcdf file and remove the data and files that are not needed anymore.\n\n\nnc_close(nc)\nrm(junk,v1)\nfile.remove('sst.nc')\n\n## [1] TRUE"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#working-with-the-extracted-data",
    "href": "tutorials/Tutorial1-basics/r/Tutorial1-basics.html#working-with-the-extracted-data",
    "title": "CoastWatch Training",
    "section": "3. Working with the extracted data",
    "text": "3. Working with the extracted data\n\nCreating a map for one time step\nLet’s create a map of SST for January 2022 (our first time step).\nYou will need to download the scale.R file and copy it to your working directory to plot the color scale properly.\n\nset some color breaks\n\n\nh &lt;- hist(sst[,,1], 100, plot=FALSE)\nbreaks &lt;- h$breaks\nn &lt;- length(breaks)-1\n\ndefine a color palette\n\n\njet.colors &lt;- colorRampPalette(c(\"blue\", \"#007FFF\", \"cyan\",\"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"))\n\nset color scale using the jet.colors palette\n\n\nc &lt;- jet.colors(n)\n\nprepare graphic window : left side for map, right side for color scale\n\n\nlayout(matrix(c(1,2), nrow=1, ncol=2), widths=c(7,2), heights=4)\npar(mar=c(3,3,3,1))\n\n#plot the SST map. Because this product was built with latitudes going from North to South, we need to reverse the lat vector because the 'image' function needs increasing values for the coordinates. We also need to flip the sst matrix along the 2d dimension so it plots correctly\nimage(lon,rev(lat),sst[,dim(sst)[2]:1,1],col=c,breaks=breaks,xlab='',ylab='',axes=TRUE,xaxs='i',yaxs='i',asp=1, main=paste(\"Monthly SST\", dates[1]))\n\n#example of how to add points to the map\npoints(-74:-71,rep(34,4), pch=20, cex=2)\n\n#example of how to add a contour (this is considered a new plot, not a feature, so you need to use par(new=TRUE)) to overlay it on top of the SST map\npar(new=TRUE)\ncontour(lon,rev(lat),sst[,dim(sst)[2]:1,1],levels=14,xaxs='i',yaxs='i',labcex=0.8,vfont = c(\"sans serif\", \"bold\"),axes=FALSE,asp=1)\n\n#plot color scale using 'image.scale' function from 'scale.R' script)\npar(mar=c(3,1,3,3))\nsource('scale.R')\nimage.scale(sst[,,1], col=c, breaks=breaks, horiz=FALSE, yaxt=\"n\",xlab='',ylab='',main='SST')\naxis(4, las=1)\nbox()\n\n\n\nPlotting a time series\nLet’s pick the following box : 36-38N, -77 to -75W.. We are going to generate a time series of mean SST within that box.\nI=which(lon&gt;=-77 & lon&lt;=-75)\nJ=which(lat&gt;=36 & lat&lt;=38)\nsst2=sst[I,J,]\nn=dim(sst2)[3]\nres=rep(NA,n)\nfor (i in 1:n)\nres[i]=mean(sst2[,,i],na.rm=TRUE)\nplot(1:n,res,axes=FALSE,type='o',pch=20,xlab='',ylab='SST (ºC)')\naxis(2)\naxis(1,1:n,format(dates,'%m'))\nbox()\n\n\n\nCreating a map of average SST over a year\nsst.yr=apply(sst[,,1:12],c(1,2),mean,na.rm=TRUE)\nh=hist(sst.yr, 100, plot=FALSE)\nbreaks=h$breaks\nn=length(breaks)-1\nc=jet.colors(n)\nlayout(matrix(c(1,2), nrow=1, ncol=2), widths=c(7,2), heights=4)\npar(mar=c(3,3,3,1))\nimage(lon,rev(lat),sst.yr[,dim(sst.yr)[2]:1],col=c,breaks=breaks,xlab='',ylab='',axes=TRUE,xaxs='i',yaxs='i',asp=1,main=paste(\"Mean SST\", format(dates[1],'%Y/%m/%d'),' - ',format(dates[12],'%Y/%m/%d')))\npar(mar=c(3,1,3,3))\nimage.scale(sst.yr, col=c, breaks=breaks, horiz=FALSE, yaxt=\"n\",xlab='',ylab='',main='SST')\naxis(4)\nbox()"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/wind-vectors/wind-vectors.html",
    "href": "tutorials/ERDDAP-Basics/wind-vectors/wind-vectors.html",
    "title": "Mapping Hurricane Jose with winds",
    "section": "",
    "text": "Hurricane Jose formed on September 5, 2017 and, on September 8, it reached its peak intensity as a high-end Category 4 hurricane. Jose worked its way northward along the US East Coast, finally dissipating on September 25, 2017. In this exercise we will try to capture the hurricane event using wind data from the ASCAT instruments on board all EUMETSAT’s MetOp satellites. ASCAT is a microwave scatterometer designed to measure surface winds over the global ocean.\n\n\n\nHurricane Jose Sept 19, 2017 off the US East Coast\n\n\nThe exercise demonstrates the following ERDDAP features\n\nmapping scalar data\n\nmapping vector data\n\ncreating a Hovmoller diagram\n\n\n\nSelecting the scalar winds dataset\n\nEnter the following URL into your browser: https://coastwatch.pfeg.noaa.gov/erddap/ or Google \"ERDDAP west coast\".\n\nIn the search box type \"ASCAT all\" and click the \"Search\" button.\n\nSeveral MUR datasets show up in the search results. In the ASCAT datasets, scalar winds (wind speed only) are called Modulus of Wind.\n\nLocate the dataset with the title \"Wind, All Metop ASCAT, 0.25°, Global, Near Real Time, 2013-present, Divergence and __Modulus__ (1 Day)\". Alternately, you can add the dataset ID \"erdQMdivmod1day\" to the search box to narrow your search.\nClick on \"graph\" in the \"Make A Graph\" column to the left of the dataset title.\n\nZoom the map in on the waters off the US East Coast\n\nChange the minimum and maximum latitude and longitude values using the latitude and longitude widgets:\n\nLatitudes: 30.75, 41.25\nLongitudes: 283.75, 294.25\n\n\nCreate a map for a time when Hurricane Jose present (Sept. 19, 2017)\n\nChange time widget to select Sept. 19 2017 (2017-09-19T00:00:00Z)\nMake sure that the \"color\" drop down menu has \"mod\" selected\nClick \"Redraw the Graph\"\n\n\n\n\nHurricane Jose wind speeds\n\n\nJose was weakening at this time, but maximum wind speeds were greater that 22 m/s (50 mph). Note the eye of the hurricane in the center of the highest winds.\nDownload the data and view in Panoply\nDownload the data as a netCDF file.\n\nFind the “File type” drop down menu and select “.nc”, which is the alias for netCDF.\nDownload the data directly to your computer by clicking “Submit” button.\nLoad the netCDF file in Panoply.\n\n\n\n\nSelecting the vector winds dataset\n\nEnter the following URL into your browser: https://coastwatch.pfeg.noaa.gov/erddap/ or Google \"ERDDAP west coast\".\n\nIn the search box type \"ASCAT all\" and click the \"Search\" button.\n\nSeveral MUR datasets show up in the search results. In the ASCAT datasets, vector winds (wind speed and direction) are calculated from wind speeds in the north-south direction (meridional winds) and wind speeds in the east-west direction (zonal winds). ERDDAP can make this calculation for you to visualize wind vectors.\n\nLocate the dataset with the title \"Wind, All Metop ASCAT, 0.25°, Global, Near Real Time, 2013-present (1 Day)\". Alternately, you can add the dataset ID \"erdQMwind1day\" to the search box to narrow your search.\nClick on \"graph\" in the \"Make A Graph\" column to the left of the dataset title.\n\nZoom the map in on the waters off the US East Coast\n\nChange the minimum and maximum latitude and longitude values using the latitude and longitude widgets:\n\nLatitudes: 30.75, 41.25\nLongitudes: 283.75, 294.25\n\n\nNote that the following on the Make A Graph page:\n\n\"Graph Type:\" is \"vector\"\n\"Vector X:\" is \"x_wind\" (Zonal Wind)\n\"Vector Y:\" is \"y_wind\" (Meridional Wind)\n\nCreate a map for a time when Hurricane Jose present (Sept. 19, 2017)\n\nChange time widget to select Sept. 19 2017 (2017-09-19T00:00:00Z)\nClick \"Redraw the Graph\"\n\n\n\n\nHurricane Jose wind direction and speed on Sept. 19\n\n\nThe vector arrows show the wind direction. You can see the counter-clockwise movement of the hurricane winds. The length of the arrows indicates the wind speed. The legend shows the arrow length that equals 25 m/s.\n\n\n\nMove the time ahead 2 days to Sept. 21, 2017 (2017-09-21T12:00:00Z) and redraw the graph (map). Hurricane Jose has moved to the northeast. Hurricane Jose has weakened. Note that the arrow length legend has changed to equals 15 m/s.\n\n\n\nHurricane Jose wind direction and speed Sept. 21\n\n\nMove the time ahead to Sept. 26, 2017 (2017-09-26T12:00:00Z) and redraw the graph (map). Hurricane Maria has moved into the southwest corner of the map.\n\n\n\nHurricane Maria wind direction and speed Sept. 26\n\n\n\n\n\nTry to locate Hurricane Gert. Gert traveled up the US East Coast between August 12-17, 2017.\nhttps://en.wikipedia.org/wiki/2017_Atlantic_hurricane_season#Hurricane_Gert\nHint: Start looking at about 30N and 287.5E on August 15"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/wind-vectors/wind-vectors.html#visualize-hurricane-jose-with-scalar-winds",
    "href": "tutorials/ERDDAP-Basics/wind-vectors/wind-vectors.html#visualize-hurricane-jose-with-scalar-winds",
    "title": "Mapping Hurricane Jose with winds",
    "section": "",
    "text": "Selecting the scalar winds dataset\n\nEnter the following URL into your browser: https://coastwatch.pfeg.noaa.gov/erddap/ or Google \"ERDDAP west coast\".\n\nIn the search box type \"ASCAT all\" and click the \"Search\" button.\n\nSeveral MUR datasets show up in the search results. In the ASCAT datasets, scalar winds (wind speed only) are called Modulus of Wind.\n\nLocate the dataset with the title \"Wind, All Metop ASCAT, 0.25°, Global, Near Real Time, 2013-present, Divergence and __Modulus__ (1 Day)\". Alternately, you can add the dataset ID \"erdQMdivmod1day\" to the search box to narrow your search.\nClick on \"graph\" in the \"Make A Graph\" column to the left of the dataset title.\n\nZoom the map in on the waters off the US East Coast\n\nChange the minimum and maximum latitude and longitude values using the latitude and longitude widgets:\n\nLatitudes: 30.75, 41.25\nLongitudes: 283.75, 294.25\n\n\nCreate a map for a time when Hurricane Jose present (Sept. 19, 2017)\n\nChange time widget to select Sept. 19 2017 (2017-09-19T00:00:00Z)\nMake sure that the \"color\" drop down menu has \"mod\" selected\nClick \"Redraw the Graph\"\n\n\n\n\nHurricane Jose wind speeds\n\n\nJose was weakening at this time, but maximum wind speeds were greater that 22 m/s (50 mph). Note the eye of the hurricane in the center of the highest winds.\nDownload the data and view in Panoply\nDownload the data as a netCDF file.\n\nFind the “File type” drop down menu and select “.nc”, which is the alias for netCDF.\nDownload the data directly to your computer by clicking “Submit” button.\nLoad the netCDF file in Panoply."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/wind-vectors/wind-vectors.html#visualize-hurricane-jose-with-vector-winds",
    "href": "tutorials/ERDDAP-Basics/wind-vectors/wind-vectors.html#visualize-hurricane-jose-with-vector-winds",
    "title": "Mapping Hurricane Jose with winds",
    "section": "",
    "text": "Selecting the vector winds dataset\n\nEnter the following URL into your browser: https://coastwatch.pfeg.noaa.gov/erddap/ or Google \"ERDDAP west coast\".\n\nIn the search box type \"ASCAT all\" and click the \"Search\" button.\n\nSeveral MUR datasets show up in the search results. In the ASCAT datasets, vector winds (wind speed and direction) are calculated from wind speeds in the north-south direction (meridional winds) and wind speeds in the east-west direction (zonal winds). ERDDAP can make this calculation for you to visualize wind vectors.\n\nLocate the dataset with the title \"Wind, All Metop ASCAT, 0.25°, Global, Near Real Time, 2013-present (1 Day)\". Alternately, you can add the dataset ID \"erdQMwind1day\" to the search box to narrow your search.\nClick on \"graph\" in the \"Make A Graph\" column to the left of the dataset title.\n\nZoom the map in on the waters off the US East Coast\n\nChange the minimum and maximum latitude and longitude values using the latitude and longitude widgets:\n\nLatitudes: 30.75, 41.25\nLongitudes: 283.75, 294.25\n\n\nNote that the following on the Make A Graph page:\n\n\"Graph Type:\" is \"vector\"\n\"Vector X:\" is \"x_wind\" (Zonal Wind)\n\"Vector Y:\" is \"y_wind\" (Meridional Wind)\n\nCreate a map for a time when Hurricane Jose present (Sept. 19, 2017)\n\nChange time widget to select Sept. 19 2017 (2017-09-19T00:00:00Z)\nClick \"Redraw the Graph\"\n\n\n\n\nHurricane Jose wind direction and speed on Sept. 19\n\n\nThe vector arrows show the wind direction. You can see the counter-clockwise movement of the hurricane winds. The length of the arrows indicates the wind speed. The legend shows the arrow length that equals 25 m/s."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/wind-vectors/wind-vectors.html#continue-tracking-hurricanes",
    "href": "tutorials/ERDDAP-Basics/wind-vectors/wind-vectors.html#continue-tracking-hurricanes",
    "title": "Mapping Hurricane Jose with winds",
    "section": "",
    "text": "Move the time ahead 2 days to Sept. 21, 2017 (2017-09-21T12:00:00Z) and redraw the graph (map). Hurricane Jose has moved to the northeast. Hurricane Jose has weakened. Note that the arrow length legend has changed to equals 15 m/s.\n\n\n\nHurricane Jose wind direction and speed Sept. 21\n\n\nMove the time ahead to Sept. 26, 2017 (2017-09-26T12:00:00Z) and redraw the graph (map). Hurricane Maria has moved into the southwest corner of the map.\n\n\n\nHurricane Maria wind direction and speed Sept. 26"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/wind-vectors/wind-vectors.html#try-this-on-your-own",
    "href": "tutorials/ERDDAP-Basics/wind-vectors/wind-vectors.html#try-this-on-your-own",
    "title": "Mapping Hurricane Jose with winds",
    "section": "",
    "text": "Try to locate Hurricane Gert. Gert traveled up the US East Coast between August 12-17, 2017.\nhttps://en.wikipedia.org/wiki/2017_Atlantic_hurricane_season#Hurricane_Gert\nHint: Start looking at about 30N and 287.5E on August 15"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/using-the-erddap-data-catalog/using-the-erddap-data-catalog.html",
    "href": "tutorials/ERDDAP-Basics/using-the-erddap-data-catalog/using-the-erddap-data-catalog.html",
    "title": "Exploring the data catalog",
    "section": "",
    "text": "There are many ERDDAP servers to chose from. For this example, we will use the ERDDAP operative by the CoastWatch West Coast Node.\n\nEnter the following URL into your browser: https://coastwatch.pfeg.noaa.gov/erddap/ or Google \"ERDDAP west coast\".\n\nTo view all the available datasets, click “View a List of All 1,429 Datasets”\nYou will see all 1400+ datasets listed on the page. You don’t have to look through them all. There is a search feature to help find datasets of interests.\n\n\nERDDAP offers several ways to search for interesting datasets. We will use the full text search in this example. Full documentation of the search options is available at: https://coastwatch.pfeg.noaa.gov/erddap/information.html#search\nEnter search criteria display SST datasets\n\nUs the back button on your browser to go back to the landing page (https://coastwatch.pfeg.noaa.gov/erddap/)\nIn the search box type “sst” and click the “Search’ button\n\nFurther narrow the choices to datasets that have global coverage\n\nAdd “global’ to the search box [i.e. sst and global] and click the”Search’ button.\n\n\n\n\nWithin the search results you have access to information about each dataset to help you decide with which dataset is useful for your application. The search results For this example we will use the global SST & Sea Ice Analysis (OSTIA) from the UK Met Office.\n\nAdd “ostia” in the search box (e.g. sst global ostia) and click the “Search’ button.\nIn the results you should several datasets, including the one displayed below.\n\n\n\n\nOSTIA search result\n\n\n\nThe listing (pictured above) gives access to a lot of information about the dataset. In a browser, try the following:\n\nMouse over the question mark ? under \"Summary\" to get an overview of the dataset.\nClick \"background\" to get more complete information from the data provider about the dataset. Now go back to the search results page.\nClick the \"M\" under \"FGDC,ISO,Metadata\" to see all of the dataset metadata. A lot of information is displayed. Some important fields are:\n\n\"geospatial_lat_min\", \"geospatial_lat_max\", \"geospatial_lon_min\", and \"geospatial_lon_max\" for the spatial coverage\n\"geospatial_lat_resolution\" and \"geospatial_lon_resolution\" for the size of each pixel\n\"time_coverage_start\" and \"time_coverage_end\" for the temporal coverage\n\"references\" for citing the dataset in publications\n\"license\" for restrictions on using the data\n\"acknowledgement\" often used to describe how to acknowledge use of the dataset\n\"creator_name\" for the entity that created the dataset\n\n\nWhen you are finished exploring the metadata, go back to the search results page."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/using-the-erddap-data-catalog/using-the-erddap-data-catalog.html#finding-datasets-on-erddap",
    "href": "tutorials/ERDDAP-Basics/using-the-erddap-data-catalog/using-the-erddap-data-catalog.html#finding-datasets-on-erddap",
    "title": "Exploring the data catalog",
    "section": "",
    "text": "ERDDAP offers several ways to search for interesting datasets. We will use the full text search in this example. Full documentation of the search options is available at: https://coastwatch.pfeg.noaa.gov/erddap/information.html#search\nEnter search criteria display SST datasets\n\nUs the back button on your browser to go back to the landing page (https://coastwatch.pfeg.noaa.gov/erddap/)\nIn the search box type “sst” and click the “Search’ button\n\nFurther narrow the choices to datasets that have global coverage\n\nAdd “global’ to the search box [i.e. sst and global] and click the”Search’ button."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/using-the-erddap-data-catalog/using-the-erddap-data-catalog.html#gather-information-about-a-dataset",
    "href": "tutorials/ERDDAP-Basics/using-the-erddap-data-catalog/using-the-erddap-data-catalog.html#gather-information-about-a-dataset",
    "title": "Exploring the data catalog",
    "section": "",
    "text": "Within the search results you have access to information about each dataset to help you decide with which dataset is useful for your application. The search results For this example we will use the global SST & Sea Ice Analysis (OSTIA) from the UK Met Office.\n\nAdd “ostia” in the search box (e.g. sst global ostia) and click the “Search’ button.\nIn the results you should several datasets, including the one displayed below.\n\n\n\n\nOSTIA search result\n\n\n\nThe listing (pictured above) gives access to a lot of information about the dataset. In a browser, try the following:\n\nMouse over the question mark ? under \"Summary\" to get an overview of the dataset.\nClick \"background\" to get more complete information from the data provider about the dataset. Now go back to the search results page.\nClick the \"M\" under \"FGDC,ISO,Metadata\" to see all of the dataset metadata. A lot of information is displayed. Some important fields are:\n\n\"geospatial_lat_min\", \"geospatial_lat_max\", \"geospatial_lon_min\", and \"geospatial_lon_max\" for the spatial coverage\n\"geospatial_lat_resolution\" and \"geospatial_lon_resolution\" for the size of each pixel\n\"time_coverage_start\" and \"time_coverage_end\" for the temporal coverage\n\"references\" for citing the dataset in publications\n\"license\" for restrictions on using the data\n\"acknowledgement\" often used to describe how to acknowledge use of the dataset\n\"creator_name\" for the entity that created the dataset\n\n\nWhen you are finished exploring the metadata, go back to the search results page."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html",
    "href": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html",
    "title": "Automating ERDDAP requests",
    "section": "",
    "text": "Download requests to ERDDAP are completely defined within a URL, allowing:\n\nmachine-to-machine data exchange,\n\nbringing data directly into analysis tools,\n\nand the use ERDDAP as a back end to drive customized online interfaces.\n\n\n\nThe URL is composed of several parts that define the data request. Let’s try breaking the URL down into its component parts.\nCopy the following URL paste it into a browser to see what the data looks like. https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.largePng?analysed_sst[(2015-07-17T12:00:00Z):(2015-07-17T12:00:00Z)][(45.025):(52.025)][(-128.975):(-121.975)]&.draw=surface&.trim=2&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccff\nNOTE: If you get an error similar to “code=404, Not Found: Currently unknown datasetID=jplUKMO_OSTIAv20.nc”, it means that the dataset is temporarily not available. Try using the following URL, which switches to the “nesdisGeoPolarSSTN5SQ” dataset, instead of the one above:\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5SQ.largePng?analysed_sst[(2015-07-17T12:00:00Z):(2015-07-17T12:00:00Z)][(45.025):(52.025)][(-128.975):(-121.975)]&.draw=surface&.trim=2&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccff\nOpen simple word processor (not Word) and paste in the URL\nTry breaking the URL down into its component parts as described below.\n\nBase URL\n\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/\n\n\ndataset ID\n\njplUKMO_OSTIAv20 (or nesdisGeoPolarSSTN5SQ if you changed the URL above)\n\nFile type\n\n.largePng\n\nEverything after ? is the data request -&gt; ?\nVariable of interest\n\nanalysed_sst\n\nTime\n\n[(2015-07-17T12:00:00Z):(2015-07-17T12:00:00Z)]\n\nLatitude range\n\n[(45.025):(52.025)]\n\nLongitude range\n\n[(-128.975):(-121.975)]\n\nEverything beginning with &.draw adjusts the look of the image\n\n&.draw=surface&.trim=2&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccff\n\n\n\n\n\nNOTE: You could do the following on the ERDDAP “Data Access Form” page and have ERDDAP generate the modified URL, but we will do it by hand in the browser.\nChange the latitude range to remove Oregon and most of Canada from the map. In the browser, look through the URL and find the part that defines the latitude. Change the lower latitude value from 45.025 to 46.5 and the higher latitude value from 52.025 to 50.0.\n\nChange this: [(45.025):(52.025)]\n\nTo this: [(46.5):(50.0)]\nHit return in the browser to see the new edited map.\n\n\n\n\nWA coast, July 15, 2015\n\n\n\n\n\nThe time is adjusted the similarly to the latitude.\nIn the browser, look through the URL and find the part that defines the time. Change the both values to be one (1) month earlier.\n\nChange this: [(2015-07-17T12:00:00Z):(2015-07-17T12:00:00Z)]\nTo this: [(2015-06-17T12:00:00Z):(2015-06-17T12:00:00Z)]\nHit return in the browser to see the new edited map.\n\n\n\n\nWA coast, June 15, 2015\n\n\nGetting the most recent data\nERDDAP allows you to call the most recent image without knowing the date of the most recent data.\nIn the browser, look through the URL and find the part that defines the time. Change the both values \"last\".\n\nChange this: [(2015-06-17T12:00:00Z):(2015-06-17T12:00:00Z)]\n\nTo this: [(last):(last)]\nHit return in the browser to see the new edited map.\n\nThe image that appears is most recent data. You can even due math while using \"last\". For example, to get the image one week before the most recent image.\n\nChange this: [(last):(last)]\n\nTo this: [(last-7):(last-7)]\nHit return in the browser to see the new edited map.\n\nYou may have to adjust the color bar minimum and maximum a little. If so, find the part of the URL that defines the color bar\n\ncolorBar=KT_thermal|||12|20|\n\nThe minimum is set to 12 and maximum is set to 20. Play around with the numbers until your image looks good.\n\n\n\nSo far we have been downloading PGN files in our URL requests to visualize the changes brought about by altering the URL. In the URL the PGN format is represented in the URL by “.png”\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20__.png__?analysed_sst[(last):(last)][(46.5):(50.0)][(-128.975):(-121.975)]&.draw=surface&.trim=2&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccff\nTo download the data, we need to change the file type section of the URL request. There are over 30 file types to choose from, but useful formats for data are MATLAB and netCDF formats. The URL representations for those file types are:\n\n.nc - netCDF files\n\n.mat - Matlab files\n\nWe will select a netCDF file.\n\nIn the browser, locate the .png in the URL and replace it with .nc\n\nHit return in the browser and the netCDF file will download onto your computer\nView the netCDF file you just downloaded in Panoply\n\nA full description of file types can be found at this link:\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/documentation.html\n\n\n\nNow that you know how the ERDDAP URL is constructed, it easy to imagine how to write a script within an analysis tool like R, MATLAB or Python to build a URL, download data, and use the data to accomplish a task. The next example, we will build a simple script in R that downloads the data from the PNG image we produced above, show some information about the file (metadata), and generate a simple plot.\nReview the parts of the ERDDAP URL\nUsing this URL as an example, the component parts of the URL are reviewed below.\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.nc?analysed_sst[(2015-07-13T12:00:00Z):1:(2015-07-14T12:00:00Z)][(46.5):(50.0)][(-128.975):(-121.975)]\n\nBase URL -&gt; https://coastwatch.pfeg.noaa.gov/erddap/griddap/\ndataset ID: jplUKMO_OSTIAv20\nFile type: .nc\nVariable of interest -&gt; analysed_sst\nTime range -&gt; [(2015-07-13T12:00:00Z):1:(2015-07-14T12:00:00Z)] The “1” between times is the stride\nLatitude range -&gt; [(45.025):1:(52.025)] The “1” between times is the stride\nLongitude range -&gt; [(-128.975):1:(-121.975)] The “1” between times is the stride\n\nCreate a function in R to build the URL\nThe code block below contains a simple function to build an ERDDAP URL.\n# A function that generates the URL\nmyURL &lt;- function(burl, data_id, ftype, data_var, dates, lats, lons) {\n  url1 = paste(burl, \"griddap/\", data_id, ftype, \"?\", data_var, sep=\"\")\n  urltime = paste(\"[(\", dates[1], \"):1:(\", dates[2], \")]\", sep=\"\")\n  urllat = paste(\"[(\", lats[1], \"):1:(\", lats[2], \")]\", sep=\"\")\n  urllon = paste(\"[(\", lons[1], \"):1:(\",  lons[2], \")]\", sep=\"\")\n  \n   erddapURL &lt;- paste(url1, urltime, urllat, urllon, sep=\"\")\n}\nUse the function in R to build the URL\nUse the function to generate a URL and download the data. The input information for the URL is hard coded below. It is likely that in a script you would write there would be a process to generate the input information.\nNOTE: If you get an error similar to “Not Found: Currently unknown datasetID=jplUKMO_OSTIAv20.nc”, it means that the dataset is temporarily not available. Try the following to get the exercise to work:\n* Switch the dataset ID from ID &lt;- “jplUKMO_OSTIAv20” to ID &lt;- “nesdisGeoPolarSSTN5SQ” * Below, put a # in front of ID &lt;- “jplUKMO_OSTIAv20” i.e. # ID &lt;- “jplUKMO_OSTIAv20” * Below, remove the # in front of # ID &lt;- “nesdisGeoPolarSSTN5SQ”, i.e. ID &lt;- “nesdisGeoPolarSSTN5SQ”\n# The location of the ERDDAP server\nbaseurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/\"\n# The id of the dataset\nID &lt;- \"jplUKMO_OSTIAv20\"\n# ID &lt;- \"nesdisGeoPolarSSTN5SQ\"\n# The name of the variable \nmydata_var &lt;- \"analysed_sst\"\n# A list containing the beginning and end dates\nmydates &lt;- c(\"2015-07-13T12:00:00Z\", \"2015-07-14T12:00:00Z\")\n# A list containing the beginning and end latitudes\nmylats &lt;- c(45, 52)\n# A list containing the beginning and end longitudes\nmylons &lt;- c(-128, -121)\n# The file type\nfile_type &lt;- \".nc\"\n\n# Generate the URL\nerddap_url &lt;- myURL(baseurl, ID, file_type, mydata_var, mydates, mylats, mylons)\nerddap_url\n## [1] \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.nc?analysed_sst[(2015-07-13T12:00:00Z):1:(2015-07-14T12:00:00Z)][(45):1:(52)][(-128):1:(-121)]\"\n# Download the data as a netCDF file\n\njunk &lt;- GET(erddap_url, write_disk(\"myDataFile.nc\", overwrite=TRUE))  \n\n# The following code will also work for Mac, but not Windows:  \n# download.file(url=erddap_url, destfile=\"myDataFile.nc\", quiet=TRUE)\nBring the data into R\nOpen the downloaded data file, load the SST data, and display some information about the SST variable.\n# open the netCDF file\nlibrary(ncdf4)\nnc &lt;- ncdf4::nc_open(\"myDataFile.nc\")\n# attributes(nc$var)$names\n# load the SST data \nsst &lt;- ncvar_get(nc, mydata_var)\n# Get the shape of the array\ndim(sst)\n## [1] 142 141   2\n# print out some metadata about the varialbe\nncatt_get(nc, mydata_var)\n## $`_FillValue`\n## [1] -327.68\n## \n## $colorBarMaximum\n## [1] 32\n## \n## $colorBarMinimum\n## [1] 0\n## \n## $comment\n## [1] \"OSTIA foundation SST\"\n## \n## $ioos_category\n## [1] \"Temperature\"\n## \n## $long_name\n## [1] \"analysed sea surface temperature\"\n## \n## $references\n## [1] \"C.J. Donlon, M. Martin, J.D. Stark, J. Roberts-Jones, E. Fiedler, W. Wimmer. The operational sea surface temperature and sea ice analysis (OSTIA) system. Remote Sensing Environ., 116 (2012), pp. 140u2013158 https://dx.doi.org/10.1016/j.rse.2010.10.017\"\n## \n## $source\n## [1] \"AVHRR18_G-NAVO-L2P-V1.0, AVHRR19_G-NAVO-L2P-V1.0, AVHRR_SST_METOP_B-OSISAF-L2P-V1.0, VIIRS_NPP-OSPO-L2P-V2.3, AMSR2-REMSS-L2P-V07.2, GOES13-OSISAF-L3C-V1.0, SEVIRI_SST-OSISAF-L3C-V1.0, OSISAF_ICE, NCEP_ICE\"\n## \n## $standard_name\n## [1] \"sea_surface_foundation_temperature\"\n## \n## $units\n## [1] \"degree_C\"\n## \n## $valid_max\n## [1] 44.99999\n## \n## $valid_min\n## [1] -3.000006\nPlot a simple visualization of the SST data.\n# Get the data for the first time step\nsst1 &lt;- (sst[,,1])\n# Visualize teh data\n#image(sst1, col=matlab.like2(255)) blue2green2red\nimage(sst1, col = rainbow(225))"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html#deconstructing-the-url",
    "href": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html#deconstructing-the-url",
    "title": "Automating ERDDAP requests",
    "section": "",
    "text": "The URL is composed of several parts that define the data request. Let’s try breaking the URL down into its component parts.\nCopy the following URL paste it into a browser to see what the data looks like. https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.largePng?analysed_sst[(2015-07-17T12:00:00Z):(2015-07-17T12:00:00Z)][(45.025):(52.025)][(-128.975):(-121.975)]&.draw=surface&.trim=2&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccff\nNOTE: If you get an error similar to “code=404, Not Found: Currently unknown datasetID=jplUKMO_OSTIAv20.nc”, it means that the dataset is temporarily not available. Try using the following URL, which switches to the “nesdisGeoPolarSSTN5SQ” dataset, instead of the one above:\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5SQ.largePng?analysed_sst[(2015-07-17T12:00:00Z):(2015-07-17T12:00:00Z)][(45.025):(52.025)][(-128.975):(-121.975)]&.draw=surface&.trim=2&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccff\nOpen simple word processor (not Word) and paste in the URL\nTry breaking the URL down into its component parts as described below.\n\nBase URL\n\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/\n\n\ndataset ID\n\njplUKMO_OSTIAv20 (or nesdisGeoPolarSSTN5SQ if you changed the URL above)\n\nFile type\n\n.largePng\n\nEverything after ? is the data request -&gt; ?\nVariable of interest\n\nanalysed_sst\n\nTime\n\n[(2015-07-17T12:00:00Z):(2015-07-17T12:00:00Z)]\n\nLatitude range\n\n[(45.025):(52.025)]\n\nLongitude range\n\n[(-128.975):(-121.975)]\n\nEverything beginning with &.draw adjusts the look of the image\n\n&.draw=surface&.trim=2&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccff"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html#adjust-the-area-in-the-url",
    "href": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html#adjust-the-area-in-the-url",
    "title": "Automating ERDDAP requests",
    "section": "",
    "text": "NOTE: You could do the following on the ERDDAP “Data Access Form” page and have ERDDAP generate the modified URL, but we will do it by hand in the browser.\nChange the latitude range to remove Oregon and most of Canada from the map. In the browser, look through the URL and find the part that defines the latitude. Change the lower latitude value from 45.025 to 46.5 and the higher latitude value from 52.025 to 50.0.\n\nChange this: [(45.025):(52.025)]\n\nTo this: [(46.5):(50.0)]\nHit return in the browser to see the new edited map.\n\n\n\n\nWA coast, July 15, 2015"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html#adjust-the-time-in-the-url",
    "href": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html#adjust-the-time-in-the-url",
    "title": "Automating ERDDAP requests",
    "section": "",
    "text": "The time is adjusted the similarly to the latitude.\nIn the browser, look through the URL and find the part that defines the time. Change the both values to be one (1) month earlier.\n\nChange this: [(2015-07-17T12:00:00Z):(2015-07-17T12:00:00Z)]\nTo this: [(2015-06-17T12:00:00Z):(2015-06-17T12:00:00Z)]\nHit return in the browser to see the new edited map.\n\n\n\n\nWA coast, June 15, 2015\n\n\nGetting the most recent data\nERDDAP allows you to call the most recent image without knowing the date of the most recent data.\nIn the browser, look through the URL and find the part that defines the time. Change the both values \"last\".\n\nChange this: [(2015-06-17T12:00:00Z):(2015-06-17T12:00:00Z)]\n\nTo this: [(last):(last)]\nHit return in the browser to see the new edited map.\n\nThe image that appears is most recent data. You can even due math while using \"last\". For example, to get the image one week before the most recent image.\n\nChange this: [(last):(last)]\n\nTo this: [(last-7):(last-7)]\nHit return in the browser to see the new edited map.\n\nYou may have to adjust the color bar minimum and maximum a little. If so, find the part of the URL that defines the color bar\n\ncolorBar=KT_thermal|||12|20|\n\nThe minimum is set to 12 and maximum is set to 20. Play around with the numbers until your image looks good."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html#changing-the-file-type-in-the-url",
    "href": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html#changing-the-file-type-in-the-url",
    "title": "Automating ERDDAP requests",
    "section": "",
    "text": "So far we have been downloading PGN files in our URL requests to visualize the changes brought about by altering the URL. In the URL the PGN format is represented in the URL by “.png”\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20__.png__?analysed_sst[(last):(last)][(46.5):(50.0)][(-128.975):(-121.975)]&.draw=surface&.trim=2&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccff\nTo download the data, we need to change the file type section of the URL request. There are over 30 file types to choose from, but useful formats for data are MATLAB and netCDF formats. The URL representations for those file types are:\n\n.nc - netCDF files\n\n.mat - Matlab files\n\nWe will select a netCDF file.\n\nIn the browser, locate the .png in the URL and replace it with .nc\n\nHit return in the browser and the netCDF file will download onto your computer\nView the netCDF file you just downloaded in Panoply\n\nA full description of file types can be found at this link:\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/documentation.html"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html#pull-data-into-a-scripting-language",
    "href": "tutorials/ERDDAP-Basics/understanding-erddap-url/understanding-erddap-url.html#pull-data-into-a-scripting-language",
    "title": "Automating ERDDAP requests",
    "section": "",
    "text": "Now that you know how the ERDDAP URL is constructed, it easy to imagine how to write a script within an analysis tool like R, MATLAB or Python to build a URL, download data, and use the data to accomplish a task. The next example, we will build a simple script in R that downloads the data from the PNG image we produced above, show some information about the file (metadata), and generate a simple plot.\nReview the parts of the ERDDAP URL\nUsing this URL as an example, the component parts of the URL are reviewed below.\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.nc?analysed_sst[(2015-07-13T12:00:00Z):1:(2015-07-14T12:00:00Z)][(46.5):(50.0)][(-128.975):(-121.975)]\n\nBase URL -&gt; https://coastwatch.pfeg.noaa.gov/erddap/griddap/\ndataset ID: jplUKMO_OSTIAv20\nFile type: .nc\nVariable of interest -&gt; analysed_sst\nTime range -&gt; [(2015-07-13T12:00:00Z):1:(2015-07-14T12:00:00Z)] The “1” between times is the stride\nLatitude range -&gt; [(45.025):1:(52.025)] The “1” between times is the stride\nLongitude range -&gt; [(-128.975):1:(-121.975)] The “1” between times is the stride\n\nCreate a function in R to build the URL\nThe code block below contains a simple function to build an ERDDAP URL.\n# A function that generates the URL\nmyURL &lt;- function(burl, data_id, ftype, data_var, dates, lats, lons) {\n  url1 = paste(burl, \"griddap/\", data_id, ftype, \"?\", data_var, sep=\"\")\n  urltime = paste(\"[(\", dates[1], \"):1:(\", dates[2], \")]\", sep=\"\")\n  urllat = paste(\"[(\", lats[1], \"):1:(\", lats[2], \")]\", sep=\"\")\n  urllon = paste(\"[(\", lons[1], \"):1:(\",  lons[2], \")]\", sep=\"\")\n  \n   erddapURL &lt;- paste(url1, urltime, urllat, urllon, sep=\"\")\n}\nUse the function in R to build the URL\nUse the function to generate a URL and download the data. The input information for the URL is hard coded below. It is likely that in a script you would write there would be a process to generate the input information.\nNOTE: If you get an error similar to “Not Found: Currently unknown datasetID=jplUKMO_OSTIAv20.nc”, it means that the dataset is temporarily not available. Try the following to get the exercise to work:\n* Switch the dataset ID from ID &lt;- “jplUKMO_OSTIAv20” to ID &lt;- “nesdisGeoPolarSSTN5SQ” * Below, put a # in front of ID &lt;- “jplUKMO_OSTIAv20” i.e. # ID &lt;- “jplUKMO_OSTIAv20” * Below, remove the # in front of # ID &lt;- “nesdisGeoPolarSSTN5SQ”, i.e. ID &lt;- “nesdisGeoPolarSSTN5SQ”\n# The location of the ERDDAP server\nbaseurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/\"\n# The id of the dataset\nID &lt;- \"jplUKMO_OSTIAv20\"\n# ID &lt;- \"nesdisGeoPolarSSTN5SQ\"\n# The name of the variable \nmydata_var &lt;- \"analysed_sst\"\n# A list containing the beginning and end dates\nmydates &lt;- c(\"2015-07-13T12:00:00Z\", \"2015-07-14T12:00:00Z\")\n# A list containing the beginning and end latitudes\nmylats &lt;- c(45, 52)\n# A list containing the beginning and end longitudes\nmylons &lt;- c(-128, -121)\n# The file type\nfile_type &lt;- \".nc\"\n\n# Generate the URL\nerddap_url &lt;- myURL(baseurl, ID, file_type, mydata_var, mydates, mylats, mylons)\nerddap_url\n## [1] \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.nc?analysed_sst[(2015-07-13T12:00:00Z):1:(2015-07-14T12:00:00Z)][(45):1:(52)][(-128):1:(-121)]\"\n# Download the data as a netCDF file\n\njunk &lt;- GET(erddap_url, write_disk(\"myDataFile.nc\", overwrite=TRUE))  \n\n# The following code will also work for Mac, but not Windows:  \n# download.file(url=erddap_url, destfile=\"myDataFile.nc\", quiet=TRUE)\nBring the data into R\nOpen the downloaded data file, load the SST data, and display some information about the SST variable.\n# open the netCDF file\nlibrary(ncdf4)\nnc &lt;- ncdf4::nc_open(\"myDataFile.nc\")\n# attributes(nc$var)$names\n# load the SST data \nsst &lt;- ncvar_get(nc, mydata_var)\n# Get the shape of the array\ndim(sst)\n## [1] 142 141   2\n# print out some metadata about the varialbe\nncatt_get(nc, mydata_var)\n## $`_FillValue`\n## [1] -327.68\n## \n## $colorBarMaximum\n## [1] 32\n## \n## $colorBarMinimum\n## [1] 0\n## \n## $comment\n## [1] \"OSTIA foundation SST\"\n## \n## $ioos_category\n## [1] \"Temperature\"\n## \n## $long_name\n## [1] \"analysed sea surface temperature\"\n## \n## $references\n## [1] \"C.J. Donlon, M. Martin, J.D. Stark, J. Roberts-Jones, E. Fiedler, W. Wimmer. The operational sea surface temperature and sea ice analysis (OSTIA) system. Remote Sensing Environ., 116 (2012), pp. 140u2013158 https://dx.doi.org/10.1016/j.rse.2010.10.017\"\n## \n## $source\n## [1] \"AVHRR18_G-NAVO-L2P-V1.0, AVHRR19_G-NAVO-L2P-V1.0, AVHRR_SST_METOP_B-OSISAF-L2P-V1.0, VIIRS_NPP-OSPO-L2P-V2.3, AMSR2-REMSS-L2P-V07.2, GOES13-OSISAF-L3C-V1.0, SEVIRI_SST-OSISAF-L3C-V1.0, OSISAF_ICE, NCEP_ICE\"\n## \n## $standard_name\n## [1] \"sea_surface_foundation_temperature\"\n## \n## $units\n## [1] \"degree_C\"\n## \n## $valid_max\n## [1] 44.99999\n## \n## $valid_min\n## [1] -3.000006\nPlot a simple visualization of the SST data.\n# Get the data for the first time step\nsst1 &lt;- (sst[,,1])\n# Visualize teh data\n#image(sst1, col=matlab.like2(255)) blue2green2red\nimage(sst1, col = rainbow(225))"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/additional-resources/additional-resources.html",
    "href": "tutorials/ERDDAP-Basics/additional-resources/additional-resources.html",
    "title": "Additional training and resources",
    "section": "",
    "text": "NOAA CoastWatch West Coast Node CoastWatch West Coast Node has compiled examples that demonstrate techniques to extract data from the ERDDAP data servers to address fisheries research needs, such as matching up satellite data to ship/animal tracks and create time series oceanographic regions such as marine protected areas. The examples use the rerddapxtracto library written in R, which generates ERDDAP URLs for you and sends data requests to extract data using ERDDAP.\nR Exercises - https://coastwatch.pfeg.noaa.gov/projects/r/\n\n\n\nMany of the NOAA CoastWatch nodes offer training in satellite ocean data use. The primary target audiences for the courses are scientists and managers who are involved in operational activities, but are not actively using satellite data in their work. The goal of the course is to provide participants the knowledge and tools they require to incorporate off-the-shelf satellite data products into their operational activities, without delving too much into the details of how the products are made.\nCourses offered by the West Coast Node\n\nWest Coast Node courses page - https://coastwatch.pfeg.noaa.gov/courses/satellite_course_reg.html\n\nPlease contact personnel for information about courses held near you.\n\nCentral Pacific Node - https://oceanwatch.pifsc.noaa.gov/course.html\nEast Coast Node - https://eastcoast.coastwatch.noaa.gov/\nGreat Lakes Node - https://coastwatch.glerl.noaa.gov/"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/additional-resources/additional-resources.html#exercises-written-in-r",
    "href": "tutorials/ERDDAP-Basics/additional-resources/additional-resources.html#exercises-written-in-r",
    "title": "Additional training and resources",
    "section": "",
    "text": "NOAA CoastWatch West Coast Node CoastWatch West Coast Node has compiled examples that demonstrate techniques to extract data from the ERDDAP data servers to address fisheries research needs, such as matching up satellite data to ship/animal tracks and create time series oceanographic regions such as marine protected areas. The examples use the rerddapxtracto library written in R, which generates ERDDAP URLs for you and sends data requests to extract data using ERDDAP.\nR Exercises - https://coastwatch.pfeg.noaa.gov/projects/r/"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/additional-resources/additional-resources.html#noaa-coastwatch-ocean-satellite-data-courses",
    "href": "tutorials/ERDDAP-Basics/additional-resources/additional-resources.html#noaa-coastwatch-ocean-satellite-data-courses",
    "title": "Additional training and resources",
    "section": "",
    "text": "Many of the NOAA CoastWatch nodes offer training in satellite ocean data use. The primary target audiences for the courses are scientists and managers who are involved in operational activities, but are not actively using satellite data in their work. The goal of the course is to provide participants the knowledge and tools they require to incorporate off-the-shelf satellite data products into their operational activities, without delving too much into the details of how the products are made.\nCourses offered by the West Coast Node\n\nWest Coast Node courses page - https://coastwatch.pfeg.noaa.gov/courses/satellite_course_reg.html\n\nPlease contact personnel for information about courses held near you.\n\nCentral Pacific Node - https://oceanwatch.pifsc.noaa.gov/course.html\nEast Coast Node - https://eastcoast.coastwatch.noaa.gov/\nGreat Lakes Node - https://coastwatch.glerl.noaa.gov/"
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html",
    "href": "trainings/upcoming/pgrsc26.html",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "",
    "text": "This 4-day satellite and ocean data training course will be held virtually during February 10-13 (FJT), 2026. It is co-hosted by CoastWatch/OceanWatch Central Pacific and the Pacific Islands Ocean Observing System (PacIOOS).\nClick here to Register.\nJoin course via googlemeet here",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#course-description",
    "href": "trainings/upcoming/pgrsc26.html#course-description",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "",
    "text": "This 4-day satellite and ocean data training course will be held virtually during February 10-13 (FJT), 2026. It is co-hosted by CoastWatch/OceanWatch Central Pacific and the Pacific Islands Ocean Observing System (PacIOOS).\nClick here to Register.\nJoin course via googlemeet here",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#learning-outcomes",
    "href": "trainings/upcoming/pgrsc26.html#learning-outcomes",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nLearn where to find satellite, remote sensing, and ocean parameter data\nBecome familiar with the ERDDAP platform to visualize, subset, and download data\nLearn to judge which products are appropriate for your application or who to contact to get guidance\nApply what you learn on a personal project so that you leave the course with ready-to-use workflows",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#course-logistics",
    "href": "trainings/upcoming/pgrsc26.html#course-logistics",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Course Logistics",
    "text": "Course Logistics\nThis course will be conducted entirely online. Anyone is free to sign up for the course, although it is targeted at participants in the Pacific Islands region, and the live sessions are scheduled to align with their workday. At the start of each day (9:00 am FJT, 11:00 am HST), there will be a live session where we will preview the material participants should go over that day, discuss the previous day’s material, and answer any questions. Each day, there will be a live Q&A session (2:00-3:00 pm FJT, 4:00-5:00 pm HST) to answer any questions regarding the materials, exercises, or the project you are working on.\nParticipants should expect to spend about 1-2 hours/day in live sessions and at least 2-3 hours/day working on their own, going through the course material at their own pace, and working on their project. All of the course materials are available online, and participants will go through them at their own pace, but there is a suggested list of modules to cover for each day of the course. Instructors will be available during the week to help or answer questions. The last day will be a 2-3 hour student presentation day (see below).",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#project",
    "href": "trainings/upcoming/pgrsc26.html#project",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Project",
    "text": "Project\nAs part of the course, participants are expected to come with a specific project to work on during the class. Participants get more out of the workshop if they have specific questions or projects to work on. Everyone will give a short (1 slide, 2-minute MAX) lightning talk during the last class session. The project can be as simple as making a map or a time series for the region of interest, for those who are new to working with satellite data, or as complex as a participant feels comfortable with. Any ancillary data needed for projects should be available on hand.",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#course-structure",
    "href": "trainings/upcoming/pgrsc26.html#course-structure",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Course Structure",
    "text": "Course Structure\nThe Day 1 live session will include an introduction to the course and the instructors. This will be an opportunity for participants to introduce themselves and briefly describe their class project. On Days 2 and 3, during the live session, the instructors will review the previous day’s homework, preview the course activities for the self-study periods, and answer any questions that have come up. Guest lectures and tools demos may also be included. Participants work at their own schedule and pace to complete the course content and work on their individual projects. The first few days feature video tutorials on satellite data, example software tutorials, and homework exercises. As the class progresses, participants will use the self-study period to work on their individual projects.",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#schedule",
    "href": "trainings/upcoming/pgrsc26.html#schedule",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nDay (FJT)\nTime (FJT)\nTopic\nPresenter\n\n\n\n\nDay 1 - February 10\n9:00 AM (live session)\nIntroduction to NOAA CoastWatch & PacIOOS\nDaisy Shi & Lauren Kaiser\n\n\n\n\nTools & Resources (ERDDAP & Voyager)\nDaisy Shi & Lauren Kaiser\n\n\n\n11:00 AM (Self-Paced Work)\nModule 1: Satellite 101 (Part 1 & Part 2)\n\n\n\n\n\nModule 2: Tools & Strategies for your Project\n\n\n\n\n\nTutorial 1: ERDDAP Basics\n\n\n\n\n\nTutorial 2: PacIOOS Voyager User Tutorial\n\n\n\n\n\nOptional Tutorial: MATLAB, R, or Python\n\n\n\n\n\nProject Development 1: Make a map on the ERDDAP make-a-graph interface with a dataset from the CoastWatch Data Catalog. Practice downloading the data as a netCDF file using the download interface (i.e., select the nc file format in ERDDAP).\n\n\n\n\n\nProject Development 2: Review presentation guidelines and examples from previous courses\n\n\n\n\n2:00 PM\nQ & A Session\n\n\n\nDay 2 - February 11\n9:00 AM (live session)\nOcean Color Satellite Data Products and Application in the Fisheries\nRyan Vandermeulen\n\n\n\n\nUsing Satellite Data with GIS\nLauren Kaiser\n\n\n\n11:00 AM (Self-Paced Work)\nModule 1: Satellite Ocean Color\n\n\n\n\n\nModule 2: Satellite Water Quality\n\n\n\n\n\nModule 3: Harmful Algal Blooms (HABS, Part 1 & Part 2)\n\n\n\n\n\nModule 4: What Dataset(s) to Choose\n\n\n\n\n\nArcGIS Tutorial 1: ArcGIS Tools Tutorial\n\n\n\n\n\nArcGIS Tutorial 2: Ocean Color & Water Quality\n\n\n\n\n\nMATLAB, R, or Python Tutorials: Comparison of chlorophyll data from different sensors\n\n\n\n\n\nProject Development 1: Identify which datasets are best suited for your application from OceanWatch Central Pacific, CoastWatch Search Tool, PacIOOS ERDDAP, and PacIOOS Search Tool.\n\n\n\n\n\nProject Development 2: Find the data on ERDDAP. Think about what date range and spatial resolution you need, and which time composite you decided to use (daily, weekly, or monthly). You should be able to explain why you chose the specific product.\n\n\n\n\n\nProject Development 3: Download data needed for your project and create a plot (map, time-series, etc.)\n\n\n\n\n2:00 PM\nQ & A Session\n\n\n\nDay 3 - February 12\n9:00 AM (live session)\nSea Surface Temperature Satellite Data and Applications in Coastal Regions\nKisei Tanaka\n\n\n\n\nData Demo\nLauren Kaiser\n\n\n\n11:00 AM (Self-Paced Work)\nModule 1: Satellite Sea Surface Temperature\n\n\n\n\n\nModule 2: Satellite Salinity, Wind, and Altimetry\n\n\n\n\n\nModule 3: Synthetic Aperture Radar (SAR)\n\n\n\n\n\nArcGIS Tutorial: Tracking Turtles & Temperature\n\n\n\n\n\nMATLAB, R, or Python Tutorial: Match satellite data to track locations\n\n\n\n\n\nProject Development 1: Create a slide. Include your name, affiliation, a short description of your project, one or two images (map, time series, histogram, cute picture) that you were able to make in relation to your project, what specific satellite product(s) and software you used\n\n\n\n\n\nProject Development 2: Optional: you can include cool picture(s) of animals or technology related to your project. If applicable: also include challenges, data products that you wish were available (satellite-related), needs unmet by current data/services offerings.\n\n\n\n\n\nProject Development 3: Upload your final slide(s) to the 2026 Paticipant Presentation folder.\n\n\n\n\n2:00 PM\nQ & A Session\n\n\n\nDay 4 - February 13\n9:00 AM (live session)\nParticipant Presentations (2-minute presentation on your slide(s) )\n\n\n\n\n\nCourse Feedback",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#contacts",
    "href": "trainings/upcoming/pgrsc26.html#contacts",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Contacts",
    "text": "Contacts\n\n\n\nName\nAffiliation\n\n\n\n\nDaisy Shi\nCoastWatch/Pacific OceanWatch, Operations Manager\n\n\nLauren Kaiser\nPacIOOS, Data Management Specialist\n\n\nRyan Vandermeulen\nNOAA Fisheries Satellite Coordinator\n\n\nKisei Tanaka\nNOAA PIFSC, Research Marine Biologist\n\n\nCara Wilson\nCoastWatch/West Coast Node, PI",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#resources",
    "href": "trainings/upcoming/pgrsc26.html#resources",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Resources",
    "text": "Resources\n\nNOAA CoastWatch Website\nCoastWatch Training Lectures & Tutorials (on YouTube)\n\nLectures\nTutorials\n\nCoastwatch Tutorials (on GitHub)\nPacIOOS",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html",
    "href": "trainings/past/pgrsc24.html",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using information tools from PacIOOS for applications in the Pacific Islands region. This training will be held during the 2024 Pacific Islands GIS and Remote Sensing Users Conference in Suva, Fiji.\nClick here to Register.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html#course-description",
    "href": "trainings/past/pgrsc24.html#course-description",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using information tools from PacIOOS for applications in the Pacific Islands region. This training will be held during the 2024 Pacific Islands GIS and Remote Sensing Users Conference in Suva, Fiji.\nClick here to Register.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html#instructors",
    "href": "trainings/past/pgrsc24.html#instructors",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "Instructors",
    "text": "Instructors\n\n\n\nName\nAffiliation\n\n\n\n\nDaisy Shi\nCoastWatch/Pacific OceanWatch, node manager\n\n\nLauren Kaiser\nPacIOOS, data management specialist\n\n\nCara Wilson\nCoastWatch/West Coast Node, PI",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html#objectives",
    "href": "trainings/past/pgrsc24.html#objectives",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the basic types of products available from satellite data\nDemonstrate how to access data on ERDDAP servers\nIntroduce CoastWatch satellite data and training resources\nExplore additional data and information tools available at PacIOOS\nProvide hands-on time to access data and run tutorials",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html#schedule",
    "href": "trainings/past/pgrsc24.html#schedule",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime (Fiji Standard Time)\nTopic\nPresenter\n\n\n\n\n1:00 - 1:10\nWelcome & Introductions\nDaisy Shi & Lauren Kaiser\n\n\n1:10 - 1:20\nInteractive Questions\n\n\n\n1:20 - 1:35\nIntro to CoastWatch, Satellite Datasets & Data Portal\nDaisy Shi\n\n\n1:35 - 1:50\nIntro to OceanWatch, Data Accessibility & Usability\nDaisy Shi\n\n\n1:50 - 2:20\nIntro to PacIOOS, Website Walkthrough & Data Search\nLauren Kaiser\n\n\n2:20 - 2:30\nInteractive Questions\n\n\n\n2:30 - 2:45\nBreak\n\n\n\n2:45 - 2:55\nOverview of CoastWatch Tutorials\nDaisy Shi\n\n\n2:55 - 3:15\nERDDAP Demos\nDaisy Shi\n\n\n3:15 - 3:45\nArcGIS & QGIS Demos\nLauren Kaiser\n\n\n3:45 - 4:00\nBreak\n\n\n\n4:00 - 5:50\nHands-On time\nAll\n\n\n5:50 - 6:00\nInteractive Questions & Feedback",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html#resources",
    "href": "trainings/past/pgrsc24.html#resources",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "Resources",
    "text": "Resources\n\nCoastwatch Tutorials\nCoastwatch Lecture series\nGeostationary satellites covering Western Pacific\nPacIOOS\nPacIOOS Voyager",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/icft25.html",
    "href": "trainings/past/icft25.html",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using the Animal Telemetry Network Portal. This training was originally going to be held before the annual ICFT (International Conference on Fish Telemetry) meeting in Traverse City, Michigan, but has been rescheduled to be an online course, open to all.\nLink to registration page",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/past/icft25.html#course-description",
    "href": "trainings/past/icft25.html#course-description",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using the Animal Telemetry Network Portal. This training was originally going to be held before the annual ICFT (International Conference on Fish Telemetry) meeting in Traverse City, Michigan, but has been rescheduled to be an online course, open to all.\nLink to registration page",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/past/icft25.html#instructors",
    "href": "trainings/past/icft25.html#instructors",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Instructors",
    "text": "Instructors\n\n\n\nName\nAffiliation\n\n\n\n\nCara Wilson\nCoastWatch/West Coast Node, PI\n\n\nDale Robinson\nCoastWatch/West Coast Node, node manager\n\n\nMegan McKinzie\nATN Data manager\n\n\nDaisy Shi\nCoastWatch/Pacific OceanWatch, node manager",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/past/icft25.html#objectives",
    "href": "trainings/past/icft25.html#objectives",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the basic types of products available from satellite data\nDemonstate how to access data on ERDDAP servers\nExplore the data available on the Animal Telemetry Network portal\nIntroduce CoastWatch satellite data training resources\nProvide hands-on time to access data and try tutorials",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/past/icft25.html#schedule",
    "href": "trainings/past/icft25.html#schedule",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Schedule",
    "text": "Schedule\nThursday, August 14, 2025\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n10:00 - 10:15\nTraining Overview - CoastWatch, ATN and the workshop component\nCara Wilson\n\n\n10:15 - 11:30\nCoastwatch satellite datasets and data portals\nCara Wilson\n\n\n11:30 - 11:45\nBreak\n\n\n\n11:45 - 12:15\nUsing the ERDDAP data server\nCara Wilson\n\n\n12:15 - 12:45\nAccessing ERDDAP using scripts (R, python)\nCara Wilson\n\n\n12:45 - 1:00\nDay 1 wrap-up\n\n\n\n\nFriday, August 15, 2025\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n10:00 - 10:30\nIntro to ATN and the DAC\nMegan McKinzie\n\n\n10:30 - 11:00\nDemo of ATN data portal\nMegan McKinzie\n\n\n11:00 - 11:30\nAccessing public ATN datasets\nMegan McKinzie\n\n\n11:30 - 11:45\nBreak\n\n\n\n11:45 - 12:00\nWorkshop, part 1: Linking CoastWatch and ATN data using scripts\nDaisy Shi\n\n\n12:00 - 12:45\nWorkshop, part 2: Hand’s on time\n\n\n\n12:45 - 13:00\nWrap up and final discussion\nAll",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/past/icft25.html#resources",
    "href": "trainings/past/icft25.html#resources",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Resources",
    "text": "Resources\n\nCoastwatch Tutorials (on GitHub)\nCoastwatch Lecture series\nAnimal telemetry Network",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/index.html",
    "href": "trainings/index.html",
    "title": "CoastWatch Workshops",
    "section": "",
    "text": "CoastWatch regularly organizes and offers in-person and online satellite training classes or workshops featuring lectures, tutorials, & tool demonstrations.\nDuring in-person and online satellite course, participants learn about environmental satellite data and how to easily obtain it. Participants also gain hands on experience working with the data of interest to them. A major goal of the course is to provide scientists who are not regular users of satellite data with the knowledge and tools they need to incorporate satellite data into their research and management projects.\nFor questions or more information about the upcoming satellite training classes, please contact coastwatch.info@noaa.gov.",
    "crumbs": [
      "Training Classes"
    ]
  },
  {
    "objectID": "news-announcements.html",
    "href": "news-announcements.html",
    "title": "News & Announcements",
    "section": "",
    "text": "This page highlights recent updates, announcements, and changes related to CoastWatch training materials, tutorials, and data resources.",
    "crumbs": [
      "News & Announcements"
    ]
  },
  {
    "objectID": "news-announcements.html#latest-updates",
    "href": "news-announcements.html#latest-updates",
    "title": "News & Announcements",
    "section": "Latest Updates",
    "text": "Latest Updates",
    "crumbs": [
      "News & Announcements"
    ]
  },
  {
    "objectID": "news-announcements.html#upcoming-training-noaa-coastwatchpacioos-satellite-and-ocean-data-training-course",
    "href": "news-announcements.html#upcoming-training-noaa-coastwatchpacioos-satellite-and-ocean-data-training-course",
    "title": "News & Announcements",
    "section": "Upcoming Training: NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "text": "Upcoming Training: NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course\nFebruary 10-13, 2026, Virtual, 9 AM-3 PM (Fiji Standard Time)\nThis 4-day satellite and ocean data training course will be held virtually during February 10-13 (FJT), 2026. It is co-hosted by CoastWatch/OceanWatch Central Pacific and the Pacific Islands Ocean Observing System (PacIOOS).\nFind more information on the upcoming course here.",
    "crumbs": [
      "News & Announcements"
    ]
  },
  {
    "objectID": "news-announcements.html#upcoming-trainings-satellite-201-summer-lecture-series",
    "href": "news-announcements.html#upcoming-trainings-satellite-201-summer-lecture-series",
    "title": "News & Announcements",
    "section": "Upcoming Trainings: Satellite 201 Summer Lecture Series",
    "text": "Upcoming Trainings: Satellite 201 Summer Lecture Series\nJuly 10, 17, 24 and 31, 2026, Virtual 11am - 1pm (Pacific Time)\nThis lecture series provides a deeper dive into satellite oceanography, exploring advanced topics beyond the regular CoastWatch satellite course.\nFind more information on the upcoming course here.",
    "crumbs": [
      "News & Announcements"
    ]
  },
  {
    "objectID": "lectures/transcripts/using-arcgis.html",
    "href": "lectures/transcripts/using-arcgis.html",
    "title": "Using Satellite Data in ArcGIS",
    "section": "",
    "text": "This training is one part of several tutorials within the NOAA CoastWatch Satellite Training Course. The GIS tutorials consist of 3 modules and although the screenshots and examples use ArcGIS, the principles apply to any GIS software packages. Finally, we’ve come a long way as this is the 20th year since the first formal CoastWatch Satellite GIS training given in the 2000. By the end of this training, you should have an understanding of the various ways to view and work with satellite data in GIS.\nThe objective of this tutorial is to present a description of the satellite imagery and products and considerations when using satellite data in a Geographic Information System or GIS. In terms of utilizing a satellite product, we’ll discuss Imagery and Data.\nOne type of satellite product you may use in your GIS is satellite imagery. Imagery is usually intended for visualization. It may display one or more types of data or be generated from multiple inputs. One of the most common examples is true color. True color imagery may either be a photo or combination of visible bands (red, green, blue) where the environment is displayed in a similar way to how we see it with our eyes. Common imagery formats include PNG, JPEG, and GeoTIFF.\nWhen data are shown in imagery, the pixel values are usually color values used to display the geophysical parameter. So, imagery is essentially a picture. And generally, within the GIS, the image cannot be queried or classified. However, some spatially-enabled formats such as GeoTIFF may contain the scaling equations that data went through to create the image and using tools within the GIS, can be treated like data.\nSatellite Data, on the other hand, is different from imagery in that it contains the geophysical values of the observed parameter. In other words, looking at sea surface temperature data we have access to the actual temperature of the water. This is an important distinction, as data can often look like imagery, but the actual values can be used in calculations and spatial operations in the GIS. Common formats for satellite data include HDF, NetCDF, and GeoTiff.\nWhat are some of the considerations for working with satellite data? One consideration is Metadata – or data about the data. Another is formats – or how the data are stored. Will my GIS recognize it? Another consideration is Resolution. Resolution can be spatial or temporal. i.e. a monthly composite, or spatial – how much space does a single pixel cover. Projection – consists of a coordinate system and reference. Projections are often selected based on the application of the data. And finally preparation. In some cases, data must be worked with to get it to the desired state. The GIS often does some of this for you, but we’ll discuss some of these cases shortly.\nMetadata. Working with GIS, it’s all about the metadata. When combining different spatial layers, it’s critical they share the same reference system. Also, we need to know what has been done to the data so that in our application, we fully understand any caveats or restrictions in working with the data. Fortunately, metadata has become more standardized. Multiple standards have converged into ISO standards and for satellite data and geographic information, there is guidance on what information to include making it much easier to understand the data we work with. In the satellite data context, metadata typically includes geographic and temporal coverage, resolution, processing details, projection information, and where to find out more information – the Point-of-contact or website of where these data actually come from.\nWe’ve discussed formats. With respect to GIS, we typically have two types of data – vector and raster. Most of the satellite data with spatial coverage will be stored in a raster friendly format. These formats, like NetCDF or HDF, are considered self-described as they contain metadata and file-level metadata on how to read the data contained within the format. Each format may have a prescribed way to store the geospatial information. Is there a latitude/longitude for each pixel? Or must some operation be performed to calculate each pixel’s location? Fortunately, this is where the attributes or metadata assist in reading data, and arcGIS knows how to read the metadata on the fly to display the data correctly.\nResolution. Spatial resolution is the size of a pixel on the ground. Sounds simple, but it can be complex. A cell or pixel isn’t always a square. And what if the data are stored in degrees? The conversion of degrees to kilometers or meters varies by latitude, so we often see resolution represented by a single value generalized for the entire dataset. Temporal resolution may vary as well. You may find a daily or weekly product and other data you are working with is monthly or seasonal. Satellite data from GOES - geostationary satellite has a new 2km dataset every 10 minutes. The main point here is that you should consider resolution in the context of the other data you are working with. What are the extents? Say you have marine mammal data aggregated monthly for the Gulf of Mexico over 3 years that you want to correlate to sea surface temperature. What satellite data are appropriate? In this scenario, a 5km monthly sea surface temperature may be adequate. Does that data exist? Is it of appropriate quality? Or will you need to assemble it yourself?\nIt may matter to you how data are combined. This is referred to as binning, and it applies to both the spatial and temporal aspects of data. For example, this shows how many granules go into generating a daily composite of chlorophyll-a from S-NPP VIIRS for a given CoastWatch Sector.\nA granule is the data captured in 84 seconds of orbit or the smallest dataset unit acquired by the spacecraft sensor. Sixty to eighty granules contribute to generating a sector. Underlying the true color imagery and overlaying the granule outlines in green, the shaded areas in white illustrate the potential overlap of data.\nSimilarly in this image, the white area shows where the most recent valid pixel is retained. Note, in addition to overlapping pixels, products that are distributed in several spatial resolutions, for example, 750m or 4km for VIIRS data, have undergone some sort of resampling. Since the binning of data may be out of your hands, i.e. it’s performed by the data provider, you just need to be aware. But if your GIS activity requires very accurate time and space measurements, then check the metadata or contact the data provider to verify the methodology in use or if there are alternatives that are best suited for your application. Projections. If you have taken the satellite 101 tutorial, you may recall satellite data has different processing levels. Most of the products used in GIS are mapped or considered Level-3, or Level-4 in satellite-data-terms, but some data providers only store Level-2 which is not mapped and in the view of the sensor/satellite. The purpose of your project should determine which projection is used for analysis. Many satellite data products are distributed in a projection that may or may not match the needs of your application and metadata may not always include how the data were handled or reprojected so you need to be careful when choosing data. All projections have distortion. And one thing to note, is that once data are projected, distortion is ‘baked’ into the data product. Additional reprojection will add additional distortion, so you need to be aware and consider this in terms of your application to understand if this particular dataset is acceptable or not for your project. It’s not all doom and gloom, as projects at a large scale (or a region or local area on earth) may be less distorted than smaller scales – trying to represent all of Earth’s surface in a 2D plane.\nThere is a vast array of projections available, but in general, projections preserve one of the following map properties: Shape, Area, Direction, and Distance. Projections are chosen to preserve one of these criteria or sometimes a compromise projection is used to minimize the distortion across multiple map properties. If your project includes azimuthal or direction, then you would select a projection that preserves direction. If you are measuring distances, then a projection that preserves distance. For a regional area of interest (or large scale map), you can often minimize distortions through manipulation of the projection parameters. But often in working with satellite data your only choice will be to use what is available; and often, these data are in the Geographic projection, which unfortunately, doesn’t preserve any of these map properties.\nThe Geographic projection with an ellipsoid is a special case of lat-long or Plate Carree. Its main use is to represent global data and it has a simple relationship between each pixel and corresponding latitude/longitude position. Shown on the map are green circles and ovals. Prior to undergoing geographic projection, these circles were of equal size. This illustrates the distortion that takes place when data is geographically projected. If you work at higher latitudes, you might want to consider other projections to minimize distortion.\nHere are other examples of global projections and their representative distortion. ESRI has added the satellite projection of GOES-16/ABI to its list of supported projections.\nIf your project requires shapes to be preserved, a conformal projection such as Mercator or Lambert Conic should be used. If coverages across a map are to be compared, then a map that preserves areas such as Albers Equal Area or Sinusoidal.\nIn this course, we are focusing on Level 3 and 4 data, which is only available in Geographic projection. This is acceptable in many cases but if you work with polar areas or need more accurate results, you might want to consider working with Level-2 data and projecting it using the most appropriate projection for your purpose. This would reduce distortion by projecting the data just once into your preferred destination mapping.\nIn summary, satellite data may be imagery or data. Data is required in order to utilize the satellite product in analysis. Most of the formats used for satellite products are GIS compatible, but some considerations may be necessary regarding metadata, temporal/spatial binning, or projections.\nThis concludes the Using Satellite Data in GIS Data tutorial. The second part of this tutorial is about Tools that enable you to get data into GIS. Visit the CoastWatch website for more information."
  },
  {
    "objectID": "lectures/transcripts/sst.html",
    "href": "lectures/transcripts/sst.html",
    "title": "Sea Surface Temperature Transcript",
    "section": "",
    "text": "Welcome to the Sea Surface Temperature, or SST lecture, part four of an online course on oceanographic satellite data products that is produced by NOAA’s CoastWatch Program. My name is Cara Wilson, I’m the node manager of the West Coast Node of NOAA’s CoastWatch Program. The materials I will present in this video were produced from a collaboration from many members of NOAA’s CoastWatch Program including Dale Robinson, Melanie Abecassis, Ron Vogel, Shelly Tomlinson, me, and the late Dave Foley.\nMeasurements of SST provide fundamental information on the global climate system, including making accurate weather forecasts, studying marine ecosystems, and identifying the onset of El Niño and La Niña cycles.\nIn this presentation, I will go over the definition of SST. I will discuss how SST is measured from space, including the use of both infrared and microwave measurements. Finally, I will describe several of the level 4 SST products.\nSST is a difficult parameter to define because the upper few meters of the ocean has a complex and variable temperature structure. This complexity and variability is due to changing solar heating, ocean currents, wind-driven surface mixing, and the air-sea fluxes of heat, moisture, and momentum. Let’s take a better look at what I mean by this.\nSo what is SST? Well we know SST means sea surface temperature, so perhaps the better question is what Surface is being referred to when we say SST? And the answer depends on the measurement. Infrared instruments measure to a depth of about 20 micrometers, called SSTskin, the symbols shown in red here, while microwave radiometers measure to a depth of a few millimeters, called SSTsubskin, the symbols in yellow. But there is more complication going on here as well. This plot is showing two schematic SST profiles for the same location, one during the day, where temperature varies in the top few meters of the ocean, and one at night where wind has mixed the surface resulting in a homogeneous layer where the temperature is all the same, and can be considerably lower than daytime values. If you were out here making measurements with a CTD from a ship your surface measurement would probably be at about 1 meter, roughly the green symbols on this plot , and would measure a different value that satellite measurements would. The foundational temperature, shown here in blue, is the temperature that is unaffected by diurnal changes. These changes can be considerable, as we will see on the next slide.\nThis graph shows the diurnal variation in near surface temperatures with depth. The closer to the surface, the more variability is observed. At around 1-10m depth, the water temperature is no longer affected by the diurnal cycle. The temperature at that depth is called the foundation SST and can be estimated analytically from satellite measurements.\nAs I’ve previously mentioned SST can be measured in both the infrared and the microwave. Infrared measurements have a higher spatial resolution, on the order of 1-5 km, but can not make measurements through clouds.Microwave measurements have a lower spatial resolution, around 25 km. They are generally not affected by cloud cover, but measurements are not possible close to the coast.\nThis table summarizes the main types of SST sensors, infrared vs microwave, polar-orbiting or geostationary, along with their typical resolutions, resampling interval , accuracy, and cloud effect.\nLet’s talk about infrared measurements in more detail. SST has been measured using infrared sensors since 1978, it’s the longest running time-series of ocean satellite measurements.\nRemember that in the infrared, satellite sensors can “see” through the atmosphere only at specific wavelengths, or windows, which are represented by the yellow bands on this figure.\nHowever, as we saw in the 101 presentation, according to Plank’s law, there is a relationship between the temperature of the Earth, and its emitted radiation. For the range of temperatures on the Earth’s surface, the peak of the Planck function is around 10-12µm, which corresponds to one of the atmospheric windows in the infrared. The apparent temperature of the Earth’s surface is called its brightness temperature.\nHowever, as we saw in the 101 presentation, the emission from the Earth’s surface is affected by the atmosphere – it can be scattered or absorbed by atmospheric gasses and aerosols. Those phenomena end up attenuating the original signal as it makes its ways to the satellite sensors.\nAs a consequence, the resulting Earth’s emission spectrum at an average temperature of 21ºC doesn’t quite match that of a blackbody of the same temperature, shown here by the red line. Instead, the energy emitted, which is highlighted here in light blue, is lower overall than it would be if there were no interactions with the atmosphere, and especially so at certain wavelengths.\nThis is especially true when there are clouds in the field of view of the sensor. Infrared radiation is completely attenuated by clouds. So a critical step to measure SST from space is cloud detection. What we are seeing here is a map of the average degree of cloudiness for the month of January. Values are greater than 50% over the entire ocean, so clearly dealing with clouds is an important part of ocean remote sensing!\nEven in the absence of clouds, some of the EMR is absorbed by the atmosphere. It is then reemitted at a temperature characteristic of that height in the atmosphere, which is cooler than the surface value we want to measure. So the Earth appears cooler than it would if the temperature was measured at sea level. This is called the temperature deficit and needs to be corrected.\nMost of the temperature deficit in the infrared is due to absorption by water vapor in the atmosphere. Other gasses are well mixed and cause a homogenous temperature deficit that is easier to correct. As can be seen in this image, water vapor concentration is very variable in time and space, and requires specific corrections.\nTo sum up, SST can be measured from space in the infrared, and to obtain accurate measurements, several steps are needed to process the raw data received from satellites. Those steps are: sensor calibration, cloud detection, atmospheric correction and SST-specific algorithms.\nSatellites have been measuring SST in the infrared since 1978. We now have multiple concurrent measurements, from geostationary and polar-orbiting platforms. This allows scientists to blend observations from multiple satellites to create SST products that are more accurate and gap-free.\nSatellite measurements of SST using microwaves sensors have been in the tropics since 1999, and globally since 2002.\nRemember that in the microwave wavelengths, there is almost no atmospheric absorption of EMR. However, the intensity of the Earth’s surface emissions in the microwave is much lower than in the infrared.\nAs a result of that low intensity, microwave instruments need to carry large antennas in order to capture enough signal from the surface. And in the microwave, the instruments are more limited by diffraction which spreads the EMR over a broader area and blurs the image. So the spatial resolution of microwave instruments is around 25-50 km.\nBecause the emissivity of land and ice in the microwaves is much higher than the emissivity of the ocean, measurements close to the coast are contaminated by the land signal. As a consequence SST from microwave instruments is not available within about 25 km of the coasts. However, a huge advantage of microwave measurements is that they are not affected by cloud cover, which makes those observations a very important complement of infrared measurements, especially in regions with persistent cloud cover.\nMicrowave SST measurements are currently only available on polar-orbiting satellites and we now have several concurrent observations.\nRemember from the 101 presentation that there are several levels of data. In this course, we are focusing only on level 3 and 4 products. These are products containing geophysical variables or derived variables that are mapped onto uniform space-time grid scales.\nBut with so many SST products available, which should you choose for your project? As with anything in life, you can’t have it all. Each product has its advantages and its drawbacks. You can find products that have the highest resolution and are based entirely on reliable satellite observations, but they can have data gaps due to cloud cover and incomplete spatial coverage between satellite swaths. You can find products that are based entirely on reliable satellite data that are almost gap-free, but they will usually be weekly or monthly composites and have a lower spatial resolution. Alternatively, you can find high-resolution level 4 products that are gap-free because they combine observations from multiple satellites and include an interpellation processing step to fill in the data gaps. Typically, such products don’t tell you which pixels are derived from observations and which from interpellation.\nHere is a list of the most popular Level 4 SST products currently available, with some of their characteristics. I will go over the last two in a bit more detail.\nThe daily NOAA GeoPolar blended SST is available from 2002 to the present, has a spatial resolution of 5km, and is interpellated to be gap-free. It’s available as night-time only, daytime only, or a daytime and night-time average, which allows users to look at diurnal variation if needed. The product is also available in near real-time and science quality versions. The daily MUR SST from NASA is a 1km product, available from 2002 to the present, and is gap-free.\nThis figure shows a few examples of level 3 and level 4 SST over the same area on the same day to get you thinking about the pros and cons of various products based on your needs. You can think of the level 3 SST as the “truth” where there is data.These are the top 3 images. They are pretty accurate, high-resolution observations, but quite a bit of data is missing. The 3 bottom images are level 4 products that attempt to fill in these gaps. The MUR product, shown on the left, is very high-resolution, and where there is data, does a really good job at reproducing the observations, but where there is no data the image can become very blurred. The OSTIA product on the right is the same resolution as the geopolar blended product in the middle, but the OSTIA product appears more blurred. The GeoPolar and OSTIA products do not capture many of the fine features present in the top images. This is partially due to the lower resolution of the of these two L4 products, which are 5 km, and partially due to the interpellation process. Although it’s the same resolution as the GeoPolar Blended product, more of the features of the SST field appear to be lost with the OSTIA product. The results shown in this example are unique to the time and place of the image we selected. Therefore, when selecting a dataset for your application it’s good practice to select a few products and compare them for several time steps and regions.\nIn this example for the Monterey Bay region, you can see that sometimes, higher resolution products like MUR can actually have a harder time at reproducing the overall patterns in SST, compared to the GeoPolar Blended or OSTIA. So be sure to look at different products for your region.\nFinally, when choosing a product, you can also compare the quality of different products using the NOAA SST Quality Monitor. You can compare them against each other or against in-situ observations from buoys and ships.\nSo lets review some of the important aspects of satellite SST measurements. SST measurements are made in different part of the EMR spectra, in both the infrared and also in the microwave. Infrared measurements, which are more common, have a higher spatial resolution, but are blocked by clouds. Microwave measurements get fuller coverage since they can see through clouds, but have reduced spatial resolution and can not be made close to land. IR SST measurements are also made from geosynchronous satellites, which can make measurements sub-hourly, and can thus mitigate the cloud issue. There are a number of products that blend these different SST data together. It’s important to compare how these different datasets perform in your region of interest to determine which one is best suited for your project.\nThis concludes this presentation on sea surface temperature. This is one of several presentations put together as part of the CoastWatch Ocean Satellite Course. We have additional presentations that cover how measurements are made for ocean color, and for measurements made in the microwave, i.e. altimetry, salinity and wind."
  },
  {
    "objectID": "lectures/transcripts/seaice.html",
    "href": "lectures/transcripts/seaice.html",
    "title": "Sea Ice Transcript",
    "section": "",
    "text": "[Slide 1]\nThis is the presentation on satellite sea ice data as part of the virtual NOAA CoastWatch virtual satellite course.\n[Slide 2]\nIn this presentation I will provide an overview of satellite sea ice data, and discuss some challenges associated with working with sea ice data. I will cover some considerations to keep in mind when choosing a dataset, how to access data through CoastWatch and our partners, and highlight some available resources to help address the challenges associated with integrating sea ice data into research projects.\n[Slide 3]\nUsing sea ice data is unique to polar and subpolar applications. Many satellite data providers do not carry sea ice data. In addition to research, sea ice data is important for multiple applications including fisheries management, safety at sea, navigation, transportation, tourism, and recreation. Because the Polar regions are very inaccessible, using satellites to monitor sea ice is important because other measurements are simply not possible.\n[Slide 4]\nWhen faced with integrating sea ice data into a project there are several challenges that are common. First it can be a challenge to know where to get the data because sea ice data may not be available where you would typically look for environmental or satellite data. There are many data providers including NSIDC1 , NIC2, EUMETSAT, and NCEI4. It is often not clear which data provider to go to and what the differences may be among the data they provide. Each data product is typically geared toward a specific user base with data formats and access methods that are suited for that user community. This can limit the broad use of products because it takes effort to dig into each of the products and determine these details. There are many map projections used in sea ice data products. This can make it difficult to preview and test out multiple products.\n[Slide 5]\nRecognizing these barriers to satellite sea ice data usage, PolarWatch addresses these challenges with the goal of encouraging broad use and integration of polar satellite data into research and management projects. PolarWatch is a NOAA CoastWatch Node that collaborates with key data providers and users. We work closely with CoastWatch Central, the national snow and ice data center, the national ice center, NOAA fisheries and NESDIS to facilitate discovery and access to satellite data covering polar and subpolar regions.\n[Slide 6]\nTo address the challenges of integrating sea ice data, PolarWatch: provides consistent access to near real-time and historical satellite observations from multiple parameters including: Sea ice, water temperature, ocean color, salinity and winds we provide a curated collection of quality datasets from multiple data providers all data are available in common formats with easy open access. The PolarWatch data catalog makes it easier to determine differences between datasets at a glance. And each dataset can be previewed online on an interactive polar map before downloading.\n[Slide 7]\nNext I will cover some of the sea ice products that are available through CoastWatch, PolarWatch, our partners, and datasets that are relevant to fisheries science and management. Please reach out with any questions about datasets. There is often more than one viable option and it is not always readily apparent which is the best dataset to use. You can email me at jennifer dot sevadjian at noaa dot gov. Or if you know you are interested in datasets from NSDIC you can reach out directly to their excellent user services support, their email is nsidc at nsidc dot org. I will be providing a brief overview of the most common types of data available for sea ice measured by satellite. I will focus on Level 3 and 4 data which are gridded, georeferenced and cloud masked datasets. I will focus on highlighting datasets most relevant to course participants and provide links to where you can learn more and to where you can access the data.\n[Slide 8]\nLet’s start with a rough overview of the properties of sea ice that can be measured by satellite. One or more of these properties may be relevant to your research area. Concentration provides the percentage of a grid cell that contains sea ice. Sea ice thickness is the vertical height of the sea ice. Ice type refers to first year ice or older multi-year ice which are important distinctions in some research areas. Ice edge products focus on providing the most accurate defining line between sea ice and its surroundings.\n[Slide 9]\nThese properties can be measured by a variety of satellite sensors, including infrared, microwave and visible sensors. Visible sensors can collect data only during the day when there is light. Infrared sensors do not need light so they can provide data both day and night. This is important in polar regions where there is complete darkness for long periods. Both Visible and IR sensors do not “see through clouds”, but microwave sensors can. This is also very relevant in the polar regions where there is often cloud cover. The trade-off is that microwave sensors have a large footprint and so a much coarser resolution than IR. Depending on the needs of your project you may want to include data from multiple sensors. For example, researchers will often use infrared data as their number one choice, but if there are gaps in the high-res infrared data they will fall back to lower-resolution passive microwave data to fill in the gaps. There are even some level 4 sea ice products that do work for you by incorporating data from multiple sensors to provide a “best of” dataset with the most coverage. I will provide an overview of some of the available datasets and how to access them next.\n[Slide 10]\nI will start with sea ice concentration products which are some of our most commonly requested products. There are a number of products available, here I will highlight a handful. If you are looking for a long-time series the NOAA/NSIDC Climate Data Record is a product with coverage in both the Arctic and Antarctic that goes back to 1978. This data comes from microwave sensors so it doesn’t have spatial gaps and it has a resolution of 25km. These data are provided by the national snow and ice data center and are available for preview, subsetting and download in a variety of formats through PolarWatch services. There are other sea ice concentration datasets that have higher resolution but don’t go as far back in time. I’ll cover some of those next.\n[Slide 11]\nYou can get gap-free higher-resolution satellite sea ice concentration data from the AMSR2 satellite sensor. This data goes back to 2012 and has a resolution of about 10-12 kilometers. Some datasets merge AMSR2 data with earlier AMSRE data for a continuous record back to 2002. You can learn more about the AMSR2 data on the NSIDC website and on the CoastWatch website. CoastWatch and PolarWath are currently working on distributing AMSR2 data as level 3 gridded products. We anticipate these will be added to the PolarWatch portal in the next few months. There are a number of different products and it can be difficult to discern the differences between them. Reach out to me if you are interested in using AMSR data and I can help you determine the best one for your needs.\n[Slide 12]\nAn interesting product that incorporates the AMSR2 data is the NSIDC MASAM2 product. This product is only available for the Arctic. By combining the AMSR2 microwave data with the higher resolution national ice center IMS product, MASAM2 can provide a more accurate picture of what is happening at the edges of the ice which may be of particular interest and benefit to researchers in fisheries.\n[Slide 13]\nSea Ice concentration data from infrared sensors can provide much higher resolution data than the microwave datasets I just mentioned - but it does not see through clouds, so spatial coverage is less reliable. The latest infrared sea ice data from CoastWatch are 750m resolution products from VIIRS and there are daily and 4-day composites for both the Arctic and Antarctic. Currently this data is served through CoastWatch as a near-real-time dataset with a rolling archive of the most recent 3-weeks. If gap-free coverage is needed, this VIIRS dataset could be complemented with AMSR2 to provide microwave coverage where IR is unavailable. The VIIRS sea ice data have recently been published to the Polar Watch portal and are available for online preview and data access.\n[Slide 14]\nI mentioned the IMS daily ice edge analysis product earlier when I was talking about the MASAM2 product. The IMS product is made by the national ice center and provides a highly accurate daily sea ice edge for the Arctic. For the Southern ocean, the national ice center makes a number of other ice edge graphical products. In cases where the ice edge is important it can often be useful to compare a satellite image to an analyst’s interpretation of the ice edge. The analysts make the edge based on all the best imagery from numerous satellites and other data so this ice edge product is respected among the community. As I mentioned, the ice edge products are incorporated into higher level satellite data products and models. NSIDC’s MASIE product is an example of a level-4 dataset based on NIC IMS ice data. The MASIE product provides statistics on ice area by region and includes time-series charts showing changes over time. PolarWatch is currently working with the NIC to integrate the IMS data and NSIDC to integrate the MASIE data. Both of those projects are nearing completion. For now, you can access the data through the NIC and NSIDC directly. This should be noted on the slide as well.\n[Slide 15]\nIce type products specify how old the ice is with designations of first-year ice or multi-year ice. This helps to discern where ice is melting and growing each year and can be useful in long-time-series studies. The NSIDC sea ice age product goes back to 1984 and is a weekly product. EUMETSAT offers a similar product that goes back to 2005 but is produced daily. These data are not currently available through PolarWatch, you can access them through NSIDC or EUMETSAT. Please let us know if you are interested in this type of product. We need to know there is an interest in the data before we can justify integrating it into PolarWatch.\n[Slide 16]\nAt the far end of the resolution spectrum is SAR imagery. The resolution can be less than a meter , so this is very high resolution imagery that can be used for ice feature detection. The trade-offs are that SAR doesn’t see through clouds and because of the high resolution the coverage area is much smaller than other sensors. CoastWatch has SAR data for both the Arctic and Antarctic. The graphic on the top right represents the coverage over one day and the graphic on the bottom right depicts the coverage over a 3 week span.\n[Slide 17]\nIt is a longer-term project to integrate these data into PolarWatch because of the challenges associated with the high-resolution and data structure. Near Real Time SAR imagery can easily be viewed and downloaded in PolarView online. You can also find SAR imagery by date/location search on the CoastWatch website. If you have an area and time of interest you can search through the images and see if there are any without clouds and a clear image of your area. In addition to SAR imagery products there are a number of other SAR products - SAR winds are available through CoastWatch and a Sea Ice Motion product is in development.\n[Slide 18]\nThere is new ice data from the ICESAT-2 satellite that was launched in 2018. This satellite focuses on high resolution, small footprint data collection. It is geared towards getting a 3D picture of sea ice and provides products like sea ice thickness, and freeboard. Level 3 products are now available through NSIDC.\n[Slide 19]\nThose are some datasets available for sea ice and where you can access the data. As you start looking into the datasets more closely, you will see they are offered in a number of different projections. Data products for the polar regions are produced in a number of projections because they have different intended uses or spatial domains. This presents another challenge to working with sea ice datasets. You will likely need to convert data between projections to integrate it with your existing data. This can be a hassle because to test a dataset in your workflow you’ll have to become intimately familiar with its format and projection just to view it and test bringing it into your routines. It is also important to be aware of the implications of reprojecting data. PolarWatch is working to alleviate some of the challenges of working with projected data by providing the online map previews of data and providing training resources for working with projected data in open source software like R and Python. We currently share examples of accessing data in different projections, converting from one projection to another, plotting projected data, integrating data of different projections. These tutorials and code examples are available online as jupyter notebooks. Two examples are included as part of this course and are available in the course r code gitbook. These and more examples are available online in the PolarWatch code gallery. We are actively expanding these examples, please let us know if you would like to see additional examples or if you have an example that you would like to add to the gallery.\n[Slide 20]\nIn addition to the integration challenges related to projections there are a number of other things that can make integrating sea ice data difficult. Sea ice data may be in an unfamiliar format designed for a different user community. Datasets that are integrated into PolarWatch are available in a variety of formats and they can also be subset before downloading. So if you are working in a specific region like the gulf of Alaska you can download only the portion that you need, you don’t have to download the whole northern hemisphere. The polarwatch erddap data server also provides API access to all datasets for integration and routine data access with R, Python, Matlab. Software tools and examples for matching up field data to satellite data. PolarWatch code gallery has code example scripts in R and Python demonstrating how to access data, make matchups and work with data in different projections.\n[Slide 21]\nIf you are interested in learning more about accessing and using sea ice data, we have a few additional training resources that are part of this coastwatch course. These cover accessing using the PolarWatch website, accessing data from the Polarwatch erddap and accessing sea ice data using R and the PolarWatch ERDDAP API. Those materials are available online. You can check out the polarwatch code gallery for more examples of working with data from PolarWatch including both R and Python. Please reach out to us if you have any questions."
  },
  {
    "objectID": "lectures/transcripts/satcourse-pt1.html",
    "href": "lectures/transcripts/satcourse-pt1.html",
    "title": "Satellite 101 Part 1 Transcript",
    "section": "",
    "text": "Hello! Welcome to Part 1 of Satellite 101, part of an online course on oceanographic satellite data products, which has been produced by NOAA’s CoastWatch Program. My name is Cara Wilson, I’m the node manager of the West Coast Node of NOAA’s CoastWatch Program. The materials I will present in this video were produced from a collaboration from many members of NOAA’s CoastWatch Program including Dale Robinson, Melanie Abecassis, Ron Vogel, Shelly Tomlinson, myself, and the late Dave Foley.\nIn part 1 of the Satellite 101 presentation, I will introduce some of the basic terminology used in the field of remote sensing. I will give an overview of available oceanographic satellite products and present the different types of orbits, resolutions and spatial coverages. I will also briefly go over the different levels of data processing. In part 2 of the Satellite 101 presentation, I will introduce the different types of satellite sensors and how measurements are made. There are also additional presentations as part of the CoastWatch course that go into more detail about how certain measurements and products are made.\nI like to use a food analogy to explain the approach of this course. I’m not a vegetarian and I like sausages, but I’d prefer to not know what goes into them, it’s often a lot of nasty body parts! And I feel the same way about satellite data. I just want to use the data without having to learn about all the processes that go into creating these products, information about electromagnetic radiation, wavelength bands, IOPs and AOPs, atmospheric correction, lunar calibration etc. etc. But just as one has to make some decisions when buying sausage at the store; chicken or pork, or tofu for my vegetarian friends, nitrate-free or not, one has to know a little bit about satellite products when using them. In this course we aim to give you the basic information you need to make decisions about choosing a satellite product to use. This course does not intend to teach the sausage making components of satellite data. That amount of detail needs a much longer and comprehensive course.\nSo what measurements of the ocean can we make from satellites? We can measure the amount and type of sea ice, we can measure sea-surface temperature, or SST for short. We can measure sea-surface height of the ocean, or SSH for short. By measuring ocean color we can derive the chlorophyll concentration of the surface ocean. We can also measure the speed and direction of ocean currents and winds over the ocean, the amount of rainfall over the ocean, as well as the sea surface salinity. For how long have we been making these measurements?\nThe answer depends on the measurement. On this slide the different measurements are arranged in order of the length of the timeseries. Measurements of sea ice have been collected the longest, with the continuous record going back to 1978. The salinity is a relatively new measurement, which started in 2011. Note that the years shown here indicate the start of the continuous record of each of these parameters, but in some cases the first measurements were made earlier. For example the first ocean color satellite was the CZCS, the Coastal Zone Color Scanner, which flew from 1979 to 1986, but there was a ten year gap between that data and the launch of SeaWiFS in 1997, which marks the beginning of the continuous record of ocean color measurements.\nThis slide shows a little bit more graphically the progression of different oceanographic satellite missions over the last few decades. Not only has the number of available products been growing, but also the number of satellites, and now there can be multiple satellites measuring the same parameter. Many countries have satellite programs, and there is international cooperation and data sharing.\nSo why do we need satellite data? The oceans are huge, covering 71% of our planet, and it is impossible to adequately measure them with in-situ measurements. Satellite data is able to provide us measurements of the ocean at temporal and spatial scales that we could never cover with ships or buoys, alone. The image on the left shows a compilation of all the in-situ sea-surface temperature data collected in a month, and the image on the right shows a compilation of all the satellite sea-surface temperature data collected in one day! Having continuous satellite measurements makes it possible to detect anomalous events and also to go back and observe past events using the archived record of measurements. An important caveat though is that the satellite measurements are just of the surface of the ocean, so for information on the subsurface structure of the ocean we need to rely on a combination of in-situ data and ocean models.\nThere are two main types of satellite orbits: polar-orbiting and geostationary. The animation on the left depicts a polar-orbiting satellite. As the name implies the satellite orbits around the poles of the earth, as the earth spins, the satellite measures a swath below it. In the course of one to several days the satellite will have passed over the entire globe. Geostationary satellites have orbits that are in sync with the Earth’s orbit, so they are always looking at the same area of the Earth, allowing frequent measurements over the region instead of only one measurement per day. Geostationary satellites sit a lot farther away from the earth than polar-orbiting satellites and therefore can observe much more surface area. Most of our environmental data comes from polar-orbiting satellites, and most of our weather data comes from geostationary satellites. Some SST measurements are made from geostationary orbit, and South Korea has an ocean color sensor on a geostationary satellite.\nThis image shows all the data collected in one day by the polar-orbiting VIIRS ocean color sensor on the NOAA-20 satellite. The black areas are regions where no measurements were made. The streaks running north to south through the image are areas where the satellite did not pass over. The other black regions are regions where measurements were not made because of cloud coverage.\nWhile there are some areas on the globe that will be missed each day by a polar-orbiting satellite, because each pass goes over the poles, they collect a lot of data at high latitudes. This image shows the 14 passes made in one day of the SNPP satellite over the north pole.\nHere we can see the global coverage of geostationary satellites. Because each satellite can only observe part of the planet, multiple satellites are needed to provide global coverage. We need two satellites to adequately cover the United States, we have GOES-West and GOES-East. Those satellites, combined with the two European satellites and the Japanese geostationary satellite, can provide nearly global coverage. However even the two US geostationary satellites do not cover all of the United States. Their coverage does not extend into high latitudes and unfortunately we can’t currently make geostationary measurements over much of Alaska.\nThis slide summarizes the difference between polar-orbiting satellites and geostationary satellites. Polar-orbiting satellites provide global coverage, at relatively high spatial resolution, on the order of 1 km resolution, but a low temporal resolution, on the order of 1 or 2 days. In contrast, geostationary satellites provide regional coverage, at lower spatial resolution, on the order of 2-4 km, but high temporal resolution, with approximately hourly resolution. With satellite data there is always a trade-off when it comes to resolution: higher temporal resolution means lower spatial resolution, and vice-versa. You can’t have both!\nI’ve mentioned the different types of resolution of satellites, let’s talk about that a little more. Resolution of a satellite can refer to a number of things. The spatial resolution is the smallest geographic area that a satellite instrument can resolve. The spatial resolution of oceanographic satellite products ranges from 250 m to 25 km. The higher the spatial resolution, the more details that can be observed. The Temporal resolution is how frequently a satellite observes the same area on Earth. The Spectral resolution refers to how many bands the sensor has. The higher the spectral resolution, the more specific types of observations are possible with the same instrument. Another relevant specification is the Swath width, which refers to the width path observed by a polar-orbiting satellite as it orbits that Earth. Satellites with larger swath widths typically have a greater temporal resolution and a lower spatial resolution.\nThere are other satellites that have higher spatial resolutions, on the order of 1 to 30 meters, compared to the 1-25 km we deal with in ocean remote sensing. I previously mentioned the trade-offs inherent with different resolutions. These very high spatial resolution sensors can have very long repeat times, or might not have any repeat times at all, but rather work on on-demand acquisition. These data can be challenging to obtain and cumbersome to process, and often better suited for land applications than for ocean applications.\nAlthough these high resolution data are not generally offered as part of this course, I will show you a cool example of a study that used one high resolution dataset for an oceanographic application. This study used data from the WorldView sensor, which has a 50 cm resolution, to try to identify whales off of Peninsula Valdes in Argentina. The white objects in the images are probable whales that were identified by automated analysis.\nA lot of processing goes into satellite data before reaching you, the sausage making that I referred to earlier. There are terms to refer to how processed the data are. For example Level 0 data is the raw data received from the satellite, level 1 data has been put into the satellite s geographical coordinates (i.e along-track ) , level 2 data has been processed into a derived geophysical variable, like sea surface temperature, but is still in swath coordinates. Level 3 has been mapped onto a standard map grid with latitude and longitude. Level 4 data has had an additional degree of analysis performed, perhaps deriving another product, performing interpolation to remove gaps, temporal compositing etc.This course focuses on accessing and using level 3 and level 4 data, i.e. off the shelf data products.\nLet’s talk briefly about temporal composites. Many satellite products contain gaps where there are no measurements due to cloud coverage. These gaps can be at least partially filled in by making composites, or averages of different satellite images. There are two different ways this can be done. Temporal composites of a sensor can be made over longer time periods. Most satellite products are composited into daily, weekly and monthly products. For measurements that are made by multiple satellites, blended products can be made that merge data from the different sensors.\nThis slide shows an example of 4 different temporal composites of geostationary sea-surface temperature data in the Pacific Ocean. The image on the top left displays one hour of data from Sept 15, 2018. There are more areas with missing data than there are areas with data. The image on the bottom left shows a daily composite of data from this same sensor, and most of the missing data from the image above it are now filled in. The image on the top right shows a weekly composite of the same area. Now there is only a small region with no data, around a longitude of 230 , where it has been cloudy all week. The monthly composite in the bottom right is gap-free, except for the region in the northwest part of the map, which is outside of the disk view of the satellite.\nThe composites we’ve just seen are necessary to make because of data gaps due to cloud coverage. The cloud issue is a huge problem for ocean remote sensing. But of course the satellite doesn’t stop making measurements when there are clouds, but rather it makes measurements of the cloud, not the ocean below it. So in order to remove this cloud data we need cloud masks that determine what data is from a cloud and what is from the ocean. Cloud masks are usually made from visible imagery, so nighttime retrievals of SST can be less accurate, since the cloud masks might not be as reliable. Different agencies and different satellite products can use different masks.\nFor many applications it is more useful to view how a parameter differs from a typical or mean value. This is called an anomaly product. For example, to see the extent of the recent marine heat wave in the North Pacific, one needs to look at the Sea Surface Temperature anomaly, rather than Sea Surface Temperature. To generate an anomaly one needs a climatology mean of the parameter to subtract from the timeseries. Here I have listed some of the anomaly products served by CoastWatch.\nIt’s important to realize the distinction between satellites and sensors. Sensors are the instruments making the measurements. Satellites are the platforms carrying the sensors. Currently most satellites have many different sensors on them. This slide shows all of the sensors on the JPSS-1 (NOAA-20) satellite. One of these sensors is VIIRS, a sensor which is also on the SNPP satellite which was launched a number of years before JPSS-1.\nIn closing I’ll mention the two major satellite agencies in the US, NASA and NOAA. Both agencies have satellite missions but they have different responsibilities and objectives. NASA is responsible for research and development of satellite instruments and products, whereas NOAA’s role is to provide operational satellite data for routine use. Those are two very different objectives. NOAA needs to measure and expand how its satellite products are being used operationally, in order to ensure a continuous and reliable suite of environmental measurements. And that need is indeed what led to the development of the NOAA CoastWatch satellite course many years ago. Oceanographic satellite data was being underutilized within the wet part of NOAA, i.e. NMFS and NOS, and this course was created to increase the utilization of satellite data within NOAA, and in other operational applications. More details on how satellite measurements are made are presented in Part 2 of the Satellite 101 presentations"
  },
  {
    "objectID": "lectures/transcripts/salinity.html",
    "href": "lectures/transcripts/salinity.html",
    "title": "Satellite Sea Surface Height, Altimetry, Winds, and Salinity",
    "section": "",
    "text": "Welcome to the online course on oceanographic satellite data products, produced by NOAA’s CoastWatch Program. In this module we will discuss the measurement of sea surface salinity, surface winds, and sea surface height using satellite remote sensing techniques. The information presented here builds on the concepts discussed in the Satellite 101 Part 1 and Part 2 modules of the online course. You might want to review those modules first before viewing this module. My name is Cara Wilson, I’m the node manager of the West Coast Node of NOAA’s CoastWatch Program. The materials I will be presenting in this video were produced from a collaboration from many members of NOAA’s CoastWatch Program including Dale Robinson, Melanie Abecassis, Ron Vogel, Shelly Tomlinson, me and the late Dave Foley.\nSalinity, winds, and sea surface height are all measured with instruments that use the microwave portion of the electromagnetic spectrum. So first I will review the characteristics of measuring microwaves from satellites. I will also cover the two basic types of satellite microwave sensors: Passive and Active sensors. Finally, I will cover how sea surface salinity, surface wind, and sea surface height measurements are made and the products derived from the measurement.\nOn the left, the EMR spectrum is pictured showing the range of wavelengths from ultraviolet to the microwave. Microwaves are at longer wavelengths than the rest of this spectrum. However, microwaves are typically measured in frequency rather than wavelength. The microwave range is approximately 300 GHz to 0.3 GHz. Sometimes parts of this range are referred to as lettered bands, such as the K-band and the X-band.\nAs discussed in Satellites 101 Part 2 module of this course, satellites primarily use the visible, infrared, and microwave wavelengths to view the Earth. This is because other wavelengths are strongly absorbed by the Earth’s atmosphere. On the plot, I have overlain the opacity of the atmosphere on the EMR spectrum; you can see the “atmospheric windows” in the visible, infrared, and microwave bands where EMR can pass through the atmosphere. Notice that most of the microwave range falls within a very transparent atmospheric window.\nAnother advantage of using microwaves for remote sensing, is that they can see through clouds. If I overlay the attenuation of EMR by clouds, the visible and infrared frequencies are blocked. However, the microwave range frequencies are unaffected, making the microwave range useful for remote sensing in almost any weather condition, except during heavy rain.\nPassive sensors, shown on the left, detect microwaves from radiation that is naturally emitted by the Earth. Active sensors, shown on the right, generate microwave pulses that are sent to the sea. The pulses interact with the sea surface and part of the pulse energy is reflected back into the atmosphere. The sensors measure the reflected signal that returns to the satellite. First, let’s take a closer look at how passive sensors work and what they measure.\nPassive microwave radiometers measure the blackbody radiation emitted by the ocean. This radiation is emitted at intensities and frequencies defined by temperature. At the temperatures found on the Earth, most of the emissions are in the infrared range, as shown in the figure on the left. The inset plot on the right shows a close up of the microwave part of the emission. There are two important features to note about the microwave plot. First, the intensity of the emissions is very low compared to the intensity in the infrared. Second, the intensity of the emissions decreases as frequency decreases.\nHowever, blackbody objects are theoretical, and do not exist in nature. For the real objects that do exist, the efficiency at which blackbody radiation is released is less than for a blackbody at the same temperature. Emissivity is a measure of how efficient an object is at emitting radiation compared to a blackbody, where a value of 1 is 100% as efficient as a blackbody. All materials have unique emissivity spectra, where values are less than one and emissivity varies with frequency. For example, at a frequency of 37 GHz, sea water has an emissivity of ~0.45 and land has an emissivity of ~0.95. So, it is easy to distinguish between these 2 surfaces based on the strength of the microwave signal at 37 GHz. On the left is an image of the Earth taken at 37 GHz where the division between land and sea is easy to determine. Similarly, physical properties like salinity and surface roughness change the emissivity. For example, the strength of the microwave signal where salinity is 30 parts per thousand will be different than where the salinity is 36 parts per thousand. This difference in signal can be used to determine surface salinity values.\nThe plot shows at which frequencies we will see a maximum change in the microwave signal due to change in a physical property. The maximum change for salinity is near 1.4 GHz\nWind speed shows maximum change at frequencies greater than 10 Ghz. SST shows a peak near 7GHz. The maxima for liquid water and water vapor are also shown. Based on these characteristics, the frequencies used to measure the parameters are chosen. Some typical frequencies used for each parameter are presented on the right. In reality, the signal measured at each frequency will have contributions from many parameters. Those contaminating contributions are corrected for by collecting measurements at many frequencies and subtracting the unwanted signal during the signal processing.\nAs we saw in the SST lesson, a drawback of passive microwave sensors is their low spatial resolution. Spatial resolution in the infrared can be in the sub-kilometer range. However, the intensity of ocean blackbody emissions in the microwave is a small fraction of that measured in the infrared. Therefore, to collect enough energy to make a measurement, microwave sensors must have larger antennas and collect energy from a larger footprint on the sea surface. There are technical limits to antenna size that make antennas bigger than about 1m impractical. Consequently, microwave sensors have a larger footprint, which translates to lower spatial resolution. The graph on the lower left shows the decreasing black body emission intensity in the microwave range with decreasing frequency. Above are the footprint sizes required in the frequency bands on the WindSat radiometer. In general, the spatial resolution of passive microwave sensors ranges from 25 to 100 km.\nA second drawback to passive microwave sensors is that measurements cannot be made close to the coast. Land has a much higher emissivity than sea water, so it emits a strong microwave signal. When the sensor’s footprint includes land and sea, like in the top left image, the signal is contaminated with radiation from the land. Even when the footprint is 100% over the sea but near land, radiation from land can be scattered into the sensor’s field of view. The image to the right shows 6 GHz data from the coast of Japan. The halo around the island represents the bad data values that are a blend of the land and sea microwave signal. In general, for passive microwave satellite products, measurements within about 50 km of land are masked out to remove the bad data.\nSea Surface Salinity is measured with passive sensors. The salinity sensors measure the blackbody radiation emitted by the sea at 1.4 GHZ, which decreases with increasing salinity, as seen on the plot to the right. This relationship between emission and salinity is used to determine salinity with satellite passive sensors.\nSalinity is a relatively new satellite measurement. Three missions have flown since 2010, and currently two sensors are still collecting data. Because data are collected at 1.4 GHz, where the signal from the Earth is weaker, the spatial resolution is relatively low: ranging from 25 km to 100 km, depending on the satellite mission. Complete global coverage takes 3-8 days. The accuracy of the measurement is 0.15 - 0.25 units on the practical salinity scale. It is important to remember that satellites can measure the salinity only in the top few centimeters of the sea.\nUses of salinity measurements include studies of global circulation patterns, defining animal habitats, and tracking surface salinity events. The salinity map on this slide, made from the SMOS data, shows the distribution of a lower salinity water plume resulting from strong fresh water outflow from the Amazon River.\nWind speed can be measured with radiometers, which are passive sensors. The radiometers measure surface roughness that is produced by wind blowing across the sea surface. As shown on the left, surface roughness increases as winds increase. The microwave signal intensity from the sea increases as surface roughness increases, as shown by the plot on the right. Measurements of surface roughness with radiometers are used as a proxy for wind speed.\nTo get both wind speed and wind direction we need to make measurements with scatterometers, which are active sensors. Wind speed and direction are measured with Scatterometers, which are active sensors. Scatterometers send pulses of microwave radiation to the sea surface. If the water is flat, the pulse is reflected like a mirror, which is called specular reflection, and most of the reflected signal doesn’t return to the sensor. With more wind, ripples on the sea surface increase. The ripples increase the amount of the pulse that is backscattered as a signal to the sensor. You may have experienced something similar with visible light at a placid lake. When the wind is still, the light hitting the lake is reflected like a mirror to your eye, and you can clearly see the landscape in the foreground. As the wind increases, ripples on the lake surface scatter light in many directions away from your eye, making the reflected landscape in the foreground harder to see.\nIn addition, for any single wind speed, the amount of the signal that is returned to the sensor via scattering is sensitive to the wind direction relative to the direction of the pulse sent by the instrument. The maximum return occurs when the pulse is in the upwind direction. The return is reduced when the pulse is in the downwind direction, and minimal returns occur when the pulse is at 90 degrees to wind direction or at crosswinds.\nTo obtain both wind speed and direction, scatterometers are built to put out pulses in many directions. The instruments measure the scattered signal from each pulse direction. On the figure on the right, the line represents the function of relative backscatter at different angles to the wind. The blue circles are the measured backscatter from the scatterometer pulses. These multiple measurements are used to calculate the wind speed and direction that best fits the function.\nPassive measurements of wind speed with radiometers date back to 1987. At present, there are multiple sensors that are orbiting the Earth. With so many instruments flying at the same time, complete global coverage can be obtained as quickly as every 6 hours. Active measurements of wind speed began in 1999, with QuickScat, and continue with ASCAT sensors on METOP satellites. Depending on the mission, these instruments can give complete global coverage in 1 to 3 days.\nHere is an example of tracking events with wind data. On the left is a true-color image of Hurricane Jose from 2017. On the right are maps from ASCAT wind data. The reddish map shows just wind speed, with black as the fastest speed. Strong winds are visible toward the center, with the eye of the storm in the middle. On the right, wind direction and speed are shown with vector arrows. You can see the counterclockwise movement of the storm.\nOnce you know wind speed and direction you can calculate other derived products. One of those products is Ekman upwelling. As illustrated on the left, when winds blow parallel to the coast on the western sides of continents, the forces from the wind and those due to the earth’s rotation push surface water offshore. The displaced water is replaced with cold, nutrient rich water from depth, which helps to drive increased productivity. On the right, the satellite wind vector product shows wind blowing parallel to the shore along Oregon and California. The map of the Ekman Upwelling satellite product shows regions of upwelling in yellow and red. You can see a strong upwelling signal along the coast, quite often just south of a cape.\nThe ocean is not flat, it’s bumpy. These differences are measured as sea surface height. The globe on the left shows areas of low SSH in blue, high in red, and exaggerated relief shows the bumpiness. The figure on the right shows a transect of sea surface height across the Central Pacific where the height difference is 32 cm. World-wide the difference in sea surface height can be up to 200 meters. Most of this difference is constant, though, and is due to the Earth’s gravity and ocean circulation. For most oceanographic purposes we are interested in the anomalies which illustrate phenomena such as El Nino events.\nSea surface height is measured with altimeters, which are active microwave sensors. Altimetry works much like police radar. The sensor sends a pulse that bounces off the surface and returns to the sensor. The time the pulse takes to return to the altimeter and the speed of light are used to calculate range, which is the distance from the altimeter to the sea surface. Because of atmospheric conditions, the speed of light varies through the atmosphere. A microwave radiometer aboard the satellite is used to correct for changes in the speed of light.\nThe exact position of the altimeter is measured in 4 dimensions, by GPS satellites and ground stations. Altitude is measured relative to a known reference, the reference ellipsoid. Latitude, longitude, and time are also recorded.\nPutting it all together we get: Range from altimeter. Satellite altitude from GPS and ground stations. Subtract range from the altitude to get sea surface height. And locate the sea surface height measurement in space and time. The map on the right shows sea surface height for the Gulf of Mexico. Blue are lower values and red are higher values.\nSeveral useful products can be derived from sea surface height. One example is sea level anomaly, which is a measure of how different a sea surface height value is from a typical value. To determine sea level anomaly, a long-term mean of SSH measurement is created to get a climatology of typical sea surface height values. At present that climatology is from 1993-2012 (19 years). The climatological values of sea surface height are then subtracted from the measured values. When SSH is greater than normal, the anomaly is positive. When SSH is less than normal, the anomaly is negative.\nSLA helps detect ocean phenomena from subtle changes in SSH. An event like El Nino can cause changes in SSH that measure in the tens of centimeters. Total SSH has a range of plus or minus 100 meters, so the El Nino signal may be hard to detect from SSH measurement. The map at the top shows the SSH during the 1997-1998 El Niño. It would take a trained eye to detect the El Niño signature from SSH. The map at the bottom shows the SLA. The unusually high SSH signature near the Peruvian coast can be easily detected in the SLA map.\nGeostrophic currents are important products that are derived from SSH information. These are currents that are driven by a gradient of high to low sea level. Geostrophic currents can be used to identify features like large scale circulation and larger eddies. On the left is a map of geostrophic currents generated by the CoastWatch Gulf of Mexico Node, which shows eddies formed in the Gulf of Mexico.\nOperational altimetry missions date back to the early 1990’s. The missions have overlapped over that time period, which has a couple of benefits. First, the mission data can be blended together to create a long time series. Second, blending data from the large number of sensors flying at the same time gives better spatial coverage than a single sensor.\nThe image on the left tracks the rise in mean sea level, from 1993 -2018. The data for this 25-year time series are a compilation of four altimetry sensors. The image on the right shows the coverage for all altimeters flying on a single day in 2018. By blending these data into a single product, far better spatial coverage is achieved than with any single sensor.\nTo summarize, all of the parameters I discussed, salinity, winds and sea-surface height, are all measurements made in the microwave port of the EMR spectrum. Because they are microwave measurements they can be made day or night and in nearly all-weather conditions. However the spatial resolution is lower than for measurements made in the visible and the IR, and passive measurements can not be made close to land.\nThis concludes this presentation on sea surface salinity, surface winds, and sea surface height. This is one of several presentations put together as part of the CoastWatch Ocean Satellite Course. We have additional presentations that cover how measurements are made for ocean color and sea-surface temperature."
  },
  {
    "objectID": "lectures/transcripts/intro-r.html",
    "href": "lectures/transcripts/intro-r.html",
    "title": "Intro to Using R with Satellite Data Transcript",
    "section": "",
    "text": "In this video I will demonstrate how to access datasets on ERDDAP from within the R software. If you aren’t familiar with ERDDAP, you should first view the ERDDAP video before viewing this one.\nLet’s start off by briefly discussing what R is. R is a free software package frequently used by many marine scientists to do statistical computing and graphics. There is a huge R user community worldwide. This community has led to the establishment of a repository of R packages that do many specialized functions. If there is some way you want to access or analyze data, chances are there is an R package that will make that task easier for you.\nToday I am going to talk in detail about one of those packages: the rerddapXtracto package. This package was written by Roy Mendelssohn of NOAA’s Southwest\nFisheries Science Center to help with some of the most common tasks that participants within the NOAA satellite core typically want to do. Like many R packages, it utilizes other R packages. In this case, the rerddap and plotdap packages, which were written to more easily access plot data served by ERDDAP. All three of these packages are available on the cran and can be easily downloaded using the default setup in R to install packages. Within the rerddapXtracto package, there are several different functions. Rxtracto is the primary function that it was designed to do. What this function does is match up satellite data to a set of user-supplied xyt data. i.e. coordinates of latitude and longitude and time. This is a task commonly done by biologists with\ndata from tagged animals that they want to acquire quiescent satellite data from. Rxtractogon extracts satellite data from within user-supplied polygons. This is useful if you want all the data from an unusually shaped area like a marine sanctuary or a fishery management area. rxtracto_3D extracts a 3-dimensional cube meaning latitude, longitude, and time within the boundaries of a user-supplied box. plotTrack will plot the results of rxtracto and plotBox will plot the results of rxtracto_3D. In this presentation, I will show you examples of using all of these functions based on the notebooks that we have available online.\nOur online notebook contains several chapters as outlined here. Chapter 2 used the rxtractogon function to plot chlorophyll data within the boundaries of Monterey Bay Sanctuary. Chapter 3 uses the rxtracto function to plot satellite data corresponding to a tagged marlin fish in the Pacific. Chapter 4 makes a time series of chlorophyll data by downloading several overlapping datasets. The data averaged spatially to make a time series and also averaged temporally to make maps. Chapter 5 shows how to use the tabledap function in rerddap to download tabular in-situ SST data and uses the rxtracto function to get corresponding satellite data to compare against the in-situ data. Chapter 6 uses the rxtracto_3D function to import SST data and use a temperature threshold to look at the turtle habitat. Next I will give a brief overview of each of these chapters.\nChapter 2 of the online tutorial uses the rxtractogon function to read in the chlorophyll data within the boundaries of the Monterey Bay Sanctuary and generates a map of this data as shown here on the slide. To provide this example, the boundaries of the Monterey Bay Sanctuary are embedded within the function. To modify this to work in a different region, the user needs to have the x and y coordinates of the polygon they are interested in.\nChapter 3 of the online tutorial uses the rxtracto function to extract the chlorophyll data synoptic with the tracks of a tagged marlin in the Pacific. It then plots this data, color-coded by the chlorophyll variable, as shown on the plot here. Chapter 3 of the tutorial also shows the rxtracto function to extract the chlorophyll data that is synoptic with some virtual survey stations in the Pacific, showing that rxtracto is capable of dealing with data that span the dateline.\nChapter 4 uses the rxtracto_3D function to download data from 4 different chlorophyll data sets to spatially average the data into one continuous time series. It also shows how to temporally average the data into average maps for each data set.\nChapter 5 shows how to use the tabledap function in rerddap to download in-situ buoy data and then uses the rxtracto_3D function to get corresponding satellite SST data to compare with that data. The graph shown here shows the matchup of VIIRS SST data against buoy data along the California coast. This chapter also shows how to compare the data graphically. This map of satellite SST is overlapping with buoy data from the same time period. Both datasets are color-coded using the same color palette.\nChapter 6 uses rxtracto_3D to import SST data from ERDDAP and uses a specific temperature threshold to identify a potential turtle habitat. The red band, the red area shown on the map here is a certain area that is defined by a temperature threshold.\nChapter 8 shows how to map projected datasets that are served on PolarWatch ERDDAP. This also demonstrates how to access an ERDDAP other than the default ERDDAP.\nThis was a quick overview of what is covered in our online R tutorial. The tutorial gives all the code you need to make the graph shown here. We also have other online tutorials. We have an overview of ERDDAP, and we have one covering different ways to import satellite data into ArcGIS."
  },
  {
    "objectID": "lectures/transcripts/best-dataset.html",
    "href": "lectures/transcripts/best-dataset.html",
    "title": "How to Choose the Best Dataset for Your Project Transcript",
    "section": "",
    "text": "Welcome to the online course on oceanographic satellite data products, produced by NOAA’s CoastWatch Program. In this module we will discuss how to select the best dataset for your application. The information presented here builds on the concepts discussed in several of the course’s earlier modules, including Satellite 101, Sea Surface Temperature, Ocean Color, and the Wind, Salinity, and Sea Surface Height. You might want to review those modules first before viewing this module. My name is Cara Wilson, I’m the node manager of the West Coast Node of NOAA’s CoastWatch Program. The materials I will be presenting in this video were produced from a collaboration from many members of NOAA’s CoastWatch Program including Dale Robinson, Melanie Abecassis, Ron Vogel, Shelly Tomlinson, me and the late Dave Foley.\nHow do you select the best dataset for your project? I will start by saying that there is no perfect dataset that will work for everybody. Each project has a unique set of requirements for ocean satellite data. Each dataset has characteristics that may be pros or cons for your project. The trick to finding the datasets that are best suited for your project is to strike a balance between the needs of your project and the properties of the available datasets. On the right, I’ve listed characteristics of datasets and some questions for you to answer in order to pick the correct dataset for each project. So for Temporal coverage I want to know if the satellite was flying during the dates of my study. For Geographical coverage I need to know if the dataset has data in my area of interest. Spatial resolution – Are the pixels small enough to resolve the features I’m interested in? If I’m looking at a large area is the spatial resolution so small that the dataset will be overly cumbersome to download and process? Temporal resolution: How often does the satellite fly over my area of interest? Latency / Quality: How fast do I need the data after it’s been collected and at what quality? Missing data: How much missing data can I tolerate, and what are my options to fill in missing data? I will explore each of these issues in more detail during this presentation.\nSo first let’s talk about temporal coverage. This is the first thing to consider to determine if data is available for your time period of interest. This image shows the timespan over which data has been collected by several ocean color sensors. If you needed chlorophyll data from the years 2005 through 2015, as pictured for study time period shown in yellow, then neither SeaWiFS or VIIRS alone could provide all the data you required. However, data from MODIS-Aqua is available for the entire time period.\nNow, suppose that you need chlorophyll data from the years 2000 through 2015, as pictured for the study time period shown again in yellow. No single sensor covers the entire time period. You could piece together the data you need by using data from SeaWiFS and MODIS-Aqua. However, you would have to reconcile the difference between the measurement from the two sensors during their overlap period from 2002 to 2010. Alternatively, you could use one of the blended datasets, where data from many ocean color missions have been merged for you. One example is the European Space Agency’s Climate Change Initiative Ocean color dataset. The dataset merges data from the SeaWiFS, MERIS, MODIS-Aqua, and VIIRS missions to create a blended dataset extending from 1997 to the present.\nNow let’s consider spatial coverage. Spatial coverage, the area of the Earth’s surface over which data is collected, is not the same for all datasets. Many satellite datasets have global coverage, but some may have only regional coverage. You need to check if the dataset covers your area of interest. Non-global coverage may be because the sensor has a limited spatial coverage or the result of splitting the global files into regional sectors to reduce file size. The top map shows the daily coverage provided by the NOAA Geopolar dataset. This dataset merges data from many polar-orbiting and geostationary satellites. If your study site were off the coast of Washington State, this dataset would provide the spatial coverage you need. The bottom map shows the coverage of a sensor on the GOES-16 geostationary satellite. The circle shows the footprint of the GOES-16 sensor, which runs from 52°N to 52°S latitude and covers South American and eastern US waters, with some coverage in the Pacific. This dataset would not provide the spatial coverage you need for a study off the coast of Washington State.\nSpatial resolution is the linear dimension on the ground represented by each pixel, and it is not the same among different satellite datasets. The slide shows SST maps of the Central California coast for two different sensors. On the left is a map from an older GOES-West sensor, which had a spatial resolution of about 4 km on a side for a pixel. The map looks blocky compared to the VIIRS map on the right, which has a spatial resolution of 750 m per side for a pixel. For work on the scale of the whole Central California coast, 4 km GOES data might have a high enough resolution for your needs. In addition, using a lower resolution dataset will make downloading and processing times for the data much faster. However, if you are interested in the feature visible in the circle on the 750 m resolution image, then the 4 km resolution data would not meet your needs.\nWhat if your project was examining a much smaller area? Let’s zoom in on a smaller area of interest within San Francisco Bay. Once again, coverage for the GOES-West sensor is on the left and for the VIIRS sensor is on the right. The GOES-West sensor data gives, at most, 4 pixels going across the bay and about 20 pixels within the entire bay. The GOES coverage probably does not well represent the temperature of the bay or show temperature features well. On the right, coverage for the VIIRS sensors has about 28 times more pixels for the entire bay than does GOES-West. The higher spatial resolution better represents the temperatures within the bay and allows the detection of surface temperature features. So finer spatial resolution provides more details, but the amount of data that needs to be downloaded is larger.\nTemporal resolution helps you address the question of how often you need a measurement for your project. If you are examining trends over the last 30 years, a monthly measurement is probably sufficient for your needs. However, if you are studying events in a dynamic coastal region, there may be a requirement for weekly, daily, or even hourly measurements. How often a dataset has a new measurement at the same location depends on the swath width of the sensors, whether the satellite is polar orbiting or geostationary, and if data from several sensors are blended together in a dataset. On the left is the coverage for the ASCAT polar orbiting sensor for 3 successive days. ASCAT is an active microwave sensor in a polar orbit with a 500 m swath width. For the location west of Mexico indicated by the white dot, you would get a wind measurement every 3 days. If you require data more often, you would need to select a different dataset. On the right is the daily coverage for the Cross-Calibrated Multi-Platform, or CCMP, dataset. This dataset blends data from many data sources, including active and passive sensors, to make a dataset with measurements as often as every 6 hours. The images on the right show daily wind maps from the CCMP dataset that provide a measurement each day of the 3-day period at the location indicated by the white dot.\nTypically, there is a tradeoff between getting data very soon after it’s been collected and getting the highest quality data. For near real-time data, the data provider is making the data available as quickly as possible, often within a day or even an hour of acquisition. To do this, the strictest quality control for the data cannot be applied. The data in NRT datasets are not bad. More likely, some pixels with questionable data may not have been removed from the dataset. In contrast, science quality data is released after a delay to allow for strict quality controls to be applied. The slide shows how cloud cover may impact datasets where science quality and near real-time quality control is applied to chlorophyll data from the same VIIRS source data. The science quality version is on the left and the near real-time version is on the right. For the NRT image on the right, the inset zooms in on an area where clouds block the ocean color signal, creating gaps in the data. However, it turns out that clouds can have more subtle impacts on the ocean color signal, which can degrade the quality of pixels near the pixels blocked by clouds in the near real-time processing. The less rigorous quality control that is applied to near real-time data can miss identification of these degraded pixels. Now look at the image on the left, which was made from science quality data. The inset zooms in on the same cloudy area. You can see that the data gaps are larger. The science quality data were delayed by about 2 weeks to allow time for more rigorous quality control. The additional degraded pixels were identified and removed from the dataset during this quality control process, resulting in the larger data gaps.\nThe next few slides help illustrate how both science quality and near real-time data make important contributions to ocean management and research. If you are developing a model to predict the distribution of harmful algal blooms, you might develop a habitat model that uses environmental data like chlorophyll concentration to define conditions under which harmful algal blooms had formed in the past. You would want the best quality data available to create the model. In other words, you would use the science quality data. Since this would be a retrospective analysis, the two-week delay for science quality data would not impact your model development.\nOn the other hand, when using the model to predict the distribution of harmful algal blooms a few days into the future, you couldn’t use science quality data that is two-weeks old. Doing so would reduce your forecasting ability. Instead, you would use the most up-to-date data available, the near real-time data. You would need to accept the potential increased error in order to obtain the data quickly for prediction purposes.\nHow much missing data can your project tolerate? If you are constructing a daily time series for a specific, small area, then frequent missing data could make your timeseries unusable. However, if you are generating mean monthly values for a larger area, then data gaps may not be of concern. There can be many reasons for missing data, but for this example let’s consider two. The slide shows SST maps for the same day using microwave imagery on the left and infrared imagery on the right. For a project set in a cloudy region that needs to minimize missing SST data, you might consider using microwave SST data, since microwaves are not blocked by clouds. If your study is at site location 1 on the maps, this strategy seems to be effective. The microwave shows no data gaps, whereas the gaps from clouds can be seen in the infrared maps. In contrast, site location 2 falls within the coastal region where the ocean microwave data is missing due to contamination from the land microwave signal. If your study is at site location 2, then you would need to use a dataset containing infrared data.\nLet’s look more closely into strategies for overcoming data gaps using a case study for reducing data gaps due to clouds in SST imagery. At the top left is a 1-day SST image from a polar-orbiting infrared satellite. There are gaps in the SST coverage that we want to minimize. One strategy to reduce data gaps is to take the average values over several days. That strategy is illustrated across the top of the slide, where 3-day, weekly, and monthly average composites are displayed. For example, for a 3-day composite data in each pixel contains a value that is an average of the day of interest, plus the day before and the data after. As more days are added to the averages, data gaps are reduced. However, the data is more smooth over more days. Notice how the finer structure visible within the circle in the 3-day image is less distinct in the weekly and monthly images. A second strategy is to use SST data from infrared sensors on geostationary satellites. This strategy is illustrated on the left-lower part of the slide. These sensors look at the same location on earth and capture an image every 30-60 minutes. The idea is that clouds will move around during the course of a day, increasing the chance of capturing data for a pixel to include in a daily composite image. Using daily geostationary imagery will often reduce data gaps, but spatial resolution can be less. Sensors on polar-orbiting infrared satellites can have sub-kilometer spatial resolution, whereas resolutions from infrared sensors on geostationary satellites typically range from 2-4 kilometers. A third strategy is to use microwave imagery, which can see through clouds. Daily microwave images will often reduce data gaps, but spatial resolution can be less. Spatial resolution from microwave sensors is about 25 km. In addition, microwave imagery has data masked out within approximately 50 km of shore. This might seem like a lot of things to consider but it’s important to realize that these three strategies are only available for SST data. Most other measurements are only made from polar-orbiting satellites, and from only one place in the EMR spectrum, so often the only strategy available is to temporally composite the data.\nAnother strategy might be to select a blended data product for your project. Blended products merge sensor data from multiple sources in order to increase spatial coverage. In addition, an interpolation step is often included to fill in any remaining data gap. Two examples of blended products are included on the slide. On the left is the Multi-Scale Ultra High Resolution, or MUR, SST dataset, which merges data from polar-orbiting infrared and microwave imagery. On the right is the NOAA GeoPolar Blended SST dataset that is produced and distributed by NOAA. The GeoPolar Blended dataset merges data from polar-orbiting and geostationary sensors. The two datasets use different interpolation methods. This strategy might seem like the perfect solution, but one consideration is that with blended products, you generally don’t know which pixels come from observations, and which pixels are interpolated. The circled region on the upper three maps is an area where there are gaps in the source data used for the blended product. Now look closely at that area on the maps made from the two blended datasets toward the bottom of the slide. The results look different in that area. Which of the two datasets more accurately represent the environment? The answer to that question will likely vary with project location and over time. If knowing the level of accuracy is important for your project, then doing some sort of comparison to non-interpolated datasets would be an important step for you to consider.\nThis concludes this presentation on choosing the best dataset for your project. Please visit the data catalogs at NOAA CoastWatch Central and any of the CoastWatch Nodes listed on this slide. The catalogs have information to help you make decisions about the datasets to use. In addition, please feel free to contact us with questions about datasets."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CoastWatch Training Website",
    "section": "",
    "text": "This site provides information on CoastWatch Satellite Training courses such as upcoming or past trainings, training tutorials, course lectures, and more to support scientists working with oceanographic satellite data.\n\nWhat you’ll find here\n\nStep-by-step coding and software tutorials for accessing and analyzing satellite data\nTraining materials developed through NOAA CoastWatch courses, including information on upcoming and past trainings\nResources and support options, including scheduled office hours, to help you integrate satellite data into research and management workflows\n\n\n\nNot sure where to start?\n\nInterested in participanting in a training course?\nVisit the Training Classes page to see upcoming trainings or past trainings to get an idea of what to expect.\nLooking for hands-on examples?\nCheck out the Training Tutorials to explore workflows in Python, R, and MATLAB, as well as software tutorials exploring NASA’s Panoply and CoastWatch Utilities.\nNeed help or have questions?\nThe Help page points you to FAQs, resources, and support options.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the CoastWatch Satellite Training Course",
    "section": "",
    "text": "The NOAA CoastWatch Satellite Training Course is a long-running professional training program designed to help scientists, managers, and decision-makers effectively use satellite-derived oceanographic and environmental data in their work. Since its earliest beginnings more than two decades ago, the course has evolved alongside satellite technology, software tools, and the needs of NOAA and its partners, while maintaining a consistent focus on applied, “fit-for-purpose” training.",
    "crumbs": [
      "About Us"
    ]
  },
  {
    "objectID": "about.html#course-history-and-evolution",
    "href": "about.html#course-history-and-evolution",
    "title": "About the CoastWatch Satellite Training Course",
    "section": "Course History and Evolution",
    "text": "Course History and Evolution\nCoastWatch training efforts began in the late 1990s with workshops focused on integrating satellite imagery into desktop GIS tools. These early courses demonstrated strong demand for satellite data training, but also highlighted limitations in length, cost, and accessibility.\nIn 2006, the first formal CoastWatch Satellite Course was held at Oregon State University, organized by the West Coast Node. This marked the beginning of a dedicated training program designed specifically for NOAA personnel. The course emphasized short intensive instruction and exposure to multiple satellite products (beyond ocean color), with hands-on support provided in whatever software languages participants used and project time centered on each particpant’s own applications and interests.\nA major milestone occurred in 2013 with support from the JPSS Proving Ground and Risk Reduction program. That year introduced the collection of participant slides, documenting how attendees use satellite data in their own work. These slides became a lasting record of course impact and remain a core component of the program today.\n\n\n\nA timeline highlighting major milestones in the CoastWatch Satellite Training Program, from early GIS-focused workshops in the late 1990s through the establishment of the formal satellite course in 2006, expansion across CoastWatch nodes beginning in 2018, the transition to online training during COVID-19, and the development of specialty courses and advanced modules in recent years.",
    "crumbs": [
      "About Us"
    ]
  },
  {
    "objectID": "about.html#expansion-across-nodes-and-the-roadshow-period",
    "href": "about.html#expansion-across-nodes-and-the-roadshow-period",
    "title": "About the CoastWatch Satellite Training Course",
    "section": "Expansion Across Nodes and the “Roadshow” Period",
    "text": "Expansion Across Nodes and the “Roadshow” Period\nBeginning in 2018, additional CoastWatch nodes began hosting their own courses, expanding participation across a wider range of the US and supporting more region-specific training needs and topics. In 2019 and early 2020, the program adopted a “roadshow” model, bringing in-person trainings to locations across the U.S. and U.S. territories, including Alaska, Texas, and Puerto Rico.\nThis period culminated in a publication describing lessons learned from the CoastWatch Satellite Course and its role in supporting operational use of satellite data.\n\n\n\nMap showing locations of in-person CoastWatch Satellite Training courses during the “roadshow” period, illustrating the program’s expansion to region-specific trainings across the United States and U.S. territories, including Alaska, Texas, and Puerto Rico.",
    "crumbs": [
      "About Us"
    ]
  },
  {
    "objectID": "about.html#transition-to-online-training-and-increased-participation",
    "href": "about.html#transition-to-online-training-and-increased-participation",
    "title": "About the CoastWatch Satellite Training Course",
    "section": "Transition to Online Training and Increased Participation",
    "text": "Transition to Online Training and Increased Participation\nThe COVID-19 pandemic in 2020 prompted a rapid shift to online delivery. While initially disruptive, this transition significantly expanded participation by reducing travel and time barriers. Shorter virtual courses and conference workshops enabled CoastWatch to reach a broader and more diverse audience.\nAs of 2025, the CoastWatch Satellite Training Course has:\n\nHosted over 40 courses\nTrained more than 1,000 participants\nCollected over 250 participant slides\nEngaged users across NOAA, academia, industry, NGOs, and international partners\n\n\n\n\nAnnual participation in CoastWatch Satellite Training courses, distinguishing between full-length courses and shorter workshops. The figure highlights a substantial increase in participation beginning in 2020, driven by the shift to online delivery and the introduction of shorter, more accessible training formats.\n\n\n\n\n\nDistribution of participant affiliations across CoastWatch Satellite Training courses, illustrating engagement from NOAA line offices, other government agencies, academia, industry, NGOs, and international organizations.",
    "crumbs": [
      "About Us"
    ]
  },
  {
    "objectID": "about.html#training-materials-courses-and-ongoing-support",
    "href": "about.html#training-materials-courses-and-ongoing-support",
    "title": "About the CoastWatch Satellite Training Course",
    "section": "Training Materials, Courses, and Ongoing Support",
    "text": "Training Materials, Courses, and Ongoing Support\nThis website serves as a central hub for CoastWatch Satellite Training materials, bringing together resources that were previously distributed across multiple platforms. Users can explore a wide range of training content developed over the course of the program, including:\n\nLecture materials covering satellite fundamentals, data products, and applied use cases\nSoftware-based tutorials for accessing, visualizing, and analyzing satellite data using tools such as Python, R, MATLAB, GIS, and web-based utilities\n\nTogether, these materials reflect the evolution of the course and support both self-paced learning and structured training activities.\nIn addition to archived content, the site provides information on past trainings and upcoming courses, including full-length courses, shorter workshops, and region-specific offerings. These listings are intended to help users understand the scope of previous trainings and identify opportunities to participate in future events.\nTo support continued learning beyond formal courses, the CoastWatch training team also offers regular office hours, providing an open forum for users to ask questions, troubleshoot workflows, and get guidance on applying satellite data to their own projects. Office hours are open to anyone and are designed to complement the training materials hosted on this site.",
    "crumbs": [
      "About Us"
    ]
  },
  {
    "objectID": "about.html#people",
    "href": "about.html#people",
    "title": "About the CoastWatch Satellite Training Course",
    "section": "People",
    "text": "People\n\n\n\nName\nAffiliation\n\n\n\n\nCara Wilson\nCoastWatch/West Coast Node/PolarWatch, Node Manager\n\n\nDale Robinson\nCoastWatch/West Coast Node/PolarWatch, Development Lead\n\n\nSunny Hospital\nCoastWatch/PolarWatch, Development Lead\n\n\nMichelle Tomlinson\nCoastWatch/East Coast Node, Node Manager\n\n\nRon Vogel\nCoastWatch/East Coast Node, Development Lead\n\n\nJames Kessler\nCoastWatch/Great Lakes Node, Node Manager\n\n\nSongzhi Liu\nCoastWatch/Great Lakes Node, Development Lead\n\n\nGregory Foltz\nCoastWatch/Caribbean and Gulf of America Node, Node Manager\n\n\nJoaquin A. Trinanes\nCoastWatch/Caribbean and Gulf of America Node, Development Lead\n\n\nRyan Rykaczewski\nCoastWatch/Pacific OceanWatch, Node Manager\n\n\nDaisy Shi\nCoastWatch/Pacific OceanWatch, Development Lead\n\n\n\n\nIn Memoriam\nWe gratefully acknowledge the contributions of Dave Foley, who played an important role the the development and delivery of the CoastWatch Satellite Training Courses. His efforts helped support scientists and resource managers in applying satellite data to real-world problems, and that impact continues through this site.",
    "crumbs": [
      "About Us"
    ]
  },
  {
    "objectID": "help.html",
    "href": "help.html",
    "title": "Help",
    "section": "",
    "text": "Are you interested in using oceanographic satellite data in your work but not sure where to start?\nNOAA CoastWatch Satellite Training Courses provide access to environmental satellite data, along with tutorials and example workflows designed to help scientists and resource managers work with these datasests more easily. This website brings together training materials, coding examples, and practical guidance developed through CoastWatch courses to support users with varying levels of experience.\nWhether you are new to satellite data or looking for reproducible ways to integrate it into your research or management projects, these resources are intended to help you explore, access, and analyze oceanographic satellite products with confidence.",
    "crumbs": [
      "Help"
    ]
  },
  {
    "objectID": "help.html#frequently-asked-questions",
    "href": "help.html#frequently-asked-questions",
    "title": "Help",
    "section": "Frequently Asked Questions",
    "text": "Frequently Asked Questions\n\n\n\n\nHow is the course structured?\n\nThe course combines instructional materials with virtual workshops. Instructional materials introduce participants to common types of environmental satellite data including:\n\nOcean color\nSea surface temperature\nSea surface height\nSalinity\nOcean surface winds\n\nWorkshops focus on practical application where participants recieve individual and group support to:\n\nLocate online satellite data\nSelect data with the spatial and temporal coverage that fits their needs\nDownload and work with the data in their preferred software\n\nMost examples focus on R, Python, and ArcGIS, but participants using other software are also welcome.\nParticipants are encouraged to come with a specific project or question to work on during the workshops.\nFor example:\n\nMerging tagged animal tracks with satellite data\nExploring environmental conditions in a study region\nPreparing satellite data for analysis or visualization\n\nParticipants tend to get the most out of workshops when they arrive with clear goals, data, or questions in mind.\n\n\n\nWho should take the course?\n\nThe courses are primarily designed for National Marine Fisheries Service and National Ocean Service scientists, but non-NOAA participants are welcome when space is available.\nTo date, over a thousand participants have taken these courses, including scientists and staff from:\n\nAll six Fisheries Science Centers\nMultiple National Marine Sanctuaries\nOther federal agencies, such as:\n\nU.S. Coast Guard\nU.S. Geological Survey\nU.S. Fish and Wildlife Service\n\n\n\n\n\nHow much does the course cost?\n\nThere is no fee to participate in the course. Participants are asked to submit a single PowerPoint slide describing the project they worked on during the course. These slides help document course outcomes and shared applications of satellite data.\n\n\n\nWhen and where is the next course?\n\nThe dates and locations of upcoming courses can be found here.\nTo be notified about future courses, contact Cara Wilson.",
    "crumbs": [
      "Help"
    ]
  },
  {
    "objectID": "help.html#resources",
    "href": "help.html#resources",
    "title": "Help",
    "section": "Resources",
    "text": "Resources\n\n\nCoastWatch Help Desk\nThe CoastWatch Help Desk provides user support regarding the use of our data products and services. Please do not hesitate to contact us using the methods below:\n\nEmail: coastwatch.info@noaa.gov\nPhone: +1 (301) 683-3335\nUser Forums (inquiry threads)\n\n\n\nTraining Lectures\nIntroductory lectures and course materials covering using satellite data.\nView lectures\n\n\nTraining Tutorials\nThe training tutorials provide step-by-step guidance for accessing, exploring, and analyzing satellite data, from software setup and data access to coding workflows in Python, R, and MATLAB.\nView training tutorials\n\n\nData Servers\nBrowse available oceanographic satellite products and datasets on ERDDAP.\n\nNOAA CoastWatch West Coast Node\nNOAA CoastWatch East Coast Node\nNOAA CoastWatch Great Lakes Node\nNOAA CoastWatch Caribbean and Gulf of America Node\nNOAA CoastWatch Central Pacific Node\nNOAA CoastWatch PolarWatch Node",
    "crumbs": [
      "Help"
    ]
  },
  {
    "objectID": "lectures/index.html",
    "href": "lectures/index.html",
    "title": "Satellite Course Lectures",
    "section": "",
    "text": "This page provides access to the lecture slide decks used in CoastWatch training courses. The lectures are designed to be short (about 20 minutes when narrated), and many have narrated versions available on YouTube. Use the table below to preview a lecture in your browser or download the slides for offline viewing.\nClick the eye icon to open the lecture, download to go to the source file, play button to view the narrated lecture, and clipboard to read the transcript of the narrated lecture.\nLecture\nPreview\nDownload\nVideo\nTranscript\n\n\n\n\nIntroduction to CoastWatch\nAn overview of the NOAA/NESDIS CoastWatch program, it's different regional nodes, and the satellite products and services it offers.\n\n\n\n\n\n\n\n\n\n\n—\n—\n\n\nSatellite 101, Part 1\nThis presentation covers the basics of ocean remote sensing, part 1.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSatellite 101, Part 2\nThis presentation covers EMR (electromagnetic radiation), atmospheric correction, and the differences between passive and active sensors.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTools and Strategy\nThis presentation provides an overview of CoastWatch data services and tools, showing how to find, visualize, and access satellite oceanographic data using NetCDF files, data viewers, and ERDDAP to simplify working with multiple data servers and formats.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to ERDDAP\nThis presentation introduces ERDDAP and demonstrates how it simplifies discovering, visualizing, subsetting, and downloading gridded and tabular oceanographic datasets from multiple satellite and in situ data servers through a consistent web interface and URL-based queries.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOcean Color\nThis presentation covers the basic principals behind ocean color satellite data and gives an overview of the suite of products generated by ocean color satellites.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSea Surface Temperature\nThis presentation explains how sea surface temperature is measured from space, comparing infrared and microwave satellite sensors, discussing atmospheric effects and data limitations, and introducing commonly used Level-3 and Level-4 blended SST products available through NOAA CoastWatch.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSatellite Sea Surface Height, Altimetry, Winds, and Salinity\nThis presentation explains how satellite microwave sensors are used to measure sea surface salinity, surface winds, and sea surface height, comparing passive and active sensing techniques and showing how these observations are combined into long, gap-free datasets for studying ocean circulation, storms, and large-scale climate variability.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Select the Best Dataset for Your Project\nThis presentation provides a practical framework for choosing the most appropriate satellite dataset for a project by evaluating tradeoffs in temporal and spatial coverage, resolution, latency versus quality, and tolerance for missing data, with examples drawn from common CoastWatch products.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Using R with Satellite Data\nThis presentation introduces how to use R with ERDDAP, focusing on the rerddapXtracto package to extract, visualize, and analyze satellite oceanographic data for applications such as track matchups, polygon-based regions, time series, and habitat analyses using reproducible R workflows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Satellite Data in ArcGIS\nThis presentation introduces how to work with satellite oceanographic data in GIS, covering imagery versus data products, formats such as NetCDF and GeoTIFF, metadata and projections, and practical considerations for visualizing and analyzing CoastWatch satellite datasets using ArcGIS (with concepts applicable to other GIS software).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelecting and Using Data in ArcGIS\nThis presentation focuses on the tools and workflows for using satellite data in GIS, demonstrating ArcGIS built-in tools, extensions, and external utilities (including ERDDAP, THREDDS, the Environmental Data Connector, and CoastWatch Utilities) to import, subset, visualize, time-enable, and export multidimensional satellite datasets for analysis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWater Quality\nThis presentation introduces how satellite remote sensing is used to assess water quality, explaining key satellite-derived parameters such as chlorophyll-a, turbidity, CDOM, suspended sediments, algal blooms, and light attenuation, along with their limitations, accuracy considerations, and applications in coastal, inland, and Great Lakes environments.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSea Ice\nThis presentation describes the different types of sea ice products available, and where and how to access them.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Aperture Radar (SAR)\nThis presentation provides a comprehensive introduction to Synthetic Aperture Radar (SAR), explaining how SAR works, what oceanic, atmospheric, and coastal features it can detect, the advantages and limitations of radar measurements, and where to access and work with SAR data products available through NOAA CoastWatch and partner archives.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub Software Tutorials\nAn overview of the different tutorials developed by CoastWatch for working with satellite data with R or python software.\n\n\n\n\n\n\n\n\n\n\n—\n—",
    "crumbs": [
      "Course Lectures"
    ]
  },
  {
    "objectID": "lectures/index.html#acknowledgements",
    "href": "lectures/index.html#acknowledgements",
    "title": "Satellite Course Lectures",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThe CoastWatch training materials have been developed, reviewed, and edited with contributions from many dedicated individuals:\n\nMelanie Abecassis — Code/content development, review\nDale Robinson — Code/content development, review\nShelly Tomlinson — Code/content development, review\nAndrea Vander Woude — Code/content development, review\nVictoria Wegman — Content review/editing\nCara Wilson — Code/content development, review\n\nWe also extend our gratitude to additional external contributors whose acknowledgements are included within the training materials they helped to create.",
    "crumbs": [
      "Course Lectures"
    ]
  },
  {
    "objectID": "lectures/transcripts/intro-erddap.html",
    "href": "lectures/transcripts/intro-erddap.html",
    "title": "Introduction to ERDDAP Transcript",
    "section": "",
    "text": "Welcome to Introduction to ERDDAP, part of an online course on oceanographic satellite data products, produced by NOAA’s CoastWatch Program. My name is Cara Wilson, and I’m the node manager of the West Coast Node of NOAA’s CoastWatch Program.\nAccessing satellite data, or any environmental data for that matter, can be challenging. There are lots of different places to get data, and they all have different ways of organizing their data. Some let you subset the data or preview it first through visualization, but not all do. Different servers can have different download protocols and different file formats. If you have to get multiple datasets from different places it can be overwhelming, even to experienced data users. In this presentation I will give a brief introduction to ERDDAP, a data server that tries to mitigate these issues.\nERDDAP was developed at the NOAA Southwest Fisheries Science Center by Bob Simons. It provides a simple, consistent way to subset and download data. The data can also be visualized in customizable graphs. Data can be downloaded in over 30 formats, as both graphs and data. ERDDAP is a restful service, meaning that the data requests are completely defined by a URL, which allows for easy access from computer programs like R or Matlab, as well as allowing machine-to-machine access. Over 85 ERDDAPs exist worldwide. In this presentation I will show examples using the ERDDAP maintained jointly by the NOAA SWFSC Environmental Research Division and the West Coast Node of NOAA’s CoastWatch program.\nThe NOAA ERD ERDDAP has over a thousand oceanographic satellite datasets on it, most of them having global coverage. Most products are available in daily, weekly or monthly composites.\nThere is more than just satellite data on the ERD ERDDAP. There are also in situ measurements from a number of different platforms and projects, underway data from NOAA and UNOLS research vessels and a variety of model data.\nThe main ERDDAP interface can be a little overwhelming at first. Datasets are listed alphabetically by their dataset title, seen here in the middle of the table. Different columns of the table provide different information about the datasets, such as their metadata, source institution and the local dataset id. If you want to download data from this interface you would click the data link to the left of the dataset title, which brings up a form that easily lets you subset the data temporally and spatially. To create a graph of the data click on the graph column to the left of the dataset title, which brings up an online form that lets you customize a graph of the data. We’ll see what these two forms look like on the next slides.\nThis is the ERDDAP graphing interface for gridded data. Data can be shown as maps, timeseries, and hovmollers, which is a hybrid map with either latitude or longitude on one axis and time on the other, to show both temporal and spatial variability. I’ll show an example of one of these later in the presentation. The date and spatial boundaries of the map can all be changed by either manually entering values, or moving the slider bar under the dimensions listed. The map domain can also be changed by using the zoom in or zoom out buttons above the map on the right. The ranges of the color are adjustable, as is the color palette, there are over 40 different palettes to choose from.\nThis is the ERDDAP Data Access Form for gridded data. You can select the temporal and spatial bounds by either directly entering values or by moving the sliders under the variable. If you access this form from the Make a graph page your spatial constraints will be copied across. By default the stride is set to 1, if you change this value, you will reduce the number of values you will obtain in that dimension. If there are multiple variables in a dataset, like there are for this one, you can choose which ones you want to download by checking the variables you want. Clicking on the dropdown list under file type gives you the list, partially shown here, of over 40 different file types. These graphical interfaces provide a user-friendly way to create a customized graph, or download data, but since all data requests are given as a URL, once can make changes by directly changing the URL. To do that it helps to understand the grammar of the ERDDAP URL data request.\nHere the text wrapped around the slide is an actual URL. I’ve marked different parts of it in different colors to help identify the different components. The red text marks the dataset id, the green text the file type, the purple text the variable name, the black text the time range and the blue text the latitude and longitude ranges. So by simply reading this URL I can tell that it will produce a png image of SST for September 2019 in the North Pacific, which is shown on the next slide.\nThis is the map produced by the URL shown on the previous slide. Let’s modify the graph by making some changes to the URL. Let’s first change the variable name from ‘sea surface temperature’ to ‘sea surface temperature anomaly’.\nNow we see a map of the SST anomaly for this same time period. The red values show the extent of the marine heat wave that has developed in the Pacific the last few years. Note that in this example changing the variable name produces an anomaly because this dataset has a variable within it with the SST anomaly in it. Most datasets do not have an anomaly variable in them, so this specific modification will only work for this dataset. How long has this marine heat wave been around? How can we see that graphically?\nWe can determine how long this heat wave has been around by making a hovmoller graph, which is a hybrid map, with time on one axis. We will take a cross-section along 30N and plot it over time. We can do this on the “make a Graph” page by changing the Y axis from latitude to time.\nHere we are looking at SST along 30N from 1985 at the bottom of the plot to the end of 2019. We can see that while most of the last 20 years there have been warmer than usual temperatures in the Central Pacific, only since 2015 has this phenomena spread to the coast, as seen by the positive anomalies east of 120W in the upper right hand side of the plot.\nYou can also make just a simple time series of the data at one of the points. Select ‘linesAndMarkers’ under Graph Type on the Make a Graph page, pick the latitude and longitude that you want, and select the time range that you want. Here I am showing the complete dataset from 1985 onward of the SST anomaly in the Bering Sea at 60°N, 170°E.\nNext, let’s take a look at Hurricane Katrina using QuikSCAT ocean winds data. The URL shown on this slide produces the map of wind speed on Aug. 27, 2005 in the Gulf of Mexico. But what if we also want to see the wind directions? ERDDAP can also plot vector data, although it can not do overlays, so we will have to make another plot.\nFrom the “Make a Graph” page we simply select vectors as the graph type. Note that the vector graph option is only available for those datasets that contain vector data. And now we can see the wind vectors associated with Hurricane Katrina in the Gulf of Mexico.\nERDDAP also serves tabular data like in-situ data. Here we are looking at a map of all of the BGC-Argo data since the beginning of 2017 in the Southern Ocean around South America. These are profiling floats that are equipped with sensors that can make biological or chemical measurements like oxygen, nitrate, pH, etc. This data is served on the PolarWatch ERDDAP. Here the float locations are colored by time, but they could also be colored by float number, or any of the variables in the dataset. The Make a Graph interface works a little differently for tabular datasets, and one can constrain the data shown by any of the variables in the dataset. Next we will look at some different graphs made from one of these floats.\nBy changing the constraint selections one can easily make maps and different types of graphs for tabular data. On the left is the float track for one of the SOCCOM Bio-Argo floats, color-coded by time. In the middle is a Temperature-Salinity diagram, color-coded by density, for that same float data, and on the right is a section plot showing oxygen in the surface 300 m for the 5-year duration of the float. For the oxygen section a color palette has been chosen that is perceptually uniform.\nSo far I have been focusing on different ways of visualizing data on ERDDAP. What if we want the data associated with one of these figures? Lets revisit that URL I showed at the beginning of the talk when I introduced the different components of the ERDDAP data request. This URL has the File type, the text in green, given as a large PNG file, so it will create an image on your browser. But if you changed that bit of the url to .mat it would produce a matlab file of that same data, which would be automatically downloaded to your computer. There are many different file formats to choose from, including netCDF, .json, kml, csv etc. Now since we were just looking at one time increment in this map, this url will only download one time period. Most likely you will want to download a range of times, and that can be done by setting the time range to actually represent a range of values, rather than having it be only one time period as shown here. Talking about the time range reminds me of another cool feature of ERDDAP I need to tell you about, and that is the ‘last’ function that can be used in the time range.\nIf you replace a specific date in the url with the word last, you will get the most recent image. That’s what we are showing on the left. That url, in December of 2020, produced a map of the data from Nov 2020. If I access that same url in January of 2021 it should show me data from December of 2020. This is a very convenient way to embed images in a website to always show the most recent data for a region of interest. You can also do simple math with the last function. The url on the right is requesting “last-24”, so is getting the data from 24 time increments before the most recent data. Since this is a data product with monthly timesteps, that is getting data 2 years before the most recent data. For a daily dataset last-24 will return data 24 days before the most recent data.\nNow you might be thinking this is all very well and good, but there is no way you will ever be able to figure out how to put one of these long cumbersome URLs together. You don’t have to. I have been showing the URLs associated with graphs to demonstrate how the URLs work. But remember you can download data directly from the Data Access Form for a dataset. You get there by clicking the data link to the left of a dataset title on the main ERDDAP data listing, or by changing the filetype in the url to .html. The screenshot shown here is the Data Access Form for the sea surface temperature product we were just looking at. If you just want the url of what this download request would be, to use in some other software, you can generate it by clicking on the “Just generate the URL” button. The “just generate the URL” feature is also available on the Make a Graph page.\nI’ve provided a very quick introduction to ERDDAP capabilities. We also have an online tutorial which demonstrates the main features of ERDDAP. It is available at the link shown here, coastwatch.pfeg.noaa.gov/projects/ERDDAP\nThe previous slides showed examples of using ERDDAP’s web pages to download data or make a customized graph. Since ERDDAP has an underlying RESTful service, one can make requests for data from programs like curl and wget, or by writing scripts which automate the process of making 100’s, 1000’s, or 1000000’s of requests. We have an online tutorial that demonstrates ways to extract data from ERDDAP using R software. It is available at coastwatch.pfeg.noaa.gov/projects/r\nThis concludes the Introduction to ERDDAP. This is one of several presentations put together as part of the CoastWatch Ocean Satellite Course."
  },
  {
    "objectID": "lectures/transcripts/ocean-color.html",
    "href": "lectures/transcripts/ocean-color.html",
    "title": "Ocean Color Transcript",
    "section": "",
    "text": "Welcome to the Ocean Color portion of our online course on oceanographic satellite data products, which has been produced by NOAA’s CoastWatch Program. My name is Shelly Tomlinson and I’m the node manager of the East Coast Node of NOAA’s CoastWatch Program. The materials I will present in this video were produced from a collaboration from many members of NOAA’s CoastWatch Program including Dale Robinson, Melanie Abecassis, Ron Vogel, Cara Wilson, myself, and the late Dave Foley.\nOcean color estimates through remote sensing have revolutionized our understanding of the living ocean on small to global scales, and provide important information for daily monitoring and long-term trend analyses. Ocean color refers to the “color” of the ocean as determined by the interactions of incident light with substances or particles present in the water. These measurements reveal many ecologically important parameters related to chlorophyll concentration, phytoplankton bloom monitoring, primary productivity, sediment transport, the dispersion of pollutants, responses of oceanic biota to long-term climate changes, and water clarity and quality, to name a few.\nThe way an ocean color sensor works is by measuring the electromagnetic energy that passes through the atmosphere, is transmitted through the surface of the ocean and then reflected back to the satellite. The electromagnetic spectrum usually used for ocean color algorithms include the visible wavelengths from 400 nm to 700 nm (blue to red), some infrared wavelengths and higher wavelengths for atmospheric corrections. As the atmosphere causes the most scattering and absorption of the light from the sun (Downwelling Irradiance, Ed), you will often hear that an “Atmospheric correction” must be applied to the measurements we use for algorithm development. This is to remove the effects of the atmosphere. As the light is transmitted through the water column, there are both absorbing materials (which can be the water itself plus pigments from phytoplankton, dissolved organic material and other particles containing absorbing compounds such as detritus. In addition, particles can scatter the light, preventing it from returning to the satellite. This can be sediment, organic matter, as well as detritus and phytoplankton. So what the satellite measures, the Water Leaving Radiance (Lw) at each wavelength of light, is actually measuring a combination of what was returned from the water column as a result of the scattering and absorption properties. You often see what is referred to as Remote Sensing Reflectance, Rrs, which is water-leaving radiance, Lw(λ), corrected for bidirectional effects of the air-sea interface and sub-surface light field, and normalized by downwelling solar irradiance, Ed(λ), just above the sea surface.\nSo, what affects the variations in color within the ocean? First of all, I should mention that what the satellite is seeing is what is called the first optical depth, which we tend to associate with about a secchi depth. So it cannot see all the way to the bottom in turbid or deeper waters. The color you see is related to these absorption and scattering properties. So for instance, far offshore the water appears very blue. This is because the water has less absorption in the blue wavelengths (400) as there is less dissolved organic matter from land, and less phytoplankton and chla, which absorbs blue and red light. There are also less scattering particles , such as sediment, in the red wavelengths (600-700 nm) which would cause red reflectance back to the satellite. So as you move closer to the coast, the increase in absorbing and scattering particles causes the blue Rrs to go down, as the red Rrs increases. The relative combination of these various scattering and absorbing materials is what affects the color of the ocean in different regions.\nSo, when looking at just the effects of chlorophyll a (chla), which can provide an estimate of the amount of phytoplankton in the water, you may often hear of blue-green ratios. Common ocean color algorithms look at the changes in the blue to green peaks in the reflectance spectra to determine the concentration of chla in the water. So from this figure, you can see that as the chla increases in concentration, the reflectance is decreasing. This is the result of an increase in absorption by chla. You can think of reflectance as the inverse of absorption, so when there is more absorption occurring at a specific wavelength, there is less reflectance back to the satellite of that wavelength of light. One thing also to note is that there is a peak occurring around 680 nm which becomes more predominant as chla increases. This is related to a peak in chlorophyll a fluorescence.\nAs I mentioned earlier, the atmosphere is responsible for about 90% of the signal measured by the sensor. So if only 10% of the signal returning back to the satellite is coming from the water, it is very important to provide an accurate atmospheric correction. This becomes even more important in coastal or estuarine areas, as the signal gets more complicated by the increased scattering and absorption closer to land.\nWe often refer to clear open ocean water as Case 1 or optically deep water, whereas Case 2 waters, or optically shallow, tend to be more complex due to influences from land. Ocean color algorithms in Case 1 waters are more straightforward as the absorption is primarily due to phytoplankton and their derivative products. In case 2 waters, there is much more absorption at all wavelengths due to absorbing compounds (dissolved and particulate matter such as Colored Dissolved Organic Matter (CDOM), phytoplankton, detritus, etc). There is also more scattering as a result of sediment from land and these other particles.\nSo, given all of these absorbing and scattering characteristics, satellite bands are selected to try to capture these changes in the optical signature. For example, Colored Dissolved Organic Matter (CDOM), often called gelbstoff absorbs in the blue wavelengths, as does chl a. Chlorophyll a also absorbs in the red wavelengths, which is why plants and phytoplankton often appear green. Pure water absorbs more in the red wavelengths. For those of you who are divers, this is why the deeper you dive the fish and coral will look more blue and start to lose the red colors first. There are also various accessory pigments in phytoplankton with different absorption peaks. There are efforts to use these differences to separate out various phytoplankton types.\nSo, for example, this is showing the various reflectance peaks due to the effects of CDOM absorption, chlorophyll absorption and fluorescence. The atmospheric correction is calculated using the infrared bands. The colored boxes represent the individual bands for each satellite sensor, and also show the width of each band. For detecting certain characteristics, it is important to have narrower bands for certain features, as the light returning back to the satellite is averaged within those wavelengths.\nSunglint can be a problem when using ocean color imagery during certain times of the year.. The angle of the sun can cause a mirror reflection off the sea surface that causes the reflectance to increase at all of the wavelengths. This usually makes the imagery unusable when this happens. However, sunglint can be used to identify oil, due to its reflective nature.\nThere are a suite of ocean color products available from NOAA’s CoastWatch Program. Some are available globally from the various satellite sensors, whereas others are more regional in nature. Normalized water-leaving radiance is available for all of the visible wavelengths. Various chlorophyll a products are available, with regional algorithms in some locations. Kd490, KdPAR and turbidity can aid in assessing water clarity. NOAA ocean color processing includes a QA score which assigns a 0 to 1 score to each pixel, where higher values indicate a likely reliability of the measurement. Through the CoastWatch regional nodes various products are available such as Harmful Algal Bloom products, total suspended sediment, phytoplankton composition and primary productivity, to name a few.\nBriefly, Kd490 (the vertical attenuation coefficient for downward irradiance at 490-nm) describes the rate of change of Ed490 (downward irradiance at 490-nm) with depth. In other words, it is a measure of the loss of blue light which is related to the absorbing particles in the water column. It is inversely proportional to the clarity of the water (the higher Kd490 is, the lower the clarity of the water).\nThere is also a product called KdPAR (PAR stands for Photosynthetically Active Radiation) which measures the attenuation of light available for photosynthesis. PAR covers the light in the visible (400-700 nm) portion of the spectrum. KdPAR can be estimated from satellites using Kd490 and some general assumptions. PAR is an important parameter in marine primary productivity models. As with Kd490, the higher the KdPAR value, the less visible light which is available for photosynthesis.\nPrimary productivity is a measure of the rate of carbon fixation by the phytoplankton during photosynthesis. Primary production can be estimated from satellite using chlorophyll a, PAR, Sea Surface Temperature and daylength, and is an important parameter as input to ocean biogeochemistry and fisheries models.\nThe measurement of phytoplankton size classes and functional groups from remote sensing imagery is an emerging field that is limited by the spectral resolution of the current ocean color sensors. New sensors look to increase the spectral resolution, thereby expanding our capability to better distinguish phytoplankton groups in the sea. We also have models that incorporate several remote sensing products to estimate total primary production, but we need to derive how much of the production is from each size class.\nIn the Chesapeake Bay, Total Suspended Matter (TSM) is available at 250 m spatial resolution, using a regional algorithm developed by Ondrusek et al, 2012. The algorithm is applied to the MODIS high resolution bands at 250 m resolution, on a daily basis. These products provide a spatial overview of turbidity patterns, and due to the high spatial resolution, can provide information on turbidity plumes in the tributaries.\nOther regional products include a suite of experimental bloom products for the Chesapeake Bay. Efforts are underway to validate these products with field collected data from the Chesapeake Bay program. While a prototype website has been developed at CoastWatch to deliver these products for the Bay, we plan to extend delivery of these OLCI products for other coastal regions. Several algorithms are being applied for Chlorophyll a, using a ratio of NIR to Red bands, which is less influenced by sediment and CDOM in coastal areas. An additional Red Band Difference algorithm (RBD) provides a fluorescence product which is useful for detecting high biomass blooms. We are also providing a low-non-fluorescing product as it tends to highlight dinoflagellate blooms of several harmful species. There are several theories as to why this happens, either due to a switch to mixotrophy, when the cells aren’t releasing energy from photosynthesis through fluorescence, or due to low irradiance during winter or high turbidity conditions. A maximum chlorophyll index is also being applied to higher resolution Sentinel 2 imagery, to help resolve harmful cyanobacteria blooms in smaller lakes.\nThis figure demonstrates the current set of ocean color satellites provided by the CoastWatch program. Historical data going back to 1997 from SeaWiFS are available for short-term climate studies. MODIS-Aqua was then launched in 2002, and has been supporting ocean studies ever since. Unfortunately, this sensor is past its design life and has begun to deteriorate. The VIIRS-NPP and NOAA-20 satellites are NOAA’s operational ocean color satellites and support global ocean color monitoring. While the European MERIS sensor, which supported higher resolution ocean color with a set of bands conducive to work in coastal regions, stopped working in 2012, the Sentinel 3 series started in 2016, with follow-on launches every 2 years, to provide 300 m data on a global scale.\nEfforts are underway to merge chlorophyll a products to develop a time-series for climate applications in order to assess long-term trends in ocean ecosystems. The European Space Agencies Climate Change Initiative have developed a long-term time-series of satellite chlorophyll spanning the SeaWiFS, MODIS, MERIS and VIIRS launch periods. This dataset is available from 1997 in weekly and monthly merged products on the West Coast and Central Pacific Node data servers.\nDeveloping a long-term ocean color time-series isn’t easy, as there are gaps in the datasets, and often one satellite may overestimate chlorophyll while others are lower. Therefore, it is necessary to adjust the various ocean color satellite datasets to provide a consistent dataset over time, and to avoid anomalous jumps in the data due to the sensor’s retrieval rather than real climatological changes.\nThe ESA CCI dataset attempts to adjust these ocean color time series to provide a more accurate assessment of ocean color trends over time.\nMost ocean color sensors used to monitor conditions in the U.S. are provided by polar-orbiting sensors. This limits the temporal resolution of the imagery, as these produce a single image per day. Also, ocean color sensors cannot see through clouds, so while daily imagery is available, they may be obscured during cloudy conditions, as well as when glint occurs. Therefore, there is a need for higher temporal resolution from geostationary sensors. The GOCI sensor has been providing OLCI-like spectral bands over Korea since 2010, at 250 m resolution. In the US, a research geostationary satellite, the Geosynchronous Littoral Imaging and Monitoring Radiometer (GLIMR) is expected to launch in 2027. This will provide high temporal resolution over the Gulf of Mexico, parts of the East Coast and South America, at almost hyperspectral spectral resolution.\nThe Plankton, Aerosol, Cloud, ocean Ecosystem (PACE) program is expected to launch a hyperspectral polar orbiting sensor in 2022. There are high expectations for this satellite sensor, as it will provide more information related to phytoplankton pigments to further tease out optical signatures, important to separating phytoplankton functional groups, address coastal biology and physiology, assess particle sizes and to improve absorbing aerosols near land and atmospheric correction properties.\nSo, in summary, when we discuss ocean color imagery, we are generally talking about the visible portion of the electromagnetic spectrum. One caveat is that ocean color imagery cannot see through clouds, and is unavailable at night. Given that 90% of the signature pertains to atmospheric effects, having a robust atmospheric correction is extremely important. There are a suite of ocean color products looking at pigments, phytoplankton blooms and productivity, water clarity and quality. Many of these are regionally based, especially in coastal areas, while there are other products which are available on a global scale. Care must be taken when using data in Case-2, coastal regions, which is why regional algorithms are necessary. The most recent U.S. ocean color sensor, VIIRS, was first launched in 2011, with a subsequent launch aboard NOAA-20 in 2017. While several polar orbiting ocean color sensors have been launched starting with SeaWiFS in 1997, with MODIS and VIIRS following afterwards, long-term time-series are available by leveraging imagery from both US and other global satellite launches, such as the European satellites MERIS and OLCI, to begin to look at climatic changes in the ecosystem. In addition, each satellite has advantages and disadvantages based on their spatial, temporal, and spectral resolution, therefore, it is important to understand the limitations of the products before selecting imagery to address your particular oceanographic question."
  },
  {
    "objectID": "lectures/transcripts/sar.html",
    "href": "lectures/transcripts/sar.html",
    "title": "Synthetic Aperture Radar (SAR) Transcript",
    "section": "",
    "text": "Slide 1\nWelcome to the NOAA CoastWatch module on Synthetic Aperture Radar (or SAR). I’m Chris Jackson and I’m part of the NOAA’s Center for Applications and Research. This module will go over the basics of what a synthetic aperture radar is and how it operates.\nSlide 2\nSo let’s start the course by looking at a Synthetic Aperture Radar image. At first glance it looks very similar to a black and white photograph but instead of recording reflected light, the variation in shading represents variations in the back scattered radar signal. The slide shows a SAR image acquired over Hawaii on 29 May 2022. The islands are clearly visible in light gray. The bright area over the ocean indicates an area of higher winds and the dark areas are the result of the wind being blocked by the island’s topography. The imprints of some storm cells are also visible adjacent to the northeast of the Big Island. This image was collected from the Sentinel-1 C-band SAR in VV vertical / vertical polarization. Later in this module I will explain what is meant by C-band and vertical polarization.\nSlide 3\nThis class consists of three modules. In this one we will give an overview of how a synthetic aperture radar operates. In the module 2 we’ll talk about some SAR data products and where you can get them then in module 3 we will go over imagery examples, pointing out some interesting features that have been observed in various SAR images\nSlide 4\nIn this overview of Synthetic Aperture Radar we will talk about what a SAR measures, why you might want to use it, and how it differs from a regular radar. We will go over the basic characteristics of frequency and polarization and provide an overview of the type of imagery they collect and where you can get access to it.\nSlide 5\nSAR is useful for observing a variety of phenomena. Oceanic phenomena include ocean surface waves, surfactants like oil from an oil spill, sea ice and internal waves. Atmospheric phenomena are detectable by SAR when they interact with the ocean surface. These include convection cells, rain cells and atmospheric gravity waves. Ships and ship wakes are readily visible. Land applications include identifying flooding and inundation or determination of land use. There are many additional applications.\nSlide 6\nAs a remote sensing instrument SAR has several advantages compared to optical sensors: it provides data independent of lighting and cloud conditions, and it can cover a swath width of up to 450 km with relatively fine resolution. And as we noted on the previous slide, it’s useful for observing a wide variety of phenomena. But SAR also has disadvantages: it requires some expertise in order to be able to properly interpret the imagery features, and some specialized software in order to read and calibrate the imagery. In addition, since the SAR is not “always on”, daily coverage is more limited compared to optical sensors like VIIRS which collect continuously. But the traditional barriers of cost and data access have largely been overcome with the Sentinel-1 system launched by the European Space Agency in 2014.\nSlide 7\nRadar is actually an acronym that stands for RAdio Detection And Ranging. Radar sensors transmit pulses and then listen for the backscattered echo, determining the distance (or range) from the time between the two. Since the radar provides its own illumination it can collect data independent of lighting conditions. The radar pulses at microwave frequencies allow for penetration through cloud cover.\nSlide 8\nA radar system is composed of a transmitter,a receiver and an antenna which allows the pulse to be sent out and then listens for the return echo. A radar’s aperture is the physical area of the antenna. Electronics on the system are responsible for creating a well characterized pulse and receiving and recording the echo of the backscattered signal\nSlide 9\nA radar system records the portion of the energy reflected back to the antenna. For smooth surfaces, the transmitted signal is mostly reflected away from the antenna. You can visualize this by thinking about shining a flashlight towards a mirror at an angle. Almost all the light will be reflected in the direction the beam is pointed rather than back to the flashlight. Rough surfaces allow a portion of the radar energy to be reflected back to the antenna. The measure of radar Backscatter is called the normalized radar cross section;\nSlide 10 Here’s a SAR image that was acquired over the Gulf of Mexico on 10th September 2021. It shows how different surfaces reflect different amounts of radar energy. The land in the image is bright because it’s very rough and more energy is backscattered. The ocean surface has different shades of gray indicating the variation in radar return signal. Oil spills and biogenics slicks are very smooth and so they appear very dark. The image shows the boundary of an atmospheric front. Behind the boundary to the north, high winds roughen the ocean surface and return more backscattered energy, but less than the land. Ahead of the front, lower winds over the ocean result in a slightly darker shade of gray. If you also look closely you can see very bright returns from the oil platforms that are on the surface of the Gulf.\nSlide 11 As the previous slide shows, the ocean surface appears in different shades of gray indicating the various amounts of radar backscatter. SAR responds to roughness, more roughness produces more backscatter and thus a brighter return. So where does the roughness on the ocean surface come from? The answer is the wind. The wind moves over the ocean surface interacting with the water and generating small capillary waves. When the capillary waves reach the wavelength of the synthetic aperture radar (approximately 5 cm for C-Band) backscatter from the ocean takes place. This capillary wavefield is modulated by the various oceanographic and atmospheric phenomena allowing their signatures to appear on the SAR image\nSlide 12 The diagram shows a side looking radar on a satellite (all current SAR systems are side looking). The direction in which the satellite travels is called the azimuth or along track direction. The direction the antenna is pointing, perpendicular to the azimuth direction, is the transmission, or range direction. Spatial resolution in the range direction depends on the characteristics of the radar pulse, in particular the pulse bandwidth (the frequency range spanned by the radar pulse). The larger the bandwidth the finer the resolution. In the azimuth direction, resolution depends on the size of the antenna beam which is given by the wavelength divided by the physical length of the antenna. The larger the antenna length, the finer the resolution. .\nThe diagram shows a side-looking radar on a satellite. In the direction parallel to the flight path, which is called the azimuth direction, spatial resolution depends on the radar wavelength divided by the physical length of the antenna. In the direction perpendicular to the spacecraft flight, which is called the range direction, spatial resolution depends on the pulse bandwidth, in other words, the number of frequencies the radar pulse spans. The larger the bandwidth the finer the resolution. In real aperture radar systems the resolution in the range direction is on the order of meters, while the resolution in the azimuth direction is on the order of kilometers.\nSlide 13 In order to achieve Azimuth resolutions comparable to range resolution, the spacecraft would need an antenna several kilometers long. Since this is physically unfeasible, signal processing is used to combine the many radar returns from the time an object is within the radar beam to improve the azimuth resolution. By taking advantage of an object’s Doppler shift, a larger antenna can be SYNTHESIZED, and an azimuth resolution comparable to the range resolution can be achieved. This explains why it is called SYNTHETIC aperture radar.\nSlide 14 This slide shows the concept of a synthetic aperture length. The spacecraft is moving from right to left. At time t1, the location labeled “point target” crosses the leading edge of the antenna beam. At time t2 the antenna is directly perpendicular to the target, and at time t3, the target crosses out of the beam. The distance traveled by the antenna in the time between t1 and t3 is the synthetic aperture length. For a SAR system with a beam width of a ¼ degree, this distance is approximately 3.5 km with the spacecraft in a polar orbit around 700 km altitude.\nSlide 15 To review, The SAR actively transmits a well characterized pulse. The radar returns over the time an object remains within the antenna’s coverage are coherently combined to improve the along-track or azimuth direction resolution. The distance traveled by the antenna in this time is the synthetic aperture length.\nSlide 16 Synthetic aperture radars can operate at a variety of frequencies. Radar frequency bands are designated by letters, and are shown here from lowest to highest frequency. The Sentinel-1 and Radarsat Constellation Mission systems operate at C-band, approximately 5 gigahertz in frequency, and with a wavelength of approximately 6 cm.\nSlide 17 The choice of radar wavelength or frequency depends on both the application of interest as well as engineering considerations like antenna size and power requirements. To date, all the satellite based SAR systems have operated between L-band and X-Band. Lower frequency, longer wavelength radars are more applicable for land applications because of the many objects that appear “rough” at &gt; 30 cm wavelength. X-Band systems require a smaller antenna for the smaller wavelengths and can produce high resolution on the order of 1 meter in the range direction, but have a more limited image footprint. C-band turns out to be a good compromise frequency requiring a medium sized antenna of approximately 12 m in length while also producing wider area coverage.\nSlide 18\nThis slide graphically shows the effect of wavelength on scattering. High frequency X-Band signals scatter from small objects while lower frequency L-band waves scatter from larger objects. The top row shows X-Band scattering from the tree leaves and L-band scattering from the tree trunks. In the bottom row X-band can be seen scattering from the top of the snow pack while the L-band penetrates the snow reflecting from the surface underneath, either land or sea ice.\nSlide 19 A basic characteristic of the SAR radar signal is polarization. Polarization refers to the orientation of the electric field in the electromagnetic wave. A SAR will transmit either a horizontally or vertically polarized wave. The system can then listen for backscatter in either the same polarization as it transmitted, called co-polarization or it can receive in the opposite polarization called cross polarization. Co-polarization signals are either VV (vertical vertical) or HH (horizontal horizontal) Cross polarization signals are VH (vertical transmit / horizontal receive or HV (horizontal transmit / vertical receive). The amount of back scatter received in a particular polarization tells you something about the characteristics of the object being observed.\nSlide 20 This slide shows a Radarsat-2 image collected in January 2020 over sea ice just off the north coast of Canada. The radar transmitted both horizontal and vertical signals and recorded both horizontal and vertical returns.\nSlide 21 You can see the effect of polarization on scattering in the lower right quadrant of the image where the scattering from one portion of the sea ice is strong in the HH polarization but much weaker in the VV polarization. This tells us that the sea ice in that area is different in some way to the sea ice in other parts of the image.\nSlide 22 Polarization and scattering are intimately connected. The amount of energy back-scattered from an object is influenced by the polarization of the incident wave. We saw this on the previous two slides where sea ice in certain areas returned a greater amount of the HH polarized wave compared to VV. This slides provides some general rules with regard to polarization and backscatter. SAR collections using multiple polarizations allow the user to determine additional information about the object being observed.\nSlide 23\nWe have talked about the concepts of synthetic aperture and backscatter as well as the basic radar operating parameters like frequency and polarization. This slide shows how a satellite SAR, in this case Sentinel-1, takes its observations. Sentinel-1 has three imaging modes: Stripmap, Interferometric Wide and Extended Wide. Stripmap mode has an 80 km swath that can be placed at different positions. IW and EW modes each combine multiple beam positions to produce swath widths of 240 and 400 km, respectively . Early SAR systems had only a single collection mode, but since Radarsat-1 launched in 1995, SAR systems have been designed to collect imagery using a variety of beam modes, which provide flexibility in terms of coverage area and resolution. For example, the Radarsat Constellation Mission has 11 different modes allowing the system to support operations from the monitoring of broad geographic areas to high resolution collections over very focused areas to support disaster response.\nSlide 24\nUnlike most optical sensors, for example VIIRS, MODIS or Landsat, the SAR does not operate 100 percent of the time. Engineering constraints allow the system to collect data only over about 30 percent of every orbit. The SAR collections are all scheduled in advance and the collection pattern will change from day to day. Sentinel-1 for example is in a 12 day repeat orbit, which means its data collection pattern is basically the same every 12th day. This was a big change to the way SAR collections were done in the past. This slide shows the difference in the collections between Sentinel-1 and the VIIRS system on 29 March 2021. It highlights the difference in total collection area. Note that compared to VIIRS, the SAR has a smaller swath width but much higher spatial resolution.\nSlide 25 You can get Sentinel-1 data from the Coastwatch Website. Go to the L1/L2 Spatial Search Tab and then click the radio button for S1A or S1B NRCS. The imagery are available in NetCDF format and preview PNG images can also be found..\nSlide 26 Imagery from a variety of SAR systems are available at the Alaska Satellite Facility through their Vertex search page. The user can filter the results on geographic region, on time, and on data format and collection characteristics (e.g beam mode).\nSlide 27 Sentinel-1 SAR imagery is also available directly from the Copernicus Open access Scientific Data Hub. The user selects the Sentinel satellite of interest and the data processing level, and can then search over a specific region and or time period.\nSlide 28 A useful tool to get started working with SAR data in its native format is the SNAP toolbox available from ESA. The software allows the user to work with nearly all the data from the Scientific Data Hub and the Alaska Satellite Facility, performing operations like calibration or image subsetting."
  },
  {
    "objectID": "lectures/transcripts/satcourse-pt2.html",
    "href": "lectures/transcripts/satcourse-pt2.html",
    "title": "Satellite 101 Part 2 Transcript",
    "section": "",
    "text": "Welcome to Part 2 of Satellite 101, part of an online course on oceanographic satellite data products, produced by NOAA’s CoastWatch Program. My name is Cara Wilson, I’m the node manager of the West Coast Node of NOAA’s CoastWatch Program. The materials that I will be presenting in this video were produced from a collaboration from many members of NOAA’s CoastWatch Program including Dale Robinson, Melanie Abecassis, Ron Vogel, Shelly Tomlinson, me and the late Dave Foley.\nIn Part 1 I gave an overview of available oceanographic satellite products and presented the different types of orbits, resolutions and spatial coverages and other general information. In this presentation we will get into some of the nitty gritty details about how satellite measurements are made. I will discuss how light propagates through the atmosphere and water column, and back out to the satellite sensor. I will introduce the different types of sensors and get into some of the details of how measurements are made. We also have additional presentations that go into greater detail about how certain measurements and products are made.\nAs satellites fly over a region of the ocean, its sensors record light, or electromagnetic radiation, within its field of view. The radiation measured by the satellite has either been emitted by the ocean, or has been emitted by the sun and reflected by the ocean. In both cases the radiation passes through the atmosphere before being received by the satellite sensor. There are multiple processes that can affect the signal as it passes through the atmosphere.\nThe atmosphere between the satellite and the ocean surface has big impacts on the signal that we want to measure. It can scatter or absorb the energy so that it is not detected by the sensor. Scattering of the energy can also result in detection of energy that is not coming from the ocean, and needs to be accounted for. Accounting for the absorption and scattering of energy in the atmosphere is part of the atmospheric correction process that is undertaken as part of creating usable products. A lot of corrections are necessary in order to obtain accurate estimates of the ocean phenomenon that we are measuring.\nLet’s talk about electromagnetic radiation, or EMR, in more detail. As energy is emitted from the sun and the surface of the Earth, photons travel at different wavelengths. The EMR spectrum is divided into bands by wavelength ranges. Wavelength bands useful for remote sensing are in the visible, infrared (IR), and microwave wavelengths, which is the area indicated by the shaded box on this slide.\nPlanets and stars emit radiation, called black body radiation. There is a close relationship between the spectrum of the light they emit and their temperature. The lower their temperature, the weaker the intensity of the light they emit, and the higher their peak wavelength, as can be seen here in the graphs of emission intensity versus wavelength for a number of different temperatures.\nIf we compare the sun’s emission vs the earth’s emission, we can see that because the sun is much warmer than the earth, the intensity of its light is much higher, and its spectrum peaks in the visible, whereas the Earth’s emission peak is at longer wavelengths in the thermal infrared, with a much weaker intensity. The light that is received by the satellite sensors is a combination of the two and their interaction with the atmosphere.\nEarth is not a perfect black body, meaning that other properties aside from temperature impact how effectively radiation is emitted from the earth. Emissivity is a measure of how effectively an object emits thermal energy. And we can take advantage of the changes in emissivity to measure different properties in the ocean. For example, while water and sea ice have a similar emissivity in the infrared, their values in the microwave portion of the spectrum are very different, allowing for differentiating sea ice from water.\nThe influence of the atmosphere depends on the wavelength of electromagnetic radiation. The atmosphere is opaque to radiation at many wavelengths, due to the absorption by atmospheric gasses, these are the areas shown in black on these graphs. There are only certain wavelengths through which radiation may be fully or partly transmitted. Remote sensing focuses on those transmission ranges, the so-called atmospheric windows, which are the non-black regions.\nTransmittance is the opposite of absorption. Where there is a little absorption, there is high transmittance. Satellites can see the earth, through the atmosphere in the regions of high transmittance, the white areas on this figure. X-Ray and shorter Ultraviolet wavelengths are almost totally attenuated, therefore these EMR bands are less relevant for remote sensing. In the visible wavelengths, where the sun emits at the highest intensity, the atmospheric transmittance is high. At higher wavelengths, transmittance is reduced to narrow bands. This includes the optical windows in the thermal infrared, where the Earth’s surface emits radiation. In the microwave, the atmosphere is nearly transparent, but radiation from the sun and earth is weak, so we need large antennas to collect enough radiation.\nAs I mentioned earlier, sensors measure electromagnetic radiation that is either reflected or re-emitted from the ocean. Light from the sun passes through the atmosphere and if it reaches the ocean surface it may reflect off of the surface or pass through it. Photons entering the water will either be scattered or absorbed. If absorbed, phytoplankton, non-algal particles, colored dissolved organic matter, called CDOM, or water itself will absorb the light. If scattered, it will do so in either the forward or backward direction. If in the backward direction, some of it will be re-emitted from the sea surface and will be detected by a sensor. We are interested in the remote sensing reflectance, at specific wavelengths, and from these we derive the concentration of chlorophyll and other products. More details are given about this in our presentation on ocean color.\nIdeally, we want to measure all of the signal within the sensor s footprint or field of view. In reality, not all of the signal makes it to the sensor. In addition, stray emissions from outside the footprint add noise to the signal reaching the sensor. In the diagram, the rays in green show the fates of the signals coming off the ocean that we want to measure. Some of the rays make it to the sensor. Others are either absorbed by the atmosphere or scattered out of the sensor’s field of view. The red rays represent the stray radiation reaching the sensor from outside its footprint on the sea. Atmospheric corrections are needed to account for the missing signals, and remove the extraneous ones.\nSome of the atmospheric components that scatter or absorb the ocean signal are well-mixed, like oxygen and nitrogen, but others are not. The distributions of water vapor, ozone and aerosols are very heterogeneous, and these components must be measured in order to correct for their impact on the satellite signal.\nSo to sum up, a lot of different processes that affect EMR need to be accounted for and corrected for, in order to get accurate measurements. This course focuses on the application of the finished products, but recognizes that it’s important to understand a bit of the sausage making that has gone into the generation of these products.\nDepending on the application they were designed for, sensors measure different parts of the electromagnetic spectrum. There are sensors that operate in the visible, the infrared, and microwave sensors, including radar instruments. Sensors target specific wavelengths depending on their application. Some products can only be measured in one part of the spectrum, for example ocean color can only be measured in the visible, whereas sea-surface temperature measurements can be made in both the infrared and the microwave portions of the spectrum.\nThis slide maps out examples of the sensors and applications that are each part of the spectrum. In the yellow box are sensors that operate in the visible, which include SeaWIFS, MODIS, and VIIRS, the primary sensors for measuring ocean color. From ocean color measurement we can derive chlorophyll concentrations, turbidity and a whole suite of other products. Measurements of sea ice are made in both the near-IR and in the microwave. Other measurements made in the microwave include sea surface height, currents, wind, salinity and temperature.\nThere are two basic technologies used for satellite sensors. Passive sensors detect radiation from two natural sources, the sun and the earth. Active sensors measure signals that are reflected back from a pulse of energy sent down by the sensor. Most of the sensors used for oceanographic remote sensing are passive. Examples of active sensors are altimeters, scatterometers, lidars, and radars. This is an animation illustrating those two concepts.\nIt takes time to do all the processing necessary for atmospheric correction as well as performing quality-control. Science quality data has undergone rigorous processing and, depending on the product, can have latencies between a few weeks to a few months. For analyzing trends over time it’s best to use science-quality data. However, some applications need data as soon as possible. To accommodate this need, some products are also offered as near-real time products, with a latency of hours to days after collection. Near-real time products have undergone a less rigorous processing and so should be used with caution.\nThis concludes part 2 of the Satellite 101 presentations. We have additional presentations that go into greater details about how measurements are made for ocean color, sea-surface temperature and altimetry, winds and salinity."
  },
  {
    "objectID": "lectures/transcripts/select-arcgis.html",
    "href": "lectures/transcripts/select-arcgis.html",
    "title": "Selecting and Using Data in ArcGIS Transcripts",
    "section": "",
    "text": "This training is one part of several tutorials within the NOAA CoastWatch Satellite Training Course. The GIS tutorials consist of 3 modules and although the screenshots and examples use ArcGIS, the principles apply to any GIS software packages.\nIn this module, we will cover tools or methods in bringing satellite data into the GIS.\nIn the Data module, we saw there are essentially two types of satellite products – imagery and data. In most cases for analysis, we’re wanting to bring in the data and there are multiple ways of doing this by leveraging hooks built-into the GIS, added extensions, or external data preparation software such as the CoastWatch Utilities.\nSince data will usually become a raster layer within the GIS, the Spatial Analyst extension is quite useful in interacting with the raster layer. In addition, the NOAA Environmental Data Connector is tailored for extracting multidimensional data from online services such as THREDDS/ERDDAP. The CoastWatch software provides functionality to reformat satellite data from the scientific data formats HDF or NetCDF to GeoTIFF, export data to CSV, and additional features including mapping, masking, and compositing data.\nLet’s first look at some of the built-in features of getting satellite data into ArcGIS. In most cases we’re discussing NetCDF files or service-provided data – where NetCDF is usually the underlying source format. These methods also work with HDF files. ArcMap allows you to add data using services such as WMS & WCS . Drag-n-drop. The Multidimension Toolbox supports the import by file or service (OpenDAP), and in some versions of ArcGIS you can use Python or Jupyter notebooks to work with data.\nLooking more in depth, to access the WMS or WCS service you use the Add Data icon. A web mapping service (WMS) returns a map or image whereas the web coverage service (WCS) returns data values. These services work OK for a single image and time step, but can be network intensive as each Pan/Zoom/Identify (or PZI) event in the GIS requires a refresh. Both of these services require a GetCapabilities URL from which to dynamically self-configure. And although the THREDDS and ERDDAP servers in NOAA have those services, it’s not always easy to find the URL associated with specific datasets. Additionally WMS and WCS do not handle time series.\nAnd even when it looks like it’s going well, you may encounter errors.\nProbably the easiest way of adding a datafile to the GIS is simply dragging a downloaded file and dropping it into the map view. If the file contains metadata and the variable or parameter (i.e. Turbidity) of interest is the first listed, you will then just need to add symbology and enable time – if warranted.\nIf the file contains more than one variable, you will most likely need to use another way like the multidimension toolbox.\nOne of the tools within the multidimension Toolbox is the ‘make OpenDAP Raster Layer.’ This is essentially the ArcMap version of a THREDDS OpenDAP page or ERDDAP GRIDDAP page. You merely enter the base url of the OpenDAP service for your desired data – again, not always easily found– enter the variable and any subset information and it’ll import the data. I’ve had mixed results with this tool, but when it works it does a good job. You will need to add some symbology and enable time to maximize its usefulness and enable time. . Because this requests data from external OpenDAP service, it’s similar to WMS or WCS in that there are some server-side limitations that may cause the tool to fail or to be too slow to be practical. We’ll talk more about OpenDAP later.\nMake NetCDF Raster Layer is the most reliable method of ingesting NetCDF data. You will first need to download the data from whichever source you identified, which can be, THREDDS or ERDDAP, and save it to your computer in the netcdf format. Once the data are imported using the Make NetCDF Raster Layer tool, you will need to add some additional configuration to fully utilize the data.\nAfter importing and once the Raster Layer has been added to the map view, you’ll need to use Layer Properties (just a right-mouse click) on the layer to open the dialog. First, adjust the symbology. This is the assignment of a color ramp to data values.\nNext, use the NetCDF tab to ensure the X and Y point to the correct variables and that if applicable, time is included as a dimension.\nFinally, if applicable, enable time under the time tab. You will probably need to adjust the time stop interval and go ahead and click the Calculate button to verify the time extent. Click Apply or Ok and return to the map view.\nTo make use of the temporal range of the data, enable the Time Slider by clicking the icon. The slider can be used to view a particular time step or generate an animation of the data over time.\nTo retain the data, you need to store it in a geospatial database. Right-mouse-click on the layer, select Data and ExportData to open the dialog. Set the geodatabase for your project or leave as the default and export the data. It may pass back to your map view.\nSo, in summary above the line, we see the two most reliable methods to get data into ArcMap are Drag-n-Drop and Multidimensional Toolbox. Let’s look next at the Environmental Data Connector.\nThe EDC bridges the online service and file import by providing a GUI to connect to the service. What this means is that you only need to give it a high-level THREDDS/ERDDAP URL and then find the dataset – in a user-friendly way – to import into your GIS. The tool can be downloaded from the CoastWatch West Coast Node and the URL is included again at the end of this presentation. A user guide is also available.\nBut first, you need to install the add-on. The Installation will create a standalone directory for programs and interim output data. On managed systems, it’s best to install as an admin for a single-user. If that is not permitted, then the output directory permissions will need to be set or linked for user access. Once installed properly, it will have added a Menu item to ArcMap, though it can be run as a standalone to fetch data. If all works well, the tool will fetch data, import as raster, add default symbology, add data to the geospatial database, and load a custom time slider that shows the temporal overlap if multiple data time series are loaded.\nThe tool is activated by clicking the EDC menu item. The EDC dialog opens and when a URL is connected, the data listing will appear on the left. Once a dataset is selected, the URLS are available or you can continue with the tool by clicking the GRIDDAP button.\nThe GRIDDAP button will add a tab to the window allowing specific subsetting information to be entered. Subset criteria can be entered either by typing the desired extents or using the map interface. Illustrated here, is the extent of the data (red) with the desired subset area highlighted as light red. Additional settings or variable, output and time were set prior to clicking ‘Process’.\nOnce process is clicked, the tool will obtain or fetch the data and add it to the map view. All of the Layer Property tasks have been completed by the tool including enabling time. Zooming in, and adding a land shapefile, we see the subset is where we expect it to be from our initial map selection.\nUsing the tabs in the EDC window and the map selector, you can load multiple datasets and even grab data in custom polygon shapes or load a track. The user guide defines the fields and CSV format for track data. The time slider adjusts and shows the temporal coverage of multiple time-enabled data. This could be useful for making a time series or ensuring the data overlap of multiple layers is correct.\nAnd for completeness, you can get data ‘manually’ from services such as OpenDAP, THREDDS, and ERDDAP. Most have a user interface, though not as friendly as the ArcGIS and EDC menus.\nOpenDap is useful to subset the dimensions of aggregated data, retrieve dataset attributes, or structure.\nTHREDDS Data Servers integrate multiple services such as WMS, WCS, OpenDAP, NetCDF Subset, and metadata. ERDDAP integrates services but in a much easier way. ERDDAP also has an array of supported output formats and is a RESTful service, meaning the requests of the service are made and preserved in a hyperlink. Ok, now that we know how to get the data into our GIS, there are a few things to keep track of.\nWhen comparing data, you need to ensure the units are similar. Often, satellite SST may be in Kelvin and in situ measurements in Celsius. Easy enough to convert, but something to pay attention to. Same thing with time. Most data are with respect to UTC, but use the metadata to make sure. Our GISs in map view usually default to -180 to 180. Data may split over the dateline with Western longitudes at the left edge of the map and Eastern Longitudes on the right. Also, some data providers may provide data in 0 to 360. The GIS can perform operations on the data, but if it is desired to display across the dateline, some modification to input data is required. Usually, putting the data in 0 to 360 or extending Western longitudes (i.e. beyond -180) will work. Finally, as discussed in the Data module, ensure your data are using the same projections and units. ArcMap will usually take on the projection of the first dataset loaded and transform/reproject other data to match it, which may not be appropriate. Similarly, make sure the ellipsoid and datums are defined and match for your data.\nThis concludes the Using Satellite Data in GIS Tools module. The Environmental Data Connector can be obtained from the CoastWatch West Coast Node link listed here. Refer to the user guide to see all the capabilities as they were not all covered in this tutorial. An online ‘adding data to GIS’ tutorial is also available at our West Coast Node. The next module in this ArcGIS series is the ArcGIS exercise. Thank you for your interest in NOAA CoastWatch!"
  },
  {
    "objectID": "lectures/transcripts/tools-strategies.html",
    "href": "lectures/transcripts/tools-strategies.html",
    "title": "Tools and Strategy Transcript",
    "section": "",
    "text": "Welcome to the online course on oceanographic satellite data products, produced by NOAA’s CoastWatch Program. In this module we will present strategies for discovering, accessing, and downloading ocean satellite data, and some tools you can use to accomplish these tasks. My name is Cara Wilson, I’m the node manager of the West Coast Node of NOAA’s CoastWatch Program. The materials I will be presenting in this video were produced from a collaboration from many members of NOAA’s CoastWatch Program including Dale Robinson, Melanie Abecassis, Ron Vogel, Shelly Tomlinson, me and the late Dave Foley.\nFor many people, discovering, accessing, and downloading ocean satellite data can be challenging. There are dozens of data providers online, each with its own:\ndata products, file formats, download protocols, subsetting abilities, and previewing abilities.\nAt CoastWatch we believe that getting data should not be difficult. People experienced with using satellite data typically have a strategy for finding satellite data that works for their application. If you are new to satellite data, suggest the following strategy to get you started. To start with, use online data viewers to explore datasets and to look for interesting ocean features. Next, develop a basic understanding of the data file formats used with satellite data and how they can benefit working with the data. Finding a good viewer for visualizing the data in the files will also help you work with the data. Find a good online site with an easy to use data server, for accessing and downloading data. In this course we will focus on using ERDDAP. Next, steal, I mean, borrow code from other people. There is no need to start from scratch. You can improve and customize existing code for your purposes. There are even code packages written in languages like R, Python, and MATLAB specifically developed for working with satellite data. We go into this in further detail in the tutorials. Finally, there are software plugins available to help with bringing data into applications like ArcGIS. We will be exploring all of these during this course.\nTo start a project or to look for interesting ocean features, a great place to start is to use an online data viewer. The viewers allow you to explore a variety of datasets and examine your area of interest. Using data viewers is like looking through department store windows: they let you shop around before you buy. There are many good data viewers available. I’ve listed a few below, including the CoastWatch viewer. Try visiting one of these sites and explore a few datasets that are of interest to you.\nIf you will work a lot with satellite data, you will need to get familiar with the netCDF file format, as most satellite data is delivered in this format. Why NetCDF? The files are self-describing, meaning they contain all the information you need to use the data, including geographical and temporal coverage, details about how the data were processed, how you are allowed to use the data, and who to acknowledge if you use the data. The files are portable. They can be used by all computer platforms. The binary format is compact, so file sizes are smaller.\nIf you are using netCDF, it is helpful to use a good netCDF viewer. A good one is NASA’s Panoply. With Panoply you can map the data, reproject maps, save the maps as images, see data and metadata, and much more. Of course if you want to do any more complicated analysis of the data you will need to use software like R, python or ArcGIS. There is a tutorial assignment in your syllabus where you will find out more about netCDF and Panoply.\nFor the workshop, we will get most of our data from the ERDDAP data server\ndeveloped at SWFSC by Bob Simons. ERDDAP gives you a consistent way to download data, the option to subset in time and space, and the choice to download the data in your preferred file format. ERDDAP has both a human interface and machine to machine capabilities.\nHere is how it works. On the data catalog side, ERDDAP can host local files. But one of ERDDAP’s strengths is that it can serve data from other remote servers. Remember that list of data servers from many different data providers that I showed on the first slide? ERDDAP can point to those servers and pull data from them when you make an ERDDAP request. So, you don’t have to learn how to get data from all of those other servers. You just have to know one way, the ERDDAP way. On the data distribution side. You can get data by hand with the ERDDAP web interface. You can pull data directly into software apps. You can get data with automatic scripts for machine to machine data exchange. You can use ERDDAP as a backend for web applications. Maybe you want to build a website about your project. You can pull data directly from ERDDAP to populate websites with data or images. This is made possible by Restful URL, where an entire data request is defined in a single URL. There is a tutorial assignment in your syllabus where you will find out more about ERDDAP.\nSome talented people have developed software libraries to help you access data from ERDDAP. One that we use in the course is RerddapXtracto, a package for R developed by Roy Mendelssohn at SWFSC ERD. The package helps you accomplish some common tasks that fisheries and management people often need, like getting satellite data at stations along a cruise or animal track, and getting satellite data from a polygon shaped area over time. Coastwatch also provides sample code in R and Python to help get you started developing your own code. You will find a lesson and a tutorial on the RerddapXtracto package in your syllabus. There are also tutorial assignments in your syllabus where you will find sample R and python code.\nThe ERD and CoastWatch West Coast Node also commissioned the development of the Environmental Data Connector. The Environmental Data Connector is a plug-in for ArcGIS that makes it easy to bring raster data into ArcGIS. It is particularly helpful to bring in spatial data with several time steps. You can also use it to extract data from station locations and from a specified area over time. There is a tutorial assignment in your syllabus where you will find out more about using the EDC.\nLastly there are multiple different CoastWatch nodes, all geared towards a particular geographical region. The West Coast node has a lot of datasets with global coverage, but if your study area falls within the domain of one of the other nodes of CoastWatch you might want to check out those nodes for regional products. This concludes this presentation. Thank you for listening, I hope you have found it useful"
  },
  {
    "objectID": "lectures/transcripts/wq.html",
    "href": "lectures/transcripts/wq.html",
    "title": "Water Quality Transcripts",
    "section": "",
    "text": "[Slide 1]\nWelcome to the online course on oceanographic satellite data products, produced by NOAA’s CoastWatch Program. In this module we will discuss how satellite data can be used for water quality applications. The information presented here builds on the concepts discussed in several of the course’s earlier modules, including Satellite 101, Sea Surface Temperature, Ocean Color, and the one covering Wind, Salinity, and Sea Surface Height. You might want to review those modules first before viewing this module. My name is Cara Wilson, I’m the node manager of the West Coast Node of NOAA’s CoastWatch Program. The materials I will be presenting here were produced from a collaboration from many members of NOAA’s CoastWatch Program including Dale Robinson, Melanie Abecassis, Ron Vogel, Shelly Tomlinson, Andrea VanderWoude, Betty Staugler, V Wegman and myself.\n[Slide 2]\nThere are a lot of satellite derived parameters that can be used for water quality monitoring as indicated by the list here. However, there is also a great deal of variation in the maturity and availability of these parameters. Some products, like sea-surface temperature and chlorophyll are quite mature, routinely used and relatively easy to find. As we go down this list the products become less mature and products like bottom substrate and surface oil slicks, are data that are produced regionally and/or sporadically. In this presentation we will go over all of these parameters in further detail and let you know where these different data products are available from. This course focuses on the use of “off the shelf products”, so the intent is to help you find existing data. Our intent is not to walk you through the algorithms to create these products yourself.\n[Slide 3]\nOne of the difficulties new users of satellite data often face is understanding the terminology used in the satellite community, which might not always coincide with terminology used for in situ observations. On the left we have a list of common observations made in situ, and on the right the corresponding satellite name. Some are fairly straight forward. In the field you measure water temperature, and satellites measure sea surface temperature, or lake surface temperature. The inclusion of “surface” in the satellite product terminology is important, as it demonstrates a weakness of satellite data compared to in situ data in that it just makes surface measurements, and doesn’t give any depth information. For field observations one often talks about turbidity or water clarity, but in the satellite community we call this the “diffuse attenuation of light at 490 nanometers” or Kd490 for short. That’s an obvious translation, right? This water quality module was designed to try to help bridge the communication gap between what water quality managers want and what satellite data can provide.\n[Slide 4]\nOne of the other big differences between satellite data and in situ data is their measurement scales. Satellite data can provide much better spatial and temporal coverage than one can achieve with in situ measurements. This slide is actually somewhat misleading because the two panels on the left, showing the spatial coverage of satellite data, also show the chlorophyll pattern with depth which of course one can not obtain with satellite data, but which one does obtain with in situ sampling, which is represented on the right-hand panel.\n[Slide 5]\nThere are other parameters that can be inferred using satellite information but that can’t be directly measured by satellites. These include algal toxins for which a number of algorithms are being developed, but the relationships between watercolor and algal toxicity is so variable that this is very challenging. Because nutrients influence algal growth where they are a limiting factor, it’s possible to statistically estimate nutrients from water color, even though nutrients can’t be measured directly by satellite. Similarly, because of their relationships with other parameters, it’s sometimes possible to get indirect information about dissolved oxygen or pollutants.\n[Slide 6]\nWe showed this slide in the ocean color presentation, but let’s revisit it again to review what ocean color satellites can measure. Different water constituents have different absorption and scattering peaks, and satellite bands are selected to capture these changes in the optical signature. For example, Colored Dissolved Organic Matter, or CDOM, absorbs in the blue wavelengths, as does chl a. Chlorophyll also absorbs in the red wavelengths, which is why plants and phytoplankton often appear green. Pure water absorbs more in the red wavelengths. For those of you who are divers, this is why the deeper you dive, the more fish and coral will appear blue and start to lose the red colors first. There are also various accessory pigments in phytoplankton with different absorption peaks. There are efforts to use these differences to separate out various phytoplankton types. In addition, scattering due to the particles in the water (phytoplankton, sediment, detritus) occurs in the red wavelengths, therefore affecting turbidity.\n[Slide 7]\nThere is a whole suite of different products that are generated from ocean color satellites. Chlorophyll, which is shown around Hawaii, on the left hand image, is the most widely used. But there are other products like Kd490, shown here off of Washington State, KdPAR, and products that estimate sediment and phytoplankton composition. In this presentation we will go over all of these products in greater detail. Some are available globally, whereas others are regional. These products are all available through the CoastWatch regional nodes.\n[Slide 8]\nTemperature is an important and widely-used parameter when looking at water quality. Satellites have been measuring Sea Surface Temperature routinely since the 1980s. SST can be measured in the infrared and in the microwave, and from polar orbiting and geostationary satellites. When combined into blended products, these different types of measurements are complementary and provide near complete global coverage on a daily basis. Many SST products are available from CoastWatch, from single-sensor high-resolution products to gap-free blended products with a coarser spatial resolution. Satellite data is also used to get lake temperatures, as shown here in the image of temperatures for the Great Lakes. More information on SST can be found in the “Fundamentals of SST” presentation.\n[Slide 9]\nChlorophyll is the most mature product measured by ocean color sensors. Since all phytoplankton contain chlorophyll, satellite-derived chlorophyll can provide an estimate of phytoplankton abundance. The global satellite chlorophyll products work well in clear open ocean waters, where changes in optical properties result mainly from changes in phytoplankton and CDOM concentrations. These waters are called Case 1. In other waters, including coastal and inland waters, optical properties are also determined by suspended sediments and terrestrial runoff. In these optically complex waters, called Case 2 waters, the global satellite chlorophyll product can be much less accurate and often overestimate chlorophyll concentration. The image shows chlorophyll concentrations off the US East Coast using the global product. Note the very high chlorophyll concentrations in the waters close to the coast. Because these are Case 2 waters, the satellite measurements may be overestimates. Some chlorophyll products have been produced that take into account to the complex optical properties of Case 2 waters, especially for US and European regions, but they are regional in spatial coverage. More information on chlorophyll can be found in the “Fundamentals of Ocean Color” presentation.\n[Slide 10]\nAlgal blooms are rapid increases in phytoplankton concentration in fresh, coastal and marine waters. Measuring algal abundance using satellite data depends on the type of algal bloom and the region of interest. Regional algorithms must be tuned to their unique optical and biological properties. Some algorithms look at specific optical characteristics of the algal type, whereas other methods use large increases in chlorophyll concentration as an indicator of new blooms. In coastal areas, algorithms that look at the changes in the chlorophyll absorption in the red and near infrared wavelengths are used as they are less impacted by CDOM. Regional monitoring and forecast systems for algal blooms have successfully used products that look at relative abundance rather than absolute cell count estimates. In particular, some models and monitoring systems use satellite imagery to monitor for new blooms or conditions that might produce Harmful Algal Blooms, or HABs. These are high biomass algal blooms which contain toxins and are a concern for public, marine and ecosystem health. For example, the Cyanobacteria Index image of Lake Erie, shown in the upper right, shows a toxic cyanobacteria bloom in September 2021. Higher algal biomass can be seen in the western portion of the lake. The Relative Fluorescence product in the lower right shows a toxic Karenia brevis bloom off the coast of Florida. Reds and yellows indicate higher concentrations of algae, where chlorophyll is greater. The NOAA and the CoastWatch program distribute several regional experimental products for lakes and coastal waters that can be accessed via the links in the yellow box.\n[Slide 11]\nThe measurement of phytoplankton community composition from remote sensing imagery is an emerging field that is limited by the spectral resolution of the current ocean color sensors. New sensors look to increase the spectral resolution, to expand our capability to better distinguish phytoplankton groups in the ocean. Phytoplankton Community Composition includes phytoplankton taxonomic class, phytoplankton size class, and also particle size distribution. Different types of experimental algorithms are being developed. You might be wondering how PCC relates to PFTs, or Phytoplankton Functional Types. There are in fact the same thing, but the community has decided that Phytoplankton Community Composition is a more accurate term.\n[Slide 12]\nI’ve already mentioned CDOM a few times in this presentation. CDOM stands for Color dissolved organic material, and is a fraction of the dissolved organic pool. Older terms for cdom are gilvin, and gelbstoff, which is German for “yellow substance”. As the name implies, CDOM influences the color of the water and absorbs primarily in the blue and UV wavelengths. The highest concentrations of CDOM are usually nearshore because of the breakdown of plants and organic matter. CDOM plays a large role in aquatic photochemistry and can be used as a tracer for water masses.\n[Slide 13]\nLet’s talk next about turbidity and light attenuation. These are related, but they are different optically. Turbidity is the amount of scattering by the particles in the water. Many types of in situ measurements are used in the field to measure turbidity such as nephelometers, turbidimeters and similar instruments. In remote sensing, we usually use the reflectance in the red to near IR portion of the electromagnetic spectrum as an indicator of relative turbidity. Relative change in turbidity is a better indicator of water visibility than light attenuation. Light attenuation, Kd, on the other hand, indicates the loss of light as you move deeper in the water column and is related to both the absorption and scattering properties of the surface water. Kd at 490 nm is generally used to quantify light attenuation, as it captures the maximum chl absorption due to algal pigments. Notice that Kd has units of inverse meters. In waters dominated by sediment, Kd is approximately 1 over secchi depth.\n[Slide 14]\nSo, in more relative terms, water clarity is a catch-all term describing how clear the water is, and can be influenced by the turbidity of the water due to the scattering properties of the particles. Water clarity is influenced more by turbidity than light attenuation. In this example, as more sediment is added to a body of water, turbidity increases as it is related to the amount of scattering particles. This corresponds to a decrease in clarity.\n[Slide 15]\nSediment, like mud, silt, sand and organic particulates, can be generated from rain runoff from land, or from wind events over nearshore water, and is highly visible in true color images, as shown here on the left, and also in satellite imagery at red wavelengths. The remote sensing reflectance, or Rrs, in the red portion of the electromagnetic spectrum, at approximately 670 nm, is often used as a relative indication of the amount of sediment in the water. The image on the right shows the remote sensing reflectance at 671 nm for the same time period as the image on the left, although the maps are not at the same scales. The Rrs at 670 is referred to as an index because it is a relative measure. It is not an absolute measure of sediment, so it is only used to distinguish areas of high or low sediment.\n[Slide 16]\nUnlike the sediment index, this product provides an absolute measure of particles in the surface water. Particles are typically defined as any particulates greater than a 0.45 um mesh filter. Total Suspended Matter includes both inorganic and organic particles. Other names for this product are Total Suspended Solids and Suspended Particulate Matter. The Great Lakes node has a total suspended mineral product, similar to total suspended solids, with an example of Lake Superior shown here. The top image shows TSM while the bottom image is a true color image. High areas of sediment appear yellow and red in the top panel, and brown in the true color image. The sediment products are often used to track sediment plumes in coastal and nearshore water after storms, or to understand how losses in water clarity affect organisms.\n[Slide 17]\nKd490 is the vertical light attenuation coefficient for downward irradiance at 490 nm. It describes how rapidly sunlight is lost with depth in the water, specifically measuring the loss of blue-green light which is related to the absorbing particles in the water column. It is inversely proportional to the clarity of the water. The higher Kd490 is, the lower the clarity of the water.\n[Slide 18]\nPAR stands for Photosynthetically Active Radiation and refers to all the wavelengths necessary for photosynthesis. So it includes all the light in the visible portion of the spectrum, between 400-700 nm, as shown in the figure. KdPAR is a measure of the attenuation of all of the PAR wavelengths, and can be estimated from satellites using Kd490 and some general assumptions. As with Kd490, with higher Kd PAR values, there is less visible light which is available for photosynthesis.\n[Slide 19]\nEuphotic Zone Depth describes the depth where only 1% of the surface PAR remains. It is determined by water constituents such as dissolved organic matter, suspended particulate matter, phytoplankton, and even water molecules, all of which attenuate solar radiation with increasing depth. Primary production is at its maximum within the euphotic zone because there is ample photosynthetically active radiation available there.\n[Slide 20]\nSatellite water quality products are also an important resource for inland lakes. Some examples include data available through the Great Lakes CoastWatch node that include ocean color products that are regionally tuned, as well as primary productivity and water clarity estimates. A cyanobacteria index is used to initiate NOAA’s Lake Erie HAB forecast system. CyAN, which covers the extent of the United States, maps cyanobacteria harmful algal blooms for many small and large inland lakes. Both of these products are available on the CoastWatch and NASA website, respectively.\n[Slide 21]\nDetecting floating vegetation and submerged aquatic vegetation, referred to as SAV, requires the use of high resolution data such as Landsat. There are monitoring efforts for submerged aquatic vegetation in coastal areas of the U.S, floating macroalgae such as cladophora in the Great Lakes and Sargassum in tropical areas. Shown here are estimates of Sargassum in the Gulf of Mexico area and submerged aquatic vegetation in the Great Lakes. The existing products are focused on specific regions and are not available globally.\n[Slide 22]\nThere are a number of different satellite products that can be used to detect oil spills. Synthetic Aperture Radar, or SAR, is very useful for detecting oil spills, the image on the left shows a SAR image of the Deepwater Horizon oil spill in the Gulf of Mexico in 2010. SAR data is very high spatial resolution, but it is also not routinely collected over the open ocean, and this data is more difficult to get ahold of than more routine products like sst or ocean color data. The image on the right shows a visible image of the Deepwater Horizon spill, taking advantage of the sunglint issue that some sensors have. In this case the sun glint phenomena makes the oil spill quite visible. There are no “off the shelf” products for oil spill monitoring. Images such as the ones shown here are generally custom produced by satellite data providers in response to an event. If you want more information there was a good review paper on the subject published in 2017 by Fingas and Brown.\n[Slide 23]\nBefore wrapping up, let’s talk a little bit about satellite data accuracy. Satellite data products are validated against in situ data during algorithm development. For a lot of products this process is hampered by the small size of available in situ data. The observations must be temporally and spatially representative of the satellite measurements. Generally validation uses in situ samples that are taken within 3 hours of the satellite measurement, and within a 3 by 3 pixel box centered on the in situ sampling location. The validation results are typically available from the scientific literature and from the ATBD, the Algorithm Theoretical Basis Document produced by the satellite data provider. We recognize that it would be useful to have this information included with the data, particularly for products where this information varies pixel by pixel. There are discussions underway to generate some products like that, but currently none are available.\n[Slide 24]\nIt’s important to remember that when we talk about satellite data accuracy, we are referring to the degree of accuracy. The degree of accuracy of a satellite product is one of the many considerations that need to be made in selecting a dataset. Maybe you are thinking - well that doesn’t make sense - why would anyone choose to use data with lower accuracy if there was a product available with higher accuracy? As always it comes down to what is the application? Near real time products will not have as high an accuracy as delayed science-quality products, but if you need to know the spatial extent of a current coastal bloom as soon as possible, the lower accuracy products may work fine, as illustrated in the images here, which clearly show the rapid development of a coastal bloom between July 1 and 6 of 2014, even though the absolute values of the chlorophyll might have a low degree of accuracy.\n[Slide 25]\nThere are a number of other resources about water quality monitoring that you might find useful. The EPA has a number of training modules and webcasts available on a range of watershed management topics. NASA’s ARSET program has a three-part online training on water quality. The IOCCG published a report on using ocean color data for water quality monitoring, and in fact that report served as the outline for this presentation. The AquaWatch program was established to improve the coordination, delivery and utilization of water quality information.\n[Slide 26]\nThis concludes this presentation on water quality monitoring . We hope that you found it useful. This is one of several presentations put together as part of the CoastWatch Ocean Satellite Course. We’ve listed here all of the available presentations. Thanks for listening."
  },
  {
    "objectID": "officehours.html",
    "href": "officehours.html",
    "title": "CoastWatch Office Hours",
    "section": "",
    "text": "Hosted by the West Coast Node and PolarWatch\nevery other Thursday at 11 am PST\nUpcoming dates: March 5, 12\nEveryone is welcome to come to the CoastWatch Office Hour where people can:\n\nAsk questions about satellite data\nRequest help with accessing satellite data products\nGet troubleshooting assistance with code examples for discovering, accessing and working with satellite data\n\nCoastWatch Lectures\nCoastWatch Tutorials",
    "crumbs": [
      "Office Hours"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html",
    "href": "trainings/past/afs24.html",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using the Animal Telemetry Network Portal. This training was originally going to be held before the annual AFS (American Fisheries Society) meeting in Honolulu, Hawaii, but has been rescheduled to be an online course, open to all.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html#course-description",
    "href": "trainings/past/afs24.html#course-description",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using the Animal Telemetry Network Portal. This training was originally going to be held before the annual AFS (American Fisheries Society) meeting in Honolulu, Hawaii, but has been rescheduled to be an online course, open to all.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html#instructors",
    "href": "trainings/past/afs24.html#instructors",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Instructors",
    "text": "Instructors\n\n\n\nName\nAffiliation\n\n\n\n\nCara Wilson\nCoastWatch/West Coast Node, PI\n\n\nDale Robinson\nCoastWatch/West Coast Node, node manager\n\n\nMegan McKinzie\nATN Data Coordinator\n\n\nDaisy Shi\nCoastWatch/Pacific OceanWatch, node manager",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html#objectives",
    "href": "trainings/past/afs24.html#objectives",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the basic types of products available from satellite data\nDemonstate how to access data on ERDDAP servers\nExplore the data available on the Animal Telemetry Network portal\nIntroduce CoastWatch satellite data training resources\nProvide hands-on time to access data and try tutorials",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html#schedule",
    "href": "trainings/past/afs24.html#schedule",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n10:00 - 10:15\nTraining Overview - CoastWatch, ATN and the workshop component\nCara Wilson\n\n\n10:15 - 10:30\nGroup Introductions\nCara Wilson\n\n\n10:30 - 11:15\nCoastwatch satellite datasets and data portals\nCara Wilson\n\n\n11:15 - 11:30\nBreak\n\n\n\n11:30 - 12:00\nUsing the ERDDAP data server\nCara Wilson\n\n\n12:00 - 12:30\nAccessing ERDDAP using scripts (R, python)\nCara Wilson\n\n\n12:30 - 1:30\nLunch break\n\n\n\n1:30 - 2:00\nIntro to ATN and the DAC\nMegan McKinzie\n\n\n2:00 - 2:30\nDemo of ATN data portal\nMegan McKinzie\n\n\n2:30 - 3:00\nAccessing public ATN datasets\nMegan McKinzie\n\n\n3:00 - 3:15\nBreak\n\n\n\n3:15 - 3:30\nWorkshop, part 1: Linking CoastWatch and ATN data using scripts\nDaisy Shi\n\n\n3:30 - 4:45\nWorkshop, part 2: Hand’s on time\n\n\n\n4:45 - 5:00\nWrap up and final discussion\nAll",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html#resources",
    "href": "trainings/past/afs24.html#resources",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Resources",
    "text": "Resources\n\nCoastwatch Tutorials (on GitHub)\nCoastwatch Lecture series\nAnimal telemetry Network",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "trainings/past/longislandsound25.html",
    "href": "trainings/past/longislandsound25.html",
    "title": "2025 Long Island Sound Class",
    "section": "",
    "text": "Virtual - Times vary daily, see schedule below (times are Eastern).\nNOAA CoastWatch is hosting this free, virtual training class:  Viewing and Analyzing Ocean/Coastal Events and Water Quality Using Satellites\nJoin Class Via Zoom Here",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Long Island Sound"
    ]
  },
  {
    "objectID": "trainings/past/longislandsound25.html#course-description",
    "href": "trainings/past/longislandsound25.html#course-description",
    "title": "2025 Long Island Sound Class",
    "section": "Course Description",
    "text": "Course Description\nMany satellite products are available for water quality applications and other uses from NOAA and other data providers. These include: chlorophyll, turbidity, sea surface temperature, organic matter, and more. In this course, learn how to use these satellite products for your region of interest using freely available tools. Address your needs and questions by creating maps and images, plotting a time series of varying conditions, or creating a virtual buoy for your study location. And other applications too!\nThis class is being offered in two Tiers as part of a larger Long Island Sound Project funded by New York/Connecticut Sea Grant.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Long Island Sound"
    ]
  },
  {
    "objectID": "trainings/past/longislandsound25.html#objectives",
    "href": "trainings/past/longislandsound25.html#objectives",
    "title": "2025 Long Island Sound Class",
    "section": "Objectives",
    "text": "Objectives\n\nTier I: Creating Images\nLearn to use tools to create images and maps of ocean or coastal features in your area of interest. Tools taught: CoastWatch Data Portal, ArcGIS, ERDDAP visualization server, and more.\n\n\nTier II: Analyzing Data for Your Study or Region\nWork more analytically with oceanographic satellite data. Learn R and/or Python techniques to access data on ERDDAP data servers for data extraction, map creation, time series analysis, matching data to your study site locations or ship tracks, creating a virtual buoy using satellite data in your location of choice, and other application skills.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Long Island Sound"
    ]
  },
  {
    "objectID": "trainings/past/longislandsound25.html#schedule",
    "href": "trainings/past/longislandsound25.html#schedule",
    "title": "2025 Long Island Sound Class",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nDay\nTime (ET)\nTopic\nPresenter\n\n\n\n\nMonday - March 31\n\nTier I and Tier II\n\n\n\n\n9:00 - 9:15\nPresentation 1: Overview – SeaGrant-funded Satellite Project\nJonathan Sherman\n\n\n\n9:15 - 9:45\nPresentation 2: Data Portal\nMichael Soracco\n\n\n\n9:45 - 10:15\nPresentation 3: ArcGIS\nMichael Soracco\n\n\n\n10:15 - 10:30\nBreak\n\n\n\n\n10:30 - 11:15\nPresentation 4: CoastWatch Utilities - CDAT  Files\nRon Vogel\n\n\n\n11:15 - 11:30\nQ & A\n\n\n\n\n11:30 - 12:15\nParticipant Exercise 1: Choose a tool and make a map  ArcGIS files, CDAT files\n\n\n\n\n12:15 - 1:15\nLunch break\n\n\n\n\n1:15 - 1:45\nPresentation 5: Choosing a Dataset\nJonathan Sherman\n\n\n\n1:45 - 2:45\nPresentation 6: ERDDAP\nRon Vogel\n\n\n\n2:45 - 3:00\nBreak\n\n\n\n\n3:00 - 3:30\nQ & A and Resources for Participants\n\n\n\n\n3:30 - 4:30\nParticipant Exercise 2: Choose a dataset from ERDDAP, download, make a map and a time series  Sample data list\n\n\n\nTuesday - April 1\n\nTier II (April 1–4)\n\n\n\n\n9:00 - 9:30\nPresentation 7: Satellite 101\nShelly Tomlinson\n\n\n\n9:30 - 10:30\nPresentation 8: CoastWatch Training Code (R and Python) – Capabilities and Tutorials  Tutorials page\nJonathan Sherman\n\n\n\n10:30 - 10:45\nBreak\n\n\n\n\n10:45 - 11:30\nPresentation 9: CoastWatch Utilities - Command Line  Files\nRon Vogel\n\n\n\n11:30 - 12:00\nOffice Hours Logistics, Mini-project & Slide Info, Q & A\n\n\n\n\n12:00 - 1:00\nLunch\n\n\n\n\n1:00 - 4:00\nOffice Hours: One-on-One\n\n\n\nWednesday - April 2\n\nParticipants work on their mini-project on their own time\n\n\n\nThursday - April 3\n9:00 - 9:15\nGauge Progress Poll\nBetty Staugler\n\n\n\n9:15 - 9:30\nPresentation 10: HAB Forecasts\nShelly Tomlinson\n\n\n\n9:30 - 9:45\nPresentation 11: COVID Impacts\nJonathan Sherman\n\n\n\n9:45 - 10:00\nPresentation 12: Participant Slide Examples from Past Classes\nRon Vogel\n\n\n\n10:00 - 12:00\nOffice Hours: Group Discussion or One-on-One\n\n\n\n\n12:00 - 1:00\nLunch\n\n\n\n\n1:00 - 4:00\nParticipants work on their mini-project on their own time\n\n\n\nFriday - April 4\n1:00 - 3:00\nFinal Mini-project Presentations (1 slide each)\nParticipants",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Long Island Sound"
    ]
  },
  {
    "objectID": "trainings/past/longislandsound25.html#resources",
    "href": "trainings/past/longislandsound25.html#resources",
    "title": "2025 Long Island Sound Class",
    "section": "Resources",
    "text": "Resources\n\nCoastWatch main website\nCoastWatch East Coast Regional Node website\nCoastWatch Data Access methods\nCoastwatch Coding Tutorials: R and Python\nCoastwatch Lecture series\nCoastwatch Data Portal video tutorials\nCoastwatch ArcGIS lecture videos and tutorials\nCoastWatch Utilities\n\nCoastWatch Utilities Tutorials - CDAT and Command-Line\nCDAT demo videos on YouTube\n\nCoastWatch Help Desk\n\nEmail: coastwatch.info@noaa.gov\nPhone: +1-301-683-3335\nUser Forums",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Long Island Sound"
    ]
  },
  {
    "objectID": "trainings/past/seaice24.html",
    "href": "trainings/past/seaice24.html",
    "title": "2024 PolarWatch Sea Ice Training",
    "section": "",
    "text": "PolarWatch node of the CoastWatch is hosting a free, virtual training class on October 21, 2024 (9am-4pm Pacific Time).",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 Sea Ice Data Course"
    ]
  },
  {
    "objectID": "trainings/past/seaice24.html#course-description",
    "href": "trainings/past/seaice24.html#course-description",
    "title": "2024 PolarWatch Sea Ice Training",
    "section": "Course Description",
    "text": "Course Description\nMany satellite sea ice products are available for download from NOAA and many other data providers: e.g. sea ice concentration, sea ice thickness, sea ice age, sea ice temperature, and sea ice extent. It can often be challenging to know the differences between the products and how each can be applied to a user’s specific application. For example, the spatial resolutions of the products can vary widely, largely dependent on the type of satellite measurement the product is derived from (passive microwave, visible radiometry or synthetic aperture radar). Additionally, when working with data in the high-latitudes issues of data projection invariably arise and can complicate accessing and working with data. To address these issues, NOAA’s PolarWatch node has developed a 1-day (6 hour) online course with the following training objectives.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 Sea Ice Data Course"
    ]
  },
  {
    "objectID": "trainings/past/seaice24.html#objectives",
    "href": "trainings/past/seaice24.html#objectives",
    "title": "2024 PolarWatch Sea Ice Training",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the basic types of sea-ice products available from satellite data\nGive an overview of working with different projections\nExplore the data available on the PolarWatch portal\nProvide hands-on time to access data and try tutorials\nIntroduce CoastWatch and other sea ice satellite data training resources",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 Sea Ice Data Course"
    ]
  },
  {
    "objectID": "trainings/past/seaice24.html#schedule",
    "href": "trainings/past/seaice24.html#schedule",
    "title": "2024 PolarWatch Sea Ice Training",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n9:00 - 9:30\nPresentation 1: Introduction to NOAA CoastWatch\nCara Wilson\n\n\n9:30 - 10:00\nPresentation 2: Overview of Sea Ice Remote Sensing\nLudovic Brucker\n\n\n10:00 - 10:30\nPresentation 3: JPSS Sea Ice Microlesson\nKevin Fuell\n\n\n10:30 - 10:45\nBreak\n\n\n\n10:45 - 11:15\nPresentation 4: Sea Ice from SAR\nChris Jackson\n\n\n11:15 - 11:30\nPresentation 5: Projections - Why they Matter\nMichael Soracco\n\n\n11:30 - 11:45\nPresentation 6: Ice in the Great Lakes\nAndrea VanderWoude\n\n\n11:45 - 12:45\nLunch break\n\n\n\n12:45 - 13:00\nPresentation 7: Projections in Action (Watch Video)\nPeter Hollemans\n\n\n13:00 - 13:30\nPresentation 8: ERDDAP Demo\nCara Wilson\n\n\n13:30 - 13:45\nPresentation 9: PolarWatch Portal Demo\nSunny Hospital\n\n\n13:45 - 14:00\nPresentation 10: CoastWatch Viewer Demo\nMichael Soracco\n\n\n14:00 - 14:15\nBreak\n\n\n\n14:15 - 14:30\nPresentation 11: Overview of Tutorials\nCara Wilson, Matthew Smith\n\n\n14:30 - 16:00\nHand’s on time, with instuctor’s guidance available",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 Sea Ice Data Course"
    ]
  },
  {
    "objectID": "trainings/past/seaice24.html#resources",
    "href": "trainings/past/seaice24.html#resources",
    "title": "2024 PolarWatch Sea Ice Training",
    "section": "Resources",
    "text": "Resources\n\nCoastwatch Tutorials\nCoastwatch Lecture series\nJPSS Sea Ice Microlesson",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 Sea Ice Data Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html",
    "href": "trainings/upcoming/sat201_26.html",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "",
    "text": "This lecture series provides a deeper dive into satellite oceanography, exploring advanced topics beyond the regular CoastWatch satellite course. Link to registration page",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#course-description",
    "href": "trainings/upcoming/sat201_26.html#course-description",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "",
    "text": "This lecture series provides a deeper dive into satellite oceanography, exploring advanced topics beyond the regular CoastWatch satellite course. Link to registration page",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#schedule-attendance",
    "href": "trainings/upcoming/sat201_26.html#schedule-attendance",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "Schedule & Attendance",
    "text": "Schedule & Attendance\nFrequency: Sessions are held every Friday for one month.\nDuration: Approximately 2.5 hours per session.\nFlexibility: Attendance for all sessions is not required; feel free to join the topics most relevant to you.",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#curriculum",
    "href": "trainings/upcoming/sat201_26.html#curriculum",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "2026 Curriculum",
    "text": "2026 Curriculum\nThe inaugural 2026 course will cover the following subjects: * Alternative Data Access: Methods for accessing data not hosted on ERDDAP servers. * CoastWatch Utilities: An introduction to using the CoastWatch proprietary software suite. * Beyond Chlorophyll: Exploring ocean color products other than chlorophyll. * SAR Data: An introduction to Synthetic Aperture Radar.",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#schedule",
    "href": "trainings/upcoming/sat201_26.html#schedule",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "Schedule",
    "text": "Schedule\nFriday, July 10, 2026\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n11:00 - 11:45\nAccessing data not on ERDDAP servers\nDale Robinson\n\n\n11:45 - 12:30\na demo\n\n\n\n12:30 - 12:45\nBreak\n\n\n\n12:45 - 1:30\nQuestion & Answer and hand’s on session\n\n\n\n\nFriday, July 17, 2026\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n11:00 - 11:45\nIntroduction to using Coastwatch Utilities software\nPeter Hollemans\n\n\n11:45 - 12:30\na demo\n\n\n\n12:30 - 12:45\nBreak\n\n\n\n12:45 - 1:30\nQuestion & Answer and hand’s on session\n\n\n\n\nFriday, July 24, 2026\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n11:00 - 11:45\nBeyond Chlorophyll\nRyan Vandermeulan\n\n\n11:45 - 12:30\nBeyond Chlorophyll Case Study\n\n\n\n12:30 - 12:45\nBreak\n\n\n\n12:45 - 1:30\nQuestion & Answer and hand’s on session\n\n\n\n\nFriday, July 31, 2026\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n11:00 - 11:45\nIntroduction to SAR Data\n\n\n\n11:45 - 12:30\nSAR Case Study\n\n\n\n12:30 - 12:45\nBreak\n\n\n\n12:45 - 1:30\nQuestion & Answer and hand’s on session",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#instructors",
    "href": "trainings/upcoming/sat201_26.html#instructors",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "Instructors",
    "text": "Instructors\n\n\n\nName\nAffiliation\n\n\n\n\nCara Wilson\nCoastWatch/West Coast Node, PI\n\n\nDale Robinson\nCoastWatch/West Coast Node, node manager\n\n\nPeter Hollemans\nCoastWatch/Pacific OceanWatch, node manager",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#resources",
    "href": "trainings/upcoming/sat201_26.html#resources",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "Resources",
    "text": "Resources\n\nCoastwatch Tutorials (on GitHub)\nCoastwatch Lecture series",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html",
    "href": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html",
    "title": "Timeseries and Hovmoller diagrams",
    "section": "",
    "text": "This exercise examines the marine heatwave that was observed in the North Pacific Ocean off the west coast of North America, also know as The Blob. It was first detected in late 2013 and continued to spread throughout 2014 and 2015.\nThe exercise demonstrates the following ERDDAP features * mapping data in an area of interest\n* creating a time series at a specified latitude and longitude coordinate\n* creating a Hovmoller diagram\n\n\nThe Blob was strong in the northern Pacific. Let’s compare SST in the area after the Blob subsided and during the Blob.\nSelecting the SST dataset\nFor this demonstration, use the Multi-scale Ultra-high Resolution sea surface temperature (MUR SST) dataset. MUR is a dataset containing data from many sensors, to increase the number of pixels that containing data. Where gaps in the measurements do exist, interpolated data fill the gaps.\n\nEnter the following URL into your browser: https://coastwatch.pfeg.noaa.gov/erddap/ or Google \"ERDDAP west coast\".\n\nIn the search box type \"MUR SST\" and click the \"Search\" button.\n\nSeveral MUR datasets show up in the search results. Since we will be visualizing data over many years, select the version of the dataset that contains monthly averages.\n\nLocate the dataset with the title \"Multi-scale Ultra-high Resolution (MUR) SST Analysis fv04.1, Global, 0.01°, 2002-present,  Monthly\". Alternately, you can add the dataset ID \"jplMURSST41mday\" to the search box to narrow your search.\nClick on \"graph\" in the \"Make A Graph\" column to the left of the dataset.\n\nZoom the map in on the northern Pacific\n\nChange the minimum and maximum latitude and longitude values using the latitude and longitude widgets:\n\nLatitudes: 20, 60\nLongitudes: -179, -100\n\n\nCreate a map for a time when Blob conditions were not present (time after 2016)\n\nChange time widget to select January 2017 (2017-01-16T00:00:00Z)\nMake sure that the \"color\" drop down menu has \"sst\" selected\nClick \"Redraw the Graph\"\n\nNow go to the \"File Type:\"' drop down menu and select“.largePng”`\nGo to the \"view the URL:\" box and copy the URL. &gt; https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplMURSST41mday.png?sst[(2017-01-16T00:00:00Z)][(20.0):(60.0)][(-179.99):(-100.0)]&.draw=surface&.vars=longitude|latitude|sst&.colorBar=|||||&.bgColor=0xffccccff\n\nOpen a new tab in your browser and paste the URL to view the image\n\n\n\n\nSST map not during the Blob\n\n\nCreate a map for a time during the Blob\nUse one of the following methods:\n\nModify the date of a data request with the URL\n\n\n\nCopy the URL from above and paste it into a new tab on your browser\nChange the January 2017 date (2017-01-16T00:00:00Z) to January 2014 (2014-01-16T00:00:00Z) &gt; https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplMURSST41mday.png?sst[(2014-01-16T00:00:00Z)][(20.0):(60.0)][(-179.99):(-100.0)]&.draw=surface&.vars=longitude|latitude|sst&.colorBar=|||||&.bgColor=0xffccccff\n\n\nUse the ERDDAP GUI\n\n\nReturn to the MUR Make A Graph page\nChange time widget to select January 2014 (2014-01-16T00:00:00Z).\nMake sure that the \"color\" drop down menu has \"sst\" selected.\nClick \"Redraw the Graph\".\n\nNow go to the \"File Type:\"' drop down menu and select“.largePng”`\nGo to the \"view the URL:\" box and copy the URL.\nOpen a new tab in your browser and paste the URL to view the image.\n\n\n\n\nSST map during the Blob\n\n\nNow click back and forth between the two tabs to compare Blob to non-Blob conditions. Do you see the blob? There is a pretty subtle distinction between images on the two tabs. During Blob conditions, the isotherms should be shifted northward in the northern Pacific.\n\n\n\nA better way to graphically the Blob is by looking at the temperature anomaly. Temperature anomaly datasets show the deviation of SST from a long-term mean (climatology), i.e. how is the SST different from the average value.\nSelecting the SST anaomaly dataset For this demonstration, use the Multi-scale Ultra-high Resolution sea surface temperature anomaly (MUR Anom) monthly dataset (ERDDAP ID = jplMURSST41anommday).\n\nIn your browser, go back to the ERDDAP search page: https://coastwatch.pfeg.noaa.gov/erddap/.\nIn the search box type “jplMURSST41anommday” and click the \"Search\" button.\nOnly one dataset should show up. Click on \"graph\" in the \"Make A Graph\" column to the left of the dataset.\n\nMapping the Blob\n\nChange the minimum and maximum latitude and longitude values using the latitude and longitude widgets:\n\nLatitudes: 20, 60\nLongitudes: -179, -100\n\n\nChange time widget to select January 2014 (2014-01-16T00:00:00Z).\nMake sure that the \"color\" drop down menu has \"anom\" selected.\nClick \"Redraw the Graph\".\n\nNow go to the \"File Type:\"' drop down menu and select“.largePng”`\nGo to the \"view the URL:\" box and copy the URL.\nOpen a new tab in your browser and paste the URL to view the image.\n\n\n\n\nSST map during the Blob\n\n\nNow the Blob is clearly visible as an area of up to +3 degrees warmer than the long-term mean! Note how the color bar has changed. By default anomaly datasets have a color bar that differentiates between negative and positive values.\n\n\n\nHow long did the Blob last? To find out let’s make a time series of data from a point within the Blob.\n\nIn the Graph Type widget change from surface to lines and markers\n\nIn the time widget, enter a Start time of 2013-01-01, which is before the Blob started, and a Stop time of 2018-01-16T00:00:00Z.\n\nPick latitude and longitude coordinates that are within the Blob area. * Enter 45 as the latitude * Enter -143 as the longitude * Click the \"Redraw the Graph\" button\n\n\n\nSST anomaly timeseries at 45N, 143W\n\n\n\n\n\nThe time series plot shows the progression of the Blob at a single latitude and longitude point. A better way to visualize the Blob is to create a Hovmoller diagram (https://en.wikipedia.org/wiki/Hovm%C3%B6ller_diagram), which is a two-dimensional timeseries. For this demonstration, we will plot along a longitude range, from -179E to -125E, at a latitude of 45N over time.\n\nIn the Graph Type widget change lines and markers back to surface\nIn the Y axis widget change latitude to time\nEnter 2013-01-01 as the Start time\nEnter 2018-01-01 as the Stop time\nEnter 45 as the latitude\nEnter -179 as the minimum longitude\nEnter -125 as the maximum longitude\nClick the \"Redraw the Graph\" button\n\n\n\n\nSST anomaly Hovmoller at 45N\n\n\nThe plot shows that the blob moved east throughout 2014 and 2015, and then expanded across most of the eastern basin at the end of 2015.\n\n\n\nCreate a Hovmoller diagram plotted against latitude rather than longitude?"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html#visualize-the-blob-with-sst",
    "href": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html#visualize-the-blob-with-sst",
    "title": "Timeseries and Hovmoller diagrams",
    "section": "",
    "text": "The Blob was strong in the northern Pacific. Let’s compare SST in the area after the Blob subsided and during the Blob.\nSelecting the SST dataset\nFor this demonstration, use the Multi-scale Ultra-high Resolution sea surface temperature (MUR SST) dataset. MUR is a dataset containing data from many sensors, to increase the number of pixels that containing data. Where gaps in the measurements do exist, interpolated data fill the gaps.\n\nEnter the following URL into your browser: https://coastwatch.pfeg.noaa.gov/erddap/ or Google \"ERDDAP west coast\".\n\nIn the search box type \"MUR SST\" and click the \"Search\" button.\n\nSeveral MUR datasets show up in the search results. Since we will be visualizing data over many years, select the version of the dataset that contains monthly averages.\n\nLocate the dataset with the title \"Multi-scale Ultra-high Resolution (MUR) SST Analysis fv04.1, Global, 0.01°, 2002-present,  Monthly\". Alternately, you can add the dataset ID \"jplMURSST41mday\" to the search box to narrow your search.\nClick on \"graph\" in the \"Make A Graph\" column to the left of the dataset.\n\nZoom the map in on the northern Pacific\n\nChange the minimum and maximum latitude and longitude values using the latitude and longitude widgets:\n\nLatitudes: 20, 60\nLongitudes: -179, -100\n\n\nCreate a map for a time when Blob conditions were not present (time after 2016)\n\nChange time widget to select January 2017 (2017-01-16T00:00:00Z)\nMake sure that the \"color\" drop down menu has \"sst\" selected\nClick \"Redraw the Graph\"\n\nNow go to the \"File Type:\"' drop down menu and select“.largePng”`\nGo to the \"view the URL:\" box and copy the URL. &gt; https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplMURSST41mday.png?sst[(2017-01-16T00:00:00Z)][(20.0):(60.0)][(-179.99):(-100.0)]&.draw=surface&.vars=longitude|latitude|sst&.colorBar=|||||&.bgColor=0xffccccff\n\nOpen a new tab in your browser and paste the URL to view the image\n\n\n\n\nSST map not during the Blob\n\n\nCreate a map for a time during the Blob\nUse one of the following methods:\n\nModify the date of a data request with the URL\n\n\n\nCopy the URL from above and paste it into a new tab on your browser\nChange the January 2017 date (2017-01-16T00:00:00Z) to January 2014 (2014-01-16T00:00:00Z) &gt; https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplMURSST41mday.png?sst[(2014-01-16T00:00:00Z)][(20.0):(60.0)][(-179.99):(-100.0)]&.draw=surface&.vars=longitude|latitude|sst&.colorBar=|||||&.bgColor=0xffccccff\n\n\nUse the ERDDAP GUI\n\n\nReturn to the MUR Make A Graph page\nChange time widget to select January 2014 (2014-01-16T00:00:00Z).\nMake sure that the \"color\" drop down menu has \"sst\" selected.\nClick \"Redraw the Graph\".\n\nNow go to the \"File Type:\"' drop down menu and select“.largePng”`\nGo to the \"view the URL:\" box and copy the URL.\nOpen a new tab in your browser and paste the URL to view the image.\n\n\n\n\nSST map during the Blob\n\n\nNow click back and forth between the two tabs to compare Blob to non-Blob conditions. Do you see the blob? There is a pretty subtle distinction between images on the two tabs. During Blob conditions, the isotherms should be shifted northward in the northern Pacific."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html#visualize-the-blob-with-an-sst-anomaly",
    "href": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html#visualize-the-blob-with-an-sst-anomaly",
    "title": "Timeseries and Hovmoller diagrams",
    "section": "",
    "text": "A better way to graphically the Blob is by looking at the temperature anomaly. Temperature anomaly datasets show the deviation of SST from a long-term mean (climatology), i.e. how is the SST different from the average value.\nSelecting the SST anaomaly dataset For this demonstration, use the Multi-scale Ultra-high Resolution sea surface temperature anomaly (MUR Anom) monthly dataset (ERDDAP ID = jplMURSST41anommday).\n\nIn your browser, go back to the ERDDAP search page: https://coastwatch.pfeg.noaa.gov/erddap/.\nIn the search box type “jplMURSST41anommday” and click the \"Search\" button.\nOnly one dataset should show up. Click on \"graph\" in the \"Make A Graph\" column to the left of the dataset.\n\nMapping the Blob\n\nChange the minimum and maximum latitude and longitude values using the latitude and longitude widgets:\n\nLatitudes: 20, 60\nLongitudes: -179, -100\n\n\nChange time widget to select January 2014 (2014-01-16T00:00:00Z).\nMake sure that the \"color\" drop down menu has \"anom\" selected.\nClick \"Redraw the Graph\".\n\nNow go to the \"File Type:\"' drop down menu and select“.largePng”`\nGo to the \"view the URL:\" box and copy the URL.\nOpen a new tab in your browser and paste the URL to view the image.\n\n\n\n\nSST map during the Blob\n\n\nNow the Blob is clearly visible as an area of up to +3 degrees warmer than the long-term mean! Note how the color bar has changed. By default anomaly datasets have a color bar that differentiates between negative and positive values."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html#creating-a-timeseries",
    "href": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html#creating-a-timeseries",
    "title": "Timeseries and Hovmoller diagrams",
    "section": "",
    "text": "How long did the Blob last? To find out let’s make a time series of data from a point within the Blob.\n\nIn the Graph Type widget change from surface to lines and markers\n\nIn the time widget, enter a Start time of 2013-01-01, which is before the Blob started, and a Stop time of 2018-01-16T00:00:00Z.\n\nPick latitude and longitude coordinates that are within the Blob area. * Enter 45 as the latitude * Enter -143 as the longitude * Click the \"Redraw the Graph\" button\n\n\n\nSST anomaly timeseries at 45N, 143W"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html#creating-a-2d-timeseries-hovmoller-plot",
    "href": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html#creating-a-2d-timeseries-hovmoller-plot",
    "title": "Timeseries and Hovmoller diagrams",
    "section": "",
    "text": "The time series plot shows the progression of the Blob at a single latitude and longitude point. A better way to visualize the Blob is to create a Hovmoller diagram (https://en.wikipedia.org/wiki/Hovm%C3%B6ller_diagram), which is a two-dimensional timeseries. For this demonstration, we will plot along a longitude range, from -179E to -125E, at a latitude of 45N over time.\n\nIn the Graph Type widget change lines and markers back to surface\nIn the Y axis widget change latitude to time\nEnter 2013-01-01 as the Start time\nEnter 2018-01-01 as the Stop time\nEnter 45 as the latitude\nEnter -179 as the minimum longitude\nEnter -125 as the maximum longitude\nClick the \"Redraw the Graph\" button\n\n\n\n\nSST anomaly Hovmoller at 45N\n\n\nThe plot shows that the blob moved east throughout 2014 and 2015, and then expanded across most of the eastern basin at the end of 2015."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html#try-this-on-your-own",
    "href": "tutorials/ERDDAP-Basics/hovmoller-plot/hovmoller-plot.html#try-this-on-your-own",
    "title": "Timeseries and Hovmoller diagrams",
    "section": "",
    "text": "Create a Hovmoller diagram plotted against latitude rather than longitude?"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html",
    "href": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html",
    "title": "Tabular Datasets, BGC-Argo data",
    "section": "",
    "text": "There are two types of data in ERDDAP, gridded data and tabular data. So far all of our examples have been with gridded data. Working with tabular data is a little different. Here we will explore the Biogeochemical-Argo (BGC-Argo) dataset, which is hosted on the PolarWatch ERDDAP.\n\n\n\nEnter the following URL into your browser to bring up the PolarWatch ERDDAP: https://polarwatch.noaa.gov/erddap/\nIn the search box type “Biogeochemical-Argo” and click the “Search’ button\n\nIn the search results, two datasets are displayed: the near-real-time dataset (Dataset ID: SOCCOM_BGC_Argo), and a science quality dataset that is updated quarterly (Dataset ID: BGC_Argo_Snapshot_Archive).\n\n\n\nSOCCOM search result\n\n\nWe will work with the near-real time dataset, so click \"graph\" to the left of the near real-time dataset.\n\n\n\nBGC Graph result\n\n\nBy default the map displays all the float locations for the last 10 days. The locations are color coded by their Nitrate concentration.\n\n\n\nLet’s make a map of all floats in Antarctica which have pCO2 data and that have reported in the for a one month time period from May 25, 2019 to June 25, 2019.\nThe “Make A Graph” page works slightly differently for the tabular datasets than it does for gridded datasets. For tabular datasets, the subsetting is done by the widgets listed under “Constraints” (for gridded datasets they are classified under “Dimensions”).\n\nSelect \"time\" as a constraint and set \"Optional Constraint #1\" to 2019-05-25T21:05:05Z. Make sure that the dropdown item to the left of \"Optional Constraint #1\" is set to \"&gt;=\" (i.e all dates greater than or equal to May 25, 2019). Set \"Optional Constraint #2\" to 2019-06-25T21:05:05Z. Make sure that the dropdown item to the left of \"Optional Constraint #1\" is set to \"&lt;=\" (i.e all dates less than or equal to June 25, 2019).\n\nChange the parameter selected next to \"Color\" at the top of the page from \"nitrate\" to \"pCO2_LIAR.\" pCO2_LIAR is calculated partial pressure of carbon_dioxide in sea_water.\n\npCO2_LIAR has a quality flag (pCO2_LIAR_QF) to indicate which data points are good and which are not. The values for the flag are 0=Good, 1=Missing or not inspected, 4=Questionable, 8=Bad”. Select \"pCO2_LIAR_QF\" as a constraint and enter 0 in \"Optional Constraint #1“. Make sure that the dropdown item to the left of \"Optional Constraint #1\" is set to \"=\" (i.e all values that are good).\n\nThis dataset has \"Region\" as a parameter, and we can use that to get just data from Antarctic. Select \"region\" as a constraint and select \"Antarctica\" from the dropdown widget menu\n\nNext click the \"Redraw the Graph\" button.\n\n\n\n\nRecent Floats in Antarctica\n\n\n\n\n\nThe scale for the pCO2 goes from 0-2000 uatm, but the data on the map seems to be between 300-500 uatm. In addition, the markers on the map are plus signs, which are hard to see. Let’s change the display to make the data easier to see.\n\nUnder \"Graph Settings\", set the \"Marker Type\" dropdown to \"Filled Square.”\nBelow \"Color Bar\", type 300 in the \"Minimum\" box and 500 in the \"Maximum\" box.\n\nNext click the \"Redraw the Graph\" button.\n\n\n\n\nRecent Floats in Antarctica\n\n\n\n\n\nNow lets zoom in on the region around Australia.\n\nSelect longitude as a constraint and 100 as \"Optional Constraint #1\". Make sure that the dropdown item to the left of \"Optional Constraint #1\" is set to \"&gt;=\". Set 180 as \"Optional Constraint #2. Make sure that the dropdown item to the left of \"Optional Constraint #2\" is set to \"&lt;=\".\nClick the \"Redraw the Graph\" button.\n\n\n\n\nRecent Floats near Australia\n\n\n\n\n\nWhat floats are we seeing? We can find this out by looking at the data itself.\n\nClick the \"Data Access Form\" above the map\n\nThis brings us to a new page which shows all the variables in the dataset, and allows constraints to be set on all of them. Constraints from the previous page have been retained.\n\nCheck the boxes next to \"WMO_ID\" and \"mbariID\" at the top of the list.\nCheck the boxes next to \"depth\" and add &lt;=10 as an as \"Optional Constraint\" for depth to limit the number of results per profile.\nClick the \"Sumbit\" button at the bottom of the page.\n\n\n\n\nListing of Floats near Australia\n\n\n\n\n\nNow lets make a map of the complete trajectory for one of these floats, color coded by time.\n\nUse the browser back button to return to the \"Data Access Page\"\nClick on the ‘“Make a graph”’ link under the dataset title\nRemove the time and longitude constraint\nThe select a single buoy, identify it with the WMO ID. Select \"WMO_ID\" as a constraint and select 5904675 from the dropdown box that shows all of the buoys that adhere to all of the other constraints.\nClick the \"Redraw the Graph\" button.\n\nThe map shows the pCO2 values along the entire buoy track.\n\n\n\nFloat Trajectory showing pCO2\n\n\nWe can also pot the use the \"Color\" widget to plot the time for each of the symbols on the map.\n\nChange the parameter selected next to \"Color\" at the top of the page from \"pCO2_LIAR\" to \"time\"\nRemove the minimum (300) and maximum (500) values from underneath the ‘“color bar”’ in ’“Graph Settings’”\nThen click the \"Redraw the Graph\" button.\n\n\n\n\nFloat Trajectory showing date\n\n\nThe color bar is now time and color of marker indicate the date the the buoy of in a location.\n\n\n\nLet’s make a section of Nitrate for this float.\n\nUnder ‘“Graph Type’” at the top of the page select’“time”’ as the ‘“X Axis”’, ‘“depth”’ as the ‘“Y Axis”’ and ‘“Nitrate”’ as the ‘“Color”’\nThen click the \"Redraw the Graph\" button.\n\n\n\n\nNitrate Section\n\n\nThe data is upside-down and not much detail can be seen in the surface so lets fix those issues.\n\nUnder ’“Graph Settings’” set the \"Y Axis Minimum\" to 0, the \"Y Axis Maximum\" to 350 and change \"Ascending\" to \"descending\".\nChange the Marker Size to \"10\"\nUnder \"Color Bar\", set \"Maximum\" to 15.\n\n\n\n\nNitrate Section, fixed up"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#searching-for-the-bgc-argo-datasets",
    "href": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#searching-for-the-bgc-argo-datasets",
    "title": "Tabular Datasets, BGC-Argo data",
    "section": "",
    "text": "Enter the following URL into your browser to bring up the PolarWatch ERDDAP: https://polarwatch.noaa.gov/erddap/\nIn the search box type “Biogeochemical-Argo” and click the “Search’ button\n\nIn the search results, two datasets are displayed: the near-real-time dataset (Dataset ID: SOCCOM_BGC_Argo), and a science quality dataset that is updated quarterly (Dataset ID: BGC_Argo_Snapshot_Archive).\n\n\n\nSOCCOM search result\n\n\nWe will work with the near-real time dataset, so click \"graph\" to the left of the near real-time dataset.\n\n\n\nBGC Graph result\n\n\nBy default the map displays all the float locations for the last 10 days. The locations are color coded by their Nitrate concentration."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#subsetting-the-area-and-selecting-a-date",
    "href": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#subsetting-the-area-and-selecting-a-date",
    "title": "Tabular Datasets, BGC-Argo data",
    "section": "",
    "text": "Let’s make a map of all floats in Antarctica which have pCO2 data and that have reported in the for a one month time period from May 25, 2019 to June 25, 2019.\nThe “Make A Graph” page works slightly differently for the tabular datasets than it does for gridded datasets. For tabular datasets, the subsetting is done by the widgets listed under “Constraints” (for gridded datasets they are classified under “Dimensions”).\n\nSelect \"time\" as a constraint and set \"Optional Constraint #1\" to 2019-05-25T21:05:05Z. Make sure that the dropdown item to the left of \"Optional Constraint #1\" is set to \"&gt;=\" (i.e all dates greater than or equal to May 25, 2019). Set \"Optional Constraint #2\" to 2019-06-25T21:05:05Z. Make sure that the dropdown item to the left of \"Optional Constraint #1\" is set to \"&lt;=\" (i.e all dates less than or equal to June 25, 2019).\n\nChange the parameter selected next to \"Color\" at the top of the page from \"nitrate\" to \"pCO2_LIAR.\" pCO2_LIAR is calculated partial pressure of carbon_dioxide in sea_water.\n\npCO2_LIAR has a quality flag (pCO2_LIAR_QF) to indicate which data points are good and which are not. The values for the flag are 0=Good, 1=Missing or not inspected, 4=Questionable, 8=Bad”. Select \"pCO2_LIAR_QF\" as a constraint and enter 0 in \"Optional Constraint #1“. Make sure that the dropdown item to the left of \"Optional Constraint #1\" is set to \"=\" (i.e all values that are good).\n\nThis dataset has \"Region\" as a parameter, and we can use that to get just data from Antarctic. Select \"region\" as a constraint and select \"Antarctica\" from the dropdown widget menu\n\nNext click the \"Redraw the Graph\" button.\n\n\n\n\nRecent Floats in Antarctica"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#adjusting-the-map-display",
    "href": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#adjusting-the-map-display",
    "title": "Tabular Datasets, BGC-Argo data",
    "section": "",
    "text": "The scale for the pCO2 goes from 0-2000 uatm, but the data on the map seems to be between 300-500 uatm. In addition, the markers on the map are plus signs, which are hard to see. Let’s change the display to make the data easier to see.\n\nUnder \"Graph Settings\", set the \"Marker Type\" dropdown to \"Filled Square.”\nBelow \"Color Bar\", type 300 in the \"Minimum\" box and 500 in the \"Maximum\" box.\n\nNext click the \"Redraw the Graph\" button.\n\n\n\n\nRecent Floats in Antarctica"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#navigating-around-the-map",
    "href": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#navigating-around-the-map",
    "title": "Tabular Datasets, BGC-Argo data",
    "section": "",
    "text": "Now lets zoom in on the region around Australia.\n\nSelect longitude as a constraint and 100 as \"Optional Constraint #1\". Make sure that the dropdown item to the left of \"Optional Constraint #1\" is set to \"&gt;=\". Set 180 as \"Optional Constraint #2. Make sure that the dropdown item to the left of \"Optional Constraint #2\" is set to \"&lt;=\".\nClick the \"Redraw the Graph\" button.\n\n\n\n\nRecent Floats near Australia"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#subsetting-the-data",
    "href": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#subsetting-the-data",
    "title": "Tabular Datasets, BGC-Argo data",
    "section": "",
    "text": "What floats are we seeing? We can find this out by looking at the data itself.\n\nClick the \"Data Access Form\" above the map\n\nThis brings us to a new page which shows all the variables in the dataset, and allows constraints to be set on all of them. Constraints from the previous page have been retained.\n\nCheck the boxes next to \"WMO_ID\" and \"mbariID\" at the top of the list.\nCheck the boxes next to \"depth\" and add &lt;=10 as an as \"Optional Constraint\" for depth to limit the number of results per profile.\nClick the \"Sumbit\" button at the bottom of the page.\n\n\n\n\nListing of Floats near Australia"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#visualize-the-buoy-track",
    "href": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#visualize-the-buoy-track",
    "title": "Tabular Datasets, BGC-Argo data",
    "section": "",
    "text": "Now lets make a map of the complete trajectory for one of these floats, color coded by time.\n\nUse the browser back button to return to the \"Data Access Page\"\nClick on the ‘“Make a graph”’ link under the dataset title\nRemove the time and longitude constraint\nThe select a single buoy, identify it with the WMO ID. Select \"WMO_ID\" as a constraint and select 5904675 from the dropdown box that shows all of the buoys that adhere to all of the other constraints.\nClick the \"Redraw the Graph\" button.\n\nThe map shows the pCO2 values along the entire buoy track.\n\n\n\nFloat Trajectory showing pCO2\n\n\nWe can also pot the use the \"Color\" widget to plot the time for each of the symbols on the map.\n\nChange the parameter selected next to \"Color\" at the top of the page from \"pCO2_LIAR\" to \"time\"\nRemove the minimum (300) and maximum (500) values from underneath the ‘“color bar”’ in ’“Graph Settings’”\nThen click the \"Redraw the Graph\" button.\n\n\n\n\nFloat Trajectory showing date\n\n\nThe color bar is now time and color of marker indicate the date the the buoy of in a location."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#visualize-the-buoy-section-of-depth-profiles",
    "href": "tutorials/ERDDAP-Basics/using-tabular-data/using-tabular-data.html#visualize-the-buoy-section-of-depth-profiles",
    "title": "Tabular Datasets, BGC-Argo data",
    "section": "",
    "text": "Let’s make a section of Nitrate for this float.\n\nUnder ‘“Graph Type’” at the top of the page select’“time”’ as the ‘“X Axis”’, ‘“depth”’ as the ‘“Y Axis”’ and ‘“Nitrate”’ as the ‘“Color”’\nThen click the \"Redraw the Graph\" button.\n\n\n\n\nNitrate Section\n\n\nThe data is upside-down and not much detail can be seen in the surface so lets fix those issues.\n\nUnder ’“Graph Settings’” set the \"Y Axis Minimum\" to 0, the \"Y Axis Maximum\" to 350 and change \"Ascending\" to \"descending\".\nChange the Marker Size to \"10\"\nUnder \"Color Bar\", set \"Maximum\" to 15.\n\n\n\n\nNitrate Section, fixed up"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html",
    "href": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html",
    "title": "Visualization and download data",
    "section": "",
    "text": "Each ERDDAP dataset has a “Make A Graph” page that allows you to browse data by date and narrow down the spatial range of your of interest.\nMake sure you are on the search results page you generated in Chapter 1 by entering “sst global ostia” in the ERDDAP search box or by putting the following link in a browser: https://coastwatch.pfeg.noaa.gov/erddap/search/index.html?page=1&itemsPerPage=1000&searchFor=ID+%3DjplUKMO_OSTIAv20\n\n\n\nERDDAP results page for OSTIA\n\n\nOn the OSTIA listing in the search results, click on the “graph” link in the “Make A Graph” column. The Make A Graph page for the OSTIA SST dataset will load.\n\n\n\nOSTIA SST Make A Graph page with widgets indicated\n\n\nUse the widgets to adjust the map that appears on the right side of the “Make A Graph” page.\n\n“Color” widget - This widget has a misleading name. Use it to select the variable that displays on the map. By default \"analysed_sst\" is displayed. Click on the drop down menu to see the other choices. Try selecting \"sea_ice_fraction\" and watch how the map changes. When you are done, reselect \"analysed_sst\".\n\n“time (UTC)” widget - Use it to select the date of interest. By default it is set on the most recent date. There are several ways to select a different date.\n\nWith the slider bar, pulling the slider all the way to the left takes you to the first date entry in the dataset or any date in between. Take the slider and select a date midway on the slider bar. Click “Redraw the Graph” to display the new map.\n\nOn the date display (under the “Stop” column), clicking the minus (\"-\") or plus (\"+\") takes you one day back or forward. Clicking the solid blue left-pointing arrow takes you to the first date entry in the dataset. Clicking the solid blue right-pointing arrow takes you to the most recent entry in the dataset.\n\nTry typing a date, e.g. 2018-06-15T12:00:00Z, directly into the date display. Then click “Redraw the Graph”.\n\n\n“latitude” and “longitude” widgets - These widgets work like the time widget, except that you can set with minimum and maximum values with the slider, the \"-\" and \"+\" buttons, and the solid blue left- and right-pointing arrows.\n\n“File Type” widget - Use this widget to select the output file type. There are over 30 types to choose from. Some of the most useful for data and image file types are listed below. A full description of file types can be found at this link:\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/documentation.html\n\n.nc - netCDF files\n\n.mat - Matlab files\n\n.json - JSON format\n\n.png, .smallPng, .largePng, transparentPng\n\n.geotif\n\n.pdf, .smallPdf, .largePdf\n\n\n\n\n\nFor this example, select an area off of the Washington coast for July 15, 2015 by doing the following:\n\nPut in the following minimum and maximum latitude and longitude values using the widgets.\n\nLatitudes: 45, 52\n\nLongitudes: -129, -122\n\n\nThen click the \"Redraw the Graph\" button.\n\nNext, use the “time (UTC)” widget to select a time of July 15, 2015 (2015-07-15T12:00:00Z).\n\nThen click the \"Redraw the Graph\" button.\n\n\n\n\nWA coast, July 15, 2015\n\n\nThere is very little difference in the map color, so adjust the map color scale. * In the “Graph Settings” under “Color Bar”, * for “Minimum” input 12 * for “Maximum” input 20 * Then click the \"Redraw the Graph\" button\nYou can even change the color palette.  * Click the drop down next to \"Color Bar\" to see a selection of palettes.\n* The palettes beginning with \"KT\" are designed to show certain parameters best and with ADA compliance. Select the KT_thermal palette, which is designed for temperature maps, and click \"Redraw the Graph\".\n\n\n\nYou can request the data in many formats. Find the drop down box below the “Redraw the Graph” button that is labeled \"File Type\". Click on the drop down box to view a list of about 30 file formats.\nSome of the most useful for data download are:\n* .nc - netCDF files\n* .mat - Matlab files\n* .json - JSON format\n* Image files are available, too\n* .png, .smallPng, .largePng, transparentPng\n* .geotif\n* .pdf, .smallPdf, .largePdf\n* A full description of file types can be found here: https://coastwatch.pfeg.noaa.gov/erddap/griddap/documentation.html\nFor demonstration purposes, select \".largePng\"\n\n\n\nYou can download the data directly to your computer by clicking “Download the Data or an image”\nAlternatively, you can copy the URL in the “or view the URL” box. This URL contains the complete request of the data as you defined it. Put the URL in any browser to download the data. You can even send the URL to a colleague and they can download the data. More importantly, you can use the URL to import the data directly into analysis programs like R, Python, or Matlab.\nFor this example use an image file. * With the “File Type” set to .largePng, copy the URL in the “or view the URL” box (see below).\n&gt; https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.png?analysed_sst[(2015-07-17T12:00:00Z)][(45.025):(52.025)][(-128.975):(-121.975)]&.draw=surface&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccff\n\nNow open a new browser tab, paste in the URL, and hit return.\nThe map should appear as a PNG file in your browser. \n\nA few tricks\n\nYou can adjust the way the image looks, e.g. remove the legend, change the size. The documentation for this is at this link: https://coastwatch.pfeg.noaa.gov/erddap/griddap/documentation.html#GraphicsCommands\nIf you would like a map like this on a website you are building, just put the URL above into an HTML  tag. The image will be automatically included on your webpage.\n\n\n\n\nNow that you have defined the area of interest, you can add a time range and refine your data request. Make sure navigate you browser back to the \"Make A Graph\" page for the OSTIA dataset. The link is below if you do not have the page in your browser.\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.graph?analysed_sst[(2015-07-17T12:00:00Z)][(45.025):(52.025)][(-128.975):(-121.975)]&.draw=surface&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccf\nOn the upper right part of the \"Make A Graph\" page below the dataset title, click on the \"Data Access Form\" link. The Data Access Form that loads (figure below) has been populated with selections you made in the “Make A Graph” page.\n\n\n\nOSTIA SST Data Form\n\n\nNote the following:\nThe time widget now has a start and stop date, so you can pick a range of dates to download.\nThe time, latitude, and longitude widgets all have a “Stride” associated with them. The stride gives you additional control over subsetting by reducing the data density. For example:\n\nIf you wanted to get every other day, the stride would be “2”. A stride of “3” would get every third day.\nSimilarly, a stride of “5” in the latitude (or longitude) widgets would sample the data every fifth latitude value.\nThe stride value is helpful when you do not need as high a resolution as found in the dataset.\n\nSetting the time range\nFind the “time” widget. Use it to adjust the time range to the following one (1) month period:\n\nStart: 2015-06-17T12:00:00Z\nStop: 2015-07-17T12:00:00Z\n\nThis is a daily dataset, so if we requested every day in the time period we would get about 30 days of data.\n\nSet the stride to 7 to get the data for just one time per week, resulting in a netCDF file with 4 or 5 days of data.\n\nSelecting the variables to include\nIn the Grid Variables section you can request that additional variables be added to the download. The analysed_sst variable you selected has been preselected. If you want, you could include any of the other three variables.\nIn this example the addition variables are “analysis_error”, “sea_ice_fraction”, and “mask”. In the polar regions, for example, sea_ice_fraction might be an important variable to include.\n\nCheck the box next to “analysis_error” and “sea_ice_fraction” to include them in the download file\n\nSelecting the file type\nYou can request the data in many formats. We use the netCDF format for NOAA satellite courses and for many examples in this tutorial so select the format now.\n\nFind the “File type” drop down and select “nc”, which is the alias for netCDF.\n\nDownload the data\nYou can download the data directly to your computer by clicking “Submit” button.\nAlternatively, you can generate and copy the URL that defines your data request. Put the URL in any browser to download the data. You can even send the URL to a colleague and they can download the data. More importantly, you can use the URL to import the data directly into analysis programs like R, Python, or Matlab.\nFor now let’s get the URL and put it in a browser.\n\nFind the button labeled “Just get the URL” and click on it.\nIn the box to the right an URL will appear. Copy the URL.\nOpen a new tab on your browser, paste the URL in the address box, and hit return. The file should start to download.\n\nView the netCDF file using Panoply\nHopefully you were able to install the NASA netCDF viewer, Panoply. If so, try to load into Panoply the netCDF file you just downloaded.\n\n\n\nSelect a dataset and create a surface map of an area of the world that interests you."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#errdap-make-a-graph-feature",
    "href": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#errdap-make-a-graph-feature",
    "title": "Visualization and download data",
    "section": "",
    "text": "Each ERDDAP dataset has a “Make A Graph” page that allows you to browse data by date and narrow down the spatial range of your of interest.\nMake sure you are on the search results page you generated in Chapter 1 by entering “sst global ostia” in the ERDDAP search box or by putting the following link in a browser: https://coastwatch.pfeg.noaa.gov/erddap/search/index.html?page=1&itemsPerPage=1000&searchFor=ID+%3DjplUKMO_OSTIAv20\n\n\n\nERDDAP results page for OSTIA\n\n\nOn the OSTIA listing in the search results, click on the “graph” link in the “Make A Graph” column. The Make A Graph page for the OSTIA SST dataset will load.\n\n\n\nOSTIA SST Make A Graph page with widgets indicated\n\n\nUse the widgets to adjust the map that appears on the right side of the “Make A Graph” page.\n\n“Color” widget - This widget has a misleading name. Use it to select the variable that displays on the map. By default \"analysed_sst\" is displayed. Click on the drop down menu to see the other choices. Try selecting \"sea_ice_fraction\" and watch how the map changes. When you are done, reselect \"analysed_sst\".\n\n“time (UTC)” widget - Use it to select the date of interest. By default it is set on the most recent date. There are several ways to select a different date.\n\nWith the slider bar, pulling the slider all the way to the left takes you to the first date entry in the dataset or any date in between. Take the slider and select a date midway on the slider bar. Click “Redraw the Graph” to display the new map.\n\nOn the date display (under the “Stop” column), clicking the minus (\"-\") or plus (\"+\") takes you one day back or forward. Clicking the solid blue left-pointing arrow takes you to the first date entry in the dataset. Clicking the solid blue right-pointing arrow takes you to the most recent entry in the dataset.\n\nTry typing a date, e.g. 2018-06-15T12:00:00Z, directly into the date display. Then click “Redraw the Graph”.\n\n\n“latitude” and “longitude” widgets - These widgets work like the time widget, except that you can set with minimum and maximum values with the slider, the \"-\" and \"+\" buttons, and the solid blue left- and right-pointing arrows.\n\n“File Type” widget - Use this widget to select the output file type. There are over 30 types to choose from. Some of the most useful for data and image file types are listed below. A full description of file types can be found at this link:\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/documentation.html\n\n.nc - netCDF files\n\n.mat - Matlab files\n\n.json - JSON format\n\n.png, .smallPng, .largePng, transparentPng\n\n.geotif\n\n.pdf, .smallPdf, .largePdf"
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#subsetting-the-area-and-selecting-a-date",
    "href": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#subsetting-the-area-and-selecting-a-date",
    "title": "Visualization and download data",
    "section": "",
    "text": "For this example, select an area off of the Washington coast for July 15, 2015 by doing the following:\n\nPut in the following minimum and maximum latitude and longitude values using the widgets.\n\nLatitudes: 45, 52\n\nLongitudes: -129, -122\n\n\nThen click the \"Redraw the Graph\" button.\n\nNext, use the “time (UTC)” widget to select a time of July 15, 2015 (2015-07-15T12:00:00Z).\n\nThen click the \"Redraw the Graph\" button.\n\n\n\n\nWA coast, July 15, 2015\n\n\nThere is very little difference in the map color, so adjust the map color scale. * In the “Graph Settings” under “Color Bar”, * for “Minimum” input 12 * for “Maximum” input 20 * Then click the \"Redraw the Graph\" button\nYou can even change the color palette.  * Click the drop down next to \"Color Bar\" to see a selection of palettes.\n* The palettes beginning with \"KT\" are designed to show certain parameters best and with ADA compliance. Select the KT_thermal palette, which is designed for temperature maps, and click \"Redraw the Graph\"."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#setting-the-file-format",
    "href": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#setting-the-file-format",
    "title": "Visualization and download data",
    "section": "",
    "text": "You can request the data in many formats. Find the drop down box below the “Redraw the Graph” button that is labeled \"File Type\". Click on the drop down box to view a list of about 30 file formats.\nSome of the most useful for data download are:\n* .nc - netCDF files\n* .mat - Matlab files\n* .json - JSON format\n* Image files are available, too\n* .png, .smallPng, .largePng, transparentPng\n* .geotif\n* .pdf, .smallPdf, .largePdf\n* A full description of file types can be found here: https://coastwatch.pfeg.noaa.gov/erddap/griddap/documentation.html\nFor demonstration purposes, select \".largePng\""
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#download-the-image",
    "href": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#download-the-image",
    "title": "Visualization and download data",
    "section": "",
    "text": "You can download the data directly to your computer by clicking “Download the Data or an image”\nAlternatively, you can copy the URL in the “or view the URL” box. This URL contains the complete request of the data as you defined it. Put the URL in any browser to download the data. You can even send the URL to a colleague and they can download the data. More importantly, you can use the URL to import the data directly into analysis programs like R, Python, or Matlab.\nFor this example use an image file. * With the “File Type” set to .largePng, copy the URL in the “or view the URL” box (see below).\n&gt; https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.png?analysed_sst[(2015-07-17T12:00:00Z)][(45.025):(52.025)][(-128.975):(-121.975)]&.draw=surface&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccff\n\nNow open a new browser tab, paste in the URL, and hit return.\nThe map should appear as a PNG file in your browser. \n\nA few tricks\n\nYou can adjust the way the image looks, e.g. remove the legend, change the size. The documentation for this is at this link: https://coastwatch.pfeg.noaa.gov/erddap/griddap/documentation.html#GraphicsCommands\nIf you would like a map like this on a website you are building, just put the URL above into an HTML  tag. The image will be automatically included on your webpage."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#refining-the-data-request",
    "href": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#refining-the-data-request",
    "title": "Visualization and download data",
    "section": "",
    "text": "Now that you have defined the area of interest, you can add a time range and refine your data request. Make sure navigate you browser back to the \"Make A Graph\" page for the OSTIA dataset. The link is below if you do not have the page in your browser.\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.graph?analysed_sst[(2015-07-17T12:00:00Z)][(45.025):(52.025)][(-128.975):(-121.975)]&.draw=surface&.vars=longitude|latitude|analysed_sst&.colorBar=KT_thermal|||12|20|&.bgColor=0xffccccf\nOn the upper right part of the \"Make A Graph\" page below the dataset title, click on the \"Data Access Form\" link. The Data Access Form that loads (figure below) has been populated with selections you made in the “Make A Graph” page.\n\n\n\nOSTIA SST Data Form\n\n\nNote the following:\nThe time widget now has a start and stop date, so you can pick a range of dates to download.\nThe time, latitude, and longitude widgets all have a “Stride” associated with them. The stride gives you additional control over subsetting by reducing the data density. For example:\n\nIf you wanted to get every other day, the stride would be “2”. A stride of “3” would get every third day.\nSimilarly, a stride of “5” in the latitude (or longitude) widgets would sample the data every fifth latitude value.\nThe stride value is helpful when you do not need as high a resolution as found in the dataset.\n\nSetting the time range\nFind the “time” widget. Use it to adjust the time range to the following one (1) month period:\n\nStart: 2015-06-17T12:00:00Z\nStop: 2015-07-17T12:00:00Z\n\nThis is a daily dataset, so if we requested every day in the time period we would get about 30 days of data.\n\nSet the stride to 7 to get the data for just one time per week, resulting in a netCDF file with 4 or 5 days of data.\n\nSelecting the variables to include\nIn the Grid Variables section you can request that additional variables be added to the download. The analysed_sst variable you selected has been preselected. If you want, you could include any of the other three variables.\nIn this example the addition variables are “analysis_error”, “sea_ice_fraction”, and “mask”. In the polar regions, for example, sea_ice_fraction might be an important variable to include.\n\nCheck the box next to “analysis_error” and “sea_ice_fraction” to include them in the download file\n\nSelecting the file type\nYou can request the data in many formats. We use the netCDF format for NOAA satellite courses and for many examples in this tutorial so select the format now.\n\nFind the “File type” drop down and select “nc”, which is the alias for netCDF.\n\nDownload the data\nYou can download the data directly to your computer by clicking “Submit” button.\nAlternatively, you can generate and copy the URL that defines your data request. Put the URL in any browser to download the data. You can even send the URL to a colleague and they can download the data. More importantly, you can use the URL to import the data directly into analysis programs like R, Python, or Matlab.\nFor now let’s get the URL and put it in a browser.\n\nFind the button labeled “Just get the URL” and click on it.\nIn the box to the right an URL will appear. Copy the URL.\nOpen a new tab on your browser, paste the URL in the address box, and hit return. The file should start to download.\n\nView the netCDF file using Panoply\nHopefully you were able to install the NASA netCDF viewer, Panoply. If so, try to load into Panoply the netCDF file you just downloaded."
  },
  {
    "objectID": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#try-this-on-you-own",
    "href": "tutorials/ERDDAP-Basics/visualize-and-download-data/visualize-and-download-data.html#try-this-on-you-own",
    "title": "Visualization and download data",
    "section": "",
    "text": "Select a dataset and create a surface map of an area of the world that interests you."
  },
  {
    "objectID": "tutorials/Tutorial1-basics/matlab/Tutorial1-basics.html",
    "href": "tutorials/Tutorial1-basics/matlab/Tutorial1-basics.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands. Note: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset monthly SST data: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.html Select your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nerddap interface\n\n\nIn this specific example, the URL we generated is: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.nc?sea_surface_temperature%5B(2018-1-31T12:00:00Z):1:(2018-12-31T12:00:00Z)%5D%5B(17):1:(30)%5D%5B(195):1:(210)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly'); \nNotice that the full data set has four variables: time, latitude, longitude, and sea_surface_temperature. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\nTime Notice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'time');\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the year we’re interested in: 2018.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2018);\nLatitude and Longitude Before we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'longitude');\nNotice in the output above that sea_surface_temperature has the dimensions of longitude x latitude x time which means it has a size of 7200 x 3600 x 444. In the code below, we’ll create indices for our particular area of interest in the central North Pacific.\n% Find longitudes from 195 - 210 E\nlon_aoi = find(lon_full &gt;= 195 & lon_full &lt;= 210);\n\n% Find latitudes from 17 - 30 N\nlat_aoi = find(lat_full &gt;= 17 & lat_full &lt;= 30);\nSea Surface Temperature Now, we’ll access just the small amount of sea_surface_temperature data we’re interested in. We’ll do this by telling the computer to access the variable ‘sea_surface_temperature’, beginning at a specific location and time, and spanning our area and time of interest.\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', ...\n    'sea_surface_temperature', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 300 x 260 x 12. Before we see what these data look like, let’s create indices for the area and timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* % Delete every variable with 'aoi' or with 'full' in its name\n\n\n\nLet’s create a map for a single month, January 2018, the first month in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 100, 'fill', 'on');\ntitle(sprintf('Monthly SST %s', datestr(time_ymdhms(1,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(26,4), 202:1:205, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 20\ncontourm(lat, lon, sst(:,:,1)', [20 20], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\nJanuary SST\n\n\n\n\n\nLet’s pick the following box: 24-26N, 200-206E. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above to identify a subsetted area of interest.\n% Find longitudes from 200 - 206 E\nlon_aoi = find(lon &gt;= 200 & lon &lt;= 206);\n\n% Find latitudes from 24 - 26 N\nlat_aoi = find(lat &gt;= 24 & lat &lt;= 26);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 12 months\nsst_ts(1:12,1) = NaN;\nfor m = 1:1:12 \n    sst_ts(m,1) = mean(sst_subset(:,:,m), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,2), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\n\n\n\nSST time series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n\n% Average over time, which is the third dimention of our data\nsst_yr = mean(sst, 3, \"omitnan\");\n\n% Plot\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_yr', 100, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(12,:),'mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nJan mean sst"
  },
  {
    "objectID": "tutorials/Tutorial1-basics/matlab/Tutorial1-basics.html#tutorial-1.-how-to-work-with-satellite-data-in-matlab",
    "href": "tutorials/Tutorial1-basics/matlab/Tutorial1-basics.html#tutorial-1.-how-to-work-with-satellite-data-in-matlab",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands. Note: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset monthly SST data: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.html Select your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nerddap interface\n\n\nIn this specific example, the URL we generated is: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.nc?sea_surface_temperature%5B(2018-1-31T12:00:00Z):1:(2018-12-31T12:00:00Z)%5D%5B(17):1:(30)%5D%5B(195):1:(210)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly'); \nNotice that the full data set has four variables: time, latitude, longitude, and sea_surface_temperature. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\nTime Notice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'time');\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the year we’re interested in: 2018.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2018);\nLatitude and Longitude Before we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'longitude');\nNotice in the output above that sea_surface_temperature has the dimensions of longitude x latitude x time which means it has a size of 7200 x 3600 x 444. In the code below, we’ll create indices for our particular area of interest in the central North Pacific.\n% Find longitudes from 195 - 210 E\nlon_aoi = find(lon_full &gt;= 195 & lon_full &lt;= 210);\n\n% Find latitudes from 17 - 30 N\nlat_aoi = find(lat_full &gt;= 17 & lat_full &lt;= 30);\nSea Surface Temperature Now, we’ll access just the small amount of sea_surface_temperature data we’re interested in. We’ll do this by telling the computer to access the variable ‘sea_surface_temperature’, beginning at a specific location and time, and spanning our area and time of interest.\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', ...\n    'sea_surface_temperature', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 300 x 260 x 12. Before we see what these data look like, let’s create indices for the area and timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* % Delete every variable with 'aoi' or with 'full' in its name\n\n\n\nLet’s create a map for a single month, January 2018, the first month in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 100, 'fill', 'on');\ntitle(sprintf('Monthly SST %s', datestr(time_ymdhms(1,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(26,4), 202:1:205, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 20\ncontourm(lat, lon, sst(:,:,1)', [20 20], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\nJanuary SST\n\n\n\n\n\nLet’s pick the following box: 24-26N, 200-206E. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above to identify a subsetted area of interest.\n% Find longitudes from 200 - 206 E\nlon_aoi = find(lon &gt;= 200 & lon &lt;= 206);\n\n% Find latitudes from 24 - 26 N\nlat_aoi = find(lat &gt;= 24 & lat &lt;= 26);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 12 months\nsst_ts(1:12,1) = NaN;\nfor m = 1:1:12 \n    sst_ts(m,1) = mean(sst_subset(:,:,m), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,2), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\n\n\n\nSST time series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n\n% Average over time, which is the third dimention of our data\nsst_yr = mean(sst, 3, \"omitnan\");\n\n% Plot\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_yr', 100, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(12,:),'mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nJan mean sst"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/matlab/Tutorial2-timeseries-compare-sensors.html",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/matlab/Tutorial2-timeseries-compare-sensors.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "As an example, we are going to plot time-series of mean chlorophyll-a concentration from various sensors from 1997 to 2018 to look at the periods of overlap.\nWe are going to download data from SeaWiFS (1997-2010), MODIS (2002-present) and VIIRS (2012-present) and compare it to the ESA-CCI data which combines all 3 sensors into a homogeneous time-series.\nIn this tutorial, the URLs to the data are provided so you don’t have to search for them. But, if you weren’t sure what the URLs were, you could find them by searing the list of datasets hosted on the OceanWatch ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/index.html) and following the steps at the beginning of Tutoral 1.\nFor this tutoral, we’re interested in all time steps in the area bounded by 15 - 25N, 198 - 208E.\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nsw_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'time');\n\n% Convert this to [Y M D H M S]\nsw_time_ymdhms = datevec(sw_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(sw_time)];\n% Download the data of interest\nsw = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nswAVG(1:length(sw_time),1) = NaN;\nfor m = 1:1:length(sw_time)\n    swAVG(m,1) = mean(sw(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* sw m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nmodis_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'time'); \n\n% Convert this to [Y M D H M S]\nmodis_time_ymdhms = datevec(modis_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(modis_time)];\n\n% Download the data of interest\nmodis = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nmodisAVG(1:length(modis_time),1) = NaN;\nfor m = 1:1:length(modis_time)\n    modisAVG(m,1) = mean(modis(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* modis m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nviirs_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'time');\n\n% Convert this to [Y M D H M S]\nviirs_time_ymdhms = datevec(viirs_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(viirs_time)];\n% Download the data of interest\nviirs = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nviirsAVG(1:length(viirs_time),1) = NaN;\nfor m = 1:1:length(viirs_time)\n    viirsAVG(m,1) = mean(viirs(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* viirs m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nesa_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'time');\n\n% Convert this to [Y M D H M S]\nesa_time_ymdhms = datevec(esa_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(esa_time)];\n\n% Download the data of interest\nesa = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nesaAVG(1:length(esa_time),1) = NaN;\nfor m = 1:1:length(esa_time)\n    esaAVG(m,1) = mean(esa(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* esa m \n\n\n\nNow we can compare the spatial averages across the three sensors: SeaWiFS, MODIS, and VIIRS. We’ll do this by generating a plot the includes all three time series, which overlap to varying degrees.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'Color', [0 70 127]/255);\nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'Color', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'Color', [127 127 255]/255);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChloraophyll-a from MODIS and VIIRS\n\n\nYou can see that the values of chlorophyll-a concentration don’t match across sensors.\n\n\n\nThe OC-CCI data are from a blended product, that merges the three sensors.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'o', 'MarkerFaceColor', [0 70 127]/255, 'MarkerEdgeColor', ...\n    [0 70 127]/255); \nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'o', 'MarkerFaceColor', [147 213 0]/255, ...\n    'MarkerEdgeColor', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'o', 'MarkerFaceColor', [127 127 255]/255, ...\n    'MarkerEdgeColor', [127 127 255]/255);\nplot(datenum(esa_time_ymdhms), esaAVG, 'k', 'LineWidth', 2);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'OC-CCI', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChlorphyll from ESA OC-CCI"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/matlab/Tutorial2-timeseries-compare-sensors.html#tutorial-2.-comparison-of-chlorophyll-data-from-different-sensors",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/matlab/Tutorial2-timeseries-compare-sensors.html#tutorial-2.-comparison-of-chlorophyll-data-from-different-sensors",
    "title": "CoastWatch Training",
    "section": "",
    "text": "As an example, we are going to plot time-series of mean chlorophyll-a concentration from various sensors from 1997 to 2018 to look at the periods of overlap.\nWe are going to download data from SeaWiFS (1997-2010), MODIS (2002-present) and VIIRS (2012-present) and compare it to the ESA-CCI data which combines all 3 sensors into a homogeneous time-series.\nIn this tutorial, the URLs to the data are provided so you don’t have to search for them. But, if you weren’t sure what the URLs were, you could find them by searing the list of datasets hosted on the OceanWatch ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/index.html) and following the steps at the beginning of Tutoral 1.\nFor this tutoral, we’re interested in all time steps in the area bounded by 15 - 25N, 198 - 208E.\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nsw_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'time');\n\n% Convert this to [Y M D H M S]\nsw_time_ymdhms = datevec(sw_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(sw_time)];\n% Download the data of interest\nsw = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nswAVG(1:length(sw_time),1) = NaN;\nfor m = 1:1:length(sw_time)\n    swAVG(m,1) = mean(sw(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* sw m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nmodis_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'time'); \n\n% Convert this to [Y M D H M S]\nmodis_time_ymdhms = datevec(modis_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(modis_time)];\n\n% Download the data of interest\nmodis = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nmodisAVG(1:length(modis_time),1) = NaN;\nfor m = 1:1:length(modis_time)\n    modisAVG(m,1) = mean(modis(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* modis m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nviirs_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'time');\n\n% Convert this to [Y M D H M S]\nviirs_time_ymdhms = datevec(viirs_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(viirs_time)];\n% Download the data of interest\nviirs = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nviirsAVG(1:length(viirs_time),1) = NaN;\nfor m = 1:1:length(viirs_time)\n    viirsAVG(m,1) = mean(viirs(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* viirs m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nesa_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'time');\n\n% Convert this to [Y M D H M S]\nesa_time_ymdhms = datevec(esa_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(esa_time)];\n\n% Download the data of interest\nesa = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nesaAVG(1:length(esa_time),1) = NaN;\nfor m = 1:1:length(esa_time)\n    esaAVG(m,1) = mean(esa(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* esa m \n\n\n\nNow we can compare the spatial averages across the three sensors: SeaWiFS, MODIS, and VIIRS. We’ll do this by generating a plot the includes all three time series, which overlap to varying degrees.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'Color', [0 70 127]/255);\nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'Color', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'Color', [127 127 255]/255);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChloraophyll-a from MODIS and VIIRS\n\n\nYou can see that the values of chlorophyll-a concentration don’t match across sensors.\n\n\n\nThe OC-CCI data are from a blended product, that merges the three sensors.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'o', 'MarkerFaceColor', [0 70 127]/255, 'MarkerEdgeColor', ...\n    [0 70 127]/255); \nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'o', 'MarkerFaceColor', [147 213 0]/255, ...\n    'MarkerEdgeColor', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'o', 'MarkerFaceColor', [127 127 255]/255, ...\n    'MarkerEdgeColor', [127 127 255]/255);\nplot(datenum(esa_time_ymdhms), esaAVG, 'k', 'LineWidth', 2);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'OC-CCI', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChlorphyll from ESA OC-CCI"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "notebook filename | sea_ice_extent.Rmd\n\n\n\nSea ice cover measurements are key to polar ecological and climatological research. This measurement has gained attention because of the recent decrease in the Arctic sea ice cover. Satellite observations are essential for tracking sea ice cover, providing continuous global coverage extending back to 1978. Typically, sea ice cover is reported as sea ice concentration, which is the percent areal coverage of ice within a grid cell. Depending on the application, additional parameters of interest can be calculated from sea ice cover:\n\nSea ice area - the cumulative coverage of all gridded sections (area), including each grid that contains a minimum ice concentration of 15%.\n\nSea ice extent - the cumulative coverage of all griddedthe sum of the areas of all grid cells with at least 15% ice concentration\n\n\n\n\nThis tutorial will demonstrate how to calculate the sea ice area and extent using sea ice concentration and grid cell area data. Please visit the NSIDC website for more detailed descriptions of the calculations.\n\n\n\n\nDownloading and saving a netcdf file from the PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nDownloading and adding grid cell area data to the satellite data\nVisualizing data on a map\nComputing sea ice area and extent using sea ice concentration data\nPlotting a time series of sea ice area and extent\n\n\n\n\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere.\nThe Sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. Near-Real-Time data are also available at PolarWatch. (SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Northern Polar Stereographic projection (EPSG:3413). The resolution is 25km, meaning each grid cell in this data set represents a value that covers a 25km by 25km area. The dataset is available on the PolarWatch data portal and can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.graph\nPolar Stereographic Grid Cell Area Values of 25km grid, Polar Stereographic (North), NSIDC Ancillary Data.\nThis dataset includes the area (in m2) of each grid cell in the 25km resolution Northern Polar Stereographic projection. This dataset is available on the PolarWatch ERDDAP\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ggplot2\" ,\"ncdf4\",  \"RColorBrewer\", \"scales\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# Set up download method as libcurl, this is only needed for Windows machines\noptions(download.file.method=\"libcurl\", url.method=\"libcurl\")\n\n\n\nHere we download the average monthly sea ice concentration for the Arctic for 2021 (January to December). We are using the NSIDC Sea Ice Concentration Climate Data Record (NSIDC ID: G002202).\nThe ERDDAP data request URL for this data subset is presented below.\nhttps://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nThe following table shows the component parts of the ERDDAP data request URL.\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID of the dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nNetCDF (there are many other available file formats)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariables from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]\nTemporal\n\n\nspatial_range\n[(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nSpatial coverage\n\n\n\n` Note The metadata states that the _FillValue for this dataset is set to -999, however when the _FillValue attribute is found, the ncdf4 package maps all the missing values (_FillValue) to NA’s.\n# Set data request URL for PolarWatch ERDDAP data server\ndata_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\"\n\n\n# Send data request and download file to the file name\nf &lt;- 'sic.nc'\ndownload.file(data_url, destfile=f, mode=\"wb\")\n# Open netcdf file\nnc=nc_open('sic.nc')\n\n# Examine file metadata\n#print(nc)\n\n# Examine names of variables\nnames(nc$var)\n\n# Get first variable metadata\nvar1 &lt;- nc$var[[1]]\n\n# Examine variable metadata\n#print(var1)\n\n# Get variable values\nsic &lt;- ncvar_get(nc,var1$name)\n\n# Examine dimension of variables\ndim(sic)\n\n# Based on metadata, set xgrid, ygrid\nxgrid &lt;- var1$dim[[1]]$vals\nygrid &lt;- var1$dim[[2]]$vals\n\n# convert time variable to date format\ndates &lt;- as.POSIXlt(var1$dim[[3]]$vals,origin='1970-01-01',tz='GMT')\n# Close and remove the netCDF file and clear memories\nnc_close(nc)\nfile.remove('sic.nc')\n## [1] TRUE\n\n\n\nTo plot sea ice concentration data that are in xgrid and ygrid dimensions, we will create a data frame with coordinates (xgrid, ygrid) and associated sea ice concentration values.\n# Create a data frame with all combinations of xgrid and ygrid\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\n\n# Add sic data array to the data frame\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude the _FillValue listed in the metadata (2.53999) which corresponds to various pixels with no data (land, coast, missing data, etc...)\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# Map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous() + \n       scale_x_continuous() +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\") +\n      ggtitle(\"Sea Ice Concentration on Polar Steregraphic projection\")\n\n\n\n\nWhile the resolution of this data set is 25km, the actual area of each grid cell depends on the grid projection. We will download the grid cell area values from the PolarWatch ERDDAP.\ncell_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k.nc?cell_area%5B(5837500.0):1:(-5337500.0)%5D%5B(-3837500.0):1:(3737500.0)%5D\"\nf &lt;- 'gridcell.nc'\ndownload.file(cell_url, destfile=f, mode=\"wb\")\n\n\n\nJust like for the sea ice concentration dataset, we will examine the metadata and extract the variables of grid cell areas along with x and y grids.\n# Open netcdf file\nnc1=nc_open('gridcell.nc')\n\n# Examine names of variables\nnames(nc1$var)\n\n# Get first variable metadata\narea_var &lt;- nc1$var[[1]]\n\n# Examine area_var\nnames(area_var)\n\n# Get variable values\ncellarea =ncvar_get(nc1,area_var$name)\n\n# Examine dimension of variable values\ndim(cellarea)\n\n# Based on metadata, set xgrid, ygrid, time\nx_area &lt;- area_var$dim[[1]]$vals\ny_area &lt;- area_var$dim[[2]]$vals\n\n# Close and remove the netCDF file and clear memories\nnc_close(nc1)\nfile.remove('gridcell.nc')\n\n\n\nNow we have two data sets: sea ice concentration and grid cell areas for each grid of northern polar stereographic projection. While the spatial coverage of both data sets is identical, we will ensure the x and y coordinates of both data sets are correctly aligned.\n# Get indices in areas where x and y grids equal those of sic\nx_indices &lt;- match(xgrid, x_area)\ny_indices &lt;- match(ygrid, y_area)\n\n# Extract grid area\ngrid.match &lt;- cellarea[x_indices, y_indices]\n\n\n\nWe need to clean the data before computing the sea ice area and extent.\n\nThe dataset includes flag values indicating non-sea ice area such as land, lakes, etc.\n\ntask: remove flag values (2 and higher) by setting the flag values as Nan.\n\nFor this example of the sea ice area and extent calculations, a value of 0.15 of sea ice concentration value will be used as a threshold.\n\ntask: set sic value to 0 if the value is less than 0.15\n\n\nFor more detailed information about the flag values, go to the user guide. For the calculation of sea ice area and extent with a threshold, go to the NSIDC article.\n# Set sic values less than 0.15 to (applying 0.15 threshold)\nsic[sic &lt; 0.15] &lt;- 0\n\n# Set 0 for all flag values (&gt;2)\nsic[sic &gt; 1] &lt;- 0\n\n# Set NA to 0\nsic[is.na(sic)] &lt;- 0\n\n# Sic for extent calc\nsic_ext &lt;- sic\nsic_ext[sic_ext &gt;= 0.15] &lt;- 1\n\n\n# Perform element-wise multiplication for the first time step\narea_total &lt;- sic[,,1] * grid.match\next_total &lt;- sic_ext[,,1] * grid.match\n\n# Sum area and extent over all grid cells and convert from m^2 to km^2\narea &lt;- sum(area_total) / 1000000\nextent &lt;- sum(ext_total) / 1000000\n\nprint(paste(\"Sea Ice Area (km^2): \", floor(area)))\n## [1] \"Sea Ice Area (km^2):  12564015\"\nprint(paste(\"Sea Ice Extent (km^2): \", floor(extent)))\n## [1] \"Sea Ice Extent (km^2):  13905993\"\n\n\n\n# Replicate grid areas for all timestep\nrep_grid_areas &lt;- array(rep(grid.match, each=dim(sic)[3]), dim=dim(sic))\n\n# Perform element-wise multiplication\narea_total12 &lt;- sic * rep_grid_areas\next_total12 &lt;- sic_ext * rep_grid_areas\n\narea12 &lt;- apply(area_total12, c(3), sum)\next12 &lt;- apply(ext_total12, c(3), sum)\n\n\n\nupper = max(max(ext12), max(area12))\nlower = min(min(ext12), min(area12))\nplot(dates,ext12,type='o',pch=20,xlab='Date',ylab='Area (km^2)', col=\"orange\" , ylim=c(lower, upper),  main=\"2021 Monthly Sea ice area and sea ice extent\")\nlines(dates, area12, type='o', pch=20, col=\"blue\")\nlegend(\"topright\", legend=c(\"Sea ice Area\", \"Sea ice Extent\"),\n       col=c(\"blue\", \"orange\"), lty=1:1, cex=0.8)\nbox()\n\n\n\n\n\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nPolarWatch Data Catalog\nWhat’s the difference between Sea ice area and extent?\nNSIDC Arctic Sea Ice News & Analysis\nClimate.gov Understanding Climate: sea ice extent\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#background",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#background",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Sea ice cover measurements are key to polar ecological and climatological research. This measurement has gained attention because of the recent decrease in the Arctic sea ice cover. Satellite observations are essential for tracking sea ice cover, providing continuous global coverage extending back to 1978. Typically, sea ice cover is reported as sea ice concentration, which is the percent areal coverage of ice within a grid cell. Depending on the application, additional parameters of interest can be calculated from sea ice cover:\n\nSea ice area - the cumulative coverage of all gridded sections (area), including each grid that contains a minimum ice concentration of 15%.\n\nSea ice extent - the cumulative coverage of all griddedthe sum of the areas of all grid cells with at least 15% ice concentration"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#objective",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#objective",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "This tutorial will demonstrate how to calculate the sea ice area and extent using sea ice concentration and grid cell area data. Please visit the NSIDC website for more detailed descriptions of the calculations."
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Downloading and saving a netcdf file from the PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nDownloading and adding grid cell area data to the satellite data\nVisualizing data on a map\nComputing sea ice area and extent using sea ice concentration data\nPlotting a time series of sea ice area and extent"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#datasets-used",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#datasets-used",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere.\nThe Sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. Near-Real-Time data are also available at PolarWatch. (SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Northern Polar Stereographic projection (EPSG:3413). The resolution is 25km, meaning each grid cell in this data set represents a value that covers a 25km by 25km area. The dataset is available on the PolarWatch data portal and can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.graph\nPolar Stereographic Grid Cell Area Values of 25km grid, Polar Stereographic (North), NSIDC Ancillary Data.\nThis dataset includes the area (in m2) of each grid cell in the 25km resolution Northern Polar Stereographic projection. This dataset is available on the PolarWatch ERDDAP\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ggplot2\" ,\"ncdf4\",  \"RColorBrewer\", \"scales\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# Set up download method as libcurl, this is only needed for Windows machines\noptions(download.file.method=\"libcurl\", url.method=\"libcurl\")"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#get-the-sea-ice-data-from-erddap",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#get-the-sea-ice-data-from-erddap",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Here we download the average monthly sea ice concentration for the Arctic for 2021 (January to December). We are using the NSIDC Sea Ice Concentration Climate Data Record (NSIDC ID: G002202).\nThe ERDDAP data request URL for this data subset is presented below.\nhttps://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nThe following table shows the component parts of the ERDDAP data request URL.\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID of the dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nNetCDF (there are many other available file formats)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariables from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]\nTemporal\n\n\nspatial_range\n[(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nSpatial coverage\n\n\n\n` Note The metadata states that the _FillValue for this dataset is set to -999, however when the _FillValue attribute is found, the ncdf4 package maps all the missing values (_FillValue) to NA’s.\n# Set data request URL for PolarWatch ERDDAP data server\ndata_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\"\n\n\n# Send data request and download file to the file name\nf &lt;- 'sic.nc'\ndownload.file(data_url, destfile=f, mode=\"wb\")\n# Open netcdf file\nnc=nc_open('sic.nc')\n\n# Examine file metadata\n#print(nc)\n\n# Examine names of variables\nnames(nc$var)\n\n# Get first variable metadata\nvar1 &lt;- nc$var[[1]]\n\n# Examine variable metadata\n#print(var1)\n\n# Get variable values\nsic &lt;- ncvar_get(nc,var1$name)\n\n# Examine dimension of variables\ndim(sic)\n\n# Based on metadata, set xgrid, ygrid\nxgrid &lt;- var1$dim[[1]]$vals\nygrid &lt;- var1$dim[[2]]$vals\n\n# convert time variable to date format\ndates &lt;- as.POSIXlt(var1$dim[[3]]$vals,origin='1970-01-01',tz='GMT')\n# Close and remove the netCDF file and clear memories\nnc_close(nc)\nfile.remove('sic.nc')\n## [1] TRUE"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#plot-sea-ice-concentration-data",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#plot-sea-ice-concentration-data",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "To plot sea ice concentration data that are in xgrid and ygrid dimensions, we will create a data frame with coordinates (xgrid, ygrid) and associated sea ice concentration values.\n# Create a data frame with all combinations of xgrid and ygrid\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\n\n# Add sic data array to the data frame\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude the _FillValue listed in the metadata (2.53999) which corresponds to various pixels with no data (land, coast, missing data, etc...)\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# Map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous() + \n       scale_x_continuous() +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\") +\n      ggtitle(\"Sea Ice Concentration on Polar Steregraphic projection\")"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#download-grid-cell-area-values",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#download-grid-cell-area-values",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "While the resolution of this data set is 25km, the actual area of each grid cell depends on the grid projection. We will download the grid cell area values from the PolarWatch ERDDAP.\ncell_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k.nc?cell_area%5B(5837500.0):1:(-5337500.0)%5D%5B(-3837500.0):1:(3737500.0)%5D\"\nf &lt;- 'gridcell.nc'\ndownload.file(cell_url, destfile=f, mode=\"wb\")"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#examine-grid-cell-dataset-metadata-and-extract-values",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#examine-grid-cell-dataset-metadata-and-extract-values",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Just like for the sea ice concentration dataset, we will examine the metadata and extract the variables of grid cell areas along with x and y grids.\n# Open netcdf file\nnc1=nc_open('gridcell.nc')\n\n# Examine names of variables\nnames(nc1$var)\n\n# Get first variable metadata\narea_var &lt;- nc1$var[[1]]\n\n# Examine area_var\nnames(area_var)\n\n# Get variable values\ncellarea =ncvar_get(nc1,area_var$name)\n\n# Examine dimension of variable values\ndim(cellarea)\n\n# Based on metadata, set xgrid, ygrid, time\nx_area &lt;- area_var$dim[[1]]$vals\ny_area &lt;- area_var$dim[[2]]$vals\n\n# Close and remove the netCDF file and clear memories\nnc_close(nc1)\nfile.remove('gridcell.nc')"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#match-cell-area-grids-with-sic-grids",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#match-cell-area-grids-with-sic-grids",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Now we have two data sets: sea ice concentration and grid cell areas for each grid of northern polar stereographic projection. While the spatial coverage of both data sets is identical, we will ensure the x and y coordinates of both data sets are correctly aligned.\n# Get indices in areas where x and y grids equal those of sic\nx_indices &lt;- match(xgrid, x_area)\ny_indices &lt;- match(ygrid, y_area)\n\n# Extract grid area\ngrid.match &lt;- cellarea[x_indices, y_indices]"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#clean-sea-ice-concentration-data-for-sea-ice-area-calculation",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#clean-sea-ice-concentration-data-for-sea-ice-area-calculation",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "We need to clean the data before computing the sea ice area and extent.\n\nThe dataset includes flag values indicating non-sea ice area such as land, lakes, etc.\n\ntask: remove flag values (2 and higher) by setting the flag values as Nan.\n\nFor this example of the sea ice area and extent calculations, a value of 0.15 of sea ice concentration value will be used as a threshold.\n\ntask: set sic value to 0 if the value is less than 0.15\n\n\nFor more detailed information about the flag values, go to the user guide. For the calculation of sea ice area and extent with a threshold, go to the NSIDC article.\n# Set sic values less than 0.15 to (applying 0.15 threshold)\nsic[sic &lt; 0.15] &lt;- 0\n\n# Set 0 for all flag values (&gt;2)\nsic[sic &gt; 1] &lt;- 0\n\n# Set NA to 0\nsic[is.na(sic)] &lt;- 0\n\n# Sic for extent calc\nsic_ext &lt;- sic\nsic_ext[sic_ext &gt;= 0.15] &lt;- 1\n\n\n# Perform element-wise multiplication for the first time step\narea_total &lt;- sic[,,1] * grid.match\next_total &lt;- sic_ext[,,1] * grid.match\n\n# Sum area and extent over all grid cells and convert from m^2 to km^2\narea &lt;- sum(area_total) / 1000000\nextent &lt;- sum(ext_total) / 1000000\n\nprint(paste(\"Sea Ice Area (km^2): \", floor(area)))\n## [1] \"Sea Ice Area (km^2):  12564015\"\nprint(paste(\"Sea Ice Extent (km^2): \", floor(extent)))\n## [1] \"Sea Ice Extent (km^2):  13905993\""
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#generate-the-sea-ice-area-and-extent-time-series",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#generate-the-sea-ice-area-and-extent-time-series",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "# Replicate grid areas for all timestep\nrep_grid_areas &lt;- array(rep(grid.match, each=dim(sic)[3]), dim=dim(sic))\n\n# Perform element-wise multiplication\narea_total12 &lt;- sic * rep_grid_areas\next_total12 &lt;- sic_ext * rep_grid_areas\n\narea12 &lt;- apply(area_total12, c(3), sum)\next12 &lt;- apply(ext_total12, c(3), sum)"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#plot-the-sea-ice-area-and-extent-time-series",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#plot-the-sea-ice-area-and-extent-time-series",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "upper = max(max(ext12), max(area12))\nlower = min(min(ext12), min(area12))\nplot(dates,ext12,type='o',pch=20,xlab='Date',ylab='Area (km^2)', col=\"orange\" , ylim=c(lower, upper),  main=\"2021 Monthly Sea ice area and sea ice extent\")\nlines(dates, area12, type='o', pch=20, col=\"blue\")\nlegend(\"topright\", legend=c(\"Sea ice Area\", \"Sea ice Extent\"),\n       col=c(\"blue\", \"orange\"), lty=1:1, cex=0.8)\nbox()"
  },
  {
    "objectID": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#references",
    "href": "tutorials/calculating-sea-ice-extent/r/calculate-seaice-extent.html#references",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "NSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nPolarWatch Data Catalog\nWhat’s the difference between Sea ice area and extent?\nNSIDC Arctic Sea Ice News & Analysis\nClimate.gov Understanding Climate: sea ice extent\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Updated August 2023 \n\nThere are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov), ARGO floats program (http://www.argo.ucsd.edu) or CoastWatch ERDDAP data servers (https://coastwatch.pfeg.noaa.gov/erddap/). In situ buoy data are widely used to monitor environmental conditions. In the absence of in situ buoy data - whether the buoy operation is discontinued, interrupted, or limited - satellite data within temporal and spatial coverage of the desired locationcan be used to create a time series of a parameter of interest.\n\n\nThis tutorial will demonstrate how to create a time series from satellite data to gap-fill or replace buoy data.\n\n\n\n\nDownloading the satellite and buoy data from ERDDAP data server\nVisualizing the datasets\nReshaping the satellite data into a buoy data format\nResampling buoy data (aggregation) to match satellite data temporal resolution\nValidating the satellite data with the actual buoy data\nPerforming a linear regression of satellite vs. buoy data\nCreating a scatter plot of satellite vs. buoy data with the regression line\n\n\n\n\nSea-Surface Temperature, NOAA Geo-polar Blended Analysis Day+Night, GHRSST,Near Real-Time, Global 5km, 2019-Present, Daily\n.\nNDBC Standard Meteorological Buoy Data, 1970-present  NDBC Standard Meteorological Buoy Data  from the buoy station no. 46259 are from off the California coast at 34.737N latitude and 121.664E longitude.\n\n\n\n\nNOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center\n\n\n\n\n# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"utils\", \"ggplot2\", \"dplyr\", \"lubridate\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\nWe will download NDBC buoy data between January 16, 2022 and August 16, 2022 from the CoastWatch ERDDAP server.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\n# Set the ERDDAP data request URL\n \nbuoy_url &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?time%2Clongitude%2Clatitude%2Cwtmp&station%3E=%2246259%22&station%3C=%2246259%22&time%3E=2022-01-16T00%3A00%3A00Z&time%3C=2022-08-16T17%3A52%3A00Z\"\n\n# Set file name\nfname = 'buoy.csv'\n\n# Download file\ndownload.file(buoy_url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\n \nbuoy_df &lt;- read.csv(fname, skip=2, header=TRUE)\n\n# Name the columns\nnames(buoy_df) &lt;- c(\"utc\", \"lon\", \"lat\", \"sst\" )\n\n# Add additional date column\nbuoy_df$date &lt;- as.Date(buoy_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(buoy_df, 3)\n\n##                    utc      lon    lat  sst       date\n## 1 2022-01-16T00:56:00Z -121.664 34.732 13.4 2022-01-16\n## 2 2022-01-16T01:26:00Z -121.664 34.732 13.4 2022-01-16\n## 3 2022-01-16T01:56:00Z -121.664 34.732 13.3 2022-01-16\n\n\n\noptions(repr.plot.width = 10)\n\nggplot(buoy_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n # geom_point(size=.2, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celsius)\", title=\"SST from NDBC Buoy Station: 46259 (Aug 2022- Aug 2023) \")\n\n\n\n\nThe satellite Sea Surface Temperature (SST) product we will use is the NOAA GeoPolar Blended SST dataset (in Celsius), which blends data from many satellite sensors to obtain good daily coverage of the globe at 5km resolution, and then an interpolation method is applied to fill in data gaps.\nThe data request can be sent to a CoastWatch ERDDAP server via URL with a query string to specify the temporal and spatial coverage of interest. In this case, we want to subset the satellite data to match the buoy station location and time range.\n\n\n# Set ERDDAP URL for the satellite data\nurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisBLENDEDsstDNDaily.csv?analysed_sst%5B(2022-01-16T12:00:00Z):1:(2022-08-16T12:00:00Z)%5D%5B(34.737):1:(34.737)%5D%5B(-121.664):1:(-121.664)%5D\"\n\n# Set file name\nfname = 'sst.csv'\n\n# Download file\ndownload.file(url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\nsst_df &lt;- read.csv(fname, skip=2, header=TRUE)\nnames(sst_df) &lt;- c(\"utc\", \"lat\", \"lon\", \"sst\")\n\n# Add formatted data column\nsst_df$date &lt;- as.Date(sst_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(sst_df, 3)\n\n##                    utc    lat      lon      sst       date\n## 1 2022-01-18T12:00:00Z 34.725 -121.675 13.49999 2022-01-18\n## 2 2022-01-19T12:00:00Z 34.725 -121.675 13.44999 2022-01-19\n## 3 2022-01-20T12:00:00Z 34.725 -121.675 13.53999 2022-01-20\n\n\n\n\nApply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, a value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Filter data that are within the valid range (-2 and 45)\nsst_df_clean = sst_df %&gt;%\n  filter(sst &gt;=-2 & sst &lt;= 45)\n\n\n\n# Plot sea surface temperature values from satellite\np &lt;- ggplot(sst_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"Sea surface temperature from satellite\")\np\n\n\n\n\nThe sampling resolution for the buoy data is a sample every 30 minutes. However, the temporal resolution for the satellite dataset is daily. We will downsample the buoy data by computing daily mean to match the temporal resolution of the satellite data.\n# Aggregating (taking a mean value) grouped by day\nbuoy_ds &lt;- buoy_df %&gt;%\n  group_by(date = floor_date(date, unit=\"days\")) %&gt;%\n  summarise(mean_sst = mean(sst))\n\n# Show first 3 rows\nhead(buoy_ds, 3)\n\n## # A tibble: 3 × 2\n##   date       mean_sst\n##   &lt;date&gt;        &lt;dbl&gt;\n## 1 2022-01-16     13.4\n## 2 2022-01-17     13.5\n## 3 2022-01-18     13.6\n\n\n\nApply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Remove outliers sst values outside of -2 and 45 deg C\nbuoy_ds_clean = buoy_ds %&gt;%\n  filter(mean_sst &gt;=-2 & mean_sst &lt;= 45)\n\n\n\n# Plot daily mean sst\nggplot(buoy_ds_clean, aes(x = date, y = mean_sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"2022 Aug- 2023 Aug Downsampled Buoy SST\")\n\n\n\n\nWe will use dplyr::inner_join() function to merge the two data frames (satellite and buoy data) based on the dates that appear in both data frames.\n# Combine two data frames with date column where dates exist in both data frames\nmerged_df &lt;- inner_join(sst_df_clean[c(\"date\", \"sst\")],  buoy_ds_clean, by = \"date\")\n\n\n\n# Plot satellite sst and buoy daily mean sst \np &lt;- ggplot(merged_df, aes(x = date)) +  \n    geom_line(aes(y = sst, color = \"Satellite\")) +   \n    geom_line(aes(y = mean_sst, color = \"NDBC Buoy\")) +   \n    scale_color_manual(name = \"Data source\", \n                       values = c(\"Satellite\" = \"blue\", \"NDBC Buoy\" = \"orange\"))+\n    labs( x = \"Date\", y = \"Temperature (in Celsius)\", title=\"SST from Satellite and NDBC Buoy\" )+\n    theme(axis.text.x = element_text(angle = 0),plot.title=element_text(hjust=0.5))\np\n ## Perform a simple linear regression\n# Run linear regression \nmodel &lt;- lm(mean_sst ~ sst, data = merged_df)   \nsummary(model)\n\n## \n## Call:\n## lm(formula = mean_sst ~ sst, data = merged_df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.48812 -0.21354 -0.02782  0.14581  1.67408 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.54793    0.30272    1.81   0.0718 .  \n## sst          0.96142    0.02221   43.29   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4462 on 203 degrees of freedom\n## Multiple R-squared:  0.9023, Adjusted R-squared:  0.9018 \n## F-statistic:  1874 on 1 and 203 DF,  p-value: &lt; 2.2e-16\n\n\n\nggplot(merged_df, aes(x=sst, y=mean_sst)) +\n  geom_point(color=\"black\", size=1) +                      # Plot the data points\n  geom_smooth(method=\"lm\", se=FALSE) +\n  labs(x = \"SST from Buoy\", y = \"SST from Satellite\", title = \"Satellite vs Buoy data with regression line\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n## `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#objective",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#objective",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "This tutorial will demonstrate how to create a time series from satellite data to gap-fill or replace buoy data."
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Downloading the satellite and buoy data from ERDDAP data server\nVisualizing the datasets\nReshaping the satellite data into a buoy data format\nResampling buoy data (aggregation) to match satellite data temporal resolution\nValidating the satellite data with the actual buoy data\nPerforming a linear regression of satellite vs. buoy data\nCreating a scatter plot of satellite vs. buoy data with the regression line"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#datasets-used",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#datasets-used",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Sea-Surface Temperature, NOAA Geo-polar Blended Analysis Day+Night, GHRSST,Near Real-Time, Global 5km, 2019-Present, Daily\n.\nNDBC Standard Meteorological Buoy Data, 1970-present  NDBC Standard Meteorological Buoy Data  from the buoy station no. 46259 are from off the California coast at 34.737N latitude and 121.664E longitude."
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#references",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#references",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "NOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#install-required-packages-and-load-libraries",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#install-required-packages-and-load-libraries",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"utils\", \"ggplot2\", \"dplyr\", \"lubridate\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#download-ndbc-buoy-data",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#download-ndbc-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "We will download NDBC buoy data between January 16, 2022 and August 16, 2022 from the CoastWatch ERDDAP server.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\n# Set the ERDDAP data request URL\n \nbuoy_url &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?time%2Clongitude%2Clatitude%2Cwtmp&station%3E=%2246259%22&station%3C=%2246259%22&time%3E=2022-01-16T00%3A00%3A00Z&time%3C=2022-08-16T17%3A52%3A00Z\"\n\n# Set file name\nfname = 'buoy.csv'\n\n# Download file\ndownload.file(buoy_url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\n \nbuoy_df &lt;- read.csv(fname, skip=2, header=TRUE)\n\n# Name the columns\nnames(buoy_df) &lt;- c(\"utc\", \"lon\", \"lat\", \"sst\" )\n\n# Add additional date column\nbuoy_df$date &lt;- as.Date(buoy_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(buoy_df, 3)\n\n##                    utc      lon    lat  sst       date\n## 1 2022-01-16T00:56:00Z -121.664 34.732 13.4 2022-01-16\n## 2 2022-01-16T01:26:00Z -121.664 34.732 13.4 2022-01-16\n## 3 2022-01-16T01:56:00Z -121.664 34.732 13.3 2022-01-16"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#visualize-sst-from-the-buoy",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#visualize-sst-from-the-buoy",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "options(repr.plot.width = 10)\n\nggplot(buoy_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n # geom_point(size=.2, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celsius)\", title=\"SST from NDBC Buoy Station: 46259 (Aug 2022- Aug 2023) \")"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#download-the-satellite-sea-surface-temperature-sst-data",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#download-the-satellite-sea-surface-temperature-sst-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "The satellite Sea Surface Temperature (SST) product we will use is the NOAA GeoPolar Blended SST dataset (in Celsius), which blends data from many satellite sensors to obtain good daily coverage of the globe at 5km resolution, and then an interpolation method is applied to fill in data gaps.\nThe data request can be sent to a CoastWatch ERDDAP server via URL with a query string to specify the temporal and spatial coverage of interest. In this case, we want to subset the satellite data to match the buoy station location and time range.\n\n\n# Set ERDDAP URL for the satellite data\nurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisBLENDEDsstDNDaily.csv?analysed_sst%5B(2022-01-16T12:00:00Z):1:(2022-08-16T12:00:00Z)%5D%5B(34.737):1:(34.737)%5D%5B(-121.664):1:(-121.664)%5D\"\n\n# Set file name\nfname = 'sst.csv'\n\n# Download file\ndownload.file(url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\nsst_df &lt;- read.csv(fname, skip=2, header=TRUE)\nnames(sst_df) &lt;- c(\"utc\", \"lat\", \"lon\", \"sst\")\n\n# Add formatted data column\nsst_df$date &lt;- as.Date(sst_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(sst_df, 3)\n\n##                    utc    lat      lon      sst       date\n## 1 2022-01-18T12:00:00Z 34.725 -121.675 13.49999 2022-01-18\n## 2 2022-01-19T12:00:00Z 34.725 -121.675 13.44999 2022-01-19\n## 3 2022-01-20T12:00:00Z 34.725 -121.675 13.53999 2022-01-20"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#clean-up-the-data",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#clean-up-the-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Apply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, a value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Filter data that are within the valid range (-2 and 45)\nsst_df_clean = sst_df %&gt;%\n  filter(sst &gt;=-2 & sst &lt;= 45)"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#visualize-the-satellite-sst-data",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#visualize-the-satellite-sst-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot sea surface temperature values from satellite\np &lt;- ggplot(sst_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"Sea surface temperature from satellite\")\np"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#resample-the-buoy-data-to-match-the-satellite-data",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#resample-the-buoy-data-to-match-the-satellite-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "The sampling resolution for the buoy data is a sample every 30 minutes. However, the temporal resolution for the satellite dataset is daily. We will downsample the buoy data by computing daily mean to match the temporal resolution of the satellite data.\n# Aggregating (taking a mean value) grouped by day\nbuoy_ds &lt;- buoy_df %&gt;%\n  group_by(date = floor_date(date, unit=\"days\")) %&gt;%\n  summarise(mean_sst = mean(sst))\n\n# Show first 3 rows\nhead(buoy_ds, 3)\n\n## # A tibble: 3 × 2\n##   date       mean_sst\n##   &lt;date&gt;        &lt;dbl&gt;\n## 1 2022-01-16     13.4\n## 2 2022-01-17     13.5\n## 3 2022-01-18     13.6"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#clean-up-the-downsampled-data",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#clean-up-the-downsampled-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Apply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Remove outliers sst values outside of -2 and 45 deg C\nbuoy_ds_clean = buoy_ds %&gt;%\n  filter(mean_sst &gt;=-2 & mean_sst &lt;= 45)"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#visualize-the-downsampled-buoy-data",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#visualize-the-downsampled-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot daily mean sst\nggplot(buoy_ds_clean, aes(x = date, y = mean_sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"2022 Aug- 2023 Aug Downsampled Buoy SST\")"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#merge-satellite-and-buoy-data",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#merge-satellite-and-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "We will use dplyr::inner_join() function to merge the two data frames (satellite and buoy data) based on the dates that appear in both data frames.\n# Combine two data frames with date column where dates exist in both data frames\nmerged_df &lt;- inner_join(sst_df_clean[c(\"date\", \"sst\")],  buoy_ds_clean, by = \"date\")"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#plot-both-satellite-and-buoy-data",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#plot-both-satellite-and-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot satellite sst and buoy daily mean sst \np &lt;- ggplot(merged_df, aes(x = date)) +  \n    geom_line(aes(y = sst, color = \"Satellite\")) +   \n    geom_line(aes(y = mean_sst, color = \"NDBC Buoy\")) +   \n    scale_color_manual(name = \"Data source\", \n                       values = c(\"Satellite\" = \"blue\", \"NDBC Buoy\" = \"orange\"))+\n    labs( x = \"Date\", y = \"Temperature (in Celsius)\", title=\"SST from Satellite and NDBC Buoy\" )+\n    theme(axis.text.x = element_text(angle = 0),plot.title=element_text(hjust=0.5))\np\n ## Perform a simple linear regression\n# Run linear regression \nmodel &lt;- lm(mean_sst ~ sst, data = merged_df)   \nsummary(model)\n\n## \n## Call:\n## lm(formula = mean_sst ~ sst, data = merged_df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.48812 -0.21354 -0.02782  0.14581  1.67408 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.54793    0.30272    1.81   0.0718 .  \n## sst          0.96142    0.02221   43.29   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4462 on 203 degrees of freedom\n## Multiple R-squared:  0.9023, Adjusted R-squared:  0.9018 \n## F-statistic:  1874 on 1 and 203 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#plot-satellite-vs.-buoy-data-and-overlay-the-regression-line",
    "href": "tutorials/create-virtual-buoy-with-satellite-data/r/virtual_buoy_example.html#plot-satellite-vs.-buoy-data-and-overlay-the-regression-line",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "ggplot(merged_df, aes(x=sst, y=mean_sst)) +\n  geom_point(color=\"black\", size=1) +                      # Plot the data points\n  geom_smooth(method=\"lm\", se=FALSE) +\n  labs(x = \"SST from Buoy\", y = \"SST from Satellite\", title = \"Satellite vs Buoy data with regression line\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n## `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/matlab/extract-satellite-data-within-boundary.html",
    "href": "tutorials/extract-satellite-data-within-boundary/matlab/extract-satellite-data-within-boundary.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial uses the Xtractomatic package to download data from within the boundaries of the Papahanaumokuakea Marine National Monument (PMNM).\nThis tutorial will teach you how to extract and display SST values for a particular time period or average SST over the whole time-series available within a shapefile.\nThe shapefile for the PMNM boundaries can be downloaded here: http://sanctuaries.noaa.gov/library/imast_gis.html. Save the file https://sanctuaries.noaa.gov/library/imast/pmnm_py.zip on your computer and extract it. It would be easiest for the purposes of this tutorial if you place the pmnm_py folder in the directory you’re working in. But, if you want to keep it elsewhere, you’ll just need to edit the path name accordingly.\n\n\nWe’ll do this in two steps. First, we’ll download the satellite data for a footprint that’s slightly larger than our area of interest. Then, we’ll clip these data to only those which fall within the Monument.\n\n\n% As always, it's helpful it take a look at what we're working with: \nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN');\n```matlab\n\n\nWe can see in the information above that longitude is in the 0 - 360 degree format.  And we know from reading the ReadMe file for the monument boundaries that the shapefile longitude is in the -180 - 180 degree format.  This means we need convert the shapefile longitudes to a 0 - 360 format for indexing puposes (the native format will plot just fine). \n\n```matlab\n% Access the Lat and Lon coordinates\nPMNM = shaperead('pmnm_py/PMNM_py_files/PMNM_py.shp','UseGeoCoords',true);\n\n% Convert negative longitudes to positive values\nneg_lon = find(PMNM.Lon &lt; 0);\nPMNM.Lon(neg_lon) = PMNM.Lon(neg_lon) + 360;\nclear neg_lon\n\n% Find the minimum and maximum lat and lon values, for using to download\n% SST data\n[Lon_min, Lon_max] = bounds(PMNM.Lon);\n[Lat_min, Lat_max] = bounds(PMNM.Lat);\n\n% Now we can follow the steps we used in the earlier tutorials to download\n% the SST data\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n   'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \n\n% In this particular example, we're interested in March - November 2015\ntime_aoi = find(time_full_ymdhms(:,1) == 2015 & time_full_ymdhms(:,2) &gt;= 3 & ...\n    time_full_ymdhms(:,2) &lt;= 11);\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'longitude');\n\n% Find longitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlon_aoi = find(lon_full &gt;= floor(Lon_min) & lon_full &lt;= ceil(Lon_max));\n% Find latitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlat_aoi = find(lat_full &gt;= floor(Lat_min) & lat_full &lt;= ceil(Lat_max));\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\n\n% Download the data of interest\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'analysed_sst', aoi_start, aoi_span);\n\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* *min *max\n\n\n\nNow we have everything we need to clip the SST data to just those within the boundaries of the Monument. The code below borrows from the no-longer-supported xtractoMatlab: https://github.com/rmendels/xtractoMatlab. You can learn about other avenues to use this tool at: https://coastwatch.pfeg.noaa.gov/xtracto/.\n% The general premise here is that we're going to create a mesh grid of our\n% full domain (what we downloaded), identify all the points that are within\n% or on the polygon that defines the Monument, and set to NaN those that\n% are not.\n% Make the meshgrid and the mask\n[XLON, XLAT] = meshgrid(lon, lat);\n[IN ON] = inpolygon(XLON, XLAT, PMNM.Lon, PMNM.Lat);\nmask2D = IN | ON;\n\n% Replicate it over the number of time steps, which is the third dimension\n% of our sst variable\nmask3D = permute(repmat(mask2D,[1 1 size(sst,3)]),[2 1 3]);\n\n% Set to NaN all points not within the polygon\nsst(~mask3D) = NaN;\n\n\n\n\nThe extracted data contains several time steps (months) of sst data in the monument boundaries. Let’s make a plot of the second time step. Also, we can see above where we used ‘ncdisp’, that the units for these data are Kelvin. Let’s changes this to degrees Celsius when we make our map.\nfigure\naxesm('mercator', 'MapLatLimit', [18 32], 'MapLonLimit', [177 207], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -180:5:-155, 'PLabelLocation', 20:5:30, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Plot SST for the second time step, in degrees C, with 50 contour levels\ncontourm(lat, lon, sst(:,:,2)'-273.15, 50, 'fill', 'on'); \n\n% Title the map\ntitle(sprintf('SST %s', datestr(time_ymdhms(2,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 50 levels\ncolormap(jet(50));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\nOn your own! Plot the average SST for the period we downloaded. Here’s a hint to get you started:\nsst_avg = mean(sst, 3, \"omitnan\");\n\n\n\nSST"
  },
  {
    "objectID": "tutorials/extract-satellite-data-within-boundary/matlab/extract-satellite-data-within-boundary.html#extract-data-within-a-shapefile-using-erddap",
    "href": "tutorials/extract-satellite-data-within-boundary/matlab/extract-satellite-data-within-boundary.html#extract-data-within-a-shapefile-using-erddap",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial uses the Xtractomatic package to download data from within the boundaries of the Papahanaumokuakea Marine National Monument (PMNM).\nThis tutorial will teach you how to extract and display SST values for a particular time period or average SST over the whole time-series available within a shapefile.\nThe shapefile for the PMNM boundaries can be downloaded here: http://sanctuaries.noaa.gov/library/imast_gis.html. Save the file https://sanctuaries.noaa.gov/library/imast/pmnm_py.zip on your computer and extract it. It would be easiest for the purposes of this tutorial if you place the pmnm_py folder in the directory you’re working in. But, if you want to keep it elsewhere, you’ll just need to edit the path name accordingly.\n\n\nWe’ll do this in two steps. First, we’ll download the satellite data for a footprint that’s slightly larger than our area of interest. Then, we’ll clip these data to only those which fall within the Monument.\n\n\n% As always, it's helpful it take a look at what we're working with: \nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN');\n```matlab\n\n\nWe can see in the information above that longitude is in the 0 - 360 degree format.  And we know from reading the ReadMe file for the monument boundaries that the shapefile longitude is in the -180 - 180 degree format.  This means we need convert the shapefile longitudes to a 0 - 360 format for indexing puposes (the native format will plot just fine). \n\n```matlab\n% Access the Lat and Lon coordinates\nPMNM = shaperead('pmnm_py/PMNM_py_files/PMNM_py.shp','UseGeoCoords',true);\n\n% Convert negative longitudes to positive values\nneg_lon = find(PMNM.Lon &lt; 0);\nPMNM.Lon(neg_lon) = PMNM.Lon(neg_lon) + 360;\nclear neg_lon\n\n% Find the minimum and maximum lat and lon values, for using to download\n% SST data\n[Lon_min, Lon_max] = bounds(PMNM.Lon);\n[Lat_min, Lat_max] = bounds(PMNM.Lat);\n\n% Now we can follow the steps we used in the earlier tutorials to download\n% the SST data\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n   'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \n\n% In this particular example, we're interested in March - November 2015\ntime_aoi = find(time_full_ymdhms(:,1) == 2015 & time_full_ymdhms(:,2) &gt;= 3 & ...\n    time_full_ymdhms(:,2) &lt;= 11);\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'longitude');\n\n% Find longitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlon_aoi = find(lon_full &gt;= floor(Lon_min) & lon_full &lt;= ceil(Lon_max));\n% Find latitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlat_aoi = find(lat_full &gt;= floor(Lat_min) & lat_full &lt;= ceil(Lat_max));\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\n\n% Download the data of interest\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'analysed_sst', aoi_start, aoi_span);\n\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* *min *max\n\n\n\nNow we have everything we need to clip the SST data to just those within the boundaries of the Monument. The code below borrows from the no-longer-supported xtractoMatlab: https://github.com/rmendels/xtractoMatlab. You can learn about other avenues to use this tool at: https://coastwatch.pfeg.noaa.gov/xtracto/.\n% The general premise here is that we're going to create a mesh grid of our\n% full domain (what we downloaded), identify all the points that are within\n% or on the polygon that defines the Monument, and set to NaN those that\n% are not.\n% Make the meshgrid and the mask\n[XLON, XLAT] = meshgrid(lon, lat);\n[IN ON] = inpolygon(XLON, XLAT, PMNM.Lon, PMNM.Lat);\nmask2D = IN | ON;\n\n% Replicate it over the number of time steps, which is the third dimension\n% of our sst variable\nmask3D = permute(repmat(mask2D,[1 1 size(sst,3)]),[2 1 3]);\n\n% Set to NaN all points not within the polygon\nsst(~mask3D) = NaN;\n\n\n\n\nThe extracted data contains several time steps (months) of sst data in the monument boundaries. Let’s make a plot of the second time step. Also, we can see above where we used ‘ncdisp’, that the units for these data are Kelvin. Let’s changes this to degrees Celsius when we make our map.\nfigure\naxesm('mercator', 'MapLatLimit', [18 32], 'MapLonLimit', [177 207], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -180:5:-155, 'PLabelLocation', 20:5:30, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Plot SST for the second time step, in degrees C, with 50 contour levels\ncontourm(lat, lon, sst(:,:,2)'-273.15, 50, 'fill', 'on'); \n\n% Title the map\ntitle(sprintf('SST %s', datestr(time_ymdhms(2,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 50 levels\ncolormap(jet(50));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\nOn your own! Plot the average SST for the period we downloaded. Here’s a hint to get you started:\nsst_avg = mean(sst, 3, \"omitnan\");\n\n\n\nSST"
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Training Tutorials",
    "section": "",
    "text": "The CoastWatch tutorial collection is organized to support users working with satellite data at different stages of their workflow. Tutorials are grouped into two broad categories: software-focused tutorials and coding-based tutorials.",
    "crumbs": [
      "Training Tutorials"
    ]
  },
  {
    "objectID": "tutorials/index.html#software-tutorials",
    "href": "tutorials/index.html#software-tutorials",
    "title": "Training Tutorials",
    "section": "Software Tutorials",
    "text": "Software Tutorials\nSoftware tutorials provide guidance on installing, configuring, and using commonly supported tools for working with CoastWatch satellite data. These tutorials focus on foundational software and utilities that are often used to access, explore, or manage data prior to analysis.\nTopics include:\n\nERDDAP access and configuration\n\nCoastWatch utilities\n\nWorking with NetCDF files\n\nUsing data visualization tools such as Panoply\n\nView Software Information\nView Software Code Gallery",
    "crumbs": [
      "Training Tutorials"
    ]
  },
  {
    "objectID": "tutorials/index.html#coding-tutorials",
    "href": "tutorials/index.html#coding-tutorials",
    "title": "Training Tutorials",
    "section": "Coding Tutorials",
    "text": "Coding Tutorials\nCoding tutorials demonstrate how to access, subset, analyze, and visualize CoastWatch satellite data using common programming languages. These tutorials are organized by exercise or topic, and many are available in multiple software languages such as Python, R, and MATLAB.\nThe Code Gallery provides an overview of available coding tutorials and direct links to each language-specific implementation.\nView Code Gallery\n\n\n\n\n\n\n\nEducational use\n\n\n\nAll tutorials are provided for educational and demonstrative purposes. Code examples are intended to illustrate workflows and techniques and should be reviewed, tested, and adapted as needed before being used for research or operational applications.",
    "crumbs": [
      "Training Tutorials"
    ]
  },
  {
    "objectID": "tutorials/index.html#acknowledgement",
    "href": "tutorials/index.html#acknowledgement",
    "title": "Training Tutorials",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nThe training materials for the CoastWatch Program have been developed, reviewed, and edited with the contributions of many dedicated individuals.\nContributors:\nMelanie Abecassis, Dave Foley, Peter Hollemans, Sun Bak Hospital, Songzhi Liu, Roy Mendelssohn, Madison Richardson, Dale Robinson, Jennifer Sevadjian, Jonathan Sherman, Hui (Daisy) Shi, Michael Soracco, Shelly Tomlinson, Ron Vogel, Victoria Wegman, Cara Wilson\nWe also extend our gratitude to other external contributors whose specific acknowledgements are included within the training materials they helped to create.",
    "crumbs": [
      "Training Tutorials"
    ]
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html",
    "href": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "history | Updated September 2023 \n\nNOAA PolarWatch distributes gridded and tabular oceanographic data for polar regions. Satellite data include geospatial information and most of them are in geographical coordinates (latitude and longitude). PolarWatch satellite data are often projected using Polar Stereographic Projections in x and y coordinates.\n\n\nThis tutorial will demonstrate how to plot a polar stereographic projected data on a projected map, and to add another dataset with geographical coordinates (latitude and longitude) onto the map.\n\n\n\n\nAccessing satellite data from ERDDAP\nMaking a projected map\nAdding projected data\nAdding geographical data\n\n\n\n\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\nThis dataset includes sea ice concentration data from the northern hemisphere, and is produced by the NOAA/NSIDC using the Climate Data Record algorithm. The resolution is 25km, meaning each grid in this data set represents a value that covers a 25km by 25km area. The dataset is avaialble from the NOAA PolarWatch Catalog.\nPolar bear tracking data  For the demonstrative purpose of adding a dataset in geographical coords (lat, lon) to the projected map, GPS data for a polar bear track were used. More information about the data can be found at https://borealisdata.ca/file.xhtml?fileId=151017&version=1.0\nR Packages\n\nncdf4 (reading data and metadata in netCDF format)\nggplot2, RColorBrewer, scales (mapping)\nreshape2 (data manipulation)\nrgdal (projection)\n\n\n\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"rgdal\",\"sp\", \"ggplot2\" ,\"ncdf4\",  \"RColorBrewer\", \"scales\", \"reshape2\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# download the sea ice data NetCDF file\nseaice_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4851137.11):1:(-4850758.92)][(-3850000.0):1:(3750000.0)]\"\nsea_ice_data_nc &lt;- download.file(seaice_url, destfile=\"../data/sea_ice_data.nc\", mode='wb')\n\n# file open\nseaice &lt;- nc_open('../data/sea_ice_data.nc')\n\n# print metadata\n#print(seaice)\n\n# get data into r variables \nxgrid &lt;- ncvar_get(seaice, \"xgrid\")\nygrid &lt;- ncvar_get(seaice, \"ygrid\")\nsic &lt;- ncvar_get(seaice, \"cdr_seaice_conc_monthly\")  #lat and lon\nfillvalue &lt;- ncatt_get(seaice, \"cdr_seaice_conc_monthly\", \"_FillValue\") #checkout fill value for missing data points\n\n# close \nnc_close(seaice)\n\n# create dataframe\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude fillvalue\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels=comma) + \n       scale_x_continuous(labels=comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\") +\n      ggtitle(\"Sea Ice Concentration on Polar Steregraphic projection\")\n ### Adding Polar bear track data onto the polar stereographic projection\n# read csv polar bear track data \npolartrack &lt;- read.csv(\"../data/PB_Argos.csv\")\npolarB &lt;- polartrack[polartrack$QualClass==\"B\",]\n\n# specify coordinate columns\ncoordinates(polarB) &lt;- c(\"Lon\", \"Lat\")\n\n# set data crs to 4326\nproj4string(polarB) &lt;-CRS(\"+init=epsg:4326\")\n\n# transform the data crs from EPSG:4326 to EPSG: 3413\npolar.3413 &lt;- spTransform(polarB, CRS(\"+init=epsg:3413\"))\n\n# for ggplot, convert spatial data to data.frame\npolar.3413.df&lt;-data.frame(polar.3413)\nnames(polar.3413.df)[names(polar.3413.df)==\"Lon\"]&lt;-\"x\"\nnames(polar.3413.df)[names(polar.3413.df)==\"Lat\"]&lt;-\"y\"\n\n\n\n\nggplot(data = sicd, aes(x = xgrid, y = ygrid) ) + \n        geom_tile(aes(fill=sic)) + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels = comma) + \n       scale_x_continuous(labels = comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\")+\n       ggtitle(\"SIC with polar bear tracks on Polar (red) Steregraphic projection\")+\n      geom_point(data=polar.3413.df, aes(x=x, y=y), color=\"red\", size=0.5)\n\n\n\n\n\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nNOAA PolarWatch Data Product Page (download, preview)"
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html#objective",
    "href": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html#objective",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "This tutorial will demonstrate how to plot a polar stereographic projected data on a projected map, and to add another dataset with geographical coordinates (latitude and longitude) onto the map."
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Accessing satellite data from ERDDAP\nMaking a projected map\nAdding projected data\nAdding geographical data"
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html#datasets-used",
    "href": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html#datasets-used",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\nThis dataset includes sea ice concentration data from the northern hemisphere, and is produced by the NOAA/NSIDC using the Climate Data Record algorithm. The resolution is 25km, meaning each grid in this data set represents a value that covers a 25km by 25km area. The dataset is avaialble from the NOAA PolarWatch Catalog.\nPolar bear tracking data  For the demonstrative purpose of adding a dataset in geographical coords (lat, lon) to the projected map, GPS data for a polar bear track were used. More information about the data can be found at https://borealisdata.ca/file.xhtml?fileId=151017&version=1.0\nR Packages\n\nncdf4 (reading data and metadata in netCDF format)\nggplot2, RColorBrewer, scales (mapping)\nreshape2 (data manipulation)\nrgdal (projection)\n\n\n\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"rgdal\",\"sp\", \"ggplot2\" ,\"ncdf4\",  \"RColorBrewer\", \"scales\", \"reshape2\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# download the sea ice data NetCDF file\nseaice_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4851137.11):1:(-4850758.92)][(-3850000.0):1:(3750000.0)]\"\nsea_ice_data_nc &lt;- download.file(seaice_url, destfile=\"../data/sea_ice_data.nc\", mode='wb')\n\n# file open\nseaice &lt;- nc_open('../data/sea_ice_data.nc')\n\n# print metadata\n#print(seaice)\n\n# get data into r variables \nxgrid &lt;- ncvar_get(seaice, \"xgrid\")\nygrid &lt;- ncvar_get(seaice, \"ygrid\")\nsic &lt;- ncvar_get(seaice, \"cdr_seaice_conc_monthly\")  #lat and lon\nfillvalue &lt;- ncatt_get(seaice, \"cdr_seaice_conc_monthly\", \"_FillValue\") #checkout fill value for missing data points\n\n# close \nnc_close(seaice)\n\n# create dataframe\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude fillvalue\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels=comma) + \n       scale_x_continuous(labels=comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\") +\n      ggtitle(\"Sea Ice Concentration on Polar Steregraphic projection\")\n ### Adding Polar bear track data onto the polar stereographic projection\n# read csv polar bear track data \npolartrack &lt;- read.csv(\"../data/PB_Argos.csv\")\npolarB &lt;- polartrack[polartrack$QualClass==\"B\",]\n\n# specify coordinate columns\ncoordinates(polarB) &lt;- c(\"Lon\", \"Lat\")\n\n# set data crs to 4326\nproj4string(polarB) &lt;-CRS(\"+init=epsg:4326\")\n\n# transform the data crs from EPSG:4326 to EPSG: 3413\npolar.3413 &lt;- spTransform(polarB, CRS(\"+init=epsg:3413\"))\n\n# for ggplot, convert spatial data to data.frame\npolar.3413.df&lt;-data.frame(polar.3413)\nnames(polar.3413.df)[names(polar.3413.df)==\"Lon\"]&lt;-\"x\"\nnames(polar.3413.df)[names(polar.3413.df)==\"Lat\"]&lt;-\"y\""
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html#combine-the-sea-ice-concentration-data-and-the-polar-bear-tracking-data",
    "href": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html#combine-the-sea-ice-concentration-data-and-the-polar-bear-tracking-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "ggplot(data = sicd, aes(x = xgrid, y = ygrid) ) + \n        geom_tile(aes(fill=sic)) + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels = comma) + \n       scale_x_continuous(labels = comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\")+\n       ggtitle(\"SIC with polar bear tracks on Polar (red) Steregraphic projection\")+\n      geom_point(data=polar.3413.df, aes(x=x, y=y), color=\"red\", size=0.5)"
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html#references",
    "href": "tutorials/map-data-with-different-projections/r/map-data-with-different-projections.html#references",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "NSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nNOAA PolarWatch Data Product Page (download, preview)"
  },
  {
    "objectID": "tutorials/matchup-polar-data-to-animal-track-locations/r/matchup-polar-data-to-animal-track-locations.html",
    "href": "tutorials/matchup-polar-data-to-animal-track-locations/r/matchup-polar-data-to-animal-track-locations.html",
    "title": "Tracking Penguins in Antarctica",
    "section": "",
    "text": "Tracking Penguins in Antarctica\n\nModified October 2024\n\n\nOverview\nIn this exercise, you will learn how to extract satellite data in polar stereographic projection (defined by xgrid and ygrid) around a set of points specified by longitude, latitude, and time coordinates. These coordinates could represent data from animal telemetry tags, ship tracks, or glider tracks.\n\n\nThe exercise demonstrates the following techniques:\n\nLoading animal telemetry tags data from tab- or comma-separated files\nExtracting satellite data along a track\nPlotting animal tracks and satellite data on a map\n\n\n\nDatasets used in this exercise:\nSea Ice Concentration Satellite Data\nThis dataset contains daily and monthly Climate Data Records (CDR) of sea ice concentration, processed by the NOAA/NSIDC team for the Arctic at a 25 km resolution, spanning from 1978 to the most recent annual data processing update. The sea ice concentration data are derived from microwave remote sensing. Due to processing and quality control, CDR data has a slight delay in availability, but near real-time data is available for more recent dates..\nFor this tutorial, the monthly sea ice concentration data is used. To preview and download CDR data, visit NOAA PolarWatch CDR Data.\nAdelie Penguin Telemetry Track\nTelemetry data from Adelie penguins (Pygoscelis adeliae) were collected via Argos satellites in the Southern Ocean between October 29, 1996, and February 19, 2013, as part of the U.S. Antarctic Marine Living Resources project. Additionally, a turtle raised in captivity in Japan was tagged and released on May 4, 2005, in the Central Pacific.\nThe telemetry track dataset is included in the data/ folder of this module. For more information about the project and to download the full dataset, visit the NOAA NCEI webpage.\n\n\nInstall the required R libraries\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                      \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\", \"dplyr\",\n                      \"sf\", \"ggspatial\", \"rnaturalearth\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\nLoad the sea ice data from PolarWatch ERDDAP\n# ERDDAP URL\nERDDAP_Node = \"https://polarwatch.noaa.gov/erddap\"\n\n# Dataset ID\nNDBC_id = 'nsidcG02202v4shmday'\nNDBC_info=info(datasetid = NDBC_id,url = ERDDAP_Node)\n\n# Check the metadata\nprint(NDBC_info)\n## &lt;ERDDAP info&gt; nsidcG02202v4shmday \n##  Base URL: https://polarwatch.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1978-11-01T00:00:00Z, 2024-03-01T00:00:00Z) \n##      ygrid: (-3937500.0, 4337500.0) \n##      xgrid: (-3937500.0, 3937500.0) \n##  Variables:  \n##      cdr_seaice_conc_monthly: \n##          Units: 1 \n##      nsidc_bt_seaice_conc_monthly: \n##          Units: 1 \n##      nsidc_nt_seaice_conc_monthly: \n##          Units: 1 \n##      qa_of_cdr_seaice_conc_monthly: \n##      stdev_of_cdr_seaice_conc_monthly:\n# Set the parameters to get the first time step of the sea ice concentration data\ntime_range &lt;- c('1978-11-01T00:00:00Z', '1978-11-01T23:59:59Z')\n#y_range &lt;- c(-3950000.0, 4350000.0) # if the entire range is desired one doesn't have to include a range \n#x_range &lt;- c(-3950000.0, 3950000.0) # if the entire range is desired one doesn't have to include a range \nfield &lt;- 'cdr_seaice_conc_monthly'\n\n# Extract data\nsic &lt;- griddap(\n  url = ERDDAP_Node,\n  NDBC_id,\n  time = time_range,\n# ygrid = y_range,      # uncomment if subsetting is desired \n# xgrid = x_range,      # uncomment if subsetting is desired\n  fields = field\n)\n\n# Extract data into the data frame\nsic.df &lt;- data.frame(\n  x = sic$data$xgrid,\n  y = sic$data$ygrid,\n  cdr_seaice_conc_monthly = sic$data$cdr_seaice_conc_monthly\n)\n\n# Remove values greater than 1\nsic.df &lt;- sic.df[sic.df$cdr_seaice_conc_monthly &lt; 1, ]\n\n\nPlot sea ice data on a map\n# Load map of Antarctica\nantarctica &lt;- ne_countries(scale = \"medium\", continent = \"Antarctica\", returnclass = \"sf\")\n\n# Plot the data\nggplot() +\n  geom_tile(data = sic.df, aes(x = x, y = y, fill = cdr_seaice_conc_monthly)) +\n  scale_fill_gradient(name = \"Sea Ice Concentration\", low = \"#deebf7\", high = \"#08306b\", limits = c(0, 1)) +\n  geom_sf(data = antarctica, fill = \"antiquewhite\", color = NA) +\n  coord_sf(crs = st_crs(3412)) +\n  theme_minimal() +\n  theme(legend.position = \"right\") +\n  labs(title = \"Sea Ice Concentration (First Time Step)\", x = \"Longitude\", y = \"Latitude\") +\n  theme(panel.grid = element_blank())\n\n\n\nLoad penguin telemetry data from a local file\n# Import csv file into a data frame\npenguin_df &lt;- read.csv(\"../data/copa_adpe_ncei.csv\")\n\n# Show 3 rows from the data frame\nhead(penguin_df, 3)\n##   BirdId    Sex   Age Breed.Stage    DateGMT  TimeGMT  Latitude Longitude\n## 1  ADPE1 female adult  incubation 28/10/1997  7:54:00 -62.17167 -58.44500\n## 2  ADPE1 female adult  incubation 28/10/1997  9:32:00 -62.17333 -58.46333\n## 3  ADPE1 female adult  incubation 28/10/1997 18:15:00 -62.15833 -58.42667\n##   ArgosQuality\n## 1            2\n## 2            2\n## 3            1\n\n\nProcess Penguin Data\nFor this exercise, we will select ADPE24, a penguin whose recorded tracks are highest within the female group, and will follow her journey in the Antarctic.\n# Find BirdID with the most count by sex\nmost_bird_count &lt;- penguin_df %&gt;%\n  group_by(Sex) %&gt;%\n  summarize(BirdId = names(which.max(table(BirdId))))\n\nhead(most_bird_count, 1)\n## # A tibble: 1 × 2\n##   Sex    BirdId\n##   &lt;chr&gt;  &lt;chr&gt; \n## 1 female ADPE24\n# Extract ADPE24 track data\nadpe24 &lt;- penguin_df %&gt;% filter(BirdId == 'ADPE24')\n\n# Inspect the data\nhead(adpe24)\n##   BirdId    Sex   Age Breed.Stage    DateGMT  TimeGMT Latitude Longitude\n## 1 ADPE24 female adult      creche 16/01/2003 21:32:00  -62.173   -58.446\n## 2 ADPE24 female adult      creche 16/01/2003 22:02:00  -62.175   -58.451\n## 3 ADPE24 female adult      creche 16/01/2003 23:10:00  -62.184   -58.466\n## 4 ADPE24 female adult      creche 16/01/2003 23:10:00  -62.176   -58.448\n## 5 ADPE24 female adult      creche 16/01/2003 23:43:00  -62.177   -58.452\n## 6 ADPE24 female adult      creche 17/01/2003  0:07:00  -62.173   -58.445\n##   ArgosQuality\n## 1            3\n## 2            3\n## 3            1\n## 4            3\n## 5            3\n## 6            1\n# Convert DateGMT to Date format\nadpe24$DateGMT &lt;- as.Date(adpe24$DateGMT, format = \"%d/%m/%Y\")\n\n# Create Year_Month column\nadpe24$Year_Month &lt;- format(adpe24$DateGMT, \"%Y-%m\")\n\n# Convert TimeGMT to POSIXct format for times\nadpe24$TimeGMT &lt;- format(strptime(adpe24$TimeGMT, format = \"%H:%M:%S\"), \"%H:%M:%S\")\n\n# Get unique penguin dates\nadpe_dates &lt;- unique(adpe24$Year_Month)\n\ndate_range &lt;- range(adpe24$DateGMT)\n\n# Print results\nprint(paste(\"Date Range:\", date_range[1], \"to\", date_range[2]))\n## [1] \"Date Range: 2003-01-16 to 2003-03-09\"\nprint(paste(\"Unique Months:\", paste(adpe_dates, collapse = \", \")))\n## [1] \"Unique Months: 2003-01, 2003-02, 2003-03\"\n\n\nVisualize penguin tracks\n# Create the plot\nggplot() +\n  geom_sf(data = antarctica, fill = \"gray80\", color = \"gray50\") +\n  geom_path(data = adpe24, aes(x = Longitude, y = Latitude), color = \"black\", fill = \"black\") +\n  geom_point(data = adpe24, aes(x = Longitude, y = Latitude), shape = 20, size = 4) +\n  geom_point(data = adpe24[1, ], aes(x = Longitude, y = Latitude), color = \"green\", size = 5, shape = 17) +\n  geom_point(data = adpe24[nrow(adpe24), ], aes(x = Longitude, y = Latitude), color = \"red\", size = 5, shape = 15) +\n  coord_sf(xlim = c(min(adpe24$Longitude) - 5, max(adpe24$Longitude) + 5),\n           ylim = c(min(adpe24$Latitude) - 5, max(adpe24$Latitude) + 5),\n           expand = FALSE) +\n  labs(title = \"Penguin Track with Start (green) and End Location (red)\",\n       x = \"Longitude (deg)\", y = \"Latitude (deg)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n ### Resample Penguin data to match satellite data\n# Subset the penguin track data\nadpe24 &lt;- adpe24 %&gt;%\n  select(DateGMT, Latitude, Longitude) %&gt;%\n  mutate(DateGMT = as.Date(DateGMT, format = \"%d/%m/%Y\"))\n\n# Resample data daily\nadpe24_df &lt;- adpe24 %&gt;%\n  group_by(DateGMT) %&gt;%\n  summarise(Latitude = mean(Latitude, na.rm = TRUE),\n            Longitude = mean(Longitude, na.rm = TRUE))\n\n\nTransform the projection of the penguin locations\n# Convert to an sf object and transform to Polar Stereographic Projection\npenguin_sf &lt;- st_as_sf(adpe24_df, coords = c(\"Longitude\", \"Latitude\"), crs = 4326)\npenguin_sf &lt;- st_transform(penguin_sf, crs = 3412)\n\n# Extract x and y coordinates\ntransformed_coords &lt;- st_coordinates(penguin_sf)\nadpe24_df$xgrid &lt;- transformed_coords[, \"X\"]\nadpe24_df$ygrid &lt;- transformed_coords[, \"Y\"]\n\nhead(adpe24_df)\n## # A tibble: 6 × 5\n##   DateGMT    Latitude Longitude     xgrid    ygrid\n##   &lt;date&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 2003-01-16    -62.2     -58.5 -2618200. 1607416.\n## 2 2003-01-17    -62.2     -58.4 -2617487. 1608715.\n## 3 2003-01-18    -62.3     -57.7 -2580637. 1632458.\n## 4 2003-01-19    -62.5     -57.5 -2556440. 1626139.\n## 5 2003-01-20    -62.2     -58.5 -2619622. 1607983.\n## 6 2003-01-21    -62.2     -58.5 -2618872. 1607944.\n\n\nExtract satellite data to match penguin locations and date\n# Extract sea ice concentration data\nsic_penguin &lt;- rxtracto(\n  NDBC_info,\n  xName = \"xgrid\",\n  yName = \"ygrid\",\n  tName = \"time\",\n  parameter = \"cdr_seaice_conc_monthly\",\n  xcoord = adpe24_df$xgrid,\n  ycoord = adpe24_df$ygrid,\n  tcoord = adpe24_df$DateGMT,\n)\n\nhead(sic_penguin)\n## $`mean cdr_seaice_conc_monthly`\n##  [1] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.37 0.27\n## [16] 0.37 0.41 0.36 0.33 0.33 0.35 0.35 0.35 0.35 0.37 0.33 0.35 0.35 0.34 0.37\n## [31] 0.46 0.64 0.64 0.64 0.71 0.63 0.70 0.70 0.71 0.71 0.71 0.71 0.70 0.70 0.78\n## [46] 0.71 0.71 0.71 0.71 0.71 0.70 0.70 0.70\n## \n## $`stdev cdr_seaice_conc_monthly`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [51] NA NA NA\n## \n## $n\n##  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n## [39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n## \n## $`satellite date`\n##  [1] \"2003-01-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n##  [4] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n##  [7] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [10] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [13] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [16] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [19] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [22] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [25] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [28] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [31] \"2003-02-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [34] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [37] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [40] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [43] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [46] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [49] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [52] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## \n## $`requested x min`\n##  [1] -2618200 -2617487 -2580637 -2556440 -2619622 -2618872 -2609300 -2581762\n##  [9] -2617878 -2618061 -2614421 -2535191 -2470714 -2414195 -2372472 -2345538\n## [17] -2314721 -2276201 -2266618 -2247613 -2234056 -2243316 -2245819 -2227527\n## [25] -2221971 -2248918 -2249757 -2237957 -2218441 -2209007 -2176294 -2139759\n## [33] -2134079 -2129105 -2114272 -2100165 -2083425 -2076899 -2070131 -2064975\n## [41] -2059881 -2058637 -2075336 -2086747 -2091354 -2104230 -2110452 -2114260\n## [49] -2118197 -2124732 -2131630 -2134295 -2149253\n## \n## $`requested x max`\n##  [1] -2618200 -2617487 -2580637 -2556440 -2619622 -2618872 -2609300 -2581762\n##  [9] -2617878 -2618061 -2614421 -2535191 -2470714 -2414195 -2372472 -2345538\n## [17] -2314721 -2276201 -2266618 -2247613 -2234056 -2243316 -2245819 -2227527\n## [25] -2221971 -2248918 -2249757 -2237957 -2218441 -2209007 -2176294 -2139759\n## [33] -2134079 -2129105 -2114272 -2100165 -2083425 -2076899 -2070131 -2064975\n## [41] -2059881 -2058637 -2075336 -2086747 -2091354 -2104230 -2110452 -2114260\n## [49] -2118197 -2124732 -2131630 -2134295 -2149253\nsic_penguin_df &lt;- data.frame(\n  time = as.Date(sic_penguin$`satellite date`),\n  xgrid = sic_penguin$`requested x min`,\n  ygrid = sic_penguin$`requested y min`,\n  matched_seaice_concen = sic_penguin$'mean cdr_seaice_conc_monthly'\n)\n\n\n# Merge the extracted data back into the penguin data frame\nadpe24_df &lt;- adpe24_df %&gt;%\n  mutate(matched_seaice_concen = sic_penguin$'mean cdr_seaice_conc_monthly')\n\nhead(adpe24_df)\n## # A tibble: 6 × 6\n##   DateGMT    Latitude Longitude     xgrid    ygrid matched_seaice_concen\n##   &lt;date&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;                 &lt;dbl&gt;\n## 1 2003-01-16    -62.2     -58.5 -2618200. 1607416.                     0\n## 2 2003-01-17    -62.2     -58.4 -2617487. 1608715.                     0\n## 3 2003-01-18    -62.3     -57.7 -2580637. 1632458.                     0\n## 4 2003-01-19    -62.5     -57.5 -2556440. 1626139.                     0\n## 5 2003-01-20    -62.2     -58.5 -2619622. 1607983.                     0\n## 6 2003-01-21    -62.2     -58.5 -2618872. 1607944.                     0\n\n\nPlot penguin tracks with matched sea ice concentration data\n# Create the base map with longitude and latitude limits, grid lines, and geographical features\nggplot() +\n  # Add a polygon layer for landmasses (adjust as needed for better visual presentation)\n  geom_sf(data = antarctica, fill = \"gray80\", color = \"gray50\") +  # Use world map or other basemap\n  \n  # Add penguin track with sea ice concentration\n  geom_point(data = adpe24_df, aes(x = Longitude, y = Latitude, color = matched_seaice_concen),\n             size = 2, alpha = 0.8) +\n  \n  # Start and end points\n  geom_point(data = adpe24_df[1,], aes(x = Longitude, y = Latitude), color = \"red\", size = 3, shape = 8, stroke = 2) +  # Start point\n  geom_point(data = adpe24_df[nrow(adpe24_df),], aes(x = Longitude, y = Latitude), color = \"orange\", size = 3, shape = 17, stroke = 2) +  # End point\n  \n  # Set the map projection and focus on South Pole region\n  coord_sf(xlim = c(-65, -44), ylim = c(-70, -60), expand = FALSE) +\n  \n  # Custom blue color palette for sea ice concentration (from light blue to dark blue)\n  scale_color_gradientn(\n    name = \"Sea Ice Concentration\", \n    colors = c(\"#dbe9f6\", \"#9ccffb\", \"#6fa9e7\", \"#3177c6\", \"#004494\"),  # Custom blue gradient\n    limits = c(0, 1), \n    breaks = seq(0, 1, by = 0.1),\n    guide = guide_colorbar(direction = \"vertical\")\n  ) +\n  \n  labs(title = \"Sea Ice Concentration Matchup to Penguin Track\",\n       x = \"Longitude\", y = \"Latitude\") +\n  \n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, size = 15), \n        axis.text = element_text(size = 10),\n        legend.position = \"right\") +\n  \n  guides(color = guide_colorbar(barwidth = 1, barheight = 10))"
  },
  {
    "objectID": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html",
    "href": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "history | Updated March 2024\n\n\n\nThere are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov) and the ARGO floats program (http://www.argo.ucsd.edu). In situ buoy data are widely used to monitor environmental conditions.\nIn-situ buoy data can be used to evaluate the accuracy of satellite data.\n\n\n\nIn this exercise, we will learn how to match up satellite data to in situ buoy data using rerddap and rxtracto R packages.\n\n\n\n\nDownloading tabular data (buoy data) from CoastWatch ERDDAP data server\nRetrieving information about a dataset from ERDDAP\nSubsetting satellite data within a rectangular boundary\nMatching satellite data with the buoy data\nRunning statistical analysis to compare buoy and satellite data\nProducing satellite maps and overlaying buoy data\n\n\n\n\n\nThe sea surface temperature (SST) satellite data from the NOAA Geo-polar blended analysis\n The NDBC Standard Meteorological Buoy Data (dataset ID: cwwcNDBCMet)  is used for validating or ground truthing the satellite SST data\n\n\n\n\n# Function to check if pkgs are installed, install missing pkgs, and load\n\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE)\n    if(!require(x,character.only = TRUE)) stop(\"Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ncdf4\", \"rerddap\", \"plotdap\", \"httr\",\n                       \"lubridate\", \"gridGraphics\",  \"mapdata\",\n                       \"ggplot2\", \"RColorBrewer\", \"grid\", \"PBSmapping\", \n                       \"rerddapXtracto\",\"dplyr\",\"viridis\",\"cmocean\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\nExtract data using the rerddap::tabledap function\nUsing rerddap::tabledap function, we will request and download data with the following specifications:\n\nBuoy dataset ID: cwwcNDBCMet\nRegion boundaries: 35 to 40 north latitude and -125 to -120 east longitude\n\nTime span: 08/01/2023 to 08/10/2023\nVariables: station, latitude, longitude, time, and water temperature parameters\n\n# Subset and download tabular data from ERDDAP \n\nERDDAP_Node = \"https://coastwatch.pfeg.noaa.gov/erddap\"\n\nNDBC_id = 'cwwcNDBCMet'\nNDBC_info=info(datasetid = NDBC_id,url = ERDDAP_Node)\n\nbuoy &lt;- rerddap::tabledap( url = ERDDAP_Node, NDBC_id,\n  fields=c('station', 'latitude',  'longitude', 'time', 'wtmp'), \n  'time&gt;=2023-08-01',   'time&lt;=2023-08-10', \n  'latitude&gt;=35','latitude&lt;=40', 'longitude&gt;=-125','longitude&lt;=-120',\n  'wtmp&gt;0'\n)\n\n#Create data frame with the downloaded data\nbuoy.df &lt;-data.frame(station=buoy$station,\n                     longitude=as.numeric(buoy$longitude),\n                     latitude=as.numeric(buoy$latitude),\n                     time=strptime(buoy$time, \"%Y-%m-%dT%H:%M:%S\"),\n                     temp=as.numeric(buoy$wtmp))\n\n# Check for unique stations\nunique.sta &lt;- unique(buoy$sta)\nn.sta &lt;- length(unique.sta)\nn.sta\n## [1] 24\nsummary(buoy.df)\n##    station            longitude         latitude    \n##  Length:28725       Min.   :-124.0   Min.   :35.18  \n##  Class :character   1st Qu.:-123.1   1st Qu.:36.79  \n##  Mode  :character   Median :-122.2   Median :37.81  \n##                     Mean   :-122.3   Mean   :37.40  \n##                     3rd Qu.:-121.9   3rd Qu.:38.06  \n##                     Max.   :-120.8   Max.   :39.20  \n##       time                             temp      \n##  Min.   :2023-08-01 00:00:00.00   Min.   : 9.10  \n##  1st Qu.:2023-08-03 03:48:00.00   1st Qu.:11.90  \n##  Median :2023-08-05 09:18:00.00   Median :13.90  \n##  Mean   :2023-08-05 10:14:05.06   Mean   :14.95  \n##  3rd Qu.:2023-08-07 16:36:00.00   3rd Qu.:16.60  \n##  Max.   :2023-08-10 00:00:00.00   Max.   :23.90\nPlot the buoy data for the first 10 stations in buoy.df\nLet’s see what the buoy data looks like for our time period.\nplot(buoy.df$time, buoy.df$temp, type='n', xlab='Date', ylab='SST (ºC)',main='SST from the first 10 stations')\n\n\nfor (i in 1:10){\n  I=which(buoy.df$station==unique.sta[i])\n  lines(buoy.df$time[I],buoy.df$temp[I])\n}\n\nSelect buoy data closest in time to satellite data\nSince buoy data are hourly and the satellite data are daily, the buoy data needs to be averaged daily for each station.\nbuoy.df.day=buoy.df %&gt;%\n  mutate(date = floor_date(time, unit=\"days\")) %&gt;%\n  group_by(station, date) %&gt;%\n  summarize(\n    lon=mean(longitude),\n    lat=mean(latitude),\n    temp.day=mean(temp),\n    .groups=\"drop\"\n    )\n\nhead(buoy.df.day)\n## # A tibble: 6 × 5\n##   station date                  lon   lat temp.day\n##   &lt;chr&gt;   &lt;dttm&gt;              &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n## 1 46013   2023-08-01 00:00:00 -123.  38.2     10.4\n## 2 46013   2023-08-02 00:00:00 -123.  38.2     10.7\n## 3 46013   2023-08-03 00:00:00 -123.  38.2     10.6\n## 4 46013   2023-08-04 00:00:00 -123.  38.2     10.4\n## 5 46013   2023-08-05 00:00:00 -123.  38.2     10.7\n## 6 46013   2023-08-06 00:00:00 -123.  38.2     10.6\n\n\n\nWe will use Sea surface temperature (SST) satellite data from CoastWatch West code node ERDDAP server.\nURL: https://coastwatch.pfeg.noaa.gov/erddap/ Dataset ID:nesdisBLENDEDsstDNDaily\nurl=  'https://coastwatch.pfeg.noaa.gov/erddap/'\ndatasetid = 'nesdisBLENDEDsstDNDaily'\n\n# Get Data Information given dataset ID and URL\ndataInfo &lt;- rerddap::info(datasetid, url)\n\n# Show data Info\ndataInfo\n## &lt;ERDDAP info&gt; nesdisBLENDEDsstDNDaily \n##  Base URL: https://coastwatch.pfeg.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (2019-07-22T12:00:00Z, 2024-03-20T12:00:00Z) \n##      latitude: (-89.975, 89.975) \n##      longitude: (-179.975, 179.975) \n##  Variables:  \n##      analysed_sst: \n##          Units: degree_C \n##      analysis_error: \n##          Units: degree_C \n##      mask: \n##      sea_ice_fraction: \n##          Units: 1\nExtract the matchup data using rxtracto\nWe will extract satellite data for each buoy station.\n1. get coordinates of each buoy station 2. use the rxtracto function and the buoy coordinates to download satellite data closest to each station\n# Set the variable name of interest from the satellite data\nparameter &lt;- 'analysed_sst'\n\n# Set x,y,t,z coordinates based on buoy data\nxcoord &lt;- buoy.df.day$lon\nycoord &lt;- buoy.df.day$lat\ntcoord &lt;- buoy.df.day$date\n\n\n# Extract satellite data \nextract &lt;- rxtracto(dataInfo, parameter=parameter, \n                    tcoord=tcoord,\n                    xcoord=xcoord,\n                    ycoord=ycoord,\n                    xlen=.01,ylen=.01)\n                     \nbuoy.df.day$sst&lt;-extract$`mean analysed_sst`\nGet subset of data where a satellite value was found\n\nOur satellite product is gap-free (gaps due to clouds were filled using some interpolation) but it has a spatial resolution of 5km. Some buoy stations may be so close to shore that they end up in the landmask of the satellite data. So let’s find the stations that were matched up to an SST pixel.\n\n# Get subset of data where there is a satellite value \ngoodbuoy&lt;-subset(buoy.df.day, sst &gt; 0)\nunique.sta&lt;-unique(goodbuoy$station)\nnbuoy&lt;-length(unique.sta)\nndata&lt;-length(goodbuoy$station)\n\n\n\n\nPlot the satellite SST verses the buoy temperature to visualize how well the two datasets match each other.\n\n# Set up map title \nmain=\"California coast, 8/1/23-8/10/23\"   \n\np &lt;- ggplot(goodbuoy, aes(temp.day, sst,color=lat)) + \n     coord_fixed(xlim=c(8,25),ylim=c(8,25)) \np + geom_point() + \n  ylab('Satellite SST')  + \n  xlab('Buoy average daily SST') +\n  scale_x_continuous(minor_breaks = seq(8, 25)) + \n  scale_y_continuous(minor_breaks = seq(8, 25)) + \n  #geom_abline(a=fit[1],b=fit[2]) +\n  #annotation_custom(my_grob) + \n  #scale_color_gradientn(colours = \"viridis\", name=\"Buoy\\nLatitude\") +\n  scale_color_viridis(discrete = FALSE, name=\"Buoy\\nLatitude\") +\n  labs(title=main) + theme(plot.title = element_text(size=20, face=\"bold\", vjust=2)) \n\nRun a linear regression of Blended SST versus the buoy data. * The R squared is close to 1 (0.8733) * The slope is 0.7151\nlmHeight = lm(sst~temp.day, data = goodbuoy)\nsummary(lmHeight)\n## \n## Call:\n## lm(formula = sst ~ temp.day, data = goodbuoy)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -2.21936 -0.47676  0.02142  0.40927  2.19949 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  3.65951    0.27549   13.28   &lt;2e-16 ***\n## temp.day     0.71469    0.01976   36.17   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7322 on 195 degrees of freedom\n## Multiple R-squared:  0.8703, Adjusted R-squared:  0.8696 \n## F-statistic:  1309 on 1 and 195 DF,  p-value: &lt; 2.2e-16\n\n\n\nExtract blended SST data for August 1st, 2023\n# First define the box and time limits of the requested data \nylim&lt;-c(32,42)\nxlim&lt;-c(-127,-118)\n\n# Extract the monthly satellite data\nSST &lt;- rxtracto_3D(dataInfo,xcoord=xlim,ycoord=ylim,parameter=parameter, \n                   tcoord=c('2023-08-01','2023-08-01'))\n\nSST$sst &lt;- drop(SST$analysed_sst)\nCreate the map frame for the satellite data and buoy SST overlay\nmapFrame&lt;- function(longitude,latitude,sst){\n  dims&lt;-dim(sst)\n  sst&lt;-array(sst,dims[1]*dims[2])\n  sstFrame&lt;-expand.grid(x=longitude,y=latitude)\n  sstFrame$sst&lt;-sst\n  return(sstFrame)\n}\n\nsstFrame&lt;-mapFrame(SST$longitude,SST$latitude,SST$sst)\ncoast &lt;- map_data(\"worldHires\", ylim = ylim, xlim = xlim)\nmy.col &lt;- colorRampPalette(rev(brewer.pal(11, \"RdYlBu\")))(22-13) \n\nbuoy2&lt;-subset(buoy.df.day, month(date)==8 &day(date)==1 & temp.day &gt; 0)\nCreate the map\nmyplot&lt;-ggplot(data = sstFrame, aes(x = x, y = y, fill = sst)) +\n  geom_tile(na.rm=T) +\n  geom_polygon(data = coast, aes(x=long, y = lat, group = group), fill = \"grey80\") +\n  theme_bw(base_size = 15) + ylab(\"Latitude\") + xlab(\"Longitude\") +\n  coord_fixed(1.3,xlim = xlim, ylim = ylim) +\n  scale_fill_cmocean(name = 'thermal',limits=c(10,25),na.value = NA) +\n  ggtitle(paste(\"Satellite SST and buoy temperature (circles) \\n\", unique(as.Date(SST$time)))) +\n  geom_point(data=buoy2, aes(x=lon,y=lat,color=temp.day),size=3,shape=21,color=\"black\") + \n  scale_color_cmocean(name = 'thermal',limits=c(10,25),na.value =\"grey20\") \n  \nmyplot\n\n\n\n\n\nNOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center\nRerddap R Package reference"
  },
  {
    "objectID": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#background",
    "href": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#background",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "There are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov) and the ARGO floats program (http://www.argo.ucsd.edu). In situ buoy data are widely used to monitor environmental conditions.\nIn-situ buoy data can be used to evaluate the accuracy of satellite data."
  },
  {
    "objectID": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#objective",
    "href": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#objective",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "In this exercise, we will learn how to match up satellite data to in situ buoy data using rerddap and rxtracto R packages."
  },
  {
    "objectID": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#the-exercise-demonstrates-the-following-techniques",
    "href": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#the-exercise-demonstrates-the-following-techniques",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "Downloading tabular data (buoy data) from CoastWatch ERDDAP data server\nRetrieving information about a dataset from ERDDAP\nSubsetting satellite data within a rectangular boundary\nMatching satellite data with the buoy data\nRunning statistical analysis to compare buoy and satellite data\nProducing satellite maps and overlaying buoy data"
  },
  {
    "objectID": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#datasets-used",
    "href": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#datasets-used",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "The sea surface temperature (SST) satellite data from the NOAA Geo-polar blended analysis\n The NDBC Standard Meteorological Buoy Data (dataset ID: cwwcNDBCMet)  is used for validating or ground truthing the satellite SST data"
  },
  {
    "objectID": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#install-required-packages-and-load-libraries",
    "href": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#install-required-packages-and-load-libraries",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "# Function to check if pkgs are installed, install missing pkgs, and load\n\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE)\n    if(!require(x,character.only = TRUE)) stop(\"Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ncdf4\", \"rerddap\", \"plotdap\", \"httr\",\n                       \"lubridate\", \"gridGraphics\",  \"mapdata\",\n                       \"ggplot2\", \"RColorBrewer\", \"grid\", \"PBSmapping\", \n                       \"rerddapXtracto\",\"dplyr\",\"viridis\",\"cmocean\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#downloading-buoy-data-from-erddap",
    "href": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#downloading-buoy-data-from-erddap",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "Extract data using the rerddap::tabledap function\nUsing rerddap::tabledap function, we will request and download data with the following specifications:\n\nBuoy dataset ID: cwwcNDBCMet\nRegion boundaries: 35 to 40 north latitude and -125 to -120 east longitude\n\nTime span: 08/01/2023 to 08/10/2023\nVariables: station, latitude, longitude, time, and water temperature parameters\n\n# Subset and download tabular data from ERDDAP \n\nERDDAP_Node = \"https://coastwatch.pfeg.noaa.gov/erddap\"\n\nNDBC_id = 'cwwcNDBCMet'\nNDBC_info=info(datasetid = NDBC_id,url = ERDDAP_Node)\n\nbuoy &lt;- rerddap::tabledap( url = ERDDAP_Node, NDBC_id,\n  fields=c('station', 'latitude',  'longitude', 'time', 'wtmp'), \n  'time&gt;=2023-08-01',   'time&lt;=2023-08-10', \n  'latitude&gt;=35','latitude&lt;=40', 'longitude&gt;=-125','longitude&lt;=-120',\n  'wtmp&gt;0'\n)\n\n#Create data frame with the downloaded data\nbuoy.df &lt;-data.frame(station=buoy$station,\n                     longitude=as.numeric(buoy$longitude),\n                     latitude=as.numeric(buoy$latitude),\n                     time=strptime(buoy$time, \"%Y-%m-%dT%H:%M:%S\"),\n                     temp=as.numeric(buoy$wtmp))\n\n# Check for unique stations\nunique.sta &lt;- unique(buoy$sta)\nn.sta &lt;- length(unique.sta)\nn.sta\n## [1] 24\nsummary(buoy.df)\n##    station            longitude         latitude    \n##  Length:28725       Min.   :-124.0   Min.   :35.18  \n##  Class :character   1st Qu.:-123.1   1st Qu.:36.79  \n##  Mode  :character   Median :-122.2   Median :37.81  \n##                     Mean   :-122.3   Mean   :37.40  \n##                     3rd Qu.:-121.9   3rd Qu.:38.06  \n##                     Max.   :-120.8   Max.   :39.20  \n##       time                             temp      \n##  Min.   :2023-08-01 00:00:00.00   Min.   : 9.10  \n##  1st Qu.:2023-08-03 03:48:00.00   1st Qu.:11.90  \n##  Median :2023-08-05 09:18:00.00   Median :13.90  \n##  Mean   :2023-08-05 10:14:05.06   Mean   :14.95  \n##  3rd Qu.:2023-08-07 16:36:00.00   3rd Qu.:16.60  \n##  Max.   :2023-08-10 00:00:00.00   Max.   :23.90\nPlot the buoy data for the first 10 stations in buoy.df\nLet’s see what the buoy data looks like for our time period.\nplot(buoy.df$time, buoy.df$temp, type='n', xlab='Date', ylab='SST (ºC)',main='SST from the first 10 stations')\n\n\nfor (i in 1:10){\n  I=which(buoy.df$station==unique.sta[i])\n  lines(buoy.df$time[I],buoy.df$temp[I])\n}\n\nSelect buoy data closest in time to satellite data\nSince buoy data are hourly and the satellite data are daily, the buoy data needs to be averaged daily for each station.\nbuoy.df.day=buoy.df %&gt;%\n  mutate(date = floor_date(time, unit=\"days\")) %&gt;%\n  group_by(station, date) %&gt;%\n  summarize(\n    lon=mean(longitude),\n    lat=mean(latitude),\n    temp.day=mean(temp),\n    .groups=\"drop\"\n    )\n\nhead(buoy.df.day)\n## # A tibble: 6 × 5\n##   station date                  lon   lat temp.day\n##   &lt;chr&gt;   &lt;dttm&gt;              &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n## 1 46013   2023-08-01 00:00:00 -123.  38.2     10.4\n## 2 46013   2023-08-02 00:00:00 -123.  38.2     10.7\n## 3 46013   2023-08-03 00:00:00 -123.  38.2     10.6\n## 4 46013   2023-08-04 00:00:00 -123.  38.2     10.4\n## 5 46013   2023-08-05 00:00:00 -123.  38.2     10.7\n## 6 46013   2023-08-06 00:00:00 -123.  38.2     10.6"
  },
  {
    "objectID": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#download-satellite-sst-sea-surface-temperature-data",
    "href": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#download-satellite-sst-sea-surface-temperature-data",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "We will use Sea surface temperature (SST) satellite data from CoastWatch West code node ERDDAP server.\nURL: https://coastwatch.pfeg.noaa.gov/erddap/ Dataset ID:nesdisBLENDEDsstDNDaily\nurl=  'https://coastwatch.pfeg.noaa.gov/erddap/'\ndatasetid = 'nesdisBLENDEDsstDNDaily'\n\n# Get Data Information given dataset ID and URL\ndataInfo &lt;- rerddap::info(datasetid, url)\n\n# Show data Info\ndataInfo\n## &lt;ERDDAP info&gt; nesdisBLENDEDsstDNDaily \n##  Base URL: https://coastwatch.pfeg.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (2019-07-22T12:00:00Z, 2024-03-20T12:00:00Z) \n##      latitude: (-89.975, 89.975) \n##      longitude: (-179.975, 179.975) \n##  Variables:  \n##      analysed_sst: \n##          Units: degree_C \n##      analysis_error: \n##          Units: degree_C \n##      mask: \n##      sea_ice_fraction: \n##          Units: 1\nExtract the matchup data using rxtracto\nWe will extract satellite data for each buoy station.\n1. get coordinates of each buoy station 2. use the rxtracto function and the buoy coordinates to download satellite data closest to each station\n# Set the variable name of interest from the satellite data\nparameter &lt;- 'analysed_sst'\n\n# Set x,y,t,z coordinates based on buoy data\nxcoord &lt;- buoy.df.day$lon\nycoord &lt;- buoy.df.day$lat\ntcoord &lt;- buoy.df.day$date\n\n\n# Extract satellite data \nextract &lt;- rxtracto(dataInfo, parameter=parameter, \n                    tcoord=tcoord,\n                    xcoord=xcoord,\n                    ycoord=ycoord,\n                    xlen=.01,ylen=.01)\n                     \nbuoy.df.day$sst&lt;-extract$`mean analysed_sst`\nGet subset of data where a satellite value was found\n\nOur satellite product is gap-free (gaps due to clouds were filled using some interpolation) but it has a spatial resolution of 5km. Some buoy stations may be so close to shore that they end up in the landmask of the satellite data. So let’s find the stations that were matched up to an SST pixel.\n\n# Get subset of data where there is a satellite value \ngoodbuoy&lt;-subset(buoy.df.day, sst &gt; 0)\nunique.sta&lt;-unique(goodbuoy$station)\nnbuoy&lt;-length(unique.sta)\nndata&lt;-length(goodbuoy$station)"
  },
  {
    "objectID": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#compare-results-for-satellite-and-buoy",
    "href": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#compare-results-for-satellite-and-buoy",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "Plot the satellite SST verses the buoy temperature to visualize how well the two datasets match each other.\n\n# Set up map title \nmain=\"California coast, 8/1/23-8/10/23\"   \n\np &lt;- ggplot(goodbuoy, aes(temp.day, sst,color=lat)) + \n     coord_fixed(xlim=c(8,25),ylim=c(8,25)) \np + geom_point() + \n  ylab('Satellite SST')  + \n  xlab('Buoy average daily SST') +\n  scale_x_continuous(minor_breaks = seq(8, 25)) + \n  scale_y_continuous(minor_breaks = seq(8, 25)) + \n  #geom_abline(a=fit[1],b=fit[2]) +\n  #annotation_custom(my_grob) + \n  #scale_color_gradientn(colours = \"viridis\", name=\"Buoy\\nLatitude\") +\n  scale_color_viridis(discrete = FALSE, name=\"Buoy\\nLatitude\") +\n  labs(title=main) + theme(plot.title = element_text(size=20, face=\"bold\", vjust=2)) \n\nRun a linear regression of Blended SST versus the buoy data. * The R squared is close to 1 (0.8733) * The slope is 0.7151\nlmHeight = lm(sst~temp.day, data = goodbuoy)\nsummary(lmHeight)\n## \n## Call:\n## lm(formula = sst ~ temp.day, data = goodbuoy)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -2.21936 -0.47676  0.02142  0.40927  2.19949 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  3.65951    0.27549   13.28   &lt;2e-16 ***\n## temp.day     0.71469    0.01976   36.17   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7322 on 195 degrees of freedom\n## Multiple R-squared:  0.8703, Adjusted R-squared:  0.8696 \n## F-statistic:  1309 on 1 and 195 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#create-a-map-of-sst-and-overlay-the-buoy-data",
    "href": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#create-a-map-of-sst-and-overlay-the-buoy-data",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "Extract blended SST data for August 1st, 2023\n# First define the box and time limits of the requested data \nylim&lt;-c(32,42)\nxlim&lt;-c(-127,-118)\n\n# Extract the monthly satellite data\nSST &lt;- rxtracto_3D(dataInfo,xcoord=xlim,ycoord=ylim,parameter=parameter, \n                   tcoord=c('2023-08-01','2023-08-01'))\n\nSST$sst &lt;- drop(SST$analysed_sst)\nCreate the map frame for the satellite data and buoy SST overlay\nmapFrame&lt;- function(longitude,latitude,sst){\n  dims&lt;-dim(sst)\n  sst&lt;-array(sst,dims[1]*dims[2])\n  sstFrame&lt;-expand.grid(x=longitude,y=latitude)\n  sstFrame$sst&lt;-sst\n  return(sstFrame)\n}\n\nsstFrame&lt;-mapFrame(SST$longitude,SST$latitude,SST$sst)\ncoast &lt;- map_data(\"worldHires\", ylim = ylim, xlim = xlim)\nmy.col &lt;- colorRampPalette(rev(brewer.pal(11, \"RdYlBu\")))(22-13) \n\nbuoy2&lt;-subset(buoy.df.day, month(date)==8 &day(date)==1 & temp.day &gt; 0)\nCreate the map\nmyplot&lt;-ggplot(data = sstFrame, aes(x = x, y = y, fill = sst)) +\n  geom_tile(na.rm=T) +\n  geom_polygon(data = coast, aes(x=long, y = lat, group = group), fill = \"grey80\") +\n  theme_bw(base_size = 15) + ylab(\"Latitude\") + xlab(\"Longitude\") +\n  coord_fixed(1.3,xlim = xlim, ylim = ylim) +\n  scale_fill_cmocean(name = 'thermal',limits=c(10,25),na.value = NA) +\n  ggtitle(paste(\"Satellite SST and buoy temperature (circles) \\n\", unique(as.Date(SST$time)))) +\n  geom_point(data=buoy2, aes(x=lon,y=lat,color=temp.day),size=3,shape=21,color=\"black\") + \n  scale_color_cmocean(name = 'thermal',limits=c(10,25),na.value =\"grey20\") \n  \nmyplot"
  },
  {
    "objectID": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#references",
    "href": "tutorials/matchup-satellite-buoy-data/r/matchup_satellite_buoy_data.html#references",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "NOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center\nRerddap R Package reference"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/matlab/matchup-satellite-data-to-track-locations.html",
    "href": "tutorials/matchup-satellite-data-to-track-locations/matlab/matchup-satellite-data-to-track-locations.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will teach you how to plot a loggerhead turtle track on a map. The turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. It transmitted for over 3 years and went all the way to the southern tip of Baja California!\nThe track data can be downloaded here: https://oceanwatch.pifsc.noaa.gov/files/25317_05.dat (You may need to copy and save the data.)\nWe’ll extract chlorophyll concentration and SST at each location along the track, and plot the data.\nLet’s load the track data.\nturtle = readtable(\"25317_05.dat\", \"Delimiter\", \",\");\n\n\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, in black\nplotm(turtle.mean_lat, turtle.mean_lon, 'k');\n\n% Mark the first location with a red triangle\nplotm(turtle.mean_lat(1), turtle.mean_lon(1), 'rv', 'MarkerFaceColor', 'r');\n\n% Add a title\ntitle('Turtle #25317');\ntightmap\n ### Now let’s extract data along the track\nWe are going to grab data from ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/griddap) so we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\n\n\n\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data are severely affected by clouds (i.e., lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer gaps. As a separate exercise, you can run all 3 temporal resolutions, and plot a time-series of each to compare.\n% Let's start by creating a shortcut to the link we're going to be calling\n% repeatedly\nMODIS = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0.csv?chlor_a\";\n\n% We also need to format the dates in a way that ERDDAP understands, i.e., 2010-12-15:\nturtle_datenum = datenum(turtle.year, turtle.month, turtle.day);\nturtle_dates = datestr(turtle_datenum, \"yyyy-mm-dd\");\nFor each date and location, we’ll extract a value of monthly chl-a concentration. To do this, we need to pass the needed parameters (which dataset, which date, which lon, and which lat) to ERDDAP by building the URL in a loop for each point of the track.\nNOTE: Because this is a very long track, running the loop on the entire track will take a while (about 5 mins). You could print the index value to the screen to gauge your progress, but this will slow down the loop. If the loop takes too long, just run it on the first ~100 points of the track, by changing the for statement below.\nIf the process breaks in the middle of the loop (sometimes there is an issue connecting to the ERDDAP server, which will cause an error and interrupt the loop), get the value of r, which will tell you which index the loop stopped at, and restart the loop there. For example, if the loop stopped at r = 163, restart the loop this way: for r = 163:1:height(turtle)\n% First, we'll create an empty matrix to hold the chlorophyll data.  This\n% isn't strictly necessary, but it will speed things up a little.\n% The data we extract will have 4 columns:\n% 1: date\n% 2: matched latitude\n% 3: matched longitude\n% 4: chlor_a\n% You can confirm this by pasting the URL below into a browser and viewing\n% the resulting data.  \nturtle_chl(1:height(turtle), 1:4) = NaN; \n\nfor r = 1:1:height(turtle)\n    % Create url from tag position\n    url = strcat(MODIS, '[(', num2str(turtle_dates(r, 1:10)), '):1:(', num2str(turtle_dates(r, 1:10)), ...\n       ')][(', num2str(turtle.mean_lat(r)), '):1:(', num2str(turtle.mean_lat(r)), ')][(', ...\n       num2str(turtle.mean_lon(r)), '):1:(', num2str(turtle.mean_lon(r)), ')]');\n    \n    % Access url\n    chl = webread(url);\n    \n    % Add data from url to our empty matrix\n    % First, time (there's probably a better way to do this...)\n    % We're going to keep time in the datenum format for now.\n    chl_time = chl.time{:};\n    turtle_chl(r,1) = datenum(datetime(chl_time(1:10), 'InputFormat', 'yyyy-MM-dd'));\n    \n    % Now the remaining variables\n    turtle_chl(r,2) = chl.latitude;\n    turtle_chl(r,3) = chl.longitude;\n    turtle_chl(r,4) = chl.chlor_a;\nend\nWe now have a value of monthly chlorophyll-a concentration for each location/date combination along the turtle track. Let’s save this information so we have it for future use.\n% There are two options for saving your output.  If you don't care about\n% including the header information, you can simply save the turtle_chl\n% matrix.\nwritematrix(turtle_chl, 'turtle_chl_NoHeader.csv');\n\n% To add the header, we just need to turn the matrix into a table.\nmatched_date = turtle_chl(:,1);\nmatched_lat = turtle_chl(:,2);\nmatched_lon = turtle_chl(:,3);\nmatched_chl = turtle_chl(:,4);\nturtle_chl_table = table(matched_date, matched_lat, matched_lon, matched_chl);\nwritetable(turtle_chl_table, 'turtle_chl_WithHeader.csv');\n\n% Note that: \n% 1) We kept the date in the 'datenum' format.  This can be changed to a\n% datevec if you'd like.  See the code in the previous tutorials for help\n% with this.\n% 2) We saved the files to our working directory.  If you want to save the\n% files elsewhere, just edit the path.\n\n\n\nExercise 1: Repeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v1_0.html\nExercise 2: Go to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ Note: some ERDDAPs are slower than others, so this could take a lot longer. If it takes too long, adjust the for loop to request data for only the first 100 days of our track.\n\n\n\n\n\nLet’s plot the track, color coded using values of monthly chlorophyll concentration. To do this, we’ll use the turtle_chl matrix we created above. We’ll also need to decide how to color code the track. Let’s take a look at the range of chlorophyll values.\n% Create a histogram with 30 bins\nfigure\nhistogram(turtle_chl(:,4), 30);\n Notice that the range of value is large, roughly 0 - 8 mg chl per m^3, but that nearly all the values are small. This suggests that we should log-transform the chlorophyll data. Let’s take a look at the log-transformed values.\n% Create a histogram with 30 bins\nfigure\nhistogram(log(turtle_chl(:,4)), 30);\n\n\n\nhistogram\n\n\nThe range of the log-transformed values is roughly -3 - 2, but most of the values are greater than -3 and less than 0. So, for our plot, we’ll use the log-transformed chlorophyll values and set the color range to -2.9 - 0.\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, with a marker size of 5 \n% Note that we're using 'scatterm' here instead of 'plotm'.  This is so\n% that we can control the colors of the individual points (here, based on\n% the log-transformed chlorophyll value).\nscatterm(turtle_chl(:,2), turtle_chl(:,3), 5, log(turtle_chl(:,4)), 'o', 'Filled');\n% Set the color map to jet colors, with 30 levels, ranging from -2.9 to 0.\ncolormap(jet(30));\ncaxis([-2.9 0]);\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'log(chl)';\n\n% Add a title\ntitle('Turtle #25317');\ntightmap\n\n\n\nTurtle track\n\n\n\n\n\nExercise 3: plot the track, color coded using values of monthly sea surface temperature. You can confirm for yourself that it’s not necessary to log-transform SST.\n\n\n\n\n\nIn the example above, we downloaded data from as close to the track position as possible. But, you could instead average all points within a given distance of a track position. Here’s how you’d do that.\n% Like last time, we'll create an empty matrix to hold the chlorophyll data.  This\n% isn't strictly necessary, but it will speed things up a little.\n% The data we extract will have 4 columns:\n% 1: date\n% 2: matched latitude\n% 3: matched longitude\n% 4: chlor_a\n% You can confirm this by pasting the URL below into a browser and viewing\n% the resulting data.  \nturtle_chl_radius(1:height(turtle), 1:4) = NaN; \n% We also need to define the radius of the area we want to average.  \n% For this example, let's say that radius is 0.1 degrees.  So, we want all\n% values within +/- 0.1 degrees of the track location.\nradius = 0.1;\n\n% When we create the url, we'll need to subtract this radius from the\n% minimum lat and lon, and add it to the maximum lat and lon.\nfor r = 1:1:height(turtle)\n    % Create url from tag position\n    url_rad = strcat(MODIS, '[(', num2str(turtle_dates(r, 1:10)), '):1:(', num2str(turtle_dates(r, 1:10)), ...\n       ')][(', num2str(turtle.mean_lat(r) + radius), '):1:(', num2str(turtle.mean_lat(r) - radius), ...\n       ')][(', num2str(turtle.mean_lon(r) - radius), '):1:(', num2str(turtle.mean_lon(r) + radius), ')]');\n    \n    % Access url\n    chl_rad = webread(url_rad);\n    \n    % The data we access via the url now has several lines.  We'll average\n    % the chlorophyll-a values.  \n    % We'll also average the lat and lon positions, but there are various\n    % options for how you could handle this (e.g., using the tag location\n    % instead)\n    \n    % Add data from url to our empty matrix\n    % First, time, which is the same for all rows \n    % We're going to keep time in the datenum format for now.\n    chl_rad_time = chl_rad.time{1,:};\n    turtle_chl_radius(r,1) = datenum(datetime(chl_rad_time(1:10), 'InputFormat', 'yyyy-MM-dd'));\n    \n    % Now the remaining variables\n    turtle_chl_radius(r,2) = mean(chl_rad.latitude);\n    turtle_chl_radius(r,3) = mean(chl_rad.longitude);\n    turtle_chl_radius(r,4) = mean(chl_rad.chlor_a);\nend\nSo far in our tutorials, we’ve been using Matlab’s built-in jet color palette. However, there are a lot of other color options that we could use. One tool with a range of palettes is the Climate Data Toolbox for Matlab. You can read how to install this add-on here: https://chadagreene.com/CDT/CDT_Getting_Started.html. Now that you’ve followed those steps, let’s use their algae color map to plot the chorlophyll values along the track.\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, with a marker size of 10 \n% Note that we're using 'scatterm' here instead of 'plotm'.  This is so\n% that we can control the colors of the individual points (here, based on\n% the log-transformed chlorophyll value).\nscatterm(turtle_chl_radius(:,2), turtle_chl_radius(:,3), 10, log(turtle_chl_radius(:,4)), 'o', 'Filled');\n\n% Set the color map to algae, with 30 levels, ranging from -2.9 to 0.\ncmocean('algae', 30);\ncaxis([-2.9 0]);\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'log(chl)';\n\n% Add a title\ntitle('Turtle #25317 - Averaging within +/- 0.1 degree of tracked location');\ntightmap\n\n\n\nTurtle tack log"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/matlab/matchup-satellite-data-to-track-locations.html#extract-data-along-a-turtle-track",
    "href": "tutorials/matchup-satellite-data-to-track-locations/matlab/matchup-satellite-data-to-track-locations.html#extract-data-along-a-turtle-track",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will teach you how to plot a loggerhead turtle track on a map. The turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. It transmitted for over 3 years and went all the way to the southern tip of Baja California!\nThe track data can be downloaded here: https://oceanwatch.pifsc.noaa.gov/files/25317_05.dat (You may need to copy and save the data.)\nWe’ll extract chlorophyll concentration and SST at each location along the track, and plot the data.\nLet’s load the track data.\nturtle = readtable(\"25317_05.dat\", \"Delimiter\", \",\");\n\n\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, in black\nplotm(turtle.mean_lat, turtle.mean_lon, 'k');\n\n% Mark the first location with a red triangle\nplotm(turtle.mean_lat(1), turtle.mean_lon(1), 'rv', 'MarkerFaceColor', 'r');\n\n% Add a title\ntitle('Turtle #25317');\ntightmap\n ### Now let’s extract data along the track\nWe are going to grab data from ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/griddap) so we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\n\n\n\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data are severely affected by clouds (i.e., lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer gaps. As a separate exercise, you can run all 3 temporal resolutions, and plot a time-series of each to compare.\n% Let's start by creating a shortcut to the link we're going to be calling\n% repeatedly\nMODIS = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0.csv?chlor_a\";\n\n% We also need to format the dates in a way that ERDDAP understands, i.e., 2010-12-15:\nturtle_datenum = datenum(turtle.year, turtle.month, turtle.day);\nturtle_dates = datestr(turtle_datenum, \"yyyy-mm-dd\");\nFor each date and location, we’ll extract a value of monthly chl-a concentration. To do this, we need to pass the needed parameters (which dataset, which date, which lon, and which lat) to ERDDAP by building the URL in a loop for each point of the track.\nNOTE: Because this is a very long track, running the loop on the entire track will take a while (about 5 mins). You could print the index value to the screen to gauge your progress, but this will slow down the loop. If the loop takes too long, just run it on the first ~100 points of the track, by changing the for statement below.\nIf the process breaks in the middle of the loop (sometimes there is an issue connecting to the ERDDAP server, which will cause an error and interrupt the loop), get the value of r, which will tell you which index the loop stopped at, and restart the loop there. For example, if the loop stopped at r = 163, restart the loop this way: for r = 163:1:height(turtle)\n% First, we'll create an empty matrix to hold the chlorophyll data.  This\n% isn't strictly necessary, but it will speed things up a little.\n% The data we extract will have 4 columns:\n% 1: date\n% 2: matched latitude\n% 3: matched longitude\n% 4: chlor_a\n% You can confirm this by pasting the URL below into a browser and viewing\n% the resulting data.  \nturtle_chl(1:height(turtle), 1:4) = NaN; \n\nfor r = 1:1:height(turtle)\n    % Create url from tag position\n    url = strcat(MODIS, '[(', num2str(turtle_dates(r, 1:10)), '):1:(', num2str(turtle_dates(r, 1:10)), ...\n       ')][(', num2str(turtle.mean_lat(r)), '):1:(', num2str(turtle.mean_lat(r)), ')][(', ...\n       num2str(turtle.mean_lon(r)), '):1:(', num2str(turtle.mean_lon(r)), ')]');\n    \n    % Access url\n    chl = webread(url);\n    \n    % Add data from url to our empty matrix\n    % First, time (there's probably a better way to do this...)\n    % We're going to keep time in the datenum format for now.\n    chl_time = chl.time{:};\n    turtle_chl(r,1) = datenum(datetime(chl_time(1:10), 'InputFormat', 'yyyy-MM-dd'));\n    \n    % Now the remaining variables\n    turtle_chl(r,2) = chl.latitude;\n    turtle_chl(r,3) = chl.longitude;\n    turtle_chl(r,4) = chl.chlor_a;\nend\nWe now have a value of monthly chlorophyll-a concentration for each location/date combination along the turtle track. Let’s save this information so we have it for future use.\n% There are two options for saving your output.  If you don't care about\n% including the header information, you can simply save the turtle_chl\n% matrix.\nwritematrix(turtle_chl, 'turtle_chl_NoHeader.csv');\n\n% To add the header, we just need to turn the matrix into a table.\nmatched_date = turtle_chl(:,1);\nmatched_lat = turtle_chl(:,2);\nmatched_lon = turtle_chl(:,3);\nmatched_chl = turtle_chl(:,4);\nturtle_chl_table = table(matched_date, matched_lat, matched_lon, matched_chl);\nwritetable(turtle_chl_table, 'turtle_chl_WithHeader.csv');\n\n% Note that: \n% 1) We kept the date in the 'datenum' format.  This can be changed to a\n% datevec if you'd like.  See the code in the previous tutorials for help\n% with this.\n% 2) We saved the files to our working directory.  If you want to save the\n% files elsewhere, just edit the path.\n\n\n\nExercise 1: Repeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v1_0.html\nExercise 2: Go to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ Note: some ERDDAPs are slower than others, so this could take a lot longer. If it takes too long, adjust the for loop to request data for only the first 100 days of our track.\n\n\n\n\n\nLet’s plot the track, color coded using values of monthly chlorophyll concentration. To do this, we’ll use the turtle_chl matrix we created above. We’ll also need to decide how to color code the track. Let’s take a look at the range of chlorophyll values.\n% Create a histogram with 30 bins\nfigure\nhistogram(turtle_chl(:,4), 30);\n Notice that the range of value is large, roughly 0 - 8 mg chl per m^3, but that nearly all the values are small. This suggests that we should log-transform the chlorophyll data. Let’s take a look at the log-transformed values.\n% Create a histogram with 30 bins\nfigure\nhistogram(log(turtle_chl(:,4)), 30);\n\n\n\nhistogram\n\n\nThe range of the log-transformed values is roughly -3 - 2, but most of the values are greater than -3 and less than 0. So, for our plot, we’ll use the log-transformed chlorophyll values and set the color range to -2.9 - 0.\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, with a marker size of 5 \n% Note that we're using 'scatterm' here instead of 'plotm'.  This is so\n% that we can control the colors of the individual points (here, based on\n% the log-transformed chlorophyll value).\nscatterm(turtle_chl(:,2), turtle_chl(:,3), 5, log(turtle_chl(:,4)), 'o', 'Filled');\n% Set the color map to jet colors, with 30 levels, ranging from -2.9 to 0.\ncolormap(jet(30));\ncaxis([-2.9 0]);\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'log(chl)';\n\n% Add a title\ntitle('Turtle #25317');\ntightmap\n\n\n\nTurtle track\n\n\n\n\n\nExercise 3: plot the track, color coded using values of monthly sea surface temperature. You can confirm for yourself that it’s not necessary to log-transform SST.\n\n\n\n\n\nIn the example above, we downloaded data from as close to the track position as possible. But, you could instead average all points within a given distance of a track position. Here’s how you’d do that.\n% Like last time, we'll create an empty matrix to hold the chlorophyll data.  This\n% isn't strictly necessary, but it will speed things up a little.\n% The data we extract will have 4 columns:\n% 1: date\n% 2: matched latitude\n% 3: matched longitude\n% 4: chlor_a\n% You can confirm this by pasting the URL below into a browser and viewing\n% the resulting data.  \nturtle_chl_radius(1:height(turtle), 1:4) = NaN; \n% We also need to define the radius of the area we want to average.  \n% For this example, let's say that radius is 0.1 degrees.  So, we want all\n% values within +/- 0.1 degrees of the track location.\nradius = 0.1;\n\n% When we create the url, we'll need to subtract this radius from the\n% minimum lat and lon, and add it to the maximum lat and lon.\nfor r = 1:1:height(turtle)\n    % Create url from tag position\n    url_rad = strcat(MODIS, '[(', num2str(turtle_dates(r, 1:10)), '):1:(', num2str(turtle_dates(r, 1:10)), ...\n       ')][(', num2str(turtle.mean_lat(r) + radius), '):1:(', num2str(turtle.mean_lat(r) - radius), ...\n       ')][(', num2str(turtle.mean_lon(r) - radius), '):1:(', num2str(turtle.mean_lon(r) + radius), ')]');\n    \n    % Access url\n    chl_rad = webread(url_rad);\n    \n    % The data we access via the url now has several lines.  We'll average\n    % the chlorophyll-a values.  \n    % We'll also average the lat and lon positions, but there are various\n    % options for how you could handle this (e.g., using the tag location\n    % instead)\n    \n    % Add data from url to our empty matrix\n    % First, time, which is the same for all rows \n    % We're going to keep time in the datenum format for now.\n    chl_rad_time = chl_rad.time{1,:};\n    turtle_chl_radius(r,1) = datenum(datetime(chl_rad_time(1:10), 'InputFormat', 'yyyy-MM-dd'));\n    \n    % Now the remaining variables\n    turtle_chl_radius(r,2) = mean(chl_rad.latitude);\n    turtle_chl_radius(r,3) = mean(chl_rad.longitude);\n    turtle_chl_radius(r,4) = mean(chl_rad.chlor_a);\nend\nSo far in our tutorials, we’ve been using Matlab’s built-in jet color palette. However, there are a lot of other color options that we could use. One tool with a range of palettes is the Climate Data Toolbox for Matlab. You can read how to install this add-on here: https://chadagreene.com/CDT/CDT_Getting_Started.html. Now that you’ve followed those steps, let’s use their algae color map to plot the chorlophyll values along the track.\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, with a marker size of 10 \n% Note that we're using 'scatterm' here instead of 'plotm'.  This is so\n% that we can control the colors of the individual points (here, based on\n% the log-transformed chlorophyll value).\nscatterm(turtle_chl_radius(:,2), turtle_chl_radius(:,3), 10, log(turtle_chl_radius(:,4)), 'o', 'Filled');\n\n% Set the color map to algae, with 30 levels, ranging from -2.9 to 0.\ncmocean('algae', 30);\ncaxis([-2.9 0]);\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'log(chl)';\n\n% Add a title\ntitle('Turtle #25317 - Averaging within +/- 0.1 degree of tracked location');\ntightmap\n\n\n\nTurtle tack log"
  },
  {
    "objectID": "tutorials/matlab-basics/matlab/matlab_basics_gl.html",
    "href": "tutorials/matlab-basics/matlab/matlab_basics_gl.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands.\nNote: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset daily SST data:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.html\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nERDDAP\n\n\nIn this specific example, the URL we generated is:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.nc?sst%5B(2021-07-21T12:00:00Z):1:(2021-07-28T12:00:00Z)%5D%5B(38.8749871947229):1:(50.6059751976437)%5D%5B(-92.4199507342304):1:(-75.8816402880577)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n% View data attributes and variables\nncdisp('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS');\nNotice that the full data set has four variables: time, latitude, longitude, and sst. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\n\n\nNotice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the week we’re interested in: 21 - 28 July 2021.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2021 & time_full_ymdhms(:,2) == 7 ...\n    & time_full_ymdhms(:,3) &gt;= 21 & time_full_ymdhms(:,3) &lt;= 28);\n\n\n\nBefore we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'latitude');\nlon = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'longitude');\nNotice in the output above that sst has the dimensions of longitude x latitude x time which means it has a size of 1181 x 838 x 9961.\n\n\n\nNow, we’ll access just the small amount of sst data we’re interested in. We’ll do this by telling the computer to access the variable ‘sst’, beginning at a specific time and spanning our time of interest.\n% Start coordinates\naoi_start = [1 1 time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon) length(lat) length(time_aoi)];\nsst = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'sst', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 1181 x 838 x 8. Before we see what these data look like, let’s create indices for the timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi*  % Delete every variable with 'aoi' in its name\n\n\n\n\nLet’s create a map for a single day, 21 July 2021, the first day in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 10:0.5:25.5, 'fill', 'on');\ntitle(sprintf('Daily SST %s', datestr(time_ymdhms(1,:), 'dd-mmm-yyyy')));\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(45,5), -83:0.5:-81, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 15\ncontourm(lat, lon, sst(:,:,1)', [15 15], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Example of how to add a marker to tutorial author's home town, just for\n% fun\nplotm(45.8527, -87.0218, 'p');\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\ndaily SST\n\n\n\n\n\nLet’s pick a box encompassing Lake Superior: north of 46N and west of 84W. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above for time to identify a subsetted area of interest.\n% Find longitudes west of 84 W\nlon_aoi = find(lon &lt;= -84);\n\n% Find latitudes north of 46 N\nlat_aoi = find(lat &gt;= 46);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 8 days\nsst_ts(1:8,1) = NaN;\nfor d = 1:1:8 \n    sst_ts(d,1) = mean(sst_subset(:,:,d), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,3), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\nset(gca, 'XTick', time_ymdhms(:,3));\nset(gca, 'XTickLabel', datestr(time_ymdhms(:,:), 'mm/dd'))\n\n\n\ntime series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n% Average over time, which is the third dimention of our data\nsst_wk = mean(sst, 3, \"omitnan\");\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_wk', 10:0.5:25.5, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'dd-mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(8,:),'dd-mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nmean SST"
  },
  {
    "objectID": "tutorials/matlab-basics/matlab/matlab_basics_gl.html#how-to-work-with-satellite-data-in-matlab",
    "href": "tutorials/matlab-basics/matlab/matlab_basics_gl.html#how-to-work-with-satellite-data-in-matlab",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands.\nNote: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset daily SST data:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.html\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nERDDAP\n\n\nIn this specific example, the URL we generated is:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.nc?sst%5B(2021-07-21T12:00:00Z):1:(2021-07-28T12:00:00Z)%5D%5B(38.8749871947229):1:(50.6059751976437)%5D%5B(-92.4199507342304):1:(-75.8816402880577)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n% View data attributes and variables\nncdisp('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS');\nNotice that the full data set has four variables: time, latitude, longitude, and sst. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\n\n\nNotice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the week we’re interested in: 21 - 28 July 2021.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2021 & time_full_ymdhms(:,2) == 7 ...\n    & time_full_ymdhms(:,3) &gt;= 21 & time_full_ymdhms(:,3) &lt;= 28);\n\n\n\nBefore we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'latitude');\nlon = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'longitude');\nNotice in the output above that sst has the dimensions of longitude x latitude x time which means it has a size of 1181 x 838 x 9961.\n\n\n\nNow, we’ll access just the small amount of sst data we’re interested in. We’ll do this by telling the computer to access the variable ‘sst’, beginning at a specific time and spanning our time of interest.\n% Start coordinates\naoi_start = [1 1 time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon) length(lat) length(time_aoi)];\nsst = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'sst', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 1181 x 838 x 8. Before we see what these data look like, let’s create indices for the timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi*  % Delete every variable with 'aoi' in its name\n\n\n\n\nLet’s create a map for a single day, 21 July 2021, the first day in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 10:0.5:25.5, 'fill', 'on');\ntitle(sprintf('Daily SST %s', datestr(time_ymdhms(1,:), 'dd-mmm-yyyy')));\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(45,5), -83:0.5:-81, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 15\ncontourm(lat, lon, sst(:,:,1)', [15 15], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Example of how to add a marker to tutorial author's home town, just for\n% fun\nplotm(45.8527, -87.0218, 'p');\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\ndaily SST\n\n\n\n\n\nLet’s pick a box encompassing Lake Superior: north of 46N and west of 84W. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above for time to identify a subsetted area of interest.\n% Find longitudes west of 84 W\nlon_aoi = find(lon &lt;= -84);\n\n% Find latitudes north of 46 N\nlat_aoi = find(lat &gt;= 46);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 8 days\nsst_ts(1:8,1) = NaN;\nfor d = 1:1:8 \n    sst_ts(d,1) = mean(sst_subset(:,:,d), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,3), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\nset(gca, 'XTick', time_ymdhms(:,3));\nset(gca, 'XTickLabel', datestr(time_ymdhms(:,:), 'mm/dd'))\n\n\n\ntime series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n% Average over time, which is the third dimention of our data\nsst_wk = mean(sst, 3, \"omitnan\");\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_wk', 10:0.5:25.5, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'dd-mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(8,:),'dd-mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nmean SST"
  },
  {
    "objectID": "tutorials/python-environment/python-environment.html",
    "href": "tutorials/python-environment/python-environment.html",
    "title": "Setting up a Python environment",
    "section": "",
    "text": "Make sure you have python 3 and conda installed on your machine\nDownload this repository.\n\nUse the green Code dropdown to select Download Zip and unzip to a location on your computer\nOr use this zip file link\n\nUse a terminal window to navigate to the unzipped folder\n\nThe following commands:\n\nUpdate conda\nCreate a new conda environment named ‘coastwatch’ and load the required modules to it\n\nActivate the environment\n\nRuns a script that checks for any missing modules\n\nLaunches jupyter-lab for displaying the jupyter notebook tutorials\n\nconda update conda\nconda env create -f environment.yml\nconda activate coastwatch\npython check_modules.py\njupyter-lab"
  },
  {
    "objectID": "tutorials/python-environment/python-environment.html#setup-and-test-your-python-environment-for-the-coastwatch-satellite-course",
    "href": "tutorials/python-environment/python-environment.html#setup-and-test-your-python-environment-for-the-coastwatch-satellite-course",
    "title": "Setting up a Python environment",
    "section": "",
    "text": "Make sure you have python 3 and conda installed on your machine\nDownload this repository.\n\nUse the green Code dropdown to select Download Zip and unzip to a location on your computer\nOr use this zip file link\n\nUse a terminal window to navigate to the unzipped folder\n\nThe following commands:\n\nUpdate conda\nCreate a new conda environment named ‘coastwatch’ and load the required modules to it\n\nActivate the environment\n\nRuns a script that checks for any missing modules\n\nLaunches jupyter-lab for displaying the jupyter notebook tutorials\n\nconda update conda\nconda env create -f environment.yml\nconda activate coastwatch\npython check_modules.py\njupyter-lab"
  },
  {
    "objectID": "tutorials/software.html",
    "href": "tutorials/software.html",
    "title": "Software Code Gallery",
    "section": "",
    "text": "This gallery brings together hands-on, software-based tutorials for working with CoastWatch and ERDDAP data. Each tutorial focuses on a specific task—such as discovering datasets, building ERDDAP URLs, visualizing gridded and tabular data, or troubleshooting common workflows—using tools like Python, R, and related utilities.\nClick the info icon to learn more about the software and tools used in the tutorial, eye icon to preview outputs, box to view tutorial resources, or download to open the source file on GitHub.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nInfo\nPreview\nResources\nDownload ↓\n\n\n\n\nERDDAP Basics - Using the ERDDAP data catalog\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n\n\nERDDAP Basics - Visualize and download data\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n\n\nERDDAP Basics - Understanding the ERDDAP URL\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n\n\nERDDAP Basics - Creating a Hovmoller plot\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n\n\nERDDAP Basics - Work with wind vectors\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n\n\nERDDAP Basics - Using tabular data\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n\n\nERDDAP Basics - Additional Resources\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n\n\nSetting up a Python environment\n—\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTroubleshooting rerrdapXtracto\n—\n\n\n\n\n\n—\n\n\n\n\n\n\n\nNetCDF and Panoply Tutorial\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n\n\nCoastWatch Utilities\n\n\n\n\n\n\n\n\n\n\n—\n—\n\n\n\n\n\n\n    \n      ERDDAP Basics - Using the ERDDAP data catalog\n      Learn how to navigate the ERDDAP data catalog to discover datasets of interest. This tutorial walks through browsing available datasets, using full-text search to refine results, and examining dataset summaries and metadata to evaluate spatial coverage, resolution, time range, and data provenance.\n\n      \n        \n          \n            \n              \n            \n            Global SST & Sea Ice Analysis (OSTIA) dataset from the UK Met Office on an ERDDAP server.\n          \n        \n        View tutorial\n      \n\n      Close\n    \n    \n    \n      ERDDAP Basics - Visualize and download data\n      This tutorial demonstrates how to use ERDDAP’s Make A Graph feature to visualize gridded data, subset by time and region, customize map appearance, and download results in common image and data formats. Users learn how to generate reproducible URLs for sharing or importing data directly into analysis tools such as Python, R, or Matlab.\n\n      \n        \n          \n            \n              \n            \n            The ERDDAP Make A Graph page for the OSTIA global sea surface temperature dataset. The interface allows users to select the displayed variable, subset data by time, latitude, and longitude, adjust graph and color-bar settings, choose output file formats, and generate reproducible RESTful URLs for visualization and data download.\n          \n        \n          \n            \n              \n            \n            Sea surface temperature map for the Washington coast on July 15, 2015, generated using ERDDAP’s Make A Graph tool.\n          \n        ◀1 / 2▶\n        View tutorial\n      \n\n      Close\n    \n    \n    \n      ERDDAP Basics - Understanding the ERDDAP URL\n      This tutorial explains how ERDDAP data requests are fully defined within a URL and how those URLs can be edited to control dataset selection, spatial and temporal subsetting, output formats, and visualization settings. You will learn how to modify URL components by hand to retrieve different maps, images, and data files, including accessing the most recent available data. The tutorial concludes by showing how ERDDAP URLs can be generated and used within scripts to automate data downloads and integrate ERDDAP directly into analysis workflows.\n\n      \n        \n          \n            \n              \n            \n            Sea surface temperature map for the Washington coast generated by directly editing an ERDDAP request URL. The spatial extent and date were modified in the URL to retrieve SST for July 15, 2015, and the output was returned as a PNG image using the KT_thermal color palette.\n          \n        \n          \n            \n              \n            \n            Sea surface temperature map generated after updating the time component of the ERDDAP URL to request data from one month earlier (June 15, 2015).\n          \n        ◀1 / 2▶\n        View tutorial\n      \n\n      Close\n    \n    \n    \n      ERDDAP Basics - Creating a Hovmoller plot\n      This tutorial uses ERDDAP to examine the North Pacific marine heatwave known as the Blob by visualizing sea surface temperature and temperature anomalies over space and time. You will learn how to generate maps, extract time series at a specific location, and create Hovmöller diagrams to track the evolution and movement of the heatwave. The exercise demonstrates how ERDDAP can be used to explore long-term ocean variability using reproducible, URL-based workflows.\n\n      \n        \n          \n            \n              \n            \n            Hovmöller diagram of monthly sea surface temperature anomalies from the MUR SST anomaly dataset, plotted along 45°N across the North Pacific from 2013 to 2018. The diagram shows the eastward progression and intensification of the marine heatwave known as the Blob, with sustained positive temperature anomalies peaking between 2014 and 2016.\n          \n        \n        View tutorial\n      \n\n      Close\n    \n    \n    \n      ERDDAP Basics - Work with wind vectors\n      This tutorial demonstrates how ERDDAP can be used to visualize and analyze hurricane events using satellite-derived ocean surface winds from the ASCAT instruments. You will learn how to map both scalar wind speed and vector wind fields to identify storm structure, intensity, and circulation patterns during Hurricane Jose in September 2017. The exercise highlights ERDDAP’s ability to work with gridded wind data for mapping, vector visualization, and time-evolving analysis of extreme weather events.\n\n      \n        \n          \n            \n              \n            \n             Map of ocean surface wind speed derived from ASCAT scatterometer data on September 19, 2017, during Hurricane Jose. Scalar wind speed highlights the storm’s intensity, with the highest winds surrounding the eye as the hurricane weakened off the U.S. East Coast.\n          \n        \n          \n            \n              \n            \n            Vector map of ASCAT-derived ocean surface winds on September 19, 2017, showing both wind speed and direction. The arrows illustrate the counterclockwise circulation associated with Hurricane Jose, with arrow length proportional to wind speed.\n          \n        ◀1 / 2▶\n        View tutorial\n      \n\n      Close\n    \n    \n    \n      ERDDAP Basics - Using tabular data\n      This tutorial introduces ERDDAP tabular datasets using Biogeochemical-Argo (BGC-Argo) float data hosted on the PolarWatch ERDDAP server. You will learn how to subset observations using constraints, filter data by quality flags and regions, and visualize float locations, trajectories, and depth profiles. The exercise highlights how ERDDAP supports interactive exploration of in-situ oceanographic data alongside gridded satellite products.\n\n      \n        \n          \n            \n              \n            \n            Map of Biogeochemical-Argo float locations in the Antarctic region, colored by surface pCO₂ values from the near-real-time SOCCOM BGC-Argo dataset. The floats were subset using ERDDAP tabular constraints for time, region, variable availability, and quality-controlled pCO₂ measurements.\n          \n        \n          \n            \n              \n            \n            Depth–time section of nitrate concentration for a single Biogeochemical-Argo float, visualized using ERDDAP’s tabular plotting tools. The section shows the vertical structure and temporal evolution of nitrate from the surface to depth, demonstrating how ERDDAP can be used to explore in-situ profile data over time.\n          \n        ◀1 / 2▶\n        View tutorial\n      \n\n      Close\n    \n    \n    \n      ERDDAP Basics - Additional Resources\n      This page provides links to supplemental training materials and courses offered through NOAA CoastWatch and its regional nodes. Resources include R-based exercises from the NOAA CoastWatch West Coast Node that demonstrate how to extract and analyze ERDDAP data for applied fisheries and oceanographic research. Also included are CoastWatch satellite data courses designed to help scientists and managers incorporate satellite products into their operational workflows.\n\n      \n        \n          \n            \n              \n            \n            The CoastWatch R Exercises Website for the NOAA Satellite Course.\n          \n        \n        View tutorial\n      \n\n      Close\n    \n    \n    \n      Setting up a Python environment\n      This tutorial walks you through setting up and testing a Python environment for use with the CoastWatch Satellite Course. You will learn how to install Python and Conda, create a dedicated coastwatch Conda environment using a provided configuration file, and verify that all required packages are installed. The tutorial also shows how to launch JupyterLab to run and explore the course’s Python notebook tutorials\n\n      \n        \n          \n            \n              \n            \n            \n          \n        \n        View tutorial\n      \n\n      Close\n    \n    \n    \n      Troubleshooting rerrdapXtracto\n      This page walks through the most common errors encountered when using the rerddapXtracto R package and explains how to interpret and resolve them. Using real error messages and worked examples, it covers issues such as missing datasets, parameter name changes, coordinate and dimension mismatches, out-of-bounds requests, NA values, and oversized data queries. The goal is to help users quickly diagnose problems, understand what the error messages are telling them, and adjust their ERDDAP requests with confidence.\n\n      \n        \n          \n            \n              \n            \n            \n          \n        \n        View tutorial\n      \n\n      Close\n    \n    \n    \n      NetCDF and Panoply Tutorial\n      This tutorial introduces the NetCDF data format and demonstrates how to explore, visualize, and interpret multidimensional satellite datasets using NASA’s Panoply viewer. It explains the structure and metadata of NetCDF files and walks through hands-on examples for mapping chlorophyll, sea surface temperature, and wind speed, including adjusting color scales, projections, and time steps. The tutorial is designed to help users become comfortable opening NetCDF files, understanding their contents, and creating publication-ready visualizations without writing code.\n\n      \n        \n          \n            \n              \n            \n            Global map of chlorophyll-a concentration using the default algorithm, shown with a linear color scale and latitude–longitude gridlines.\n          \n        \n          \n            \n              \n            \n            Global map of VIIRS SNPP chlorophyll-a concentration for March 2021, visualized in NASA Panoply using a Mollweide projection.\n          \n        ◀1 / 2▶\n        View tutorial\n      \n\n      Close\n    \n    \n    \n      CoastWatch Utilities\n      This online course provides comprehensive training on the CoastWatch Utilities software package for processing and analyzing satellite imagery and derived oceanographic data. Through a series of self-paced units, the course covers both graphical and command-line workflows for inspecting data files, visualizing variables, extracting statistics, creating composites, and automating data processing—no programming experience required. The material includes hands-on exercises, sample datasets, quizzes, and assignments, making it a complete resource for learning how to work efficiently with CoastWatch NetCDF and HDF data products across Windows, Mac, and Linux systems.\n\n      \n        \n          \n            \n              \n            \n            \n          \n        \n        View tutorial\n      \n\n      Close\n    \n\n\n\n\n✕",
    "crumbs": [
      "Training Tutorials",
      "Software Tutorials",
      "Software Code Gallery"
    ]
  },
  {
    "objectID": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html",
    "href": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html",
    "title": "Subset and extract ims data",
    "section": "",
    "text": "Updated September 2024\n\n\n\n\nDownload sea ice satellite data from the PolarWatch ERDDAP data server\nImport geographical features of Lake Iliamna from a shapefile\nTransform data from one projection to another\nSubset the satellite data for Lake Iliamna\nVisualize data in different projection\n\n\n\n\nWorld Lake shape data\nThe world lake shapefile can be downloaded from ArcGIS Hub at https://hub.arcgis.com, and is also available in the resource/ directory of this tutorial folder. The file includes geographical features of all world lakes. For this exercise, only the features of Lake Illemna will be used.\nIMS Snow and Ice Analysis, Arctic, 4km, 2004 - Present, Daily (PolarWatch Preview)\nThe IMS dataset includes daily snow and ice coverage data for the Arctic with a 4-km resolution, available starting from 2004. The values in the dataset are categorical, representing five categories: 0 for areas outside the coverage zone, 1 for open water, 2 for land without snow, 3 for sea ice or lake ice, and 4 for snow-covered land. Data with a 1-km resolution are also available. Please contact us for more information.\n\n\n\nknitr::opts_chunk$set(\n  echo = TRUE,\n  fig.path = \"images/\",\n  warning = FALSE, message = FALSE\n)\n# Function to check if pkgs are installed, install missing pkgs, and load\n\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"sp\", \"ggplot2\" , \"rerddap\", \"RColorBrewer\", \"scales\", \"reshape2\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\nlibrary(terra)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(rerddap)"
  },
  {
    "objectID": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html#subset-data-in-polar-stereographic-projection-using-a-shape-file-fr",
    "href": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html#subset-data-in-polar-stereographic-projection-using-a-shape-file-fr",
    "title": "Subset and extract ims data",
    "section": "",
    "text": "Updated September 2024\n\n\n\n\nDownload sea ice satellite data from the PolarWatch ERDDAP data server\nImport geographical features of Lake Iliamna from a shapefile\nTransform data from one projection to another\nSubset the satellite data for Lake Iliamna\nVisualize data in different projection\n\n\n\n\nWorld Lake shape data\nThe world lake shapefile can be downloaded from ArcGIS Hub at https://hub.arcgis.com, and is also available in the resource/ directory of this tutorial folder. The file includes geographical features of all world lakes. For this exercise, only the features of Lake Illemna will be used.\nIMS Snow and Ice Analysis, Arctic, 4km, 2004 - Present, Daily (PolarWatch Preview)\nThe IMS dataset includes daily snow and ice coverage data for the Arctic with a 4-km resolution, available starting from 2004. The values in the dataset are categorical, representing five categories: 0 for areas outside the coverage zone, 1 for open water, 2 for land without snow, 3 for sea ice or lake ice, and 4 for snow-covered land. Data with a 1-km resolution are also available. Please contact us for more information.\n\n\n\nknitr::opts_chunk$set(\n  echo = TRUE,\n  fig.path = \"images/\",\n  warning = FALSE, message = FALSE\n)\n# Function to check if pkgs are installed, install missing pkgs, and load\n\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"sp\", \"ggplot2\" , \"rerddap\", \"RColorBrewer\", \"scales\", \"reshape2\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\nlibrary(terra)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(rerddap)"
  },
  {
    "objectID": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html#load-ims-sea-ice-data-from-erddap",
    "href": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html#load-ims-sea-ice-data-from-erddap",
    "title": "Subset and extract ims data",
    "section": "Load IMS Sea ice data from ERDDAP",
    "text": "Load IMS Sea ice data from ERDDAP\n\npw_url = \"https://polarwatch.noaa.gov/erddap/\"\ndataset_id = \"usnic_ims_4km\"\nvar_name = \"IMS_Surface_Values\"\ndat_info &lt;- info(datasetid = dataset_id, url = pw_url)\ndat_info"
  },
  {
    "objectID": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html#convert-ims-data-to-raster-s4-object",
    "href": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html#convert-ims-data-to-raster-s4-object",
    "title": "Subset and extract ims data",
    "section": "Convert IMS data to raster S4 object",
    "text": "Convert IMS data to raster S4 object\n\n# ensure numeric (rerddap often returns list columns)\nims$x &lt;- as.numeric(unlist(ims$x))\nims$y &lt;- as.numeric(unlist(ims$y))\nims[[var_name]] &lt;- as.numeric(unlist(ims[[var_name]]))\n\n# create raster from xyz explicitly\nims_ras &lt;- terra::rast(ims[, c(\"x\", \"y\", var_name)], type = \"xyz\")\n\n# IMS 4km grid is Polar Stereographic (proj4 from NSIDC IMS user guide)\nims_proj4 &lt;- \"+proj=stere +lat_0=90 +lat_ts=60 +lon_0=-80 +k=1 +x_0=0 +y_0=0 +a=6378137 +b=6356257 +units=m +no_defs\"\nterra::crs(ims_ras) &lt;- ims_proj4\n\n\n# get CRS as an sf object for st_transform\ndata_crs &lt;- sf::st_crs(\"EPSG:3857\")\n# plot the raster data\nplot(ims_ras)"
  },
  {
    "objectID": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html#convert-the-lake-shape-to-raster-s4-object",
    "href": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html#convert-the-lake-shape-to-raster-s4-object",
    "title": "Subset and extract ims data",
    "section": "Convert the lake shape to raster S4 object",
    "text": "Convert the lake shape to raster S4 object\n\nshapes_polar &lt;- sf::st_transform(lake_shp, sf::st_crs(ims_proj4))\nlake_ras &lt;- terra::vect(shapes_polar)\nplot(lake_ras, border = \"red\")"
  },
  {
    "objectID": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html#crop-the-ims-data",
    "href": "tutorials/subset-polar-data-with-shapefile/r/subset-polar-data-with-shapefile.html#crop-the-ims-data",
    "title": "Subset and extract ims data",
    "section": "Crop the IMS data",
    "text": "Crop the IMS data\n\n# crop to the bounding box of the lake\ncropped_lake &lt;- crop(ims_ras, lake_ras)\n\n# mask data with the lake shape\nmasked_lake &lt;- mask(cropped_lake, lake_ras)\nplot(masked_lake)"
  },
  {
    "objectID": "tutorials/troubleshooting-rerddapXtracto/troubleshooting-rerddapXtracto.html",
    "href": "tutorials/troubleshooting-rerddapXtracto/troubleshooting-rerddapXtracto.html",
    "title": "Troubleshooting rerddapXtracto",
    "section": "",
    "text": "Unlike most R error messages, the error messages given out by the functions in the rerddapXtracto package actually ARE helpful (Thank you Roy!). Here are the most common errors encountered when using these functions:\n\nDataset not found\n\nChanges in the parameter name\n\nCalling, or not calling, the altitude dimension\nCoordinates out of bounds\nNAs in passed variables\nerror in the url call, perhaps a time out\nCoordinate name mismatch (actually not a common error!)\n\nBelow each of these errors is explained in more detail, showing examples of the resulting error messages.\n\n\nThe rerddapXtracto package uses the info function in the rerddap package to obtain the basic metadata about a dataset. The default erddap used by rerddap::info is https://upwell.pfeg.noaa.gov/erddap/. If the dataset ID passed to rerddap::info is not on this erddap then an error will be given as in the example below.\ndataInfo &lt;- rerddap::info('hawaii_soest_5687_3d16_a6d4')\nError: 'Error {\n    code=404;\n    message=\"Not Found: Currently unknown datasetID=hawaii_soest_5687_3d16_a6d4\";\n}\ndoes not exist in current working directory (‘C:/Users/CaraWilson/Documents’).\nTo fix this error identify the url of the erddap with this dataset in the call.\ndataInfo &lt;- rerddap::info('hawaii_soest_5687_3d16_a6d4',\n                      url='https://oceanwatch.pifsc.noaa.gov/erddap/')\nThis error can also arise if you have a typo in the datasetID, so make sure that is not the case. Occasionally ERDDAP servers are restarted and when this happens it can take a few hours for the datasets to all get reloaded. When this is happening you will also encounter this error. If you are sure you are pointing to the correct ERDDAP, and there are no typos in the call, wait a few hours and see if the error gets resolved.\n\n\n\nThere are multiple variations of variable names for chlorophyll (chl, chla, chlor_a, etc,) and temperature (sst, sea_surface_temperature, CRW_SST, etc.) among the most commonly used datasets, so if you change datasets you will probably also have to change the parameter name.\nBelow is an example of making a call with an erroneous parameter name. Here the parameter name is passed as “chl’”, but the actual parameter name for this dataset is “chla”. As seen below this information is clearly given in the error message:\ndataInfo &lt;- rerddap::info('erdVHNchlamday')\nparameter &lt;- 'chl'\nchlVIIRS &lt; -rxtracto_3D(dataInfo, parameter=parameter,\ntcoord=c(\"2021-01-15\",”2021-03-15”),\nxcoord=c(-170,-160),\n                ycoord=c(10,20),\n                zcoord=c(0,0))\nParameter given is not in dataset\nParameter given:  chl\nDataset Parameters:  chla\n\n[1] \"Execution halted\"\nSo to fix this error, rerun the command after redefining the parameter name as parameter &lt;- ’chla’. The metadata returned by the rerddap info call, which is read into the dataInfo variable in the CoastWatch scripts, lists all the parameter names. You can also directly extract this information out of the dataInfo variable:\nparameter &lt;- dataInfo$variable$variable_name\nKeep in mind that if the chosen dataset has more than one variable the line above would have to be amended.\n\n\n\nSome datasets have an altitude dimension, although most do not. If the dataset has an altitude dimension it must be given in the call (even though one usually just passes an empty vector). If the requested dataset does not have altitude then it must not be passed in the request.\nIn the example below a call is made which didn’t pass the altitude dimension, but the dataset being used has this dimension, causing an error:\ndataInfo &lt;- rerddap::info('erdVHNchlamday')\nparameter &lt;- 'chla'\nchlVIIRS&lt;-rxtracto_3D(dataInfo,parameter=parameter,\ntcoord=c(\"2021-01-15\",2021-03-15”),\nxcoord=c(-170,-160),\n                ycoord=c(10,20))\n\n[1] \"Ranges not given for all of the dataset dimensions\"\n[1] \"Coordinates given: \"\n[1] \"longitude\"  \"latitude\"  \"time\"     \n[1] \"Dataset Coordinates: \"\n[1] \"time\"   \"altitude\"  \"latitude\"  \"longitude\"\n[1] \"Execution halted\"\nTo fix this error add “zcoord=c(0,0)” to the call. If you are using a dataset with an altitude dimension the data returned will be in 4 dimensions, as can be seen in this example:\n&gt; dim(chlVIIRS$chla)\n[1] 1334 1334    1    3\nThe CoastWatch scripts are set up to work with returned data with only 3 dimensions. So the extraneous 4th dimension should be dropped:\n&gt; chlVIIRS$chla &lt;- drop(chlVIIRS$chla)\n&gt; dim(chlVIIRS$chla)\n[1] 1334 1334    3\nIn the example below a call is made which passes the altitude dimension, but the dataset being used doesn’t have this dimension, causing an error:\ndataInfo &lt;- rerddap::info('erdMH1chlamday')\nparameter &lt;- dataInfo$variable$variable_name\nchlMODIS &lt;- rxtracto_3D(dataInfo,parameter=parameter,\n                      tcoord=c(\"2021-01-15\",\"2021-03-15\"),\n                      xcoord=c(-170,-160),\n                      ycoord=c(10,20),\n                      zcoord=c(0,0))\n\n\n[1] \"Requested coordinate names do no match dataset coordinate names\"\n[1] \"Requested coordinate names: longitude\"\n[2] \"Requested coordinate names: latitude\" \n[3] \"Requested coordinate names: altitude\" \n[4] \"Requested coordinate names: time\"     \n[1] \"Dataset coordinate names: time\"     \n[2] \"Dataset coordinate names: latitude\" \n[3] \"Dataset coordinate names: longitude\"\nTo fix this error remove the “zcoord=c(0,0)” from the call.\n\n\n\nAsking for dates outside of the timespan of a dataset is the most common example of the ‘coordinates out of bounds’ error, but it can also happen for latitude and longitude if you are not using a global dataset. The example below requests satellite data for times that are not within the temporal span of the satellite dataset. The error message says there is a problem with the bounds of the time dimension, and lists the bounds requested, and the bounds of the dataset. Data was requested for Feb 2015 but the dataset only starts in March 2015.\ndataInfo &lt;- rerddap::info('erdVHNchlamday')\nchlVIIRS&lt;-rxtracto_3D(dataInfo, parameter='chla',\n                      tcoord=c(\"2015-02-15\",\"2016-04-15\"),\n                      xcoord=c(-170,-160),\n                      ycoord=c(10,20),zcoord=c(0,0))\n[1] \"dimension name: time\"\n[1] \"given coordinate bounds 2015-02-15 2016-04-15\"\n[1] \"ERDDAP datasets bounds 2015-03-16 2021-12-16 12:00:00\"\n[1] \"Coordinates out of dataset bounds - see messages above\"\nTo fix this problem change the time request so that it is within the bounds of the satellite dataset. Remember, you can always determine the bounds by looking at the dataset metadata returned from the rerddap info call (contained in the variable dataInfo in the Coastwatch scripts). You can also encounter this error if you forget to put quotes around the dates that are passed to tcoord.\n\n\n\nIf there are any NAs in the passed vectors of latitude, longitude or time then the functions will fail. This error will occur most often when using the rxtracto function. Here’s an example.\ndataInfo &lt;- rerddap::info('erdMH1chla1day')\nparameter &lt;- dataInfo$variable$variable_name\nMake up some data with a missing datapoint:\n&gt; lon &lt;- c(-180, -170, -160, -150, -140, NA, -130, -120)\n&gt; lat &lt;- c(31, 31.2, 33.2, 34, 33, 34, 32, 31)\n&gt; time &lt;- rep(\"2020-09-13\", length(lon)) \n\n&gt; tagchl &lt;- rxtracto(dataInfo, parameter=parameter,\n                  xcoord=lon, ycoord=lat,\n                  tcoord=time, xlen=.1, ylen=.1)\nError in if ((temp_coord1 &lt; 180) && (temp_coord2 &gt; 180)) { :            0s\n  missing value where TRUE/FALSE needed\nThis error is a little more obscure than the others we have been seeing but it is saying that one of the coordinate values is outside of the bounds. Given that the valid bound is listed as 180, we can assume this is an error with the longitude dimension. With our made-up dataset of only 8 points, it is obvious that the problem is with a longitude value, but if you are reading in a dataset with 1000s of points it might not be so easy to determine where the bad points are. The easiest way to deal with this is to consolidate the variables together in a dataframe and omit any NA values.\n&gt; tagdata &lt;- data.frame(lon=lon, lat=lat, time=time)\n&gt; good_tagdata &lt;- na.omit(tagdata)\nThen run the extraction with the dataset without any NA values.\n&gt; tagchl &lt;- rxtracto(dataInfo, parameter=parameter,\n                  xcoord=good_tagdata$lon, ycoord=good_tagdata$lat,\n                  tcoord=good_tagdata$time, xlen=.1, ylen=.1)\nAnother common error that can occur when running rxtracto is requesting data for time values that are not within the dataset bounds (see error example #4). In this case you would want to subset your data to remove any points not within the temporal span of the dataset being used.\n\n\n\nThis example is a little harder to troubleshoot. Here’s an example trying to request a 3D block of MUR SST data.\n&gt; dataInfo &lt;- rerddap::info('erdMH1chla1day')\n&gt; parameter &lt;- dataInfo$variable$variable_name\n\n&gt; sstMUR&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=c(\"2002-06-02\",\"last\"),\n                     xcoord=c(-140,-130),\n                     ycoord=c(50,60))\n 0s 0s[1] \"error in trying to download the subset\"                                                                    \n[1] \"check your settings\"\n$x\n&lt;ERDDAP info&gt; jplMURSST41 \n Base URL: https://upwell.pfeg.noaa.gov/erddap \n Dataset Type: griddap \n Dimensions (range):  \n     time: (2002-06-01T09:00:00Z, 2022-01-30T09:00:00Z) \n     latitude: (-89.99, 89.99) \n     longitude: (-179.99, 180.0) \n Variables:  \n     analysed_sst: \n         Units: degree_C \n     analysis_error: \n         Units: degree_C \n     mask: \n     sea_ice_fraction: \n         Units: 1 \n\n$longitude\n[1] -140 -130\n\n$latitude\n[1] 50 60\n\n$time\n[1] \"2002-06-02T09:00:00Z\" \"2022-01-30T09:00:00Z\"\n\n$fields\n[1] \"analysed_sst\"\n\n$read\n[1] FALSE\n\n[1] \"stopping execution  - will return what has been downloaded so far\"\n[1] \"There was an error in the url call, perhaps a time out. See message on screen and URL called\"\n\nThe error message here is less specific.  It has returned the coordinates which were requested and the dimensions of the dataset and they seem consistent.  We can get more information by redoing the call with the verbose option on, by adding “verbose=TRUE” in the command.  \n\n&gt; sstMUR&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=c(\"2002-06-02\",\"last\"),\n                     xcoord=c(-140,-130),\n                     ycoord=c(50,60), verbose=T)\nThe final part of the error message will look the same, but scroll up to the start of the error message and you can find the exact url that was executed by this command, in this case it is:\n&gt; GET /erddap/griddap/jplMURSST41.nc?analysed_sst[(2002-06-02T09:00:00Z):1:(2022-01-30T09:00:00Z)][(50):1:(60)][(-140):1:(-130)] HTTP/1.1\nHost: upwell.pfeg.noaa.gov\nGenerate the full url by appending the host url to the start of the data request, ie:\nupwell.pfeg.noaa.gov/erddap/griddap/jplMURSST41.nc?analysed_sst[(2002-06-02T09:00:00Z):1:(2022-01-30T09:00:00Z)][(50):1:(60)][(-140):1:(-130)]\nPaste that url into an internet browser window. By doing this you are directly asking ERDDAP the same data request made by that call. Doing so returns the following error from ERDDAP:\nError {\n    code=413;\n    message=\"Payload Too Large: Your query produced too much data.  Try to request less data. [memory]  54896 MB is more than the .nc 2 GB limit.\";\n}\nSo the problem is that this request is asking for way too much data! This is a common error when using the MUR dataset. The spatial resolution of this dataset is 1 km, one of the highest resolution datasets that we serve. In this case the request is asking for the entire dataset, 20 years of data, at a daily resolution, for a 10 x 10 degree box. This is a lot of data! There are multiple ways to address this error:\n\nRethink what temporal resolution is needed. Daily data is overkill when looking for trends or anomalies in 20 years of data, and the monthly dataset would be a much more appropriate choice to use. Using a monthly dataset instead would reduce the data request by more than an order of magnitude.\n\nIs a 1 km resolution dataset really needed for this exercise, or could a dataset with a coarser resolution be adequate?\nIf a data request larger than the 2 GB limit is truly necessary, split the data request into smaller chunks, and then stitch the data back together in R. Ie, get data one year at a time.\n\n\n\n\nThis error is actually quite rare. Some datasets have an altitude dimension that is not called altitude, which is the default name for this dimension. In this case the name of the altitude dimension has to be defined by using the zName parameter in the function call. If that isn’t done the error message looks like this:\n&gt; dataInfo &lt;- rerddap::info('ncdcOisst21Agg')\n&gt; sst &lt;-rxtracto_3D(dataInfo, parameter='sst',\n+                       tcoord=c(\"2021-01-15\",\"2021-03-15\"),\n+                       xcoord=c(170,160),\n+                       ycoord=c(10,20),\n+                       zcoord=c(0,0))\n[1] \"Requested coordinate names do no match dataset coordinate names\"\n[1] \"Requested coordinate names: longitude\"\n[2] \"Requested coordinate names: latitude\" \n[3] \"Requested coordinate names: altitude\" \n[4] \"Requested coordinate names: time\"     \n[1] \"Dataset coordinate names: time\"     \n[2] \"Dataset coordinate names: zlev\"     \n[3] \"Dataset coordinate names: latitude\" \n[4] \"Dataset coordinate names: longitude\"\nThe error message lists the coordinate names of the datasets and the names of the requested coordinate and there is a mismatch for one of them. The dataset has a coordinate of ‘zlev’ but the coordinate name requested was ‘altitude’, which is the default name for this dimension. Inserting \"zName = 'zlev'\" in the rxtracto_3D call will eliminate this error."
  },
  {
    "objectID": "tutorials/troubleshooting-rerddapXtracto/troubleshooting-rerddapXtracto.html#help-im-getting-an-error-using-a-function-in-rerddapxtracto",
    "href": "tutorials/troubleshooting-rerddapXtracto/troubleshooting-rerddapXtracto.html#help-im-getting-an-error-using-a-function-in-rerddapxtracto",
    "title": "Troubleshooting rerddapXtracto",
    "section": "",
    "text": "Unlike most R error messages, the error messages given out by the functions in the rerddapXtracto package actually ARE helpful (Thank you Roy!). Here are the most common errors encountered when using these functions:\n\nDataset not found\n\nChanges in the parameter name\n\nCalling, or not calling, the altitude dimension\nCoordinates out of bounds\nNAs in passed variables\nerror in the url call, perhaps a time out\nCoordinate name mismatch (actually not a common error!)\n\nBelow each of these errors is explained in more detail, showing examples of the resulting error messages.\n\n\nThe rerddapXtracto package uses the info function in the rerddap package to obtain the basic metadata about a dataset. The default erddap used by rerddap::info is https://upwell.pfeg.noaa.gov/erddap/. If the dataset ID passed to rerddap::info is not on this erddap then an error will be given as in the example below.\ndataInfo &lt;- rerddap::info('hawaii_soest_5687_3d16_a6d4')\nError: 'Error {\n    code=404;\n    message=\"Not Found: Currently unknown datasetID=hawaii_soest_5687_3d16_a6d4\";\n}\ndoes not exist in current working directory (‘C:/Users/CaraWilson/Documents’).\nTo fix this error identify the url of the erddap with this dataset in the call.\ndataInfo &lt;- rerddap::info('hawaii_soest_5687_3d16_a6d4',\n                      url='https://oceanwatch.pifsc.noaa.gov/erddap/')\nThis error can also arise if you have a typo in the datasetID, so make sure that is not the case. Occasionally ERDDAP servers are restarted and when this happens it can take a few hours for the datasets to all get reloaded. When this is happening you will also encounter this error. If you are sure you are pointing to the correct ERDDAP, and there are no typos in the call, wait a few hours and see if the error gets resolved.\n\n\n\nThere are multiple variations of variable names for chlorophyll (chl, chla, chlor_a, etc,) and temperature (sst, sea_surface_temperature, CRW_SST, etc.) among the most commonly used datasets, so if you change datasets you will probably also have to change the parameter name.\nBelow is an example of making a call with an erroneous parameter name. Here the parameter name is passed as “chl’”, but the actual parameter name for this dataset is “chla”. As seen below this information is clearly given in the error message:\ndataInfo &lt;- rerddap::info('erdVHNchlamday')\nparameter &lt;- 'chl'\nchlVIIRS &lt; -rxtracto_3D(dataInfo, parameter=parameter,\ntcoord=c(\"2021-01-15\",”2021-03-15”),\nxcoord=c(-170,-160),\n                ycoord=c(10,20),\n                zcoord=c(0,0))\nParameter given is not in dataset\nParameter given:  chl\nDataset Parameters:  chla\n\n[1] \"Execution halted\"\nSo to fix this error, rerun the command after redefining the parameter name as parameter &lt;- ’chla’. The metadata returned by the rerddap info call, which is read into the dataInfo variable in the CoastWatch scripts, lists all the parameter names. You can also directly extract this information out of the dataInfo variable:\nparameter &lt;- dataInfo$variable$variable_name\nKeep in mind that if the chosen dataset has more than one variable the line above would have to be amended.\n\n\n\nSome datasets have an altitude dimension, although most do not. If the dataset has an altitude dimension it must be given in the call (even though one usually just passes an empty vector). If the requested dataset does not have altitude then it must not be passed in the request.\nIn the example below a call is made which didn’t pass the altitude dimension, but the dataset being used has this dimension, causing an error:\ndataInfo &lt;- rerddap::info('erdVHNchlamday')\nparameter &lt;- 'chla'\nchlVIIRS&lt;-rxtracto_3D(dataInfo,parameter=parameter,\ntcoord=c(\"2021-01-15\",2021-03-15”),\nxcoord=c(-170,-160),\n                ycoord=c(10,20))\n\n[1] \"Ranges not given for all of the dataset dimensions\"\n[1] \"Coordinates given: \"\n[1] \"longitude\"  \"latitude\"  \"time\"     \n[1] \"Dataset Coordinates: \"\n[1] \"time\"   \"altitude\"  \"latitude\"  \"longitude\"\n[1] \"Execution halted\"\nTo fix this error add “zcoord=c(0,0)” to the call. If you are using a dataset with an altitude dimension the data returned will be in 4 dimensions, as can be seen in this example:\n&gt; dim(chlVIIRS$chla)\n[1] 1334 1334    1    3\nThe CoastWatch scripts are set up to work with returned data with only 3 dimensions. So the extraneous 4th dimension should be dropped:\n&gt; chlVIIRS$chla &lt;- drop(chlVIIRS$chla)\n&gt; dim(chlVIIRS$chla)\n[1] 1334 1334    3\nIn the example below a call is made which passes the altitude dimension, but the dataset being used doesn’t have this dimension, causing an error:\ndataInfo &lt;- rerddap::info('erdMH1chlamday')\nparameter &lt;- dataInfo$variable$variable_name\nchlMODIS &lt;- rxtracto_3D(dataInfo,parameter=parameter,\n                      tcoord=c(\"2021-01-15\",\"2021-03-15\"),\n                      xcoord=c(-170,-160),\n                      ycoord=c(10,20),\n                      zcoord=c(0,0))\n\n\n[1] \"Requested coordinate names do no match dataset coordinate names\"\n[1] \"Requested coordinate names: longitude\"\n[2] \"Requested coordinate names: latitude\" \n[3] \"Requested coordinate names: altitude\" \n[4] \"Requested coordinate names: time\"     \n[1] \"Dataset coordinate names: time\"     \n[2] \"Dataset coordinate names: latitude\" \n[3] \"Dataset coordinate names: longitude\"\nTo fix this error remove the “zcoord=c(0,0)” from the call.\n\n\n\nAsking for dates outside of the timespan of a dataset is the most common example of the ‘coordinates out of bounds’ error, but it can also happen for latitude and longitude if you are not using a global dataset. The example below requests satellite data for times that are not within the temporal span of the satellite dataset. The error message says there is a problem with the bounds of the time dimension, and lists the bounds requested, and the bounds of the dataset. Data was requested for Feb 2015 but the dataset only starts in March 2015.\ndataInfo &lt;- rerddap::info('erdVHNchlamday')\nchlVIIRS&lt;-rxtracto_3D(dataInfo, parameter='chla',\n                      tcoord=c(\"2015-02-15\",\"2016-04-15\"),\n                      xcoord=c(-170,-160),\n                      ycoord=c(10,20),zcoord=c(0,0))\n[1] \"dimension name: time\"\n[1] \"given coordinate bounds 2015-02-15 2016-04-15\"\n[1] \"ERDDAP datasets bounds 2015-03-16 2021-12-16 12:00:00\"\n[1] \"Coordinates out of dataset bounds - see messages above\"\nTo fix this problem change the time request so that it is within the bounds of the satellite dataset. Remember, you can always determine the bounds by looking at the dataset metadata returned from the rerddap info call (contained in the variable dataInfo in the Coastwatch scripts). You can also encounter this error if you forget to put quotes around the dates that are passed to tcoord.\n\n\n\nIf there are any NAs in the passed vectors of latitude, longitude or time then the functions will fail. This error will occur most often when using the rxtracto function. Here’s an example.\ndataInfo &lt;- rerddap::info('erdMH1chla1day')\nparameter &lt;- dataInfo$variable$variable_name\nMake up some data with a missing datapoint:\n&gt; lon &lt;- c(-180, -170, -160, -150, -140, NA, -130, -120)\n&gt; lat &lt;- c(31, 31.2, 33.2, 34, 33, 34, 32, 31)\n&gt; time &lt;- rep(\"2020-09-13\", length(lon)) \n\n&gt; tagchl &lt;- rxtracto(dataInfo, parameter=parameter,\n                  xcoord=lon, ycoord=lat,\n                  tcoord=time, xlen=.1, ylen=.1)\nError in if ((temp_coord1 &lt; 180) && (temp_coord2 &gt; 180)) { :            0s\n  missing value where TRUE/FALSE needed\nThis error is a little more obscure than the others we have been seeing but it is saying that one of the coordinate values is outside of the bounds. Given that the valid bound is listed as 180, we can assume this is an error with the longitude dimension. With our made-up dataset of only 8 points, it is obvious that the problem is with a longitude value, but if you are reading in a dataset with 1000s of points it might not be so easy to determine where the bad points are. The easiest way to deal with this is to consolidate the variables together in a dataframe and omit any NA values.\n&gt; tagdata &lt;- data.frame(lon=lon, lat=lat, time=time)\n&gt; good_tagdata &lt;- na.omit(tagdata)\nThen run the extraction with the dataset without any NA values.\n&gt; tagchl &lt;- rxtracto(dataInfo, parameter=parameter,\n                  xcoord=good_tagdata$lon, ycoord=good_tagdata$lat,\n                  tcoord=good_tagdata$time, xlen=.1, ylen=.1)\nAnother common error that can occur when running rxtracto is requesting data for time values that are not within the dataset bounds (see error example #4). In this case you would want to subset your data to remove any points not within the temporal span of the dataset being used.\n\n\n\nThis example is a little harder to troubleshoot. Here’s an example trying to request a 3D block of MUR SST data.\n&gt; dataInfo &lt;- rerddap::info('erdMH1chla1day')\n&gt; parameter &lt;- dataInfo$variable$variable_name\n\n&gt; sstMUR&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=c(\"2002-06-02\",\"last\"),\n                     xcoord=c(-140,-130),\n                     ycoord=c(50,60))\n 0s 0s[1] \"error in trying to download the subset\"                                                                    \n[1] \"check your settings\"\n$x\n&lt;ERDDAP info&gt; jplMURSST41 \n Base URL: https://upwell.pfeg.noaa.gov/erddap \n Dataset Type: griddap \n Dimensions (range):  \n     time: (2002-06-01T09:00:00Z, 2022-01-30T09:00:00Z) \n     latitude: (-89.99, 89.99) \n     longitude: (-179.99, 180.0) \n Variables:  \n     analysed_sst: \n         Units: degree_C \n     analysis_error: \n         Units: degree_C \n     mask: \n     sea_ice_fraction: \n         Units: 1 \n\n$longitude\n[1] -140 -130\n\n$latitude\n[1] 50 60\n\n$time\n[1] \"2002-06-02T09:00:00Z\" \"2022-01-30T09:00:00Z\"\n\n$fields\n[1] \"analysed_sst\"\n\n$read\n[1] FALSE\n\n[1] \"stopping execution  - will return what has been downloaded so far\"\n[1] \"There was an error in the url call, perhaps a time out. See message on screen and URL called\"\n\nThe error message here is less specific.  It has returned the coordinates which were requested and the dimensions of the dataset and they seem consistent.  We can get more information by redoing the call with the verbose option on, by adding “verbose=TRUE” in the command.  \n\n&gt; sstMUR&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=c(\"2002-06-02\",\"last\"),\n                     xcoord=c(-140,-130),\n                     ycoord=c(50,60), verbose=T)\nThe final part of the error message will look the same, but scroll up to the start of the error message and you can find the exact url that was executed by this command, in this case it is:\n&gt; GET /erddap/griddap/jplMURSST41.nc?analysed_sst[(2002-06-02T09:00:00Z):1:(2022-01-30T09:00:00Z)][(50):1:(60)][(-140):1:(-130)] HTTP/1.1\nHost: upwell.pfeg.noaa.gov\nGenerate the full url by appending the host url to the start of the data request, ie:\nupwell.pfeg.noaa.gov/erddap/griddap/jplMURSST41.nc?analysed_sst[(2002-06-02T09:00:00Z):1:(2022-01-30T09:00:00Z)][(50):1:(60)][(-140):1:(-130)]\nPaste that url into an internet browser window. By doing this you are directly asking ERDDAP the same data request made by that call. Doing so returns the following error from ERDDAP:\nError {\n    code=413;\n    message=\"Payload Too Large: Your query produced too much data.  Try to request less data. [memory]  54896 MB is more than the .nc 2 GB limit.\";\n}\nSo the problem is that this request is asking for way too much data! This is a common error when using the MUR dataset. The spatial resolution of this dataset is 1 km, one of the highest resolution datasets that we serve. In this case the request is asking for the entire dataset, 20 years of data, at a daily resolution, for a 10 x 10 degree box. This is a lot of data! There are multiple ways to address this error:\n\nRethink what temporal resolution is needed. Daily data is overkill when looking for trends or anomalies in 20 years of data, and the monthly dataset would be a much more appropriate choice to use. Using a monthly dataset instead would reduce the data request by more than an order of magnitude.\n\nIs a 1 km resolution dataset really needed for this exercise, or could a dataset with a coarser resolution be adequate?\nIf a data request larger than the 2 GB limit is truly necessary, split the data request into smaller chunks, and then stitch the data back together in R. Ie, get data one year at a time.\n\n\n\n\nThis error is actually quite rare. Some datasets have an altitude dimension that is not called altitude, which is the default name for this dimension. In this case the name of the altitude dimension has to be defined by using the zName parameter in the function call. If that isn’t done the error message looks like this:\n&gt; dataInfo &lt;- rerddap::info('ncdcOisst21Agg')\n&gt; sst &lt;-rxtracto_3D(dataInfo, parameter='sst',\n+                       tcoord=c(\"2021-01-15\",\"2021-03-15\"),\n+                       xcoord=c(170,160),\n+                       ycoord=c(10,20),\n+                       zcoord=c(0,0))\n[1] \"Requested coordinate names do no match dataset coordinate names\"\n[1] \"Requested coordinate names: longitude\"\n[2] \"Requested coordinate names: latitude\" \n[3] \"Requested coordinate names: altitude\" \n[4] \"Requested coordinate names: time\"     \n[1] \"Dataset coordinate names: time\"     \n[2] \"Dataset coordinate names: zlev\"     \n[3] \"Dataset coordinate names: latitude\" \n[4] \"Dataset coordinate names: longitude\"\nThe error message lists the coordinate names of the datasets and the names of the requested coordinate and there is a mismatch for one of them. The dataset has a coordinate of ‘zlev’ but the coordinate name requested was ‘altitude’, which is the default name for this dimension. Inserting \"zName = 'zlev'\" in the rxtracto_3D call will eliminate this error."
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "",
    "text": "CoastWatch Python Exercises"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#background",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#background",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Background",
    "text": "Background\nSeveral ocean color sensors have been launched since 1997 to provide continuous global coverage for ocean color data. The sensors have differences in design and calibration, and different algorithms may be applied to generate chlorophyll values. Consequently, chlorophyll-a values can vary among the sensors during periods where measurements overlap.\nTo examine this phenomenon, we will download and plot a time series of chlorophyll-a concentrations from various sensors that collected data between 1997 and the present to see how the measurements compare during periods of overlap."
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#objective",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#objective",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show how to extract a time series from four different monthly satellite chlorophyll datasets for the period that each was in operation between 1997-present."
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nUsing xarray to extract data from a rectangular area of the ocean over time\nRetrieving information about a dataset from ERDDAP\nComparing results from different sensors\nAveraging data spatially\nProducing time-series plots\nDrawing maps with satellite data"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Datasets used",
    "text": "Datasets used\nSeaWiFS Chlorophyll-a, V.2018, Monthly, Global, 4km, 1997-2012\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nMODIS Aqua, Chlorophyll-a, V.2022, Monthly, Global, 4km, 2002-present\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022SQ\nNOAA VIIRS S-NPP, Chlorophyll-a, Monthly, Global, 4km, 2012-present\nhttps://coastwatch.noaa.gov/erddap/griddap/noaacwNPPVIIRSSQchlaMonthly\nESA CCI Ocean Colour Dataset, v6.0, Monthly, Global, 4km, 1997-Present\nThis dataset was developed by the European Space Agency’s Climate Change Initiative. The dataset merges data from multiple sensors (MERIS, MODIS, VIIRS and SeaWiFS) to create a long time series (1997 to present) with better spatial coverage than any single sensor. Parameters include chlorophyll a, remote sensing reflectance, diffuse attenuation coefficients, absorption coefficients, backscatter coefficients, and water classification.\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorMonthly"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#import-required-packages",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#import-required-packages",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Import required packages",
    "text": "Import required packages\n\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nFor each dataset we will extract data for an area in the Gulf of Mexico between -95 to -90°W longitude and 25-30°N latitude.\nSet up variables with the minimum and maximum values from the longitude and latitude ranges.\n\nlon_min = -95.\nlon_max = -90.\nlat_min = 25.\nlat_max = 30."
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#get-the-seawifs-data",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#get-the-seawifs-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get the SeaWiFS data",
    "text": "Get the SeaWiFS data\n\nOpen a dataset object in xarray\n\nurl_sw = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday'\nsw_ds = xr.open_dataset(url_sw)\nsw_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:      (time: 157, latitude: 2160, longitude: 4320)\nCoordinates:\n  * time         (time) datetime64[ns] 1997-09-16 1997-10-16 ... 2010-12-16\n  * latitude     (latitude) float32 89.96 89.88 89.79 ... -89.79 -89.88 -89.96\n  * longitude    (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nData variables:\n    chlorophyll  (time, latitude, longitude) float32 ...\nAttributes: (12/50)\n    _lastModified:                     2018-01-31T04:58:26.000Z\n    _NCProperties:                     version=1|netcdflibversion=4.4.1.1|hdf...\n    cdm_data_type:                     Grid\n    Conventions:                       CF-1.6, COARDS, ACDD-1.3\n    creator_email:                     data@oceancolor.gsfc.nasa.gov\n    creator_name:                      NASA/GSFC/OBPG\n    ...                                ...\n    summary:                           NASA GSFC Ocean Color Web distributes ...\n    temporal_range:                    10-day\n    time_coverage_end:                 2010-12-16T00:00:00Z\n    time_coverage_start:               1997-09-16T00:00:00Z\n    title:                             Chlorophyll-a, Orbview-2 SeaWiFS, R201...\n    Westernmost_Easting:               -179.9583xarray.DatasetDimensions:time: 157latitude: 2160longitude: 4320Coordinates: (3)time(time)datetime64[ns]1997-09-16 ... 2010-12-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000', '1998-02-16T00:00:00.000000000',\n       '1998-03-16T00:00:00.000000000', '1998-04-16T00:00:00.000000000',\n       '1998-05-16T00:00:00.000000000', '1998-06-16T00:00:00.000000000',\n       '1998-07-16T00:00:00.000000000', '1998-08-16T00:00:00.000000000',\n       '1998-09-16T00:00:00.000000000', '1998-10-16T00:00:00.000000000',\n       '1998-11-16T00:00:00.000000000', '1998-12-16T00:00:00.000000000',\n       '1999-01-16T00:00:00.000000000', '1999-02-16T00:00:00.000000000',\n       '1999-03-16T00:00:00.000000000', '1999-04-16T00:00:00.000000000',\n       '1999-05-16T00:00:00.000000000', '1999-06-16T00:00:00.000000000',\n       '1999-07-16T00:00:00.000000000', '1999-08-16T00:00:00.000000000',\n       '1999-09-16T00:00:00.000000000', '1999-10-16T00:00:00.000000000',\n       '1999-11-16T00:00:00.000000000', '1999-12-16T00:00:00.000000000',\n       '2000-01-16T00:00:00.000000000', '2000-02-16T00:00:00.000000000',\n       '2000-03-16T00:00:00.000000000', '2000-04-16T00:00:00.000000000',\n       '2000-05-16T00:00:00.000000000', '2000-06-16T00:00:00.000000000',\n       '2000-07-16T00:00:00.000000000', '2000-08-16T00:00:00.000000000',\n       '2000-09-16T00:00:00.000000000', '2000-10-16T00:00:00.000000000',\n       '2000-11-16T00:00:00.000000000', '2000-12-16T00:00:00.000000000',\n       '2001-01-16T00:00:00.000000000', '2001-02-16T00:00:00.000000000',\n       '2001-03-16T00:00:00.000000000', '2001-04-16T00:00:00.000000000',\n       '2001-05-16T00:00:00.000000000', '2001-06-16T00:00:00.000000000',\n       '2001-07-16T00:00:00.000000000', '2001-08-16T00:00:00.000000000',\n       '2001-09-16T00:00:00.000000000', '2001-10-16T00:00:00.000000000',\n       '2001-11-16T00:00:00.000000000', '2001-12-16T00:00:00.000000000',\n       '2002-01-16T00:00:00.000000000', '2002-02-16T00:00:00.000000000',\n       '2002-03-16T00:00:00.000000000', '2002-04-16T00:00:00.000000000',\n       '2002-05-16T00:00:00.000000000', '2002-06-16T00:00:00.000000000',\n       '2002-07-16T00:00:00.000000000', '2002-08-16T00:00:00.000000000',\n       '2002-09-16T00:00:00.000000000', '2002-10-16T00:00:00.000000000',\n       '2002-11-16T00:00:00.000000000', '2002-12-16T00:00:00.000000000',\n       '2003-01-16T00:00:00.000000000', '2003-02-16T00:00:00.000000000',\n       '2003-03-16T00:00:00.000000000', '2003-04-16T00:00:00.000000000',\n       '2003-05-16T00:00:00.000000000', '2003-06-16T00:00:00.000000000',\n       '2003-07-16T00:00:00.000000000', '2003-08-16T00:00:00.000000000',\n       '2003-09-16T00:00:00.000000000', '2003-10-16T00:00:00.000000000',\n       '2003-11-16T00:00:00.000000000', '2003-12-16T00:00:00.000000000',\n       '2004-01-16T00:00:00.000000000', '2004-02-16T00:00:00.000000000',\n       '2004-03-16T00:00:00.000000000', '2004-04-16T00:00:00.000000000',\n       '2004-05-16T00:00:00.000000000', '2004-06-16T00:00:00.000000000',\n       '2004-07-16T00:00:00.000000000', '2004-08-16T00:00:00.000000000',\n       '2004-09-16T00:00:00.000000000', '2004-10-16T00:00:00.000000000',\n       '2004-11-16T00:00:00.000000000', '2004-12-16T00:00:00.000000000',\n       '2005-01-16T00:00:00.000000000', '2005-02-16T00:00:00.000000000',\n       '2005-03-16T00:00:00.000000000', '2005-04-16T00:00:00.000000000',\n       '2005-05-16T00:00:00.000000000', '2005-06-16T00:00:00.000000000',\n       '2005-07-16T00:00:00.000000000', '2005-08-16T00:00:00.000000000',\n       '2005-09-16T00:00:00.000000000', '2005-10-16T00:00:00.000000000',\n       '2005-11-16T00:00:00.000000000', '2005-12-16T00:00:00.000000000',\n       '2006-01-16T00:00:00.000000000', '2006-02-16T00:00:00.000000000',\n       '2006-03-16T00:00:00.000000000', '2006-04-16T00:00:00.000000000',\n       '2006-05-16T00:00:00.000000000', '2006-06-16T00:00:00.000000000',\n       '2006-07-16T00:00:00.000000000', '2006-08-16T00:00:00.000000000',\n       '2006-09-16T00:00:00.000000000', '2006-10-16T00:00:00.000000000',\n       '2006-11-16T00:00:00.000000000', '2006-12-16T00:00:00.000000000',\n       '2007-01-16T00:00:00.000000000', '2007-02-16T00:00:00.000000000',\n       '2007-03-16T00:00:00.000000000', '2007-04-16T00:00:00.000000000',\n       '2007-05-16T00:00:00.000000000', '2007-06-16T00:00:00.000000000',\n       '2007-07-16T00:00:00.000000000', '2007-08-16T00:00:00.000000000',\n       '2007-09-16T00:00:00.000000000', '2007-10-16T00:00:00.000000000',\n       '2007-11-16T00:00:00.000000000', '2007-12-16T00:00:00.000000000',\n       '2008-01-16T00:00:00.000000000', '2008-04-16T00:00:00.000000000',\n       '2008-05-16T00:00:00.000000000', '2008-06-16T00:00:00.000000000',\n       '2008-07-16T00:00:00.000000000', '2008-08-16T00:00:00.000000000',\n       '2008-09-16T00:00:00.000000000', '2008-10-16T00:00:00.000000000',\n       '2008-11-16T00:00:00.000000000', '2008-12-16T00:00:00.000000000',\n       '2009-01-16T00:00:00.000000000', '2009-02-16T00:00:00.000000000',\n       '2009-03-16T00:00:00.000000000', '2009-04-16T00:00:00.000000000',\n       '2009-06-16T00:00:00.000000000', '2009-07-16T00:00:00.000000000',\n       '2009-08-16T00:00:00.000000000', '2009-09-16T00:00:00.000000000',\n       '2009-10-16T00:00:00.000000000', '2009-11-16T00:00:00.000000000',\n       '2009-12-16T00:00:00.000000000', '2010-01-16T00:00:00.000000000',\n       '2010-02-16T00:00:00.000000000', '2010-03-16T00:00:00.000000000',\n       '2010-04-16T00:00:00.000000000', '2010-05-16T00:00:00.000000000',\n       '2010-06-16T00:00:00.000000000', '2010-07-16T00:00:00.000000000',\n       '2010-08-16T00:00:00.000000000', '2010-09-16T00:00:00.000000000',\n       '2010-10-16T00:00:00.000000000', '2010-11-16T00:00:00.000000000',\n       '2010-12-16T00:00:00.000000000'], dtype='datetime64[ns]')latitude(latitude)float3289.96 89.88 89.79 ... -89.88 -89.96_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([ 89.958336,  89.875   ,  89.79167 , ..., -89.791664, -89.87501 ,\n       -89.958336], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_CoordinateAxisType :Lonactual_range :[-179.9583  179.9584]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79166, ...,  179.79167,  179.87502,\n        179.95836], dtype=float32)Data variables: (1)chlorophyll(time, latitude, longitude)float32...colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll Concentration, OCI Algorithmreferences :Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.standard_name :concentration_of_chlorophyll_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001[1464998400 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16', '1998-02-16', '1998-03-16', '1998-04-16',\n               '1998-05-16', '1998-06-16',\n               ...\n               '2010-03-16', '2010-04-16', '2010-05-16', '2010-06-16',\n               '2010-07-16', '2010-08-16', '2010-09-16', '2010-10-16',\n               '2010-11-16', '2010-12-16'],\n              dtype='datetime64[ns]', name='time', length=157, freq=None))latitudePandasIndexPandasIndex(Index([ 89.95833587646484,             89.875,  89.79167175292969,\n        89.70833587646484,             89.625,  89.54167175292969,\n        89.45833587646484,             89.375,  89.29167175292969,\n        89.20833587646484,\n       ...\n       -89.20833587646484, -89.29166412353516, -89.37500762939453,\n       -89.45833587646484, -89.54166412353516, -89.62500762939453,\n       -89.70833587646484, -89.79166412353516, -89.87500762939453,\n       -89.95833587646484],\n      dtype='float32', name='latitude', length=2160))longitudePandasIndexPandasIndex(Index([ -179.9583282470703,            -179.875, -179.79165649414062,\n        -179.7083282470703,            -179.625, -179.54165649414062,\n        -179.4583282470703,            -179.375, -179.29165649414062,\n        -179.2083282470703,\n       ...\n        179.20835876464844,   179.2916717529297,  179.37501525878906,\n        179.45835876464844,   179.5416717529297,  179.62501525878906,\n        179.70835876464844,   179.7916717529297,  179.87501525878906,\n        179.95835876464844],\n      dtype='float32', name='longitude', length=4320))Attributes: (50)_lastModified :2018-01-31T04:58:26.000Z_NCProperties :version=1|netcdflibversion=4.4.1.1|hdf5libversion=1.8.18cdm_data_type :GridConventions :CF-1.6, COARDS, ACDD-1.3creator_email :data@oceancolor.gsfc.nasa.govcreator_name :NASA/GSFC/OBPGcreator_type :groupcreator_url :https://oceandata.sci.gsfc.nasa.govdate_created :2018-01-31T04:58:26.000ZEasternmost_Easting :179.9584geospatial_lat_max :89.95834geospatial_lat_min :-89.95834geospatial_lat_units :degrees_northgeospatial_lon_max :179.9584geospatial_lon_min :-179.9583geospatial_lon_units :degrees_eastgrid_mapping_name :latitude_longitudehistory :These R2018.0 data files were downloaded from https://oceandata.sci.gsfc.nasa.gov/SeaWiFS/Mapped/Monthly/9km/chlor_a to NOAA NMFS SWFSC by erd.data@noaa.gov ERD on 2018-03-05.\n2023-09-06T13:45:15Z (local files)\n2023-09-06T13:45:15Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday.dasidentifier_product_doi :10.5067/ORBVIEW-2/SEAWIFS/L3M/CHL/2018identifier_product_doi_authority :https://dx.doi.orginfoUrl :https://oceandata.sci.gsfc.nasa.govinstitution :NASA/GSFC OBPGinstrument :SeaWiFSkeywords :algorithm, biology, center, chemistry, chlor_a, chlorophyll, color, concentration, concentration_of_chlorophyll_in_sea_water, data, Earth Science &gt; Oceans &gt; Ocean Chemistry &gt; Chlorophyll, Earth Science &gt; Oceans &gt; Ocean Optics &gt; Ocean Color, field, field-of-view, flight, goddard, group, gsfc, image, L3, level, level-3, mapped, nasa, noaa, obpg, ocean, ocean color, oceans, oci, optics, orbview, orbview-2, palette, processing, sea, sea-wide, seawater, seawifs, sensor, smi, space, standard, view, water, widekeywords_vocabulary :GCMD Science Keywordsl2_flag_names :ATMFAIL,LAND,HILT,HISATZEN,STRAYLIGHT,CLDICE,COCCOLITH,LOWLW,CHLWARN,CHLFAIL,NAVWARN,MAXAERITER,ATMWARN,HISOLZEN,NAVFAIL,FILTER,HIGLINTlicense :https://science.nasa.gov/earth-science/earth-science-data/data-information-policy/\n\nPlease cite: NASA Goddard Space Flight Center, Ocean Ecology Laboratory, Ocean Biology Processing Group. Sea-viewing Wide Field-of-view Sensor (SeaWiFS) R2018.0 Chlorophyll Data; NASA OB.DAAC, Greenbelt, MD, USA. doi: https://dx.doi.org/10.5067/ORBVIEW-2/SEAWIFS/L3M/CHL/2018 .\n\nThe data may be used and redistributed for free but is not intended\nfor legal use, since it may contain inaccuracies. Neither the data\nContributor, ERD, NOAA, nor the United States Government, nor any\nof their employees or contractors, makes any warranty, express or\nimplied, including warranties of merchantability and fitness for a\nparticular purpose, or assumes any legal liability for the accuracy,\ncompleteness, or usefulness, of this information.map_projection :Equidistant Cylindricalmeasure :Meannaming_authority :gov.noaa.pfeg.coastwatchNorthernmost_Northing :89.95834platform :Orbview-2processing_level :L3 Mappedprocessing_version :2018.0project :Ocean Biology Processing Group (NASA/GSFC/OBPG)publisher_email :data@oceancolor.gsfc.nasa.govpublisher_name :NASA/GSFC/OBPGpublisher_type :grouppublisher_url :https://oceandata.sci.gsfc.nasa.govreferences :SeaWiFS information: https://oceancolor.gsfc.nasa.gov/SeaWiFS/ . NASA Ocean\nColor information: https://oceancolor.gsfc.nasa.gov/\nProcessing reference: O'Reilly, J.E., Maritorena, S., Mitchell, B.G., Siegel, D.A., Carder, K.L., Garver, S.A., Kahru, M. and McClain, C. (1998). Ocean color chlorophyll algorithms for SeaWiFS. J. Geophys. Res., 103: 24, 937-24, 953.\nProcessing reference: O'Reilly, J. E., and 21 others. 2000. Ocean color chlorophyll a algorithms for SeaWiFS, OC2 and OC4: Version 4. SeaWiFS Postlaunch Calibration and Validation Analyses, part 3. NASA SeaWiFS technical report series. pp. 8 226 22.\nProcessing reference: Fu, G., Baith, K. S., and McClain, C. R. (1998). SeaDAS: The SeaWiFS Data Analysis System. Proceedings of \"The 4th Pacific Ocean Remote Sensing Conference\", Qingdao, China, July 28-31, 1998, 73-79.\nValidation reference: Hooker, S.B., and C.R. McClain (2000). The Calibration and Validation of SeaWiFS Data. Prog. Oceanogr., 45, 427-465.\nR2014.0 processing reference: Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.\nR2018.0 reprocessing information: https://oceancolor.gsfc.nasa.gov/reprocessing/r2018/seawifs/sourceUrl :(local files)Southernmost_Northing :-89.95834spatialResolution :9.28 kmstandard_name_vocabulary :CF Standard Name Table v70summary :NASA GSFC Ocean Color Web distributes science-quality chlorophyll-a\nconcentration data from the Sea-viewing Wide Field-of-view Sensor (SeaWiFS)\non the Orbview-2 satellite. This version is the 2018.0 Reprocessing (R2018.0). https://oceancolor.gsfc.nasa.gov/reprocessing/r2018/seawifs/\n\nThe SeaWiFS instrument was launched by Orbital Sciences Corporation on the\nOrbView-2 (a.k.a. SeaStar) satellite in August 1997, and collected data from\nSeptember 1997 until the end of mission in December 2010. SeaWiFS had 8\nspectral bands from 412 to 865 nm. It collected global data at 4 km\nresolution, and local data (limited onboard storage and direct broadcast)\nat 1 km. The mission and sensor were optimized for ocean color measurements,\nwith a local noon (descending) equator crossing time orbit, fore-and-aft\ntilt capability, full dynamic range, and low polarization sensitivity.temporal_range :10-daytime_coverage_end :2010-12-16T00:00:00Ztime_coverage_start :1997-09-16T00:00:00Ztitle :Chlorophyll-a, Orbview-2 SeaWiFS, R2018.0, 0.1�, Global, 1997-2010 (Monthly Composite)Westernmost_Easting :-179.9583\n\n\n\n\nPrint out some useful metadata\nYou can view all of the metadata above in the dataset object. Let’s print out some metadata items to point a few things out: * The SeaWiFS dataset spans 13 years, from 1997 to 2010\n* The chlorophyll variable is called “chlorophyll”. Knowing this is important because variable names are not standardized, and we will need to know the exact variable name to extract the data. * Checking the first and last value of latitude can tell us if the latitude values are in ascending or descending order.\n\nprint('earliest date =', sw_ds.time.values[0])\nprint('most recent date =', sw_ds.time.values[-1], '\\n')\nprint('variable:', list(sw_ds.data_vars.keys()), '\\n')\n\nprint(\"Is latitude's first value --&gt;\", round(sw_ds.latitude[0].item(), 6))\nprint('greater than') \nprint(\"latitude's last value --&gt;\", round(sw_ds.latitude[-1].item(), 6))\n\nprint(sw_ds.latitude[0].item() &gt; sw_ds.latitude[-1].item())\n\n\nearliest date = 1997-09-16T00:00:00.000000000\nmost recent date = 2010-12-16T00:00:00.000000000 \n\nvariable: ['chlorophyll'] \n\nIs latitude's first value --&gt; 89.958336\ngreater than\nlatitude's last value --&gt; -89.958336\nTrue\n\n\n\n\nPay attention to the first and last values of latitude in the dataset\nIn a netCDF file that completely follows accepted standards, the latitude values are ascending; the values go from lowest to highest (south to north). Therefore, when we use the slice function (below) to subset the dataset we would list the lowest value in our subset followed by the highest.\n* slice(lat_min, lat_max)\nHowever, for some datasets the latitude values are in descending order, meaning the files were built with latitudes indexed from highest to lowest (north to south). It is a common occurrence and it impacts how we subset that dataset, so you need to be aware of it.\n* With latitude values in descending order, if you use “slice(lat_min, lat_max)” you will get no data, because there are no latitude values between lat_min and lat_max. * However, by reversing the order within slice by using “slice(lat_max, lat_min)” you will get data.\nFor the SeaWiFS dataset, the metadata above show that the first latitude value (89.958336) is greater than the last (-89.958336). The latitude values are in descending order.\n* There are methods in xarray to flip the latitude dimension. A simpler solution is to use a logic step that determines if latitude values are descending, then set slice values to use the higher value first (see below).\n\n# The lat1 and lat2 values are used in the slice function\n# At first we set them as if the dataset is compliant with standards\nlat1 = lat_min\nlat2 = lat_max\n\n# Then switch them if latitude values are descending\nif sw_ds.latitude[0].item() &gt; sw_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\n\n\nSubset the data from the dataset object.\nNote that so far we have not downloaded data. We have only set up how we want to download the data. * The download will happen when we request to use data, like when creating the map below.\n\n\nsw_subset = sw_ds['chlorophyll'].sel(time=slice(sw_ds.time[0], sw_ds.time[-1]),\n                                     latitude=slice(lat1, lat2),\n                                     longitude=slice(lon_min, lon_max)\n                                     )\nsw_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlorophyll' (time: 157, latitude: 60, longitude: 60)&gt;\n[565200 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 1997-09-16 1997-10-16 ... 2010-12-16\n  * latitude   (latitude) float32 29.96 29.87 29.79 29.71 ... 25.21 25.12 25.04\n  * longitude  (longitude) float32 -94.96 -94.88 -94.79 ... -90.21 -90.12 -90.04\nAttributes:\n    colorBarMaximum:  30.0\n    colorBarMinimum:  0.03\n    colorBarScale:    Log\n    ioos_category:    Ocean Color\n    long_name:        Chlorophyll Concentration, OCI Algorithm\n    references:       Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a a...\n    standard_name:    concentration_of_chlorophyll_in_sea_water\n    units:            mg m^-3\n    valid_max:        100.0\n    valid_min:        0.001xarray.DataArray'chlorophyll'time: 157latitude: 60longitude: 60...[565200 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]1997-09-16 ... 2010-12-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000', '1998-02-16T00:00:00.000000000',\n       '1998-03-16T00:00:00.000000000', '1998-04-16T00:00:00.000000000',\n       '1998-05-16T00:00:00.000000000', '1998-06-16T00:00:00.000000000',\n       '1998-07-16T00:00:00.000000000', '1998-08-16T00:00:00.000000000',\n       '1998-09-16T00:00:00.000000000', '1998-10-16T00:00:00.000000000',\n       '1998-11-16T00:00:00.000000000', '1998-12-16T00:00:00.000000000',\n       '1999-01-16T00:00:00.000000000', '1999-02-16T00:00:00.000000000',\n       '1999-03-16T00:00:00.000000000', '1999-04-16T00:00:00.000000000',\n       '1999-05-16T00:00:00.000000000', '1999-06-16T00:00:00.000000000',\n       '1999-07-16T00:00:00.000000000', '1999-08-16T00:00:00.000000000',\n       '1999-09-16T00:00:00.000000000', '1999-10-16T00:00:00.000000000',\n       '1999-11-16T00:00:00.000000000', '1999-12-16T00:00:00.000000000',\n       '2000-01-16T00:00:00.000000000', '2000-02-16T00:00:00.000000000',\n       '2000-03-16T00:00:00.000000000', '2000-04-16T00:00:00.000000000',\n       '2000-05-16T00:00:00.000000000', '2000-06-16T00:00:00.000000000',\n       '2000-07-16T00:00:00.000000000', '2000-08-16T00:00:00.000000000',\n       '2000-09-16T00:00:00.000000000', '2000-10-16T00:00:00.000000000',\n       '2000-11-16T00:00:00.000000000', '2000-12-16T00:00:00.000000000',\n       '2001-01-16T00:00:00.000000000', '2001-02-16T00:00:00.000000000',\n       '2001-03-16T00:00:00.000000000', '2001-04-16T00:00:00.000000000',\n       '2001-05-16T00:00:00.000000000', '2001-06-16T00:00:00.000000000',\n       '2001-07-16T00:00:00.000000000', '2001-08-16T00:00:00.000000000',\n       '2001-09-16T00:00:00.000000000', '2001-10-16T00:00:00.000000000',\n       '2001-11-16T00:00:00.000000000', '2001-12-16T00:00:00.000000000',\n       '2002-01-16T00:00:00.000000000', '2002-02-16T00:00:00.000000000',\n       '2002-03-16T00:00:00.000000000', '2002-04-16T00:00:00.000000000',\n       '2002-05-16T00:00:00.000000000', '2002-06-16T00:00:00.000000000',\n       '2002-07-16T00:00:00.000000000', '2002-08-16T00:00:00.000000000',\n       '2002-09-16T00:00:00.000000000', '2002-10-16T00:00:00.000000000',\n       '2002-11-16T00:00:00.000000000', '2002-12-16T00:00:00.000000000',\n       '2003-01-16T00:00:00.000000000', '2003-02-16T00:00:00.000000000',\n       '2003-03-16T00:00:00.000000000', '2003-04-16T00:00:00.000000000',\n       '2003-05-16T00:00:00.000000000', '2003-06-16T00:00:00.000000000',\n       '2003-07-16T00:00:00.000000000', '2003-08-16T00:00:00.000000000',\n       '2003-09-16T00:00:00.000000000', '2003-10-16T00:00:00.000000000',\n       '2003-11-16T00:00:00.000000000', '2003-12-16T00:00:00.000000000',\n       '2004-01-16T00:00:00.000000000', '2004-02-16T00:00:00.000000000',\n       '2004-03-16T00:00:00.000000000', '2004-04-16T00:00:00.000000000',\n       '2004-05-16T00:00:00.000000000', '2004-06-16T00:00:00.000000000',\n       '2004-07-16T00:00:00.000000000', '2004-08-16T00:00:00.000000000',\n       '2004-09-16T00:00:00.000000000', '2004-10-16T00:00:00.000000000',\n       '2004-11-16T00:00:00.000000000', '2004-12-16T00:00:00.000000000',\n       '2005-01-16T00:00:00.000000000', '2005-02-16T00:00:00.000000000',\n       '2005-03-16T00:00:00.000000000', '2005-04-16T00:00:00.000000000',\n       '2005-05-16T00:00:00.000000000', '2005-06-16T00:00:00.000000000',\n       '2005-07-16T00:00:00.000000000', '2005-08-16T00:00:00.000000000',\n       '2005-09-16T00:00:00.000000000', '2005-10-16T00:00:00.000000000',\n       '2005-11-16T00:00:00.000000000', '2005-12-16T00:00:00.000000000',\n       '2006-01-16T00:00:00.000000000', '2006-02-16T00:00:00.000000000',\n       '2006-03-16T00:00:00.000000000', '2006-04-16T00:00:00.000000000',\n       '2006-05-16T00:00:00.000000000', '2006-06-16T00:00:00.000000000',\n       '2006-07-16T00:00:00.000000000', '2006-08-16T00:00:00.000000000',\n       '2006-09-16T00:00:00.000000000', '2006-10-16T00:00:00.000000000',\n       '2006-11-16T00:00:00.000000000', '2006-12-16T00:00:00.000000000',\n       '2007-01-16T00:00:00.000000000', '2007-02-16T00:00:00.000000000',\n       '2007-03-16T00:00:00.000000000', '2007-04-16T00:00:00.000000000',\n       '2007-05-16T00:00:00.000000000', '2007-06-16T00:00:00.000000000',\n       '2007-07-16T00:00:00.000000000', '2007-08-16T00:00:00.000000000',\n       '2007-09-16T00:00:00.000000000', '2007-10-16T00:00:00.000000000',\n       '2007-11-16T00:00:00.000000000', '2007-12-16T00:00:00.000000000',\n       '2008-01-16T00:00:00.000000000', '2008-04-16T00:00:00.000000000',\n       '2008-05-16T00:00:00.000000000', '2008-06-16T00:00:00.000000000',\n       '2008-07-16T00:00:00.000000000', '2008-08-16T00:00:00.000000000',\n       '2008-09-16T00:00:00.000000000', '2008-10-16T00:00:00.000000000',\n       '2008-11-16T00:00:00.000000000', '2008-12-16T00:00:00.000000000',\n       '2009-01-16T00:00:00.000000000', '2009-02-16T00:00:00.000000000',\n       '2009-03-16T00:00:00.000000000', '2009-04-16T00:00:00.000000000',\n       '2009-06-16T00:00:00.000000000', '2009-07-16T00:00:00.000000000',\n       '2009-08-16T00:00:00.000000000', '2009-09-16T00:00:00.000000000',\n       '2009-10-16T00:00:00.000000000', '2009-11-16T00:00:00.000000000',\n       '2009-12-16T00:00:00.000000000', '2010-01-16T00:00:00.000000000',\n       '2010-02-16T00:00:00.000000000', '2010-03-16T00:00:00.000000000',\n       '2010-04-16T00:00:00.000000000', '2010-05-16T00:00:00.000000000',\n       '2010-06-16T00:00:00.000000000', '2010-07-16T00:00:00.000000000',\n       '2010-08-16T00:00:00.000000000', '2010-09-16T00:00:00.000000000',\n       '2010-10-16T00:00:00.000000000', '2010-11-16T00:00:00.000000000',\n       '2010-12-16T00:00:00.000000000'], dtype='datetime64[ns]')latitude(latitude)float3229.96 29.87 29.79 ... 25.12 25.04_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([29.958334, 29.874998, 29.791666, 29.708334, 29.624998, 29.541666,\n       29.458334, 29.374998, 29.291666, 29.208334, 29.124998, 29.041666,\n       28.958334, 28.874998, 28.791666, 28.708334, 28.624998, 28.541666,\n       28.458334, 28.374998, 28.291666, 28.208334, 28.124998, 28.041666,\n       27.958334, 27.874998, 27.791666, 27.708334, 27.624998, 27.541666,\n       27.458334, 27.374998, 27.291666, 27.208334, 27.124998, 27.041666,\n       26.958334, 26.874998, 26.791666, 26.708334, 26.624998, 26.541666,\n       26.458334, 26.374998, 26.291666, 26.208334, 26.124998, 26.041666,\n       25.958334, 25.874998, 25.791662, 25.708334, 25.624998, 25.541662,\n       25.458334, 25.374998, 25.291662, 25.208334, 25.124998, 25.041662],\n      dtype=float32)longitude(longitude)float32-94.96 -94.88 ... -90.12 -90.04_CoordinateAxisType :Lonactual_range :[-179.9583  179.9584]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-94.958336, -94.875   , -94.791664, -94.708336, -94.625   , -94.541664,\n       -94.458336, -94.375   , -94.291664, -94.208336, -94.125   , -94.041664,\n       -93.958336, -93.875   , -93.791664, -93.708336, -93.625   , -93.541664,\n       -93.458336, -93.375   , -93.291664, -93.208336, -93.125   , -93.041664,\n       -92.958336, -92.875   , -92.791664, -92.708336, -92.625   , -92.541664,\n       -92.458336, -92.375   , -92.291664, -92.208336, -92.125   , -92.041664,\n       -91.958336, -91.875   , -91.791664, -91.708336, -91.625   , -91.541664,\n       -91.458336, -91.375   , -91.291664, -91.208336, -91.125   , -91.041664,\n       -90.958336, -90.875   , -90.791664, -90.708336, -90.625   , -90.541664,\n       -90.458336, -90.375   , -90.291664, -90.208336, -90.125   , -90.041664],\n      dtype=float32)Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16', '1998-02-16', '1998-03-16', '1998-04-16',\n               '1998-05-16', '1998-06-16',\n               ...\n               '2010-03-16', '2010-04-16', '2010-05-16', '2010-06-16',\n               '2010-07-16', '2010-08-16', '2010-09-16', '2010-10-16',\n               '2010-11-16', '2010-12-16'],\n              dtype='datetime64[ns]', name='time', length=157, freq=None))latitudePandasIndexPandasIndex(Index([ 29.95833396911621, 29.874998092651367,  29.79166603088379,\n        29.70833396911621, 29.624998092651367,  29.54166603088379,\n        29.45833396911621, 29.374998092651367,  29.29166603088379,\n        29.20833396911621, 29.124998092651367,  29.04166603088379,\n        28.95833396911621, 28.874998092651367,  28.79166603088379,\n        28.70833396911621, 28.624998092651367,  28.54166603088379,\n        28.45833396911621, 28.374998092651367,  28.29166603088379,\n        28.20833396911621, 28.124998092651367,  28.04166603088379,\n        27.95833396911621, 27.874998092651367,  27.79166603088379,\n        27.70833396911621, 27.624998092651367,  27.54166603088379,\n        27.45833396911621, 27.374998092651367,  27.29166603088379,\n        27.20833396911621, 27.124998092651367,  27.04166603088379,\n        26.95833396911621, 26.874998092651367,  26.79166603088379,\n        26.70833396911621, 26.624998092651367,  26.54166603088379,\n        26.45833396911621, 26.374998092651367,  26.29166603088379,\n        26.20833396911621, 26.124998092651367,  26.04166603088379,\n        25.95833396911621, 25.874998092651367, 25.791662216186523,\n        25.70833396911621, 25.624998092651367, 25.541662216186523,\n        25.45833396911621, 25.374998092651367, 25.291662216186523,\n        25.20833396911621, 25.124998092651367, 25.041662216186523],\n      dtype='float32', name='latitude'))longitudePandasIndexPandasIndex(Index([-94.95833587646484,            -94.875, -94.79166412353516,\n       -94.70833587646484,            -94.625, -94.54166412353516,\n       -94.45833587646484,            -94.375, -94.29166412353516,\n       -94.20833587646484,            -94.125, -94.04166412353516,\n       -93.95833587646484,            -93.875, -93.79166412353516,\n       -93.70833587646484,            -93.625, -93.54166412353516,\n       -93.45833587646484,            -93.375, -93.29166412353516,\n       -93.20833587646484,            -93.125, -93.04166412353516,\n       -92.95833587646484,            -92.875, -92.79166412353516,\n       -92.70833587646484,            -92.625, -92.54166412353516,\n       -92.45833587646484,            -92.375, -92.29166412353516,\n       -92.20833587646484,            -92.125, -92.04166412353516,\n       -91.95833587646484,            -91.875, -91.79166412353516,\n       -91.70833587646484,            -91.625, -91.54166412353516,\n       -91.45833587646484,            -91.375, -91.29166412353516,\n       -91.20833587646484,            -91.125, -91.04166412353516,\n       -90.95833587646484,            -90.875, -90.79166412353516,\n       -90.70833587646484,            -90.625, -90.54166412353516,\n       -90.45833587646484,            -90.375, -90.29166412353516,\n       -90.20833587646484,            -90.125, -90.04166412353516],\n      dtype='float32', name='longitude'))Attributes: (10)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll Concentration, OCI Algorithmreferences :Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.standard_name :concentration_of_chlorophyll_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001\n\n\n\n\nPlot data to show where it is in the world.\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\nax1.set_extent([240, 300, 5, 45], ccrs.PlateCarree())\n\n# Set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(235, 305, 20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(0, 50, 10), crs=ccrs.PlateCarree())\n\n# Add features to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# Format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nnp.log10(sw_subset[-1]).plot.pcolormesh(ax=ax1, \n                                        transform=ccrs.PlateCarree(), \n                                        cmap='jet', \n                                        cbar_kwargs={'label': \"log chlorophyll (mg m-3)\"})\n\nplt.title('Time series data location - Gulf of Mexico')\n\nText(0.5, 1.0, 'Time series data location - Gulf of Mexico')\n\n\n\n\n\n\n\n\n\n\n\nCompute the monthly mean over the region\n\nswAVG = sw_subset.mean(dim=['latitude','longitude'])\nswAVG.head()\n\n# If you are running low on memory, uncomment the next line\n# del sw_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlorophyll' (time: 5)&gt;\narray([0.59386134, 0.59238297, 0.68359953, 0.81557316, 0.85900825],\n      dtype=float32)\nCoordinates:\n  * time     (time) datetime64[ns] 1997-09-16 1997-10-16 ... 1998-01-16xarray.DataArray'chlorophyll'time: 50.5939 0.5924 0.6836 0.8156 0.859array([0.59386134, 0.59238297, 0.68359953, 0.81557316, 0.85900825],\n      dtype=float32)Coordinates: (1)time(time)datetime64[ns]1997-09-16 ... 1998-01-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000'], dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#get-monthly-modis-data",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#get-monthly-modis-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get monthly MODIS data",
    "text": "Get monthly MODIS data\n\nRepeat the steps above to get data for the MODIS Aqua chlorophyll dataset\n\nurl_modis = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                      'erddap',\n                      'griddap',\n                      'erdMH1chlamday_R2022SQ'\n                      ])\nmodis_ds = xr.open_dataset(url_modis)\nmodis_ds\n\nprint('earliest date =', modis_ds.time.values[0])\nprint('latest date =', modis_ds.time.values[-1], '\\n')\nprint('variables:', modis_ds.data_vars.keys(), '\\n')\nprint('Is the first latitude value --&gt;', modis_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', modis_ds.latitude[-1].item())\n\nprint(modis_ds.latitude[0].item() &gt; modis_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif modis_ds.latitude[0].item() &gt; modis_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\nmodis_subset = modis_ds['chlor_a'].sel(time=slice(modis_ds.time[0], modis_ds.time[-1]),\n                                       latitude=slice(lat1, lat2),\n                                       longitude=slice(lon_min, lon_max)\n                                       )\n\nmodisAVG = modis_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del modis_subset \n\nearliest date = 2002-07-16T00:00:00.000000000\nlatest date = 2023-07-16T00:00:00.000000000 \n\nvariables: KeysView(Data variables:\n    chlor_a  (time, latitude, longitude) float32 ...) \n\nIs the first latitude value --&gt; 89.97916412353516\ngreater than the last latitude value --&gt; -89.97917175292969\nTrue"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#get-monthly-viirs-data",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#get-monthly-viirs-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get monthly VIIRS data",
    "text": "Get monthly VIIRS data\n\nRepeat the steps above to get data for the VIIRS SNPP chlorophyll dataset\n\nurl_viirs = '/'.join(['https://coastwatch.noaa.gov',\n                        'erddap',\n                        'griddap',\n                        'noaacwNPPVIIRSSQchlaMonthly'\n                        ])\nviirs_ds = xr.open_dataset(url_viirs)\nviirs_ds\n\nprint('earliest date =', viirs_ds.time.values[0])\nprint('latest date =', viirs_ds.time.values[-1], '\\n')\nprint('variables:', viirs_ds.data_vars.keys(), '\\n')\n\nprint('Is the first latitude value --&gt;', viirs_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', viirs_ds.latitude[-1].item())\n\nprint(viirs_ds.latitude[0].item() &gt; viirs_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif viirs_ds.latitude[0].item() &gt; viirs_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\nviirs_subset = modis_ds['chlor_a'].sel(time=slice(viirs_ds.time[0], viirs_ds.time[-1]),\n                                       latitude=slice(lat1, lat2),\n                                       longitude=slice(lon_min, lon_max)\n                                       )\nviirsAVG = viirs_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del viirs_subset \n\nearliest date = 2012-01-02T12:00:00.000000000\nlatest date = 2023-08-01T12:00:00.000000000 \n\nvariables: KeysView(Data variables:\n    chlor_a  (time, altitude, latitude, longitude) float32 ...) \n\nIs the first latitude value --&gt; 89.75625\ngreater than the last latitude value --&gt; -89.75625\nTrue"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#plot-the-time-series",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#plot-the-time-series",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Plot the time series",
    "text": "Plot the time series\n\nPlot the result for three datasets\n\nplt.figure(figsize=(10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(swAVG.time, swAVG, \n              'o', markersize=3, \n              label='SeaWiFS', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(modisAVG.time, modisAVG, \n              'o', markersize=3, \n              label='MODIS', c='blue', \n              linestyle='-', linewidth=1) \n\n# Add VIIRS data\nplt.plot_date(viirsAVG.time, viirsAVG, \n              'o', markersize=3, \n              label='VIIRS', c='green', \n              linestyle='-', linewidth=1) \n\nplt.ylim([0, 3])\nplt.ylabel('Chl-a (mg m-3)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#get-oc-cci-data",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#get-oc-cci-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get OC-CCI data",
    "text": "Get OC-CCI data\nIf you needed a single time series from 1997 to present, you would have to use the plot above to devise some method to reconcile the difference in values where two datasets overlap. Alternatively, you could use the ESA OC-CCI (Ocean Color Climate Change Initiative) dataset, which blends data from many satellite missions into a single dataset, including data from SeaWiFS, MODIS, and VIIRS.\nAdd the ESA OC-CCI dataset to the plot above to see how it compares with data from the individual satellite missions.\n### Repeat the steps above to get data from the ESA OC-CCI chlorophyll dataset\n\nurl_cci = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                    'erddap',\n                    'griddap',\n                    'pmlEsaCCI60OceanColorMonthly'\n                    ])\ncci_ds = xr.open_dataset(url_cci)\ncci_ds\n\nprint('earliest date =', cci_ds.time.values[0])\nprint('latest date =', cci_ds.time.values[-1])\n\n# From the 93 variables in the dataset, \n# display only those with chl in the name\nsubset_variables = [ln for ln in list(cci_ds.data_vars.keys()) if 'chl' in ln]\n\nprint('variables with chl in name:', subset_variables, '\\n')\n\n\nprint('Is the first latitude value --&gt;', cci_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', cci_ds.latitude[-1].item())\n\nprint(cci_ds.latitude[0].item() &gt; cci_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif cci_ds.latitude[0].item() &gt; cci_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\ncci_subset = cci_ds['chlor_a'].sel(time=slice(cci_ds.time[0], cci_ds.time[-1]),\n                                   latitude=slice(lat1, lat2),\n                                   longitude=slice(lon_min, lon_max)\n                                   )\ncciAVG = cci_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del cci_subset \n\nearliest date = 1997-09-04T00:00:00.000000000\nlatest date = 2023-03-01T00:00:00.000000000\nvariables with chl in name: ['chlor_a', 'chlor_a_log10_bias', 'chlor_a_log10_rmsd'] \n\nIs the first latitude value --&gt; 89.97916666666667\ngreater than the last latitude value --&gt; -89.97916666666666\nTrue"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#replot-the-results-using-data-from-all-four-datasets",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#replot-the-results-using-data-from-all-four-datasets",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Replot the results using data from all four datasets",
    "text": "Replot the results using data from all four datasets\n\nplt.figure(figsize=(10, 5)) \n\n# Add SeaWiFS data\nplt.plot_date(swAVG.time, swAVG, \n              'o', markersize=0, \n              label='SeaWiFS', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(modisAVG.time, modisAVG, \n              's', markersize=0, \n              label='MODIS', c='blue', \n              linestyle='-', linewidth=1) \n\n# Add VIIRS data\nplt.plot_date(viirsAVG.time, viirsAVG, \n              '^', markersize=0, \n              label='VIIRS', c='green', \n              linestyle='-', linewidth=1) \n\n# Add CCI data\nplt.plot_date(cciAVG.time, cciAVG, \n              'o', markersize=3,\n              label='OC-CCI', c='black', \n              linestyle='-', linewidth=1) \n\nplt.ylim([0, 3])\nplt.ylabel('Chl-a (mg m-3)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#references",
    "href": "tutorials/Tutorial2-timeseries-compare-sensors/python/Tutorial2-timeseries-compare-sensors.html#references",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "References",
    "text": "References\n\nCoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html\nhttps://polarwatch.noaa.gov/catalog/"
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html",
    "title": "Working with data that crosses the antimeridian",
    "section": "",
    "text": "History | Updated Sep 2023"
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#background",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#background",
    "title": "Working with data that crosses the antimeridian",
    "section": "Background",
    "text": "Background\nMany datasets use a system where longitude is numbered from -180 to +180 degrees east (see example below). This numbering system presents a problem for researchers working in a region that spans the antimeridian, because the parts of the data end up on the opposite ends of the map.\n\n\n\nmap_-180to180_500px.png\n\n\n\nFigure. Global map on -180/+180 longitude showing data region crossing the antimeridian."
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#objectives",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#objectives",
    "title": "Working with data that crosses the antimeridian",
    "section": "Objectives",
    "text": "Objectives\nThis tutorial will demonstrate how to use datasets with -180 to +180 longitude values to work within regions that cross the antimeridian."
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Working with data that crosses the antimeridian",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data that crosses the antimeridian from a dataset with -180 to +180 longitude values\n\nConvert the data to a 0-360 longitude values\nReordering the longitude axis so that the longitude values are in ascending order\nVisualizing data on a map"
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#datasets-used",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#datasets-used",
    "title": "Working with data that crosses the antimeridian",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Chlorophyll Gap-filled, Blended NOAA-20 and S-NPP VIIRS, Science Quality, Global, 9km, 2018- recent, Daily\nThis NOAA dataset blends chlorophyll data from the Visible and Infrared Imager/Radiometer Suite (VIIRS) sensors aboard the Suomi-NPP and NOAA-20 spacecraft. The gaps in the data are then filled using an empirical orthogonal function (DINEOF). The dataset is available from the CoastWatch Central ERDDAP: https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily\n\nImport packages\n\nimport xarray as xr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl"
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#define-the-area-to-extract",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#define-the-area-to-extract",
    "title": "Working with data that crosses the antimeridian",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nWe will extract data for an area in the Bering Sea between Russia and the United States at 176°E to -152°E longitude and 50°N to 70°N latitude.\n\n\n\ninterest_area_500px.png\n\n\n\nSet up variables\n\nDate to extract\nMinimum and maximum values for the longitude and latitude ranges.\n\n\nmy_date = '2023-08-18'\nlon_min = -152.\nlon_max = 176.\nlat_min = 50.\nlat_max = 70."
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#get-the-seawifs-data",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#get-the-seawifs-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Get the SeaWiFS data",
    "text": "Get the SeaWiFS data\n\nOpen an xarray dataset object\n\n#url = 'https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily'\n\nurl = '/'.join(['https://coastwatch.noaa.gov',\n                'erddap',\n                'griddap',\n                'noaacwNPPN20VIIRSSCIDINEOFDaily'\n                ])\n\nds = xr.open_dataset(url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:    (time: 1874, altitude: 1, latitude: 2160, longitude: 4320)\nCoordinates:\n  * time       (time) datetime64[ns] 2018-05-30T12:00:00 ... 2023-08-24T12:00:00\n  * altitude   (altitude) float64 0.0\n  * latitude   (latitude) float32 89.96 89.88 89.79 ... -89.79 -89.88 -89.96\n  * longitude  (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nData variables:\n    chlor_a    (time, altitude, latitude, longitude) float32 ...\nAttributes: (12/77)\n    _lastModified:                    2023-09-04T21:15:13.000Z\n    _NCProperties:                    version=2,netcdf=4.7.3,hdf5=1.12.0,\n    cdm_data_type:                    Grid\n    Conventions:                      CF-1.6, COARDS, ACDD-1.3\n    creator_email:                    coastwatch.info@noaa.gov\n    creator_name:                     NOAA CoastWatch\n    ...                               ...\n    testOutOfDate:                    now-4days\n    time_coverage_end:                2023-08-24T12:00:00Z\n    time_coverage_start:              2018-05-30T12:00:00Z\n    title:                            Chlorophyll (Gap-filled DINEOF), NOAA S...\n    Westernmost_Easting:              -179.9583\n    westernmost_longitude:            -180.0xarray.DatasetDimensions:time: 1874altitude: 1latitude: 2160longitude: 4320Coordinates: (4)time(time)datetime64[ns]2018-05-30T12:00:00 ... 2023-08-..._CoordinateAxisType :Timeactual_range :[1.5276816e+09 1.6928784e+09]axis :Tioos_category :Timelong_name :Timesource_name :timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2018-05-30T12:00:00.000000000', '2018-05-31T12:00:00.000000000',\n       '2018-06-01T12:00:00.000000000', ..., '2023-08-22T12:00:00.000000000',\n       '2023-08-23T12:00:00.000000000', '2023-08-24T12:00:00.000000000'],\n      dtype='datetime64[ns]')altitude(altitude)float640.0_CoordinateAxisType :Height_CoordinateZisPositive :upactual_range :[0. 0.]axis :Zioos_category :Locationlong_name :Altitudepositive :upstandard_name :altitudeunits :marray([0.])latitude(latitude)float3289.96 89.88 89.79 ... -89.88 -89.96_ChunkSizes :2160_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudesource_name :latstandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([ 89.958336,  89.875   ,  89.791664, ..., -89.79167 , -89.87501 ,\n       -89.958336], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_ChunkSizes :4320_CoordinateAxisType :Lonactual_range :[-179.9583  179.9583]axis :Xioos_category :Locationlong_name :Longitudesource_name :lonstandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79167, ...,  179.79167,  179.87502,\n        179.95834], dtype=float32)Data variables: (1)chlor_a(time, altitude, latitude, longitude)float32...C_format :%.4gcell_methods :time:mean(interval:1 day)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logcoverage_content_type :physicalMeasurementgrid_mapping :coord_refioos_category :Ocean Colorlong_name :Chlorophyll Concentration, DINEOF Gap-Filledstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001[17486668800 values with dtype=float32]Indexes: (4)timePandasIndexPandasIndex(DatetimeIndex(['2018-05-30 12:00:00', '2018-05-31 12:00:00',\n               '2018-06-01 12:00:00', '2018-06-02 12:00:00',\n               '2018-06-03 12:00:00', '2018-06-04 12:00:00',\n               '2018-06-05 12:00:00', '2018-06-06 12:00:00',\n               '2018-06-07 12:00:00', '2018-06-08 12:00:00',\n               ...\n               '2023-08-15 12:00:00', '2023-08-16 12:00:00',\n               '2023-08-17 12:00:00', '2023-08-18 12:00:00',\n               '2023-08-19 12:00:00', '2023-08-20 12:00:00',\n               '2023-08-21 12:00:00', '2023-08-22 12:00:00',\n               '2023-08-23 12:00:00', '2023-08-24 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=1874, freq=None))altitudePandasIndexPandasIndex(Index([0.0], dtype='float64', name='altitude'))latitudePandasIndexPandasIndex(Index([ 89.95833587646484,             89.875,  89.79166412353516,\n        89.70833587646484,             89.625,  89.54166412353516,\n        89.45833587646484,             89.375,  89.29166412353516,\n        89.20833587646484,\n       ...\n       -89.20833587646484, -89.29167175292969, -89.37500762939453,\n       -89.45833587646484, -89.54167175292969, -89.62500762939453,\n       -89.70833587646484, -89.79167175292969, -89.87500762939453,\n       -89.95833587646484],\n      dtype='float32', name='latitude', length=2160))longitudePandasIndexPandasIndex(Index([-179.9583282470703,           -179.875, -179.7916717529297,\n       -179.7083282470703,           -179.625, -179.5416717529297,\n       -179.4583282470703,           -179.375, -179.2916717529297,\n       -179.2083282470703,\n       ...\n       179.20834350585938,  179.2916717529297, 179.37501525878906,\n       179.45834350585938,  179.5416717529297, 179.62501525878906,\n       179.70834350585938,  179.7916717529297, 179.87501525878906,\n       179.95834350585938],\n      dtype='float32', name='longitude', length=4320))Attributes: (77)_lastModified :2023-09-04T21:15:13.000Z_NCProperties :version=2,netcdf=4.7.3,hdf5=1.12.0,cdm_data_type :GridConventions :CF-1.6, COARDS, ACDD-1.3creator_email :coastwatch.info@noaa.govcreator_name :NOAA CoastWatchcreator_type :groupcreator_url :https://coastwatch.noaa.gov/data_bins :4466138.0data_maximum :301.4826data_minimum :0.0022108806date_created :2023-09-04T21:15:13.000ZEasternmost_Easting :179.9583easternmost_longitude :180.0end_orbit_number :0geospatial_lat_max :89.95834geospatial_lat_min :-89.95834geospatial_lat_resolution :0.08333333950903196geospatial_lat_units :degrees_northgeospatial_lon_max :179.9583geospatial_lon_min :-179.9583geospatial_lon_resolution :0.0833333178976615geospatial_lon_units :degrees_eastgeospatial_vertical_max :0.0geospatial_vertical_min :0.0geospatial_vertical_positive :upgeospatial_vertical_units :mhistory :/data/data369/hgu/ocssw/bin/l3mapgen par=/data/data652/coastwatch/oc/L3/scripts/bin/../config/l3mapgen_par_dineof_chlor_a ifile=/data/data652/coastwatch/oc/L3/scripts/bin/../temp/Config_dineof/V2023236_oci_L3.nc ofile=/data/data369/viirs/L3_dineof/236/V2023236_A1_WW00_chlor_a.nc   Mon Sep  4 21:15:16 2023\n: /data/data652/coastwatch/oc/L3/scripts/bin/l3cnvtr -b -s Suomi-NPP,NOAA-20 /data/data369/viirs/L3_dineof/236/V2023236_A1_WW00_chlor_a.nc /data/aftp/socd1/mecb/coastwatch/viirs/science/L3/global/chlora/dineof/2023/V2023236_A1_WW00_chlora.nc\n2023-09-05T23:55:50Z (local files)\n2023-09-05T23:55:50Z https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily.dasid :L3//data/data540/DINEOF/EOF-global-daily4/reconstructed_mix_nsw/V2023236_oci_L3.ncinfoUrl :https://coastwatch.noaa.gov/institution :NOAA NESDIS CoastWatchinstrument :VIIRSkeywords :altitude, applications, baseline, center, chlorophyll, data, environmental, graphics, imager, imager/radiometer, imaging, information, infrared, latitude, leaving, longitude, mean, merged, n20, national, nesdis, noaa, NOAA-20, normalized, npp, optical, optical properties, orbiting, overlay, partnership, planes, polar, polar-orbiting, properties, radiance, radiometer, research, satellite, service, suite, time, viirs, visible, water, water-leaving, ww00l2_flag_names :ATMFAIL,LAND,HIGLINT,HILT,HISATZEN,CLOUD,HISOLZEN,LOWLW,CHLFAIL,NAVWARN,CLDSHDSTL,MAXAERITER,CHLWARN,ALGICE,SEAICE,NAVFAIL,FILTERlatitude_step :0.083333336latitude_units :degrees_northlicense :These data were produced by NOAA and are not subject to copyright protection in the United States. \nNOAA waives any potential copyright and related rights in these data worldwide through the Creative \nCommons Zero 1.0 Universal Public Domain Dedication (CC0-1.0). \nThe data may be used and redistributed for free but is not intended\n for legal use, since it may contain inaccuracies. Neither the data\n Contributor, ERD, NOAA, nor the United States Government, nor any\n of their employees or contractors, makes any warranty, express or\n implied, including warranties of merchantability and fitness for a\n particular purpose, or assumes any legal liability for the accuracy,\n completeness, or usefulness, of this information.longitude_step :0.083333336longitude_units :degrees_eastmap_projection :geographicmeasure :Meannaming_authority :gov.noaa.coastwatchnorthernmost_latitude :90.0Northernmost_Northing :89.95834number_of_columns :4320number_of_lines :2160platform :Suomi-NPP, NOAA-20processing_level :L3 Mappedprocessing_version :Unspecifiedproduct_name :V2023236_A1_WW00_chlora.ncproj4_string :+proj=eqc +lat_ts=0 +lat_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +lon_0=0.000000project :Ocean Color Science Team (NOAA/NESDIS/STAR/OCST)publisher_email :coastwatch.info@noaa.gov;ncei.info@noaa.govpublisher_name :NOAA CoastWatch;National Centers for Environmental Information (NCEI)publisher_url :https://coastwatch.noaa.gov;https://www.ncei.noaa.gov/Satellite :Suomi-NPP\n NOAA-20Sensor :VIIRSsourceUrl :(local files)southernmost_latitude :-90.0Southernmost_Northing :-89.95834spatialResolution :9.28 kmstandard_name_vocabulary :CF Standard Name Table v29start_orbit_number :0suggested_image_scaling_applied :Nosuggested_image_scaling_maximum :20.0suggested_image_scaling_minimum :0.01suggested_image_scaling_type :LOGsummary :Visible and Infrared Imager/Radiometer Suite/Suomi-NPP NOAA-20 (VIIRS) Level-3 (WW00), Chlorophyll, DINEOF, Gap filled, MSL12,  Science Quality,Global, Daily, processed by NOAA.  EXPERIMENTAL.sw_point_latitude :-89.958336sw_point_longitude :-179.95833temporal_range :dailytestOutOfDate :now-4daystime_coverage_end :2023-08-24T12:00:00Ztime_coverage_start :2018-05-30T12:00:00Ztitle :Chlorophyll (Gap-filled DINEOF), NOAA S-NPP NOAA-20, VIIRS, Science Quality, Global 9km, 2018-recent,  DailyWesternmost_Easting :-179.9583westernmost_longitude :-180.0\n\n\n\n\nSubset the data\nWe will do this in two steps to make the process easier to follow. 1. Subset the data for date and latitude range 2. Subset the area around the antimeridian * Request data &lt; the limit (-152) on the US side of the antimeridian, i.e. -180 to -152 * Request data &gt; the limit (176) on the Russian side of the antimeridian, i.e. 176 to 180\n\n# The lat1 and lat2 values are used in the slice function\n# At first we set them as if the dataset is compliant with standards\nlat1 = lat_min\nlat2 = lat_max\n\n# Then switch them if latitude values are descending\nif ds.latitude[0].item() &gt; ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\n# Subset the data in two steps to make it easier to understand\n# 1. Subset the date and latitude range\nds_subset = ds['chlor_a'].sel(time=my_date, \n                              method='nearest').sel(latitude=slice(lat1, lat2))\n\n# 2. Subset the around the antimeridian\nds_subset = ds_subset.sel(longitude=(ds.longitude &lt; lon_min) \n                          | (ds.longitude &gt; lon_max)\n                          )\n\nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlor_a' (altitude: 1, latitude: 240, longitude: 384)&gt;\n[92160 values with dtype=float32]\nCoordinates:\n    time       datetime64[ns] 2023-08-18T12:00:00\n  * altitude   (altitude) float64 0.0\n  * latitude   (latitude) float32 69.96 69.88 69.79 69.71 ... 50.21 50.12 50.04\n  * longitude  (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nAttributes: (12/13)\n    C_format:               %.4g\n    cell_methods:           time:mean(interval:1 day)\n    colorBarMaximum:        30.0\n    colorBarMinimum:        0.03\n    colorBarScale:          Log\n    coverage_content_type:  physicalMeasurement\n    ...                     ...\n    ioos_category:          Ocean Color\n    long_name:              Chlorophyll Concentration, DINEOF Gap-Filled\n    standard_name:          mass_concentration_of_chlorophyll_a_in_sea_water\n    units:                  mg m^-3\n    valid_max:              100.0\n    valid_min:              0.001xarray.DataArray'chlor_a'altitude: 1latitude: 240longitude: 384...[92160 values with dtype=float32]Coordinates: (4)time()datetime64[ns]2023-08-18T12:00:00_CoordinateAxisType :Timeactual_range :[1.5276816e+09 1.6928784e+09]axis :Tioos_category :Timelong_name :Timesource_name :timestandard_name :timetime_origin :01-JAN-1970 00:00:00array('2023-08-18T12:00:00.000000000', dtype='datetime64[ns]')altitude(altitude)float640.0_CoordinateAxisType :Height_CoordinateZisPositive :upactual_range :[0. 0.]axis :Zioos_category :Locationlong_name :Altitudepositive :upstandard_name :altitudeunits :marray([0.])latitude(latitude)float3269.96 69.88 69.79 ... 50.12 50.04_ChunkSizes :2160_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudesource_name :latstandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([69.958336, 69.875   , 69.791664, ..., 50.208332, 50.125   , 50.041664],\n      dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_ChunkSizes :4320_CoordinateAxisType :Lonactual_range :[-179.9583  179.9583]axis :Xioos_category :Locationlong_name :Longitudesource_name :lonstandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79167, ...,  179.79167,  179.87502,\n        179.95834], dtype=float32)Indexes: (3)altitudePandasIndexPandasIndex(Index([0.0], dtype='float64', name='altitude'))latitudePandasIndexPandasIndex(Index([ 69.95833587646484,             69.875,  69.79166412353516,\n        69.70833587646484,             69.625,  69.54166412353516,\n        69.45833587646484,             69.375,  69.29166412353516,\n        69.20833587646484,\n       ...\n       50.791664123535156,  50.70833206176758,             50.625,\n       50.541664123535156,  50.45833206176758,             50.375,\n       50.291664123535156,  50.20833206176758,             50.125,\n       50.041664123535156],\n      dtype='float32', name='latitude', length=240))longitudePandasIndexPandasIndex(Index([-179.9583282470703,           -179.875, -179.7916717529297,\n       -179.7083282470703,           -179.625, -179.5416717529297,\n       -179.4583282470703,           -179.375, -179.2916717529297,\n       -179.2083282470703,\n       ...\n       179.20834350585938,  179.2916717529297, 179.37501525878906,\n       179.45834350585938,  179.5416717529297, 179.62501525878906,\n       179.70834350585938,  179.7916717529297, 179.87501525878906,\n       179.95834350585938],\n      dtype='float32', name='longitude', length=384))Attributes: (13)C_format :%.4gcell_methods :time:mean(interval:1 day)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logcoverage_content_type :physicalMeasurementgrid_mapping :coord_refioos_category :Ocean Colorlong_name :Chlorophyll Concentration, DINEOF Gap-Filledstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001"
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#plot-the-downloaded-data",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#plot-the-downloaded-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Plot the downloaded data",
    "text": "Plot the downloaded data\n\n# Make plot area\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Set the color palette\ncmap = mpl.cm.get_cmap(\"jet\").copy()\ncmap.set_bad(color='gray')\n\n# Show image\nshw = ax.imshow(np.log10(ds_subset.squeeze()), cmap=cmap, vmin=-1, vmax=2)\n\nbar = plt.colorbar(shw, shrink=0.65)\n  \n# Show plot with labels\nbar.set_label('Chlorophyll (log mg m-3)')\nplt.show()\n\n\n\n\n\n\n\n\n\nThe plot of the data shows a discontinuity\nThe plot of subsetted data (above) shows that we downloaded the data we requested, but there is a discontinuity on the right side of the map. The data from the Russian side (west of the antimeridian) is mapped to the east of the data on the US side.\nTo fix the discontinuity, we need to:\n* Change the longitude values on the US side of the antimeridian (-180 to -152) to values on the 0-360 longitude indexing system (180-208). * Rearrange the longitude values so that the data on the Russian side is moved to the west of the data on the US side."
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#change-to-0-360-longitude-numbering",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#change-to-0-360-longitude-numbering",
    "title": "Working with data that crosses the antimeridian",
    "section": "Change to 0-360 longitude numbering",
    "text": "Change to 0-360 longitude numbering\n\nds_360 = ds_subset.assign_coords(longitude=(ds_subset.longitude % 360))\n\nprint('minimum lon value =', ds_360.longitude.min().item())\nprint('minimum lon value =', ds_360.longitude.max().item(), end='\\n\\n')\n\nprint('first value in lon array =', ds_360.longitude[0].item())\nprint('last value in lon array =', ds_360.longitude[-1].item())\n\nminimum lat value = 176.0416717529297\nminimum lat value = 207.9583282470703\n\nfirst value in lat array = 180.0416717529297\nlast value in lat array = 179.95834350585938"
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#reorder-the-longitude-axis",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#reorder-the-longitude-axis",
    "title": "Working with data that crosses the antimeridian",
    "section": "Reorder the longitude axis",
    "text": "Reorder the longitude axis\nThe output from the cell above shows that the longitude values have been converted to 0-360. However, the lowest longitude value is not at the beginning of the array and the highest longitude value is not at the end of the array.\nTo rearrange the longitude values, use the roll function of xarray. The roll function will push values along an axis by the number of steps you enter. The values that are “pushed off” of the end of the array will be put at the beginning of the array.\n\nFirst we need to find the position where the longitude discontinuity happens, i.e. where the most easterly longitude (208.0) abruptly meets the most easterly longitude value (176.0)\nNext, use the discontinuity position to determine how many positions to roll the longitude array to the right. Apply the number to the roll function.\n\n\n# This code finds the index where the absolute value between each longitude value \n# and the largest longitude value is maximal\ndiscont_index = max(range(len(ds_360.longitude)), \n                    key=lambda i: abs(ds_360.longitude[i] -\n                                      ds_360.longitude.max())\n                    )\nprint('the index marking the discontinuity is:', discont_index, end='\\n\\n')\n\n# Substract the discontinuity position from the length of the array \n# to obtain the number of positions to roll the longitude axis\npostions_to_roll = len(ds_360.longitude) - discont_index\n\n# Roll the dataset\nds_rolled = ds_360.roll(longitude=postions_to_roll, roll_coords=True)\n\nprint('minimum lon value =', ds_rolled.longitude.min().item())\nprint('minimum lon value =', ds_rolled.longitude.max().item(), end='\\n\\n')\n\nprint('first value in lon array =', ds_rolled.longitude[0].item())\nprint('last value in lon array =', ds_rolled.longitude[-1].item())\n\nthe index marking the discontinuity is: 336\n\nminimum lon value = 176.0416717529297\nminimum lon value = 207.9583282470703\n\nfirst value in lon array = 176.0416717529297\nlast value in lon array = 207.9583282470703\n\n\nThe output from the cell above shows that the longitude values have been converted to 0-360, and that the lowest longitude value is at the beginning of the array and the highest longitude value is at the end of the array."
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#plot-the-data",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#plot-the-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Plot the data",
    "text": "Plot the data\n\nThe discontinuity has been corrected!\n\n# Make plot area\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Set the color palette\ncmap = mpl.cm.get_cmap(\"jet\").copy()\ncmap.set_bad(color='gray')\n\n# show image\nshw = ax.imshow(np.log10(ds_rolled.squeeze()), \n                cmap=cmap,\n                vmin=-1, \n                vmax=2)\n\nbar = plt.colorbar(shw, shrink=0.65)\n  \n# show plot with labels\nbar.set_label('Chlorophyll (log mg m-3)')\nplt.show()"
  },
  {
    "objectID": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#save-the-corrected-dataset-as-a-netcdf-file",
    "href": "tutorials/convert-180+180-to-0-360-longitude/python/convert-180+180-to-0-360-longitude.html#save-the-corrected-dataset-as-a-netcdf-file",
    "title": "Working with data that crosses the antimeridian",
    "section": "Save the corrected dataset as a netCDF file",
    "text": "Save the corrected dataset as a netCDF file\n\nds_rolled.to_netcdf('data_corrected_0_to_360.nc')"
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html",
    "title": "Define a marine habitat",
    "section": "",
    "text": "History | Updated Sep 2023 ## Background The TurtleWatch project investigated the overlap between loggerhead sea turtles habitat and fishing effort of the Hawaii-based shallow-set longline fishery in the Pacific Ocean north of the Hawaiian Islands. That fishery, which targets swordfish, used to experience high levels of bycatch of loggerhead turtles. Considerable changes in gear and operations lowered bycatch rate and TurtleWatch was designed as a tool to advise fishermen on areas to avoid to limit bycatch.\nResearch results indicated that 50% of interactions occurred between 17.5°C and 18.5°C."
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html#objective",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html#objective",
    "title": "Define a marine habitat",
    "section": "Objective",
    "text": "Objective\nHere we will draw the 17.5 and 18.5ºC temperature contours on a map of satellite sea surface temperature."
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html#the-exercise-demonstrates-the-following-techniques",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html#the-exercise-demonstrates-the-following-techniques",
    "title": "Define a marine habitat",
    "section": "The exercise demonstrates the following techniques:",
    "text": "The exercise demonstrates the following techniques:\n\nSubsetting and loading data from an ERDDAP server using xarray\n\nSet flag values for features of interest\n\nPlotting maps"
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html#datasets-used",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html#datasets-used",
    "title": "Define a marine habitat",
    "section": "Datasets used",
    "text": "Datasets used\nCoralTemp Sea Surface Temperature product from the NOAA Coral Reef Watch program. The NOAA Coral Reef Watch (CRW) daily global 5km Sea Surface Temperature (SST) product, also known as CoralTemp, shows the nighttime ocean temperature measured at the surface. The SST scale ranges from -2 to 35 °C. The CoralTemp SST data product was developed from two related reanalysis (reprocessed) SST products and a near real-time SST product. Spanning January 1, 1985 to the present, the CoralTemp SST is one of the best and most internally consistent daily global 5km SST products available. More information about the product: https://coralreefwatch.noaa.gov/product/5km/index_5km_sst.php"
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html#install-required-packages",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html#install-required-packages",
    "title": "Define a marine habitat",
    "section": "Install required packages",
    "text": "Install required packages\n\nimport xarray as xr    \nimport matplotlib.pyplot as plt\nimport matplotlib as mpl"
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html#download-the-sst-data",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html#download-the-sst-data",
    "title": "Define a marine habitat",
    "section": "Download the SST data",
    "text": "Download the SST data\n\nSelect a geographical range\n\nSelect an area of the central North Pacific where the fishery operates: longitude range of 185 to 235 east and latitude range of 20 to 45 north\n\n\n\nSelect a date\n\nSelect a date in the first quarter of the year when bycatch typically occurs: 2023-01-06\n\n\n\nSet variables for the habitat temperature range\n\n# Longitude range\nlon_min = 185\nlon_max = 235\n\n# Latitude range\nlat_min = 20\nlat_max = 45\n\ndate_for_sat_data = '2023-01-06'\n\n# Turtle habitat temperature range\nhab_temp_min = 17.5\nhab_temp_max = 18.5"
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html#open-the-netcdf-file-to-create-an-xarray-dataset-object",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html#open-the-netcdf-file-to-create-an-xarray-dataset-object",
    "title": "Define a marine habitat",
    "section": "Open the netCDF file to create an xarray dataset object",
    "text": "Open the netCDF file to create an xarray dataset object\n\nurl = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1\"\nds = xr.open_dataset(url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (time: 14130, latitude: 3600, longitude: 7200)\nCoordinates:\n  * time              (time) datetime64[ns] 1985-01-01T12:00:00 ... 2023-09-0...\n  * latitude          (latitude) float32 -89.97 -89.93 -89.88 ... 89.93 89.97\n  * longitude         (longitude) float32 0.025 0.075 0.125 ... 359.9 360.0\nData variables:\n    analysed_sst      (time, latitude, longitude) float64 ...\n    sea_ice_fraction  (time, latitude, longitude) float64 ...\nAttributes: (12/68)\n    acknowledgement:                  NOAA Coral Reef Watch Program\n    cdm_data_type:                    Grid\n    comment:                          This product is designed to improve on ...\n    contributor_name:                 NOAA Coral Reef Watch Program\n    contributor_role:                 Collecting source data and deriving pro...\n    Conventions:                      CF-1.6, ACDD-1.3, COARDS\n    ...                               ...\n    time_coverage_duration:           P1D\n    time_coverage_end:                2023-09-09T12:00:00Z\n    time_coverage_resolution:         P1D\n    time_coverage_start:              1985-01-01T12:00:00Z\n    title:                            Sea Surface Temperature, Coral Reef Wat...\n    Westernmost_Easting:              0.025xarray.DatasetDimensions:time: 14130latitude: 3600longitude: 7200Coordinates: (3)time(time)datetime64[ns]1985-01-01T12:00:00 ... 2023-09-..._CoordinateAxisType :Timeactual_range :[4.7342880e+08 1.6942608e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the sst fieldstandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1985-01-01T12:00:00.000000000', '1985-01-02T12:00:00.000000000',\n       '1985-01-03T12:00:00.000000000', ..., '2023-09-07T12:00:00.000000000',\n       '2023-09-08T12:00:00.000000000', '2023-09-09T12:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float32-89.97 -89.93 ... 89.93 89.97_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([-89.975, -89.925, -89.875, ...,  89.875,  89.925,  89.975],\n      dtype=float32)longitude(longitude)float320.025 0.075 0.125 ... 359.9 360.0_CoordinateAxisType :Lonactual_range :[2.50000e-02 3.59975e+02]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :359.975valid_min :0.025array([2.50000e-02, 7.50000e-02, 1.25000e-01, ..., 3.59875e+02, 3.59925e+02,\n       3.59975e+02], dtype=float32)Data variables: (2)analysed_sst(time, latitude, longitude)float64...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[366249600000 values with dtype=float64]sea_ice_fraction(time, latitude, longitude)float64...colorBarMaximum :1.0colorBarMinimum :0.0comment :0 is 0% ice, 1 is 100% icecoverage_content_type :physicalMeasurementioos_category :Ice Distributionlong_name :Sea Ice Fractionstandard_name :sea_ice_area_fractionunits :1valid_max :1.0valid_min :0.0[366249600000 values with dtype=float64]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1985-01-01 12:00:00', '1985-01-02 12:00:00',\n               '1985-01-03 12:00:00', '1985-01-04 12:00:00',\n               '1985-01-05 12:00:00', '1985-01-06 12:00:00',\n               '1985-01-07 12:00:00', '1985-01-08 12:00:00',\n               '1985-01-09 12:00:00', '1985-01-10 12:00:00',\n               ...\n               '2023-08-31 12:00:00', '2023-09-01 12:00:00',\n               '2023-09-02 12:00:00', '2023-09-03 12:00:00',\n               '2023-09-04 12:00:00', '2023-09-05 12:00:00',\n               '2023-09-06 12:00:00', '2023-09-07 12:00:00',\n               '2023-09-08 12:00:00', '2023-09-09 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=14130, freq=None))latitudePandasIndexPandasIndex(Float64Index([ -89.9749984741211, -89.92500305175781,            -89.875,\n              -89.82499694824219,  -89.7750015258789,  -89.7249984741211,\n              -89.67500305175781,            -89.625, -89.57499694824219,\n               -89.5250015258789,\n              ...\n                89.5250015258789,  89.57499694824219,             89.625,\n               89.67500305175781,   89.7249984741211,   89.7750015258789,\n               89.82499694824219,             89.875,  89.92500305175781,\n                89.9749984741211],\n             dtype='float64', name='latitude', length=3600))longitudePandasIndexPandasIndex(Float64Index([0.02500000037252903, 0.07500000298023224,               0.125,\n              0.17499999701976776, 0.22499999403953552,  0.2750000059604645,\n              0.32499998807907104,               0.375, 0.42500001192092896,\n               0.4749999940395355,\n              ...\n                359.5249938964844,  359.57501220703125,             359.625,\n               359.67498779296875,   359.7250061035156,   359.7749938964844,\n               359.82501220703125,             359.875,  359.92498779296875,\n                359.9750061035156],\n             dtype='float64', name='longitude', length=7200))Attributes: (68)acknowledgement :NOAA Coral Reef Watch Programcdm_data_type :Gridcomment :This product is designed to improve on and replace the use of AVHRR Pathfinder SST for use within the Coral Reef Watch Program.contributor_name :NOAA Coral Reef Watch Programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archiveConventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch Programcreator_name :NOAA Coral Reef Watch Programcreator_type :groupcreator_url :https://coralreefwatch.noaa.gov/data_source :NOAA Daily Global 5km Geo-Polar Blended Night-only Sea Surface Temperature Analysis from the date specified in the global attribute time_coverage_start. Note, if the text of this global attribute begins with \"Due to ...\", one of the following situations occurred: (1) the source data file for the CoralTemp of data file for the CoralTemp of the day was missing; (2) the sea_ice_fraction data array in the source data was missing, (3) some alternation was made on the source data to derive the CoralTemp data of the day.date_created :2018-01-01T00:00:00Zdate_issued :2021-04-04T13:40:08Zdate_metadata_modified :2020-11-18T00:00:00Zdate_modified :2018-01-01T00:00:00ZEasternmost_Easting :359.975geospatial_bounds :\"POLYGON((-90.0 360.0, 90.0 360.0, 90.0 0.0, -90.0 0.0, -90.0 360.0))\"geospatial_bounds_crs :EPSG:4326geospatial_lat_max :89.975geospatial_lat_min :-89.975geospatial_lat_resolution :0.049999999999999996geospatial_lat_units :degrees_northgeospatial_lon_max :359.975geospatial_lon_min :0.025geospatial_lon_resolution :0.05000000000000001geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:4326grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Sat Sep  9 06:30:11 2023: ncatted -O -a geospatial_bounds,global,o,c,\"POLYGON((-90.0 360.0, 90.0 360.0, 90.0 0.0, -90.0 0.0, -90.0 360.0))\" coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a geospatial_lon_max,global,o,f,359.975 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a geospatial_lon_min,global,o,f,0.025 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a valid_max,lon,o,f,359.975 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a valid_min,lon,o,f,0.025 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:10 2023: ncap2 -O -s where(lon&lt;0) lon=lon+360 coraltemp_v3.1_20230908-0-360.nc coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:08 2023: ncks -O --msa_usr_rdr -d lon,0.0,180.0 -d lon,-180.0,0.0 coraltemp_v3.1_20230908.nc coraltemp_v3.1_20230908-0-360.nc\nThis is the first version of CoralTemp. It was originally called v1.0 and then renamed to v3.1 with no change to the overall product)\n2023-09-11T14:46:38Z (local files)\n2023-09-11T14:46:38Z https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1.dasid :CoralTemp-v3.1infoUrl :https://coralreefwatch.noaa.gov/satellite/bleaching5kminstitution :NOAA/NESDIS/STAR Coral Reef Watch Programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, analysed_sst, analysis, area, coral, coraltemp, crw, cryosphere, daily, data, day, distribution, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, extent, fraction, global, ice, ice distribution, information, infrared, national, near, nesdis, noaa, nrt, ocean, oceans, operational, ostia, program, real, reef, satellite, science, sea, sea_ice_area_fraction, sea_ice_fraction, sea_surface_temperature, seawater, service, spectral, spectral/engineering, sst, star, surface, temperature, thermal, time, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :OSTIA Usage Statement (1985-2002): IMPORTANT usage statement. Unless otherwise agreed in writing, these data may be used for pure academic research only, with no commercial or other application and all usage must meet the Met Office Standard Terms and Conditions, which may be found here: https://www.metoffice.gov.uk/corporate/legal/tandc.html. The data may be used for a maximum period of 5 years. Reproduction of the data is permitted provided the following copyright statement is included: (C) Crown Copyright 2010, published by the Met Office. You must submit a completed reproduction license application form (here https://www.metoffice.gov.uk/corporate/legal/repro_licence.html) before using the data. This only needs to be completed once for each user. WARNING Some applications are unable to properly handle signed byte values. If values are encountered &gt; 127, please subtract 256 from this reported value. GHRSST statement (2002-present): GHRSST protocol describes data use as free and open. Coral Reef Watch program statement: The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of Coral Reef Watch's website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/satellite/bleaching5kmnaming_authority :gov.noaa.coralreefwatchNCO :netCDF Operators version 4.7.5 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)nco_openmp_thread_number :1Northernmost_Northing :89.975platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :L4product_version :3.1program :NOAA Coral Reef Watch Programproject :NOAA Coral Reef Watch Programpublisher_email :coralreefwatch@noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch Programpublisher_name :NOAA Coral Reef Watch Programpublisher_type :grouppublisher_url :https://coralreefwatch.noaa.gov/references :Donlon, et al., 2011. The Operational Sea Surface Temperature and Sea Ice analysis (OSTIA). Maturi, et al., 2017. A new high-resolution sea surface temperature analysis. https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :OSTIA Sea Surface Temperature Reanalysis (night-only), NOAA Geo-Polar Blended Night-only Sea Surface Temperature Reanalysis, NOAA Geo-Polar Blended Night-only Sea Surface Temperature (near real-time)sourceUrl :(local files)Southernmost_Northing :-89.975standard_name_vocabulary :CF Standard Name Table v27summary :NOAA Coral Reef Watch Daily Global 5km Satellite Sea Surface Temperature (CoralTemp). CoralTemp is derived from three different but related 5km daily gap-free SST data sets and provides an internally consistent SST product that stretches from 1985 to present: Operational Sea Surface Temperature and Sea Ice Analysis (OSTIA) Sea Surface Temperature Reanalysis (1985-2002), Geo-Polar Blended Night-only Sea Surface Temperature Reanalysis (2002-2016), Geo-Polar Blended Night-only Sea Surface Temperature Near Real-Time (2017 to present).time_coverage_duration :P1Dtime_coverage_end :2023-09-09T12:00:00Ztime_coverage_resolution :P1Dtime_coverage_start :1985-01-01T12:00:00Ztitle :Sea Surface Temperature, Coral Reef Watch, CoralTemp, v3.1 - Daily, 1985-presentWesternmost_Easting :0.025"
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html#subset-the-erddap-dataset",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html#subset-the-erddap-dataset",
    "title": "Define a marine habitat",
    "section": "Subset the ERDDAP dataset",
    "text": "Subset the ERDDAP dataset\nThe code below does the following: * Trims the data to include only SST data\n* Selects the date. To avoid the need to match the exact date found in the dataset, include method='nearest'. * Slices within the latitude and longitude ranges\n\nds_subset = ds['analysed_sst'].sel(time=date_for_sat_data, \n                          method='nearest'\n                          ).sel(latitude=slice(lat_min, lat_max),\n                                longitude=slice(lon_min, lon_max)\n                                )"
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html#make-a-plot-to-view-the-data",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html#make-a-plot-to-view-the-data",
    "title": "Define a marine habitat",
    "section": "Make a plot to view the data",
    "text": "Make a plot to view the data\nThis may take a few seconds. So far you have only set the parameters for download but not requested that the data be downloaded. However, downloading will be necessary to plot the data, so xarray will download it.\n\nds_subset.plot.pcolormesh(cmap=\"gist_rainbow_r\",\n                          vmin=5,\n                          vmax=30,\n                          aspect=2,\n                          size=4\n                          )"
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html#define-and-mask-the-turtlewatch-band",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html#define-and-mask-the-turtlewatch-band",
    "title": "Define a marine habitat",
    "section": "Define and mask the TurtleWatch band",
    "text": "Define and mask the TurtleWatch band\n\nThe band is between 17.5°C and 18.5°C.\nUse the “where” function of xarray to flag all pixels in the habitat range by replacing their values with a value that is much smaller than the data range minimum.\n\n\nds_masked = xr.where((ds_subset &gt; hab_temp_min) & (ds_subset &lt; hab_temp_max), \n                     -999,  # Set flag value\n                     ds_subset  \n                     )"
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html#map-the-masked-data",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html#map-the-masked-data",
    "title": "Define a marine habitat",
    "section": "Map the masked data",
    "text": "Map the masked data\nMake some adjustments to the color map:\n* Set the palette to be the reverse of the gist_rainbow\n* Set missing values (like land..) to gray\n* Set the flag value color\n\n# Create the color palette\ncmap = mpl.cm.get_cmap(\"gist_rainbow_r\").copy()\n\n# Set the color of the missing or masked data \ncmap.set_bad(color='gray')  # missing values color (like land..)\n\n# Set the color of flag value (-999)\ncmap.set_under(color='firebrick')  # flag value color\n\n# Plot the data\nds_masked.plot.pcolormesh(cmap=cmap,\n                          vmin=5,\n                          vmax=30,\n                          aspect=2,\n                          size=4\n                          )\n\n# Add plot annotation\nplt.title('TurtleWatch band - ' + date_for_sat_data)\nplt.ylabel('Latitude')\nplt.xlabel('Longitude')\n\nText(0.5, 0, 'Longitude')"
  },
  {
    "objectID": "tutorials/define_marine_habitat/python/define_marine_habitat.html#references",
    "href": "tutorials/define_marine_habitat/python/define_marine_habitat.html#references",
    "title": "Define a marine habitat",
    "section": "References",
    "text": "References\n\nTurtleWatch: https://oceanwatch.pifsc.noaa.gov/turtlewatch.html\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html\nhttps://polarwatch.noaa.gov/catalog/"
  },
  {
    "objectID": "tutorials/gl-access-sat-surface-temp-data/python/gl-access-sat-surface-temp-data.html",
    "href": "tutorials/gl-access-sat-surface-temp-data/python/gl-access-sat-surface-temp-data.html",
    "title": "Python Tutorial - How to work with CoastWatch data in Python",
    "section": "",
    "text": "This tutorial is based on the OceanWatch tutorial meterial edited with Great Lakes data. This tutorial will show the steps to grab data in ERDDAP from Python, how to work with NetCDF files in Python and how to make some maps and time-series water surface temperature (sst) in Lake Erie."
  },
  {
    "objectID": "tutorials/gl-access-sat-surface-temp-data/python/gl-access-sat-surface-temp-data.html#downlading-data-from-python",
    "href": "tutorials/gl-access-sat-surface-temp-data/python/gl-access-sat-surface-temp-data.html#downlading-data-from-python",
    "title": "Python Tutorial - How to work with CoastWatch data in Python",
    "section": "1. Downlading data from Python",
    "text": "1. Downlading data from Python\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure. For example, the following page allows you to subset daily water surface temperature data from the dataset GLSEA_ACSPO_GCS\nIn this specific example, the URL we generated is :\nhttps://apps.glerl.noaa.gov/erddap/griddap/GLSEA_ACSPO_GCS.nc?sst%5B(2023-06-01T12:00:00Z):1:(2023-06-30T12:00:00Z)%5D%5B(41):1:(43)%5D%5B(-83.5):1:(-78.5)%5D\nIn Python, run the following to download the data using the generated URL. Note: replace coastwatch.glerl.noaa.gov with apps.glerl.noaa.gov) :\n\nimport urllib.request\n\nurl=\"https://apps.glerl.noaa.gov/erddap/griddap/GLSEA_ACSPO_GCS.nc?sst%5B(2023-06-01T12:00:00Z):1:(2023-06-30T12:00:00Z)%5D%5B(41):1:(43)%5D%5B(-83.5):1:(-78.5)%5D\"\nurllib.request.urlretrieve(url, \"e_sst.nc\")\n\n('e_sst.nc', &lt;http.client.HTTPMessage at 0x1b7d5152610&gt;)"
  },
  {
    "objectID": "tutorials/gl-access-sat-surface-temp-data/python/gl-access-sat-surface-temp-data.html#working-with-the-extracted-data",
    "href": "tutorials/gl-access-sat-surface-temp-data/python/gl-access-sat-surface-temp-data.html#working-with-the-extracted-data",
    "title": "Python Tutorial - How to work with CoastWatch data in Python",
    "section": "Working with the extracted data",
    "text": "Working with the extracted data\n\nCreating a map for one time step\nLet’s create a map of SST for June 1, 2021 (our first time step).\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n#np.warnings.filterwarnings('ignore')\n\n\n- Examine the values of sst:\n\nds.sst.values\n\narray([[[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       ...,\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]]],\n      dtype=float32)\n\n\n\nds.sst.attrs\n\n{'_FillValue': -99999.0,\n 'colorBarMaximum': 32.0,\n 'colorBarMinimum': 0.0,\n 'ioos_category': 'Temperature',\n 'long_name': 'Temperature',\n 'standard_name': 'sea_water_temperature',\n 'units': 'degree_C'}\n\n\n\nds.sst.attrs['_FillValue']\n\n-99999.0\n\n\n\n#ds.sst.dims\n#ds.sst.coords\n\n\n\n- Make a new sst DataArray and replace _fillValue with NaN\n\n#nan_sst = ds.sst.where(ds.sst.values != -99999.0)\nnan_sst = ds.sst.where(ds.sst.values != ds.sst.attrs['_FillValue'])\n\n# nan_sst[time][latitude][longitude]\n#print(nan_sst[10][100][200])\n\nprint(nan_sst)\n\n\n&lt;xarray.DataArray 'sst' (time: 30, latitude: 143, longitude: 358)&gt;\narray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)\nCoordinates:\n  * time       (time) float64 1.686e+09 1.686e+09 ... 1.688e+09 1.688e+09\n  * latitude   (latitude) float64 41.01 41.02 41.03 41.05 ... 42.97 42.98 43.0\n  * longitude  (longitude) float64 -83.51 -83.49 -83.48 ... -78.53 -78.52 -78.5\nAttributes:\n    _FillValue:       -99999.0\n    colorBarMaximum:  32.0\n    colorBarMinimum:  0.0\n    ioos_category:    Temperature\n    long_name:        Temperature\n    standard_name:    sea_water_temperature\n    units:            degree_C\n\n\n\n\n- Set some color breaks\n\nnp.nanmin(ds.sst)\n\n-99999.0\n\n\n\n# find min value in man_sst\nnp.nanmin(nan_sst)\n\n13.25\n\n\n\nnp.nanmax(nan_sst)\n\n23.35\n\n\n\nlevs = np.arange(13.25, 23.35, 0.05)\nlen(levs)\n\n203\n\n\n\n\n- Define a color palette\n\n# init a color list\njet=[\"blue\", \"#007FFF\", \"cyan\",\"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"]\n\n\n\n- Set color scale using the jet palette\n\ncm = LinearSegmentedColormap.from_list('my_jet', jet, N=len(levs))\n\n#https://www.youtube.com/watch?v=qk0n-YaKIkY\n\n\n\n- plot the SST map\n\nnp.linspace(-82.5,-80,num=4)\n\narray([-82.5       , -81.66666667, -80.83333333, -80.        ])\n\n\n\nplt.subplots(figsize=(10, 5))\n\n#plot first sst image: nan_sst[0,:,:]\nplt.contourf(nan_sst.longitude, nan_sst.latitude, nan_sst[0,:,:], levs,cmap=cm)\n\n#plot the color scale\nplt.colorbar()\n\n#example of how to add points to the map\nplt.scatter(np.linspace(-82,-80.5,num=4),np.repeat(42,4),c='black')\n\n#example of how to add a contour line\nstep = np.arange(9,26, 1)\n\nplt.contour(ds.longitude, ds.latitude, ds.sst[0,:,:],levels=step,linewidths=1)\n\n#plot title\nplt.title(\"Lake Erie Water Surface Temperature - \" + dates[0].strftime('%b %d, %Y'))\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPlotting a time series\nLet’s pick the following box : 41.75-42.0N, 83.0-83.5W. We are going to generate a time series of mean SST within that box.\n\n- first, let’s subset our data:\n\nlat_bnds, lon_bnds = [41.75, 42.0], [-83.5, -83.0]\na_sst=nan_sst.sel(latitude=slice(*lat_bnds), longitude=slice(*lon_bnds))\nprint(a_sst)\n\n&lt;xarray.DataArray 'sst' (time: 30, latitude: 17, longitude: 36)&gt;\narray([[[  nan,   nan,   nan, ..., 18.86, 18.84, 18.84],\n        [  nan,   nan,   nan, ..., 18.82, 18.8 , 18.8 ],\n        [  nan,   nan,   nan, ..., 18.78, 18.76, 18.76],\n        ...,\n        [  nan,   nan,   nan, ..., 18.5 , 18.46, 18.46],\n        [  nan,   nan,   nan, ..., 18.5 , 18.46, 18.46],\n        [  nan,   nan,   nan, ..., 18.53, 18.49, 18.49]],\n\n       [[  nan,   nan,   nan, ..., 19.45, 19.44, 19.44],\n        [  nan,   nan,   nan, ..., 19.42, 19.41, 19.41],\n        [  nan,   nan,   nan, ..., 19.39, 19.38, 19.38],\n        ...,\n        [  nan,   nan,   nan, ..., 19.13, 19.1 , 19.1 ],\n        [  nan,   nan,   nan, ..., 19.07, 19.06, 19.06],\n        [  nan,   nan,   nan, ..., 19.06, 19.04, 19.04]],\n\n       [[  nan,   nan,   nan, ..., 19.63, 19.61, 19.61],\n        [  nan,   nan,   nan, ..., 19.6 , 19.58, 19.58],\n        [  nan,   nan,   nan, ..., 19.56, 19.54, 19.54],\n        ...,\n...\n        ...,\n        [  nan,   nan,   nan, ..., 21.24, 21.31, 21.31],\n        [  nan,   nan,   nan, ..., 21.24, 21.34, 21.34],\n        [  nan,   nan,   nan, ..., 21.29, 21.42, 21.42]],\n\n       [[  nan,   nan,   nan, ..., 21.8 , 21.75, 21.75],\n        [  nan,   nan,   nan, ..., 21.7 , 21.67, 21.67],\n        [  nan,   nan,   nan, ..., 21.6 , 21.59, 21.59],\n        ...,\n        [  nan,   nan,   nan, ..., 21.36, 21.41, 21.41],\n        [  nan,   nan,   nan, ..., 21.36, 21.44, 21.44],\n        [  nan,   nan,   nan, ..., 21.44, 21.53, 21.53]],\n\n       [[  nan,   nan,   nan, ..., 21.93, 21.82, 21.82],\n        [  nan,   nan,   nan, ..., 21.86, 21.79, 21.79],\n        [  nan,   nan,   nan, ..., 21.78, 21.75, 21.75],\n        ...,\n        [  nan,   nan,   nan, ..., 21.49, 21.52, 21.52],\n        [  nan,   nan,   nan, ..., 21.51, 21.55, 21.55],\n        [  nan,   nan,   nan, ..., 21.63, 21.66, 21.66]]], dtype=float32)\nCoordinates:\n  * time       (time) float64 1.686e+09 1.686e+09 ... 1.688e+09 1.688e+09\n  * latitude   (latitude) float64 41.76 41.78 41.79 41.8 ... 41.96 41.97 41.99\n  * longitude  (longitude) float64 -83.49 -83.48 -83.46 ... -83.03 -83.02 -83.0\nAttributes:\n    _FillValue:       -99999.0\n    colorBarMaximum:  32.0\n    colorBarMinimum:  0.0\n    ioos_category:    Temperature\n    long_name:        Temperature\n    standard_name:    sea_water_temperature\n    units:            degree_C\n\n\n\n\n- let’s plot the subset:\n\n#plot first image of the a_sst array\nplt.contourf(a_sst.longitude, a_sst.latitude, a_sst[0,:,:], levs,cmap=cm)\nplt.colorbar()\nplt.title(\"Subset of Lake Erie Water Surface Temperature \" + dates[0].strftime('%b %d, %Y'))\nplt.show()\n\n\n\n\n\n\n\n\n\n\n- let’s compute the daily mean over the bounding region:\n\nres=np.nanmean(a_sst,axis=(1,2))\nres\n\narray([19.252283, 19.84715 , 20.109388, 20.06981 , 20.01454 , 20.00379 ,\n       19.958447, 19.921082, 19.963646, 19.956564, 19.885717, 19.525248,\n       19.253717, 19.179811, 19.149954, 19.190142, 19.41266 , 19.634283,\n       19.90713 , 20.220236, 20.525293, 20.747812, 21.015364, 21.460989,\n       21.71833 , 21.710024, 21.643694, 21.593224, 21.749012, 22.0068  ],\n      dtype=float32)\n\n\n\n\n- let’s plot the time-series:\n\nplt.figure(figsize=(8,4))\n\nplt.scatter(dates,res)\n\ndegree_sign = u\"\\N{DEGREE SIGN}\"\nplt.ylabel('SST (' + degree_sign + 'C)')\n\nplt.xlim(dates[0], dates[-1])\n\nplt.xticks(dates,rotation=70, fontsize=10 )\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCreating a map of average SST over a month\n\n- let’s compute the monthly mean for the region:\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\nmean_sst=np.nanmean(nan_sst,axis=0)\n\n\nmean_sst.shape\n\n(143, 358)\n\n\n\n\n- let’s plot the map of the average SST in the region for 2021 June:\n\nplt.subplots(figsize=(10, 5))\n\nplt.contourf(ds.longitude, ds.latitude, mean_sst, levs,cmap=cm)\n\ncbar = plt.colorbar()\ncbar.set_label('SST')\n\nplt.title(\"Mean SST \" + dates[0].strftime('%Y-%m-%d')+' - '+dates[-1].strftime('%Y-%m-%d'))\nplt.show()\n\n\n\n\n\n\n\n\n\n!jupyter nbconvert --to html GL_python_tutorial1.ipynb\n\n[NbConvertApp] Converting notebook GL_python_tutorial1.ipynb to html\n[NbConvertApp] Writing 974120 bytes to GL_python_tutorial1.html"
  },
  {
    "objectID": "tutorials/gl-timeseries-chloro-from-diff-sensors/python/gl-timeseries-chloro-from-diff-sensors.html",
    "href": "tutorials/gl-timeseries-chloro-from-diff-sensors/python/gl-timeseries-chloro-from-diff-sensors.html",
    "title": "Time series of chlorophyll data from different sensors",
    "section": "",
    "text": "Great Lakes color producing agents (CPA) are derived from two different sensors.\nAs an example, we are going to plot time-series of mean chlorophyll a concentration from different sensors from 2002 to 2023. We are going to download MODIS data (2002-2017) and VIIRS data (2018-2023).\nFirst, let’s load all the packages needed:\nimport urllib.request \nimport xarray as xr \nimport netCDF4 as nc\n\nimport pandas as pd \nimport numpy as np \nfrom matplotlib import pyplot as plt \nfrom matplotlib.colors import LinearSegmentedColormap \n\nimport warnings\n\nwarnings.filterwarnings('ignore')\n##Get Lake Erie Monthly Average MODIS data\nGo to ERDDAP to find the name of the dataset for dailly MODIS data: LE_CHL_MODIS_Daily\nYou should always examine the dataset in ERDDAP to check the date range, names of the variables and dataset ID, to make sure your griddap calls are correct:\nhttps://apps.glerl.noaa.gov/erddap/griddap/LE_CHL_MODIS_Daily.graph\n# in Python code replace coastwatch.glerl.noaa.gov with apps.glerl.noaa.gov\n\nurl='https://apps.glerl.noaa.gov/erddap/griddap/LE_CHL_MODIS_Daily.nc?chlorophyll%5B(2002-08-07T19:05:00Z):1:(2017-10-22T18:00:00Z)%5D%5B(41.0051550293714):1:(42.9950003885447)%5D%5B(-83.4950003885448):1:(-78.505388156246)%5D'\nurllib.request.urlretrieve(url, \"e_chl_modis.nc\")\n\n('e_chl_modis.nc', &lt;http.client.HTTPMessage at 0x1a2705704d0&gt;)"
  },
  {
    "objectID": "tutorials/gl-timeseries-chloro-from-diff-sensors/python/gl-timeseries-chloro-from-diff-sensors.html#get-lake-erie-dailly-average-viirs-data",
    "href": "tutorials/gl-timeseries-chloro-from-diff-sensors/python/gl-timeseries-chloro-from-diff-sensors.html#get-lake-erie-dailly-average-viirs-data",
    "title": "Time series of chlorophyll data from different sensors",
    "section": "Get Lake Erie Dailly Average VIIRS data",
    "text": "Get Lake Erie Dailly Average VIIRS data\n\nurl2='https://apps.glerl.noaa.gov/erddap/griddap/LE_CHL_VIIRS_Daily.nc?Chlorophyll%5B(2023-01-04T18:47:05Z):1:(2023-12-28T18:32:33Z)%5D%5B(41.2690208353804):1:(43.017997272827)%5D%5B(-83.6574899492178):1:(-78.4429490894234)%5D'\nurllib.request.urlretrieve(url2, \"e_viirs_chl.nc\")\n\n('e_viirs_chl.nc', &lt;http.client.HTTPMessage at 0x1a20d832610&gt;)\n\n\n\ne_v_ds = xr.open_dataset('e_viirs_chl.nc',decode_cf=False)\n\n\nprint(e_v_ds)\n\n&lt;xarray.Dataset&gt;\nDimensions:      (time: 544, latitude: 271, longitude: 806)\nCoordinates:\n  * time         (time) float64 1.673e+09 1.673e+09 ... 1.704e+09 1.704e+09\n  * latitude     (latitude) float64 41.27 41.28 41.28 ... 43.01 43.01 43.02\n  * longitude    (longitude) float64 -83.66 -83.65 -83.64 ... -78.45 -78.44\nData variables:\n    Chlorophyll  (time, latitude, longitude) float32 ...\nAttributes: (12/34)\n    cdm_data_type:                  Grid\n    colorBarMaximum:                30.0\n    colorBarMinimum:                1.0\n    colorBarScale:                  Log\n    Conventions:                    CF-1.6, COARDS, ACDD-1.3\n    Easternmost_Easting:            -78.4429490894234\n    ...                             ...\n    summary:                        Color Producing Agent (CPA) Chlorophyll, ...\n    testOutOfDate:                  now-18days\n    time_coverage_end:              2023-12-28T18:32:33Z\n    time_coverage_start:            2023-01-04T18:47:05Z\n    title:                          Color Producing Agent (CPA) Chlorophyll, ...\n    Westernmost_Easting:            -83.6574899492178\n\n\n\nnan_e_v_ds_chlorophyll = e_v_ds.Chlorophyll.where(e_v_ds.Chlorophyll.values != e_v_ds.Chlorophyll.attrs['_FillValue'])\n\nv_chl_avg = np.nanmean(nan_e_v_ds_chlorophyll,axis=(1,2))\n#print(v_chl_avg)\n#print(len(v_chl_avg))\n\n\ne_v_dates=nc.num2date(e_v_ds.time,e_v_ds.time.units, only_use_cftime_datetimes=False, \n                        only_use_python_datetimes=True )\ne_v_dates\n\narray([real_datetime(2023, 1, 4, 18, 47, 5),\n       real_datetime(2023, 1, 5, 18, 28, 10),\n       real_datetime(2023, 1, 7, 17, 50, 19),\n       real_datetime(2023, 1, 7, 19, 31, 19),\n       real_datetime(2023, 1, 8, 19, 12, 23),\n       real_datetime(2023, 1, 9, 17, 12, 27),\n       real_datetime(2023, 1, 9, 17, 13, 53),\n       real_datetime(2023, 1, 9, 18, 53, 28),\n       real_datetime(2023, 1, 10, 18, 34, 32),\n       real_datetime(2023, 1, 11, 18, 15, 36),\n       real_datetime(2023, 1, 14, 17, 18, 51),\n       real_datetime(2023, 1, 14, 18, 59, 52),\n       real_datetime(2023, 1, 15, 16, 59, 56),\n       real_datetime(2023, 1, 15, 17, 1, 21),\n       real_datetime(2023, 1, 15, 18, 40, 56),\n       real_datetime(2023, 1, 16, 18, 22),\n       real_datetime(2023, 1, 17, 18, 3, 5),\n       real_datetime(2023, 1, 19, 17, 25, 14),\n       real_datetime(2023, 1, 19, 19, 6, 14),\n       real_datetime(2023, 1, 24, 17, 31, 37),\n       real_datetime(2023, 1, 24, 19, 12, 38),\n       real_datetime(2023, 1, 31, 18, 41, 10),\n       real_datetime(2023, 2, 1, 18, 22, 15),\n       real_datetime(2023, 2, 2, 18, 3, 19),\n       real_datetime(2023, 2, 3, 17, 44, 23),\n       real_datetime(2023, 2, 3, 19, 25, 24),\n       real_datetime(2023, 2, 4, 17, 25, 28),\n       real_datetime(2023, 2, 4, 19, 6, 28),\n       real_datetime(2023, 2, 6, 18, 28, 37),\n       real_datetime(2023, 2, 7, 18, 9, 41),\n       real_datetime(2023, 2, 8, 17, 50, 47),\n       real_datetime(2023, 2, 8, 19, 31, 46),\n       real_datetime(2023, 2, 9, 17, 31, 52),\n       real_datetime(2023, 2, 9, 19, 12, 52),\n       real_datetime(2023, 2, 10, 18, 52, 31),\n       real_datetime(2023, 2, 10, 18, 53, 56),\n       real_datetime(2023, 2, 11, 18, 33, 35),\n       real_datetime(2023, 2, 11, 18, 35, 1),\n       real_datetime(2023, 2, 12, 18, 14, 40),\n       real_datetime(2023, 2, 12, 18, 16, 5),\n       real_datetime(2023, 2, 13, 17, 57, 9),\n       real_datetime(2023, 2, 13, 19, 36, 44),\n       real_datetime(2023, 2, 13, 19, 38, 10),\n       real_datetime(2023, 2, 14, 17, 38, 14),\n       real_datetime(2023, 2, 14, 19, 19, 14),\n       real_datetime(2023, 2, 15, 17, 19, 18),\n       real_datetime(2023, 2, 15, 18, 58, 53),\n       real_datetime(2023, 2, 15, 19, 0, 18),\n       real_datetime(2023, 2, 17, 18, 22, 29),\n       real_datetime(2023, 2, 18, 18, 2, 8),\n       real_datetime(2023, 2, 18, 18, 3, 33),\n       real_datetime(2023, 2, 19, 17, 44, 38),\n       real_datetime(2023, 2, 19, 19, 24, 12),\n       real_datetime(2023, 2, 19, 19, 25, 38),\n       real_datetime(2023, 2, 20, 17, 25, 42),\n       real_datetime(2023, 2, 20, 19, 5, 17),\n       real_datetime(2023, 2, 20, 19, 6, 42),\n       real_datetime(2023, 2, 21, 17, 6, 46),\n       real_datetime(2023, 2, 21, 18, 46, 21),\n       real_datetime(2023, 2, 21, 18, 47, 47),\n       real_datetime(2023, 2, 23, 18, 8, 30),\n       real_datetime(2023, 2, 24, 17, 51),\n       real_datetime(2023, 2, 24, 19, 30, 34),\n       real_datetime(2023, 2, 24, 19, 32),\n       real_datetime(2023, 2, 25, 19, 13, 4),\n       real_datetime(2023, 2, 26, 17, 13, 10),\n       real_datetime(2023, 2, 26, 18, 52, 45),\n       real_datetime(2023, 2, 28, 18, 14, 54),\n       real_datetime(2023, 3, 1, 17, 57, 23),\n       real_datetime(2023, 3, 1, 19, 38, 24),\n       real_datetime(2023, 3, 2, 17, 38, 28),\n       real_datetime(2023, 3, 2, 19, 18, 3),\n       real_datetime(2023, 3, 5, 18, 21, 17),\n       real_datetime(2023, 3, 5, 18, 22, 43),\n       real_datetime(2023, 3, 6, 18, 2, 22),\n       real_datetime(2023, 3, 7, 17, 44, 52),\n       real_datetime(2023, 3, 7, 19, 24, 26),\n       real_datetime(2023, 3, 7, 19, 25, 52),\n       real_datetime(2023, 3, 8, 17, 25, 56),\n       real_datetime(2023, 3, 11, 18, 10, 9),\n       real_datetime(2023, 3, 15, 16, 54, 28),\n       real_datetime(2023, 3, 15, 18, 35, 29),\n       real_datetime(2023, 3, 16, 18, 15, 8),\n       real_datetime(2023, 3, 16, 18, 16, 33),\n       real_datetime(2023, 3, 18, 19, 18, 16),\n       real_datetime(2023, 3, 19, 17, 19, 46),\n       real_datetime(2023, 3, 19, 18, 59, 21),\n       real_datetime(2023, 3, 20, 17, 0, 52),\n       real_datetime(2023, 3, 20, 18, 40, 25),\n       real_datetime(2023, 3, 21, 18, 21, 31),\n       real_datetime(2023, 3, 21, 18, 22, 57),\n       real_datetime(2023, 3, 24, 17, 26, 10),\n       real_datetime(2023, 3, 25, 17, 7, 14),\n       real_datetime(2023, 3, 25, 18, 46, 49),\n       real_datetime(2023, 3, 25, 18, 48, 14),\n       real_datetime(2023, 3, 26, 18, 27, 53),\n       real_datetime(2023, 3, 26, 18, 29, 19),\n       real_datetime(2023, 3, 27, 18, 10, 23),\n       real_datetime(2023, 3, 28, 17, 51, 29),\n       real_datetime(2023, 3, 29, 17, 32, 33),\n       real_datetime(2023, 3, 29, 19, 13, 34),\n       real_datetime(2023, 3, 30, 17, 13, 38),\n       real_datetime(2023, 3, 30, 18, 53, 13),\n       real_datetime(2023, 3, 30, 18, 54, 38),\n       real_datetime(2023, 4, 1, 18, 16, 47),\n       real_datetime(2023, 4, 2, 17, 57, 51),\n       real_datetime(2023, 4, 2, 19, 37, 26),\n       real_datetime(2023, 4, 2, 19, 38, 51),\n       real_datetime(2023, 4, 4, 17, 20, 2),\n       real_datetime(2023, 4, 4, 19, 1),\n       real_datetime(2023, 4, 6, 18, 23, 10),\n       real_datetime(2023, 4, 7, 18, 4, 15),\n       real_datetime(2023, 4, 8, 17, 45, 19),\n       real_datetime(2023, 4, 8, 19, 24, 54),\n       real_datetime(2023, 4, 8, 19, 26, 19),\n       real_datetime(2023, 4, 9, 17, 26, 23),\n       real_datetime(2023, 4, 9, 19, 5, 58),\n       real_datetime(2023, 4, 9, 19, 7, 24),\n       real_datetime(2023, 4, 10, 17, 7, 28),\n       real_datetime(2023, 4, 10, 18, 47, 3),\n       real_datetime(2023, 4, 10, 18, 48, 28),\n       real_datetime(2023, 4, 11, 18, 28, 7),\n       real_datetime(2023, 4, 11, 18, 29, 32),\n       real_datetime(2023, 4, 12, 18, 9, 13),\n       real_datetime(2023, 4, 12, 18, 10, 38),\n       real_datetime(2023, 4, 13, 17, 51, 43),\n       real_datetime(2023, 4, 13, 19, 31, 18),\n       real_datetime(2023, 4, 13, 19, 32, 43),\n       real_datetime(2023, 4, 14, 17, 32, 47),\n       real_datetime(2023, 4, 14, 19, 12, 22),\n       real_datetime(2023, 4, 14, 19, 13, 47),\n       real_datetime(2023, 4, 15, 17, 13, 52),\n       real_datetime(2023, 4, 15, 18, 53, 26),\n       real_datetime(2023, 4, 15, 18, 54, 52),\n       real_datetime(2023, 4, 16, 16, 54, 56),\n       real_datetime(2023, 4, 16, 18, 34, 31),\n       real_datetime(2023, 4, 16, 18, 35, 56),\n       real_datetime(2023, 4, 18, 17, 58, 5),\n       real_datetime(2023, 4, 19, 17, 39, 11),\n       real_datetime(2023, 4, 19, 19, 18, 44),\n       real_datetime(2023, 4, 19, 19, 20, 9),\n       real_datetime(2023, 4, 20, 18, 59, 50),\n       real_datetime(2023, 4, 21, 17, 1, 20),\n       real_datetime(2023, 4, 22, 18, 21, 59),\n       real_datetime(2023, 4, 23, 18, 3, 3),\n       real_datetime(2023, 4, 23, 18, 4, 28),\n       real_datetime(2023, 4, 24, 17, 44, 7),\n       real_datetime(2023, 4, 24, 17, 45, 33),\n       real_datetime(2023, 4, 24, 19, 25, 8),\n       real_datetime(2023, 4, 25, 17, 26, 37),\n       real_datetime(2023, 4, 26, 17, 7, 43),\n       real_datetime(2023, 4, 26, 18, 47, 16),\n       real_datetime(2023, 4, 27, 18, 28, 23),\n       real_datetime(2023, 4, 30, 17, 31, 36),\n       real_datetime(2023, 4, 30, 17, 33, 1),\n       real_datetime(2023, 4, 30, 19, 12, 36),\n       real_datetime(2023, 5, 1, 17, 14, 5),\n       real_datetime(2023, 5, 1, 18, 53, 40),\n       real_datetime(2023, 5, 3, 18, 15, 49),\n       real_datetime(2023, 5, 4, 17, 56, 53),\n       real_datetime(2023, 5, 4, 19, 37, 53),\n       real_datetime(2023, 5, 5, 17, 37, 59),\n       real_datetime(2023, 5, 5, 17, 39, 25),\n       real_datetime(2023, 5, 5, 19, 18, 58),\n       real_datetime(2023, 5, 6, 17, 19, 4),\n       real_datetime(2023, 5, 6, 17, 20, 29),\n       real_datetime(2023, 5, 6, 19, 0, 4),\n       real_datetime(2023, 5, 7, 18, 41, 8),\n       real_datetime(2023, 5, 8, 18, 22, 13),\n       real_datetime(2023, 5, 10, 17, 44, 21),\n       real_datetime(2023, 5, 10, 19, 25, 22),\n       real_datetime(2023, 5, 11, 17, 25, 26),\n       real_datetime(2023, 5, 11, 19, 6, 26),\n       real_datetime(2023, 5, 12, 17, 6, 32),\n       real_datetime(2023, 5, 12, 17, 7, 57),\n       real_datetime(2023, 5, 12, 18, 47, 30),\n       real_datetime(2023, 5, 13, 18, 28, 36),\n       real_datetime(2023, 5, 15, 17, 50, 45),\n       real_datetime(2023, 5, 15, 19, 31, 45),\n       real_datetime(2023, 5, 16, 19, 12, 50),\n       real_datetime(2023, 5, 17, 17, 12, 54),\n       real_datetime(2023, 5, 17, 18, 53, 54),\n       real_datetime(2023, 5, 18, 18, 34, 58),\n       real_datetime(2023, 5, 19, 18, 16, 3),\n       real_datetime(2023, 5, 20, 17, 57, 9),\n       real_datetime(2023, 5, 21, 17, 38, 13),\n       real_datetime(2023, 5, 23, 18, 41, 22),\n       real_datetime(2023, 5, 24, 18, 22, 27),\n       real_datetime(2023, 5, 25, 18, 3, 31),\n       real_datetime(2023, 5, 26, 17, 44, 35),\n       real_datetime(2023, 5, 26, 19, 24, 10),\n       real_datetime(2023, 5, 26, 19, 25, 35),\n       real_datetime(2023, 5, 27, 17, 25, 40),\n       real_datetime(2023, 5, 27, 19, 5, 14),\n       real_datetime(2023, 5, 27, 19, 6, 40),\n       real_datetime(2023, 5, 28, 18, 46, 19),\n       real_datetime(2023, 5, 28, 18, 47, 44),\n       real_datetime(2023, 5, 29, 18, 27, 25),\n       real_datetime(2023, 5, 29, 18, 28, 50),\n       real_datetime(2023, 5, 30, 18, 8, 29),\n       real_datetime(2023, 5, 30, 18, 9, 55),\n       real_datetime(2023, 5, 31, 17, 50, 59),\n       real_datetime(2023, 5, 31, 19, 30, 34),\n       real_datetime(2023, 5, 31, 19, 31, 59),\n       real_datetime(2023, 6, 1, 17, 32, 3),\n       real_datetime(2023, 6, 1, 19, 11, 38),\n       real_datetime(2023, 6, 1, 19, 13, 4),\n       real_datetime(2023, 6, 2, 17, 13, 8),\n       real_datetime(2023, 6, 2, 18, 52, 43),\n       real_datetime(2023, 6, 2, 18, 54, 8),\n       real_datetime(2023, 6, 3, 18, 33, 47),\n       real_datetime(2023, 6, 3, 18, 35, 12),\n       real_datetime(2023, 6, 4, 18, 14, 51),\n       real_datetime(2023, 6, 4, 18, 16, 17),\n       real_datetime(2023, 6, 5, 17, 57, 23),\n       real_datetime(2023, 6, 6, 17, 38, 27),\n       real_datetime(2023, 6, 6, 19, 18, 2),\n       real_datetime(2023, 6, 7, 17, 19, 32),\n       real_datetime(2023, 6, 7, 18, 59, 6),\n       real_datetime(2023, 6, 8, 18, 40, 11),\n       real_datetime(2023, 6, 9, 18, 21, 15),\n       real_datetime(2023, 6, 9, 18, 22, 40),\n       real_datetime(2023, 6, 10, 18, 2, 19),\n       real_datetime(2023, 6, 10, 18, 3, 45),\n       real_datetime(2023, 6, 11, 17, 44, 49),\n       real_datetime(2023, 6, 12, 19, 5, 28),\n       real_datetime(2023, 6, 13, 17, 7),\n       real_datetime(2023, 6, 13, 18, 46, 33),\n       real_datetime(2023, 6, 14, 18, 27, 39),\n       real_datetime(2023, 6, 15, 18, 8, 43),\n       real_datetime(2023, 6, 16, 17, 49, 48),\n       real_datetime(2023, 6, 17, 17, 30, 52),\n       real_datetime(2023, 6, 17, 17, 32, 17),\n       real_datetime(2023, 6, 17, 19, 11, 52),\n       real_datetime(2023, 6, 18, 17, 13, 22),\n       real_datetime(2023, 6, 18, 18, 52, 57),\n       real_datetime(2023, 6, 19, 18, 34, 1),\n       real_datetime(2023, 6, 20, 18, 15, 5),\n       real_datetime(2023, 6, 21, 17, 56, 10),\n       real_datetime(2023, 6, 21, 19, 37, 10),\n       real_datetime(2023, 6, 22, 17, 37, 16),\n       real_datetime(2023, 6, 22, 19, 18, 14),\n       real_datetime(2023, 6, 23, 18, 59, 20),\n       real_datetime(2023, 6, 24, 17, 0, 50),\n       real_datetime(2023, 6, 24, 18, 40, 25),\n       real_datetime(2023, 6, 25, 18, 21, 29),\n       real_datetime(2023, 6, 26, 18, 2, 34),\n       real_datetime(2023, 6, 27, 17, 43, 38),\n       real_datetime(2023, 6, 27, 19, 24, 38),\n       real_datetime(2023, 6, 28, 17, 24, 42),\n       real_datetime(2023, 6, 28, 17, 26, 8),\n       real_datetime(2023, 6, 28, 19, 5, 43),\n       real_datetime(2023, 6, 29, 17, 7, 14),\n       real_datetime(2023, 6, 29, 18, 46, 47),\n       real_datetime(2023, 6, 30, 18, 27, 53),\n       real_datetime(2023, 7, 2, 17, 50, 2),\n       real_datetime(2023, 7, 2, 19, 31, 2),\n       real_datetime(2023, 7, 3, 17, 31, 6),\n       real_datetime(2023, 7, 3, 17, 32, 32),\n       real_datetime(2023, 7, 3, 19, 12, 6),\n       real_datetime(2023, 7, 4, 17, 12, 10),\n       real_datetime(2023, 7, 4, 17, 13, 36),\n       real_datetime(2023, 7, 4, 18, 53, 11),\n       real_datetime(2023, 7, 5, 16, 54, 40),\n       real_datetime(2023, 7, 5, 18, 34, 15),\n       real_datetime(2023, 7, 6, 18, 15, 19),\n       real_datetime(2023, 7, 7, 17, 56, 24),\n       real_datetime(2023, 7, 7, 19, 37, 24),\n       real_datetime(2023, 7, 8, 17, 37, 30),\n       real_datetime(2023, 7, 8, 19, 18, 28),\n       real_datetime(2023, 7, 9, 17, 18, 34),\n       real_datetime(2023, 7, 9, 18, 59, 35),\n       real_datetime(2023, 7, 10, 17, 1, 4),\n       real_datetime(2023, 7, 10, 18, 40, 39),\n       real_datetime(2023, 7, 11, 18, 21, 43),\n       real_datetime(2023, 7, 12, 18, 2, 48),\n       real_datetime(2023, 7, 13, 17, 43, 52),\n       real_datetime(2023, 7, 13, 19, 24, 52),\n       real_datetime(2023, 7, 14, 17, 24, 56),\n       real_datetime(2023, 7, 14, 19, 5, 57),\n       real_datetime(2023, 7, 16, 18, 28, 5),\n       real_datetime(2023, 7, 17, 18, 9, 11),\n       real_datetime(2023, 7, 18, 17, 50, 16),\n       real_datetime(2023, 7, 18, 19, 31, 16),\n       real_datetime(2023, 7, 19, 17, 31, 20),\n       real_datetime(2023, 7, 19, 19, 12, 20),\n       real_datetime(2023, 7, 20, 17, 12, 25),\n       real_datetime(2023, 7, 20, 17, 13, 50),\n       real_datetime(2023, 7, 20, 18, 53, 25),\n       real_datetime(2023, 7, 21, 16, 54, 54),\n       real_datetime(2023, 7, 21, 18, 34, 29),\n       real_datetime(2023, 7, 22, 18, 15, 33),\n       real_datetime(2023, 7, 23, 17, 56, 38),\n       real_datetime(2023, 7, 24, 17, 37, 44),\n       real_datetime(2023, 7, 24, 19, 18, 42),\n       real_datetime(2023, 7, 25, 18, 59, 47),\n       real_datetime(2023, 7, 27, 18, 21, 56),\n       real_datetime(2023, 7, 28, 18, 3, 1),\n       real_datetime(2023, 7, 29, 17, 44, 7),\n       real_datetime(2023, 7, 29, 19, 25, 5),\n       real_datetime(2023, 7, 30, 17, 25, 11),\n       real_datetime(2023, 7, 30, 19, 6, 11),\n       real_datetime(2023, 7, 31, 17, 6, 16),\n       real_datetime(2023, 7, 31, 18, 47, 16),\n       real_datetime(2023, 8, 1, 18, 28, 20),\n       real_datetime(2023, 8, 2, 18, 9, 25),\n       real_datetime(2023, 8, 3, 17, 50, 29),\n       real_datetime(2023, 8, 3, 19, 31, 29),\n       real_datetime(2023, 8, 4, 17, 31, 33),\n       real_datetime(2023, 8, 4, 19, 12, 33),\n       real_datetime(2023, 8, 5, 18, 53, 38),\n       real_datetime(2023, 8, 6, 16, 53, 44),\n       real_datetime(2023, 8, 6, 18, 34, 44),\n       real_datetime(2023, 8, 7, 18, 15, 48),\n       real_datetime(2023, 8, 8, 17, 56, 53),\n       real_datetime(2023, 8, 8, 19, 37, 53),\n       real_datetime(2023, 8, 9, 17, 37, 57),\n       real_datetime(2023, 8, 10, 17, 19, 1),\n       real_datetime(2023, 8, 10, 18, 58, 36),\n       real_datetime(2023, 8, 10, 19, 0, 2),\n       real_datetime(2023, 8, 11, 17, 0, 6),\n       real_datetime(2023, 8, 11, 18, 39, 41),\n       real_datetime(2023, 8, 11, 18, 41, 6),\n       real_datetime(2023, 8, 12, 18, 20, 45),\n       real_datetime(2023, 8, 12, 18, 22, 10),\n       real_datetime(2023, 8, 13, 18, 3, 15),\n       real_datetime(2023, 8, 15, 17, 25, 25),\n       real_datetime(2023, 8, 15, 19, 5),\n       real_datetime(2023, 8, 15, 19, 6, 25),\n       real_datetime(2023, 8, 16, 17, 6, 30),\n       real_datetime(2023, 8, 16, 18, 46, 4),\n       real_datetime(2023, 8, 16, 18, 47, 30),\n       real_datetime(2023, 8, 17, 18, 27, 9),\n       real_datetime(2023, 8, 17, 18, 28, 34),\n       real_datetime(2023, 8, 18, 18, 8, 13),\n       real_datetime(2023, 8, 18, 18, 9, 39),\n       real_datetime(2023, 8, 19, 17, 50, 43),\n       real_datetime(2023, 8, 19, 19, 30, 18),\n       real_datetime(2023, 8, 19, 19, 31, 43),\n       real_datetime(2023, 8, 20, 17, 31, 47),\n       real_datetime(2023, 8, 20, 19, 11, 22),\n       real_datetime(2023, 8, 20, 19, 12, 47),\n       real_datetime(2023, 8, 21, 18, 52, 26),\n       real_datetime(2023, 8, 22, 16, 53, 58),\n       real_datetime(2023, 8, 22, 18, 33, 33),\n       real_datetime(2023, 8, 22, 18, 34, 56),\n       real_datetime(2023, 8, 24, 17, 55, 41),\n       real_datetime(2023, 8, 24, 17, 57, 7),\n       real_datetime(2023, 8, 25, 17, 38, 11),\n       real_datetime(2023, 8, 25, 19, 17, 46),\n       real_datetime(2023, 8, 26, 17, 19, 15),\n       real_datetime(2023, 8, 26, 18, 58, 50),\n       real_datetime(2023, 8, 26, 19, 0, 16),\n       real_datetime(2023, 8, 27, 17, 0, 20),\n       real_datetime(2023, 8, 27, 18, 39, 55),\n       real_datetime(2023, 8, 27, 18, 41, 20),\n       real_datetime(2023, 8, 28, 18, 20, 59),\n       real_datetime(2023, 8, 28, 18, 22, 24),\n       real_datetime(2023, 8, 29, 18, 2, 3),\n       real_datetime(2023, 8, 29, 18, 3, 29),\n       real_datetime(2023, 8, 30, 17, 44, 35),\n       real_datetime(2023, 8, 30, 19, 24, 8),\n       real_datetime(2023, 8, 31, 17, 25, 39),\n       real_datetime(2023, 8, 31, 19, 5, 14),\n       real_datetime(2023, 9, 1, 17, 6, 44),\n       real_datetime(2023, 9, 1, 18, 46, 18),\n       real_datetime(2023, 9, 2, 18, 27, 23),\n       real_datetime(2023, 9, 3, 18, 8, 27),\n       real_datetime(2023, 9, 4, 17, 49, 31),\n       real_datetime(2023, 9, 4, 17, 50, 57),\n       real_datetime(2023, 9, 4, 19, 30, 32),\n       real_datetime(2023, 9, 5, 17, 30, 36),\n       real_datetime(2023, 9, 5, 17, 32, 1),\n       real_datetime(2023, 9, 5, 19, 11, 36),\n       real_datetime(2023, 9, 6, 17, 13, 7),\n       real_datetime(2023, 9, 6, 18, 52, 40),\n       real_datetime(2023, 9, 7, 16, 54, 12),\n       real_datetime(2023, 9, 7, 18, 33, 47),\n       real_datetime(2023, 9, 8, 18, 14, 51),\n       real_datetime(2023, 9, 9, 17, 55, 55),\n       real_datetime(2023, 9, 10, 17, 37),\n       real_datetime(2023, 9, 10, 17, 38, 25),\n       real_datetime(2023, 9, 10, 19, 18),\n       real_datetime(2023, 9, 11, 17, 18, 4),\n       real_datetime(2023, 9, 11, 17, 19, 29),\n       real_datetime(2023, 9, 11, 18, 59, 4),\n       real_datetime(2023, 9, 12, 18, 40, 9),\n       real_datetime(2023, 9, 13, 18, 21, 13),\n       real_datetime(2023, 9, 14, 18, 2, 17),\n       real_datetime(2023, 9, 15, 17, 43, 23),\n       real_datetime(2023, 9, 15, 19, 24, 22),\n       real_datetime(2023, 9, 16, 17, 24, 28),\n       real_datetime(2023, 9, 16, 19, 5, 28),\n       real_datetime(2023, 9, 17, 17, 5, 32),\n       real_datetime(2023, 9, 17, 17, 6, 58),\n       real_datetime(2023, 9, 17, 18, 46, 32),\n       real_datetime(2023, 9, 18, 18, 27, 37),\n       real_datetime(2023, 9, 19, 18, 8, 41),\n       real_datetime(2023, 9, 20, 17, 49, 46),\n       real_datetime(2023, 9, 20, 19, 30, 46),\n       real_datetime(2023, 9, 21, 17, 30, 50),\n       real_datetime(2023, 9, 21, 19, 11, 50),\n       real_datetime(2023, 9, 22, 17, 11, 54),\n       real_datetime(2023, 9, 22, 18, 52, 54),\n       real_datetime(2023, 9, 23, 18, 33, 59),\n       real_datetime(2023, 9, 24, 18, 15, 5),\n       real_datetime(2023, 9, 25, 17, 56, 9),\n       real_datetime(2023, 9, 26, 17, 37, 14),\n       real_datetime(2023, 9, 26, 19, 18, 14),\n       real_datetime(2023, 9, 27, 18, 59, 18),\n       real_datetime(2023, 9, 28, 18, 40, 23),\n       real_datetime(2023, 9, 29, 18, 21, 27),\n       real_datetime(2023, 9, 30, 18, 2, 32),\n       real_datetime(2023, 10, 1, 17, 43, 36),\n       real_datetime(2023, 10, 1, 19, 23, 11),\n       real_datetime(2023, 10, 1, 19, 24, 36),\n       real_datetime(2023, 10, 2, 17, 24, 42),\n       real_datetime(2023, 10, 2, 19, 4, 15),\n       real_datetime(2023, 10, 2, 19, 5, 41),\n       real_datetime(2023, 10, 3, 17, 5, 46),\n       real_datetime(2023, 10, 3, 18, 45, 21),\n       real_datetime(2023, 10, 3, 18, 46, 47),\n       real_datetime(2023, 10, 4, 18, 26, 26),\n       real_datetime(2023, 10, 4, 18, 27, 51),\n       real_datetime(2023, 10, 5, 18, 8, 55),\n       real_datetime(2023, 10, 6, 17, 50),\n       real_datetime(2023, 10, 6, 19, 29, 35),\n       real_datetime(2023, 10, 6, 19, 31),\n       real_datetime(2023, 10, 7, 17, 31, 4),\n       real_datetime(2023, 10, 7, 19, 10, 39),\n       real_datetime(2023, 10, 7, 19, 12, 4),\n       real_datetime(2023, 10, 8, 17, 12, 9),\n       real_datetime(2023, 10, 8, 18, 51, 43),\n       real_datetime(2023, 10, 8, 18, 53, 9),\n       real_datetime(2023, 10, 9, 16, 53, 13),\n       real_datetime(2023, 10, 9, 18, 32, 48),\n       real_datetime(2023, 10, 9, 18, 34, 13),\n       real_datetime(2023, 10, 11, 17, 54, 57),\n       real_datetime(2023, 10, 11, 17, 56, 22),\n       real_datetime(2023, 10, 11, 19, 35, 57),\n       real_datetime(2023, 10, 12, 17, 37, 28),\n       real_datetime(2023, 10, 12, 19, 17, 1),\n       real_datetime(2023, 10, 13, 17, 18, 33),\n       real_datetime(2023, 10, 15, 18, 20, 16),\n       real_datetime(2023, 10, 16, 18, 1, 21),\n       real_datetime(2023, 10, 17, 17, 43, 50),\n       real_datetime(2023, 10, 18, 17, 24, 55),\n       real_datetime(2023, 10, 18, 19, 4, 30),\n       real_datetime(2023, 10, 20, 18, 26, 38),\n       real_datetime(2023, 10, 21, 18, 7, 43),\n       real_datetime(2023, 10, 21, 18, 9, 8),\n       real_datetime(2023, 10, 22, 17, 48, 49),\n       real_datetime(2023, 10, 22, 17, 50, 14),\n       real_datetime(2023, 10, 22, 19, 29, 47),\n       real_datetime(2023, 10, 23, 17, 29, 53),\n       real_datetime(2023, 10, 23, 17, 31, 19),\n       real_datetime(2023, 10, 23, 19, 10, 54),\n       real_datetime(2023, 10, 24, 17, 12, 23),\n       real_datetime(2023, 10, 24, 18, 51, 58),\n       real_datetime(2023, 10, 26, 18, 14, 7),\n       real_datetime(2023, 10, 27, 17, 55, 11),\n       real_datetime(2023, 10, 27, 17, 56, 37),\n       real_datetime(2023, 10, 27, 19, 36, 11),\n       real_datetime(2023, 10, 28, 17, 37, 41),\n       real_datetime(2023, 10, 28, 19, 17, 16),\n       real_datetime(2023, 10, 30, 18, 39, 25),\n       real_datetime(2023, 10, 31, 18, 20, 29),\n       real_datetime(2023, 11, 2, 17, 44, 4),\n       real_datetime(2023, 11, 2, 19, 23, 39),\n       real_datetime(2023, 11, 3, 17, 23, 45),\n       real_datetime(2023, 11, 3, 17, 25, 10),\n       real_datetime(2023, 11, 3, 19, 4, 43),\n       real_datetime(2023, 11, 4, 18, 45, 49),\n       real_datetime(2023, 11, 5, 18, 26, 54),\n       real_datetime(2023, 11, 6, 18, 7, 58),\n       real_datetime(2023, 11, 7, 17, 49, 2),\n       real_datetime(2023, 11, 7, 17, 50, 28),\n       real_datetime(2023, 11, 7, 19, 30, 3),\n       real_datetime(2023, 11, 9, 17, 12, 37),\n       real_datetime(2023, 11, 9, 18, 52, 11),\n       real_datetime(2023, 11, 10, 18, 33, 16),\n       real_datetime(2023, 11, 11, 18, 14, 20),\n       real_datetime(2023, 11, 12, 17, 55, 25),\n       real_datetime(2023, 11, 12, 17, 56, 50),\n       real_datetime(2023, 11, 12, 19, 36, 25),\n       real_datetime(2023, 11, 13, 17, 36, 31),\n       real_datetime(2023, 11, 13, 17, 37, 56),\n       real_datetime(2023, 11, 13, 19, 17, 29),\n       real_datetime(2023, 11, 14, 17, 17, 35),\n       real_datetime(2023, 11, 14, 17, 19, 1),\n       real_datetime(2023, 11, 14, 18, 58, 35),\n       real_datetime(2023, 11, 15, 17, 0, 5),\n       real_datetime(2023, 11, 15, 18, 39, 40),\n       real_datetime(2023, 11, 16, 18, 20, 44),\n       real_datetime(2023, 11, 18, 17, 42, 53),\n       real_datetime(2023, 11, 18, 17, 44, 19),\n       real_datetime(2023, 11, 18, 19, 23, 53),\n       real_datetime(2023, 11, 19, 17, 23, 58),\n       real_datetime(2023, 11, 19, 17, 25, 23),\n       real_datetime(2023, 11, 19, 19, 4, 58),\n       real_datetime(2023, 11, 20, 18, 46, 2),\n       real_datetime(2023, 11, 23, 17, 49, 15),\n       real_datetime(2023, 11, 23, 19, 30, 16),\n       real_datetime(2023, 11, 24, 17, 30, 22),\n       real_datetime(2023, 11, 24, 17, 31, 47),\n       real_datetime(2023, 11, 24, 19, 11, 20),\n       real_datetime(2023, 11, 25, 17, 11, 26),\n       real_datetime(2023, 11, 25, 17, 12, 51),\n       real_datetime(2023, 11, 25, 18, 52, 26),\n       real_datetime(2023, 11, 27, 18, 14, 35),\n       real_datetime(2023, 11, 28, 17, 55, 40),\n       real_datetime(2023, 11, 28, 19, 36, 40),\n       real_datetime(2023, 11, 29, 17, 36, 44),\n       real_datetime(2023, 11, 29, 19, 17, 44),\n       real_datetime(2023, 11, 30, 17, 17, 48),\n       real_datetime(2023, 11, 30, 18, 58, 49),\n       real_datetime(2023, 12, 3, 18, 2, 2),\n       real_datetime(2023, 12, 4, 17, 43, 6),\n       real_datetime(2023, 12, 6, 17, 5, 17),\n       real_datetime(2023, 12, 6, 18, 46, 17),\n       real_datetime(2023, 12, 7, 18, 27, 21),\n       real_datetime(2023, 12, 8, 18, 8, 26),\n       real_datetime(2023, 12, 9, 17, 49, 30),\n       real_datetime(2023, 12, 10, 17, 30, 35),\n       real_datetime(2023, 12, 11, 18, 52, 39),\n       real_datetime(2023, 12, 12, 18, 33, 44),\n       real_datetime(2023, 12, 13, 18, 14, 48),\n       real_datetime(2023, 12, 14, 17, 55, 53),\n       real_datetime(2023, 12, 15, 17, 36, 57),\n       real_datetime(2023, 12, 15, 19, 16, 32),\n       real_datetime(2023, 12, 15, 19, 17, 57),\n       real_datetime(2023, 12, 16, 17, 18, 3),\n       real_datetime(2023, 12, 16, 18, 57, 36),\n       real_datetime(2023, 12, 16, 18, 59, 2),\n       real_datetime(2023, 12, 19, 18, 2, 17),\n       real_datetime(2023, 12, 20, 17, 43, 21),\n       real_datetime(2023, 12, 20, 19, 22, 56),\n       real_datetime(2023, 12, 20, 19, 24, 21),\n       real_datetime(2023, 12, 21, 17, 24, 26),\n       real_datetime(2023, 12, 21, 19, 4),\n       real_datetime(2023, 12, 21, 19, 5, 26),\n       real_datetime(2023, 12, 25, 17, 49, 43),\n       real_datetime(2023, 12, 26, 19, 10, 23),\n       real_datetime(2023, 12, 28, 18, 32, 33)], dtype=object)\n\n\n\nv_chl_avg = np.nanmean(nan_e_v_ds_chlorophyll.values,axis=(1,2))\nv_chl_avg\n\narray([ 3.8245378 , 17.05229   ,  0.77159315,  1.6202371 ,  2.068805  ,\n        1.7207391 ,  2.0681734 ,  9.915978  , 12.000377  , 60.60568   ,\n        2.9275532 , 15.261721  ,  2.1003587 ,  2.5391452 , 15.000816  ,\n       18.150581  ,  4.041805  ,  5.558531  , 14.340515  ,  7.0143795 ,\n       24.486782  , 10.351516  ,  9.925964  ,  8.393265  ,  7.0230336 ,\n       19.298477  , 13.378698  , 17.380596  ,  8.412001  , 18.604963  ,\n        9.874779  , 34.36881   ,  2.2588596 ,  3.6034255 ,  2.506503  ,\n        7.9039016 , 28.500935  , 15.452688  , 18.463425  , 11.424103  ,\n        8.926837  , 29.18119   , 15.104329  ,  7.305774  , 12.944991  ,\n       28.979595  , 31.491842  , 17.951267  ,  4.4605803 , 14.379     ,\n       28.11916   ,  9.264345  , 26.880186  , 46.661022  , 14.642408  ,\n       13.05799   , 13.633649  ,  1.418521  , 13.829434  ,  5.444851  ,\n       16.703632  , 20.848345  ,  5.0073376 , 43.061474  ,  4.4501486 ,\n       10.821825  , 13.9933815 , 31.618942  , 18.309826  ,  0.626642  ,\n        1.3072004 ,  0.5550653 , 18.288877  ,  8.388084  , 84.72084   ,\n       21.264292  , 30.243666  ,  8.217334  , 26.758741  , 12.297731  ,\n        1.0648437 ,  7.8218217 ,  6.743732  ,  8.725778  ,  0.37988   ,\n       20.73484   , 37.852497  , 23.765854  , 36.893124  , 43.02589   ,\n       21.644255  ,  7.4811535 ,  0.56276786, 21.756771  ,  8.571441  ,\n       34.194794  , 24.734491  , 20.891743  , 19.614132  , 20.337917  ,\n        0.89833146, 15.468415  , 23.633438  , 12.742027  , 10.469747  ,\n       19.536373  , 63.70876   , 31.262995  , 12.08394   ,  6.5038023 ,\n       23.642673  , 15.831917  ,  9.192328  , 18.234331  , 18.983482  ,\n       12.585856  , 19.876034  , 10.024232  ,  6.4187565 , 11.187998  ,\n        5.847157  , 15.026388  , 13.55039   , 57.649048  , 10.104386  ,\n       10.101064  , 25.943897  ,  9.368579  ,  6.515471  , 10.244264  ,\n        1.1295458 ,  7.0011516 , 10.233358  ,  6.5892057 ,  5.111359  ,\n        5.5639024 ,  4.002067  ,  2.6186795 , 20.945406  , 22.75246   ,\n       22.861576  , 26.649107  ,  3.9389431 ,  6.8372855 ,  4.1539216 ,\n        7.945154  ,  2.4636204 ,  2.8101442 ,  2.9989738 ,  3.761499  ,\n        4.040188  ,  6.779965  ,  4.0392694 ,  5.058976  ,  3.642377  ,\n        5.0899043 ,  1.535409  ,  5.489851  , 12.624435  , 14.986074  ,\n       19.135656  ,  8.674835  ,  1.8120102 ,  6.0505404 ,  4.0770435 ,\n        4.2323365 ,  4.5445585 ,  6.407044  ,  4.4135103 , 10.111502  ,\n        2.559734  ,  6.3161306 ,  4.1022396 ,  5.3999968 ,  5.693675  ,\n        4.2225466 ,  4.975449  ,  5.87973   ,  1.8912128 ,  4.844044  ,\n        8.326566  , 21.682102  ,  5.796414  ,  4.81131   ,  1.6386082 ,\n        4.858289  ,  1.0573728 ,  5.3810554 , 19.722094  , 12.00176   ,\n       23.595955  , 31.021114  ,  6.9326816 ,  5.9504557 ,  3.3385806 ,\n        4.8724666 ,  2.2861915 , 12.186277  ,  3.0852036 , 30.52236   ,\n        4.891082  ,  4.0605354 , 27.45894   , 12.472047  ,  3.3337376 ,\n        3.500256  ,  0.65000206,  1.3446043 ,  5.6772294 ,  2.0434697 ,\n        6.4364944 ,  3.82695   , 26.283665  ,  6.5254254 ,  0.35209   ,\n        1.7417568 ,  0.323401  ,  1.3526874 , 19.266989  , 16.352032  ,\n        4.9344935 ,  4.533328  ,  1.8704015 ,  1.9660938 ,  2.0816095 ,\n        0.31560874,  2.6231666 ,  6.254045  ,  3.8463306 ,  1.3136346 ,\n        2.3147666 ,  3.226815  ,  3.4912894 ,  9.928331  ,  5.029834  ,\n        7.1034536 ,  2.6826584 ,  3.407092  ,  5.1383185 ,  4.0941634 ,\n        3.3249714 ,  2.8196743 ,  1.0019007 ,  0.4673027 ,  6.095398  ,\n        2.4684315 ,  2.894028  ,  1.7736832 ,  0.53535175,  2.3534393 ,\n        5.9133415 ,  1.4854542 ,  0.98389864,  2.8314965 ,  3.388785  ,\n        1.7273644 ,  1.4295217 ,  3.9137824 ,  0.8343511 ,  5.592705  ,\n        4.1189713 ,  4.519481  ,  4.514461  ,  1.216034  ,  4.9332423 ,\n        4.501184  ,  5.48342   ,  5.1219296 ,  1.8448588 ,  1.8978752 ,\n        2.399244  ,  4.452588  ,  2.9473898 ,  4.242     ,  5.101925  ,\n        3.4773014 ,  4.1459665 ,  3.9358723 ,  4.571998  ,  4.4941797 ,\n        1.8119017 ,  1.184782  ,  3.4886737 ,  1.7374743 ,  5.519011  ,\n        4.1905513 ,  2.60639   ,  0.7090206 ,  4.3053236 ,  0.48008502,\n        4.8589377 ,  5.2264676 ,  4.044144  ,  3.4191263 ,  1.1011882 ,\n        3.1120796 ,  6.7359877 ,  2.9646623 ,  2.554451  ,  2.4505644 ,\n        2.142144  ,  4.9301887 ,  1.2831734 ,  2.7954278 ,  1.5539587 ,\n        5.100337  ,  3.3232377 ,  1.7723247 ,  4.5153937 ,  3.388878  ,\n        6.257826  ,  1.1053416 ,  3.9824939 ,  0.76826215,  4.1770864 ,\n        5.84404   ,  3.564656  ,  4.186695  ,  3.18334   ,  4.3410416 ,\n        2.4948015 ,  5.7432327 ,  3.2015507 ,  4.697011  ,  8.011776  ,\n        6.00471   ,  1.4959276 ,  3.4044938 ,  2.7345881 ,  3.1861002 ,\n        6.807063  ,  3.672278  ,  4.4842434 ,  4.369128  , 10.34134   ,\n        7.659503  ,  4.640015  ,  2.260385  ,  2.9616964 ,  5.770283  ,\n        5.8344135 ,  3.0287185 ,  4.6171303 ,  1.8015864 ,  3.3256059 ,\n        4.025933  , 15.307446  , 24.68179   ,  5.1921005 ,  0.95913076,\n        2.531541  ,  3.3621345 ,  5.42665   ,  2.610918  ,  7.0007544 ,\n        4.5238733 ,  6.4797854 ,  7.7474403 ,  8.129336  ,  6.065284  ,\n        6.313556  , 23.959946  ,  6.9332256 ,  7.346444  ,  3.9448545 ,\n        7.4828005 ,  9.371148  ,  6.901665  ,  6.0786414 ,  7.611087  ,\n        4.072118  ,  5.4114847 ,  5.8930087 ,  6.2145314 ,  3.5961418 ,\n        3.5599902 ,  0.31376082,  4.7233195 ,  1.835947  ,  1.3035926 ,\n        3.0226147 ,  0.4981069 ,  6.3224025 ,  3.036155  ,  2.8434775 ,\n        4.545952  , 18.239357  ,  6.450544  ,  6.273684  ,  6.03156   ,\n        3.223308  ,  3.63122   ,  2.694837  ,  2.6652293 ,  1.1407009 ,\n        4.5644073 ,  6.183016  ,  4.285992  ,  4.728611  ,  1.2699568 ,\n        3.6176095 ,  2.5436394 ,  2.7925599 ,  3.8075545 ,  8.981911  ,\n       22.87494   ,  7.5639124 ,  1.6238711 ,  0.5307012 ,  6.469891  ,\n        3.0692794 ,  4.6451344 ,  7.6391034 ,  6.2791705 ,  7.3014994 ,\n        4.254345  ,  6.4056168 ,  7.458692  ,  3.457129  ,  5.2672634 ,\n        9.947004  ,  4.4163375 , 10.526679  ,  4.949929  ,  1.9953364 ,\n        8.43534   ,  8.067071  ,  5.2787495 ,  3.2672718 , 14.374089  ,\n        1.9808887 , 36.714443  , 25.423502  , 10.191787  ,  2.9083974 ,\n       13.615338  ,  7.3216214 , 16.14564   ,  7.027708  ,  8.500385  ,\n        4.132675  ,  3.6679573 ,  1.4386141 , 35.34755   , 27.14011   ,\n        0.611455  ,  9.363178  , 12.209044  ,  7.530161  ,  8.551426  ,\n        1.8653786 ,  4.8010054 ,  5.6198926 , 35.149426  , 30.55753   ,\n        5.9123573 ,  2.7006626 ,  3.9975345 ,  6.327705  ,  5.3463564 ,\n        6.5932918 ,  6.520323  ,  3.5866342 ,  0.6119649 ,  0.34683716,\n        4.459534  ,  5.4071994 ,  6.77416   , 20.245544  ,  1.24846   ,\n       16.727642  , 34.44699   ,  3.2000692 ,  6.9570527 ,  4.8707566 ,\n        0.85470015,  1.5286115 ,  1.4164749 , 16.511541  , 23.00998   ,\n       11.719736  , 10.880672  ,  6.8268065 ,  1.6250918 ,  8.308749  ,\n       11.111537  , 24.678076  , 11.334251  ,  3.5857413 ,  6.996021  ,\n        4.5214167 ,  8.312405  ,  7.4295473 ,  7.6591887 , 10.038146  ,\n        1.7212489 ,  8.699176  ,  8.796391  ,  9.621361  ,  9.075598  ,\n        0.19450001, 14.5820675 , 18.2731    , 15.891861  ,  5.1796503 ,\n       23.901497  ,  6.602838  ,  8.11695   ,  5.7776127 ,  0.9575611 ,\n       19.564034  , 44.46723   ,  6.194875  , 20.724203  , 18.15552   ,\n       36.427177  ,  3.437948  ,  0.62041324,  0.78566986,  7.326401  ,\n       13.820853  ,  4.118893  ,  0.77267   ,  0.74762917,  0.88341135,\n       20.338709  , 18.454927  , 13.954808  , 11.78991   , 11.854942  ,\n       14.00589   ,  9.306969  ,  9.987267  ,  6.9419265 , 10.148791  ,\n        8.151923  , 18.923534  , 18.946314  ,  1.1267239 ,  1.1251845 ,\n        1.3136889 , 71.61      ,  1.9791391 ,  0.40409204], dtype=float32)\n\n\n\nplt.figure(figsize=(12,5)) \nplt.plot(e_v_dates,v_chl_avg,label='VIIRS CHL',c='red',marker='.',linestyle='-')\nplt.ylabel('Chl-a (mg/m^3)')\nplt.title(\"Lake Erie Daily Average CHL - 2023\")\nplt.legend()\nprint(type(v_chl_avg))\nprint(v_chl_avg.shape)\nprint(e_v_dates.shape)\n\n&lt;class 'numpy.ndarray'&gt;\n(544,)\n(544,)\n\n\n\n\n\n\n\n\n\n\n#e_v_ds.close()\n!jupyter nbconvert --to html GL_python_tutorial2.ipynb\n\n[NbConvertApp] Converting notebook GL_python_tutorial2.ipynb to html\n[NbConvertApp] Writing 878306 bytes to GL_python_tutorial2.html"
  },
  {
    "objectID": "tutorials/jpss-projects/python/sport-jpss-seaice.html#notes",
    "href": "tutorials/jpss-projects/python/sport-jpss-seaice.html#notes",
    "title": "Visualizing JPSS Sea Ice Concentration products using Google Colab",
    "section": "Notes",
    "text": "Notes\nJupyter Notebooks are made up of code cells and text cells. Code cells contain executable code and its output, while text cells contain explanatory text - like this cell.\nEach code cell has a play icon at the left gutter of the cell. Press play to execute the cell’s tasks, or hit Cmd/Ctrl+Enter. Note - sometimes the play icon is not shown (showing only empty brackets) unless your cursor hovers over it.\nAny text or image output resulting from execution of a code cell is displayed right below the code cell - or you’ll see an ‘elapsed processing time beside a checkmark’ near the play icon - or both.\nSome text cells are ‘section headers’, denoted by a “&gt;” (greater than) sign. The “&gt;” can be pressed to expand (show) the cells under it (down to the next section header). That turns the “&gt;” into a “\\/” (chevron), which can then be pressed to collapse (hide) its cells."
  },
  {
    "objectID": "tutorials/jpss-projects/python/sport-jpss-seaice.html#loadinstall-required-packages-mount-google-drive",
    "href": "tutorials/jpss-projects/python/sport-jpss-seaice.html#loadinstall-required-packages-mount-google-drive",
    "title": "Visualizing JPSS Sea Ice Concentration products using Google Colab",
    "section": "Load/install required packages & Mount Google Drive",
    "text": "Load/install required packages & Mount Google Drive\n\n\n# Load/install the required non-standard Python packages\n!pip install cartopy\n!pip install netCDF4\n!pip install pyresample\n!pip install ecmwflibs\n!pip install xarray\n!pip install rioxarray\n!pip install rasterio\n!pip install --upgrade rasterio rioxarray\n# Ensure the Google Drive is mounted"
  },
  {
    "objectID": "tutorials/jpss-projects/python/sport-jpss-seaice.html#modify-the-python-script-and-run-it",
    "href": "tutorials/jpss-projects/python/sport-jpss-seaice.html#modify-the-python-script-and-run-it",
    "title": "Visualizing JPSS Sea Ice Concentration products using Google Colab",
    "section": "Modify the Python script and Run it",
    "text": "Modify the Python script and Run it\nWithin Google Colab, you can access your Google Drive directories. At the far left of the Google Colab screen, press the simple folder icon. This will expand the left-most panel, showing your available Google drives. Navigate the directories to find your file, select it, and Right-Click to select “Copy path”. Then paste that result into the Filename variable in the next cell (below), like so:\n\nFilename = ‘MyDrive/ColabNotebooks/JPSS_Soil_Data/AMSR2-SOIL_v2r2_GW1_s20240210122904_e20240210123456_.nc’\n\nor\n\nFilename = ‘MyDrive/ColabNotebooks/JPSS_Soil_Data/NPR_SMOPS_CMAP_D20240131.nc’\n\nNext, choose one of the recognized domains, placing it into the Domain variable below.\nFinally, specify the location where you want the output PNG files to be created; in the Out_dir_L2 and Out_dir_L3 variables for level-2, and level-3 output, respectively. Execute this cell with the ‘play’ icon.\n\n# Specify Filename\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/JRR-IceConcentration_v3r3_j01_s202403070044010_e202403070045255_c202403070121021.nc'\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Blended_SIC_N20_2020_350_12_15_0000_2400_north.tiff'  # SSEC\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Blended_AMSR2_VIIRS_SIC_2023_135_05_15_2346_2357.tiff'  # GINA (swath)\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20240804_c20240805.nc'  # PolarWatch\nFilename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20241005_c20241007.nc'  # PolarWatch\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/nesdis_blendedsic_nhem_daily_79da_d8e9_7b6a_U1723144597211.nc'  # PolarWatch\n\n# Specify 1 of the recognized domains:\n#   arctic, antarctic\nDomain = 'arctic'\n\n# Specify the output directory\nOut_dir_L2 = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Output_L2'\nOut_dir_L3 = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Output_L3'\n\nThis portion of code imports required Python packages, as well as defining the domains to be recognized by the script. You can add your own domain, or change on of the existing ones, in the ‘domains’ dictionary.\n\nimport os\nimport re\nimport sys\n\nfrom time import gmtime, strftime\nimport cartopy.feature as cfeature\nimport cartopy.crs as ccrs\nimport netCDF4\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pyresample as pr\nimport rioxarray as rio\nfrom pyresample.geometry import SwathDefinition\nfrom pathlib import Path\nimport ecmwflibs # This little bugger is required to find the eccodes library!!!!\necmwflibs.find(\"eccodes\") # This line is simply to *use* the imported ecmwflibs module\n\n# geographic regions\ndomains = {\n   'world':{                             # region\n      'states':False,                    # state outlines?\n      'shape':(1000, 500),               # size (x,y)\n      'area_extent':(-180, -90, 180, 90) # lat/lon extent (degrees) (W,S,E,N)\n      },\n   'arctic':{\n      'states':False,\n      'shape':(700, 700),\n      'area_extent':(-180, 50, 180, 90)\n      },\n   'antarctic':{\n      'states':False,\n      'shape':(700, 700),\n      'area_extent':(-180, -90, 180, -55)\n      },\n    }\n\nThese classes, or functions (SIC_L2 and SIC_L3), handle the Level-2 (swath) VIIRS SIC files and the Level-3 (gridded) Blended files.\n\nclass SIC_L2:\n   \"\"\"Level2 SIC files\"\"\"\n\n   def __init__(self, domain: str, fil: str):\n      self.domain = domain\n      self.fil = fil\n      self.lats = []\n      self.lons = []\n      self.data = []\n      self.plot_data()\n\n   def plot_data(self):\n      \"\"\"Plot the data, overlay with a map, colormap, and label\"\"\"\n\n      print(f'Reading file {self.fil}')\n      f = rio.open_rasterio(self.fil, band_as_variable=True)\n\n      # Get data\n      data_tmp = f.IceConc.values\n      x_tmp = f.Longitude.values\n      y_tmp = f.Latitude.values\n\n      subsam = 20\n\n      # Subsample if needed and Mask out out-of-bounds values\n      self.lats = y_tmp[::subsam, ::subsam].squeeze()\n      self.lons = x_tmp[::subsam, ::subsam].squeeze()\n      self.data = data_tmp[::subsam, ::subsam].squeeze()\n\n      # Get date and time from filename\n      ymd, hm = re.search(r's(?P&lt;ymd&gt;\\d{8})(?P&lt;hm&gt;\\d{4})',\n                          os.path.basename(self.fil)).groups()\n      print('ymd=', ymd, 'hm=', hm)\n\n      # Min and Max for SIC percentage\n      vmin, vmax = 0.0, 100.0\n\n      # Get center lat/lon\n      ctr_lon = (domains[self.domain]['area_extent'][2]+domains[self.domain]['area_extent'][0]) / 2\n      print('ctr_lon=', ctr_lon)\n\n      # Define PROJ4 target projection (stere = stereographic)\n      proj4 = {'proj': 'stere', 'lat_0': 90.0, 'lon_0': ctr_lon,\n                    'ellps': 'WGS84', 'units': 'm'}\n\n      # Create pyresample AreaDefinition\n      area_def = pr.create_area_def(\n                                    self.domain,\n                                    proj4,\n                                    description = 'stereographic',\n                                    units = 'deg',\n                                    shape = domains[self.domain]['shape'],\n                                    area_extent = domains[self.domain]['area_extent']\n                                   )\n\n      # Create a cartopy CRS object (from pyresample)\n      crs = area_def.to_cartopy_crs()\n\n      # Define the swath projection\n      swath_def = SwathDefinition(self.lons, self.lats)\n\n      # resample swath data (self.data) to the target grid using nearest neighbour method\n      result = pr.kd_tree.resample_nearest(swath_def, self.data, area_def,\n                                           radius_of_influence=30000,\n                                           fill_value=None)\n\n      # Prepare picture\n      fig = plt.figure(figsize=(12, 8))\n      ax = plt.axes(projection=crs)\n      ax.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=0.25, edgecolor='black')\n      ax.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=0.25)\n      if domains[self.domain]['states']:\n         ax.add_feature(cfeature.STATES.with_scale('50m'), linewidth=0.1)\n\n      # Title\n      title = f'NOAA JPSS NOAA-20 VIIRS (Sea Ice Conc.) - {ymd} {hm} UTC'\n      units = '%'\n\n      # Display picture\n      result = np.float64(result) # only to remove a runtime \"overflow\" warning\n      ax.imshow(result, transform=crs, extent=crs.bounds,\n                cmap='jet_r', origin='upper', vmin=vmin, vmax=vmax)\n      ax.set_title(title, fontsize=11)\n\n      # Add color legend\n      sic = plt.cm.ScalarMappable(cmap='jet_r', norm=plt.Normalize(vmin, vmax))\n      cbar = plt.colorbar(sic, ax=ax, shrink=0.45, pad=0.03)\n\n      # ...with tick marks and labels\n      cbar.ax.tick_params(labelsize=9)\n      cbar.set_label(units, size=9)\n\n      # Display image in Google Colab\n      plt.show()\n\n      # Save as PNG\n      pngname = (f'{Out_dir_L2}/{ymd}_{hm}_VIIRS_SIC_{self.domain}.png')\n\n      print(f'{strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())} - Saving PNG  {pngname}')\n      fig.savefig(f'{pngname}', bbox_inches='tight', dpi=200)\n\n      # Verify/notify write success\n      if not os.path.isfile(f'{pngname}'):\n         print(f'Error: {pngname} NOT saved')\n\n      # Close plot\n      plt.close()\n\n################################################################################\n################################################################################\nclass SIC_L3:\n   \"\"\"Level3 Blended SIC NetCDf & GeoTIFF files\"\"\"\n\n   def __init__(self, domain: str, fil: str):\n      self.domain = domain\n      self.fil = fil\n      # Prep projection (EASE-Grid 2.0 - - - EPSG:6931, NPole)\n      self.ease_proj = ccrs.LambertAzimuthalEqualArea(central_latitude=90.)\n      self.cart_proj = ccrs.PlateCarree(central_longitude=0.0)\n      self.plot_data()\n\n   def convert_cart_laea(self, lats:list, lons:list) -&gt; tuple[int, int, int, int]:\n      \"\"\"Convert each point of the region's lat/lon polygon to LAEA coords (meters)\n      Args:\n         lons:list of longitude values\n         lats:list of latitude values\n      Returns: min_x, max_x, min_y, max_y (meters) (integer)\n      \"\"\"\n      min_x = min_y = float('inf')\n      max_x = max_y = float('-inf')\n\n      # Perform transforms on all points of polygon\n      for lat in lats:\n         for lon in lons:\n            x, y = self.ease_proj.transform_point(lon, lat, src_crs=self.cart_proj)\n            min_x = min(min_x, x)\n            max_x = max(max_x, x)\n            min_y = min(min_y, y)\n            max_y = max(max_y, y)\n      return(int(min_x), int(max_x), int(min_y), int(max_y))\n\n   def find_value_address_in(self, list:list, value:int) -&gt; tuple[int, int]:\n      \"\"\"Find address of value in monotonically increasing or decreasing list\n      Args:\n         list: list of values\n         value: value to find\n      Returns: address, direction (0 or 1)\n      \"\"\"\n      if list[0] &lt; list[1]:\n         # increasing/normal\n         dir = 1\n         for j, i in enumerate(list):\n            if i &gt;= value:\n               break\n      else:\n         # decreasing/abnormal\n         dir = 0\n         for j, i in enumerate(list):\n            if i &lt;= value:\n               break\n      return j, dir\n\n   def plot_data(self):\n      \"\"\"Read data, create sample Plot of Blended SIC data\n      \"\"\"\n      # Check consistency of request\n      print(self.domain)\n      if self.domain not in ['arctic', 'antarctic']:\n         raise ValueError(f'Only arctic and antarctic currently supported')\n      self.ctr_lat = 90. if self.domain == 'arctic' else -90.\n\n      # Read NetCDF/GeoTIFF\n      print(f'Reading file {self.fil}')\n      f = rio.open_rasterio(self.fil, band_as_variable=True)\n      print('type(f)=', type(f))\n\n      # Set full and half size variables\n      full = f.rio.width\n      half = int(full/2)\n\n      # quadrant x,y starting values (meters) (in the full array)\n      #       Dateline-90W     90W-Prime        Prime-90E       90E-Dateline    hemisphere\n      start = {'nw':[0, 0], 'sw':[0, half], 'se':[half, half], 'ne':[half, 0], 'full':[0, 0]}\n\n      # Define regions dict with series of lat,lon pairs (3 or more pairs)\n      regions = {\n                 'alaska':[59,-141,\n                           55,-163,\n                           60,-168,\n                           68,-167,\n                           70,-140],\n                 'greenland':[59,-70,\n                              84,-70,\n                              84,-10,\n                              59,-10],\n                 'hudsonbay':[52,-95,\n                              52,-72,\n                              69,-72,\n                              69,-95],\n                 'uk':[50,-10,\n                       50,2,\n                       60,2,\n                       60,-10]}\n      # Each region's list does not need to be a closed polygon\n\n      # Parameters\n      vmin, vmax = 0.0, 100.0\n      domain = 'full'\n      subsam = 20\n      print('domain=', domain)\n\n      # Subset & Subsample\n      if domain == 'full':  # full polar EASE\n         data = f.band_1.values[start[domain][0]:start[domain][0]+full:subsam, start[domain][1]:start[domain][1]+full:subsam]\n         x = f.x.values[start[domain][0]:start[domain][0]+full:subsam]\n         y = f.y.values[start[domain][1]:start[domain][1]+full:subsam]\n      elif domain in ['nw', 'ne', 'sw', 'se']:  # EASE quadrants\n         data = f.band_1.values[start[domain][1]:start[domain][1]+half:subsam, start[domain][0]:start[domain][0]+half:subsam]\n         x = f.x.values[start[domain][0]:start[domain][0]+half:subsam]\n         y = f.y.values[start[domain][1]:start[domain][1]+half:subsam]\n      else:  # polygon\n         data_tmp = f.band_1.values\n         x_tmp = f.x.values\n         y_tmp = f.y.values\n\n         # Fill lats/lons arrays with coords\n         lats = [regions[domain][i] for i in range(0, len(regions[domain]), 2)]  # even\n         lons = [regions[domain][i] for i in range(1, len(regions[domain]), 2)]  # odd\n\n         # Find min and max of x and y values (meters in LAEA proj space)\n         x1, x2, y1, y2 = self.convert_cart_laea(lats, lons)\n         print('polygon coords in LAEA meters:', x1, x2, y1, y2)\n\n         # Locate min/max x/y values in the x and y lists\n         col1, xdir = self.find_value_address_in(x_tmp, x1)\n         col2, xdir = self.find_value_address_in(x_tmp, x2)\n         row1, ydir = self.find_value_address_in(y_tmp, y1)\n         row2, ydir = self.find_value_address_in(y_tmp, y2)\n         print('col1=', col1, 'col2=', col2, 'row1=', row1, 'row2=', row2)\n         if xdir:\n            x = x_tmp[col1:col2:subsam]\n            if ydir:\n               data = data_tmp[row1:row2:subsam, col1:col2:subsam]\n            else:\n               data = data_tmp[row2:row1:subsam, col1:col2:subsam]\n         else:\n            x = x_tmp[col2:col1:subsam]\n            if ydir:\n               data = data_tmp[row1:row2:subsam, col2:col1:subsam]\n            else:\n               data = data_tmp[row2:row1:subsam, col2:col1:subsam]\n\n         if ydir:\n            y = y_tmp[row1:row2:subsam]\n         else:\n            y = y_tmp[row2:row1:subsam]\n         print(col1, col2, row1, row2)\n\n      print('data shape=', data.shape)\n      #plt.hist(data, density=True, bins=10)\n      #plt.show()\n\n      # Get date from filename  Polar-AMSR2VIIRSBLEND_\n      if '_AMSR2_VIIRS_SIC_' in self.fil:\n         data[data&gt;100] = np.nan\n         ymd_txt = re.search(r'Blended_AMSR2_VIIRS_SIC_(\\d{4})_\\d{3}_(\\d{2})_(\\d{2})', os.path.basename(self.fil))\n         ymd = (ymd_txt.group(1) + ymd_txt.group(2) + ymd_txt.group(3))\n      elif 'Blended_SIC_' in self.fil:\n         data[data&gt;100] = np.nan\n         #                     Blended_SIC_N20_2020_350_12_15_0000_2400_north.tiff\n         ymd_txt = re.search(r'Blended_SIC_N20_(\\d{4})_\\d{3}_(\\d{2})_(\\d{2})', os.path.basename(self.fil))\n         ymd = (ymd_txt.group(1) + ymd_txt.group(2) + ymd_txt.group(3))\n      elif 'Polar-AMSR2VIIRSBLEND_' in self.fil:\n         data[data&gt;100] = np.nan\n         ymd_txt = re.search(r'Polar-AMSR2VIIRSBLEND_..._v..r.._Nhem_0000_2400_d(\\d{4})(\\d{2})(\\d{2})', os.path.basename(self.fil))\n         ymd = (ymd_txt.group(1) + ymd_txt.group(2) + ymd_txt.group(3))\n      elif 'nesdis_blendedsic_nhem_daily_' in self.fil:\n         data[data&gt;100] = np.nan\n         ymd = 'YYYYMMDD'\n      else:\n         sys.exit('Not a valid file type')\n\n      # Prepare figure\n      fig = plt.figure(figsize=(12, 12))\n      axm = plt.subplot(projection = self.ease_proj)\n      axm.set_title(f'Blended Sea Ice Concentration - {ymd}', fontsize=11)\n\n      # Add map features\n      axm.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=0.25, edgecolor='black')\n      axm.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=0.25)\n      if domains[self.domain]['states']:\n         axm.add_feature(cfeature.STATES.with_scale('50m'), linewidth=0.1)\n      axm.gridlines(draw_labels=True)\n\n      # Add color bar with 'jet' cmap\n      sic = plt.cm.ScalarMappable(cmap='jet')\n      cbar = plt.colorbar(sic, ax=axm, shrink=0.45, pad=0.03)\n\n      # ...with tick marks and labels\n      cbar.ax.tick_params(labelsize=9)\n      cbar.set_label('percent', size=9)\n\n      # Display image in Google Colab\n      axm.imshow(data, cmap='jet', transform=self.ease_proj, vmin=vmin, vmax=vmax,\n                 extent=(x.min(), x.max(), y.min(), y.max()))\n      plt.show()\n\n      # Save as PNG\n      pngname = (f'{Out_dir_L3}/{ymd}_Blended_AMSR2VIIRS_SIC_{self.domain}.png')\n      print(f'{strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())} - Saving PNG  {pngname}')\n      fig.savefig(pngname, bbox_inches='tight', dpi=200)\n\n      # Verify/notify write success\n      if not os.path.isfile(pngname):\n         print(f'Error: {pngname} NOT saved')\n\n      # Close figure\n      plt.close()\n\nFinally, execute the code below. Either SIC_L2 or SIC_L3 will be executed, depending on which type of file you’ve specified. You may have to scroll down a bit to see the resulting image here in Colab, but a PNG file will be generated, as well.\nNote: During the first execution of this script, the Python module ‘Cartopy’ will need to download map-related files from “Natural Earth”. You will see Python-generated warning messages for this.\n\n# Verify data file exists\nif not os.path.exists(f'{Filename}'):\n   sys.exit(f'{Filename} does not exist')\n\n# Determine data type and call its procedure\nif Filename.find('JRR-IceConcentration', 0) != -1:  # CLASS\n   # Verify L2 output directory exists\n   if not os.path.isdir(f'{Out_dir_L2}'):\n      sys.exit(f'Output directory {Out_dir_L2} does not exist')\n   SIC_L2(Domain, f'{Filename}')\n\nelif Filename.find('Blended_', 0) != -1:  # SSEC/GINA\n   # Verify L3 output directory exists\n   if not os.path.isdir(f'{Out_dir_L3}'):\n      sys.exit(f'Output directory {Out_dir_L3} does not exist')\n   print('calling SIC_L3', Domain, Filename)\n   SIC_L3(Domain, f'{Filename}')\n\nelif Filename.find('nesdis_blendedsic_nhem_daily_', 0) != -1:  # PolarWatch\n   # Verify L3 output directory exists\n   if not os.path.isdir(f'{Out_dir_L3}'):\n      sys.exit(f'Output directory {Out_dir_L3} does not exist')\n   print('calling SIC_L3', Domain, Filename)\n   SIC_L3(Domain, f'{Filename}')\n\nelif Filename.find('Polar-AMSR2VIIRSBLEND_', 0) != -1:  # PolarWatch\n   # Verify L3 output directory exists\n   if not os.path.isdir(f'{Out_dir_L3}'):\n      sys.exit(f'Output directory {Out_dir_L3} does not exist')\n   print('calling SIC_L3', Domain, Filename)\n   SIC_L3(Domain, f'{Filename}')\n\nelse:\n   sys.exit('File must be: Blend or ????')\n###############################################################################\n\ncalling SIC_L3 arctic /content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20241005_c20241007.nc\narctic\nReading file /content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20241005_c20241007.nc\n\n\nWARNING:rasterio._env:CPLE_AppDefined in Unhandled X/Y axis unit meters. SRS will ignore axis unit and be likely wrong.\nWARNING:rasterio._env:CPLE_AppDefined in Unhandled X/Y axis unit meters. SRS will ignore axis unit and be likely wrong.\n\n\ntype(f)= &lt;class 'xarray.core.dataset.Dataset'&gt;\ndomain= full\ndata shape= (452, 452)\n\n\n/usr/local/lib/python3.10/dist-packages/cartopy/io/__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/50m_physical/ne_50m_coastline.zip\n  warnings.warn(f'Downloading: {url}', DownloadWarning)\n/usr/local/lib/python3.10/dist-packages/cartopy/io/__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/50m_cultural/ne_50m_admin_0_boundary_lines_land.zip\n  warnings.warn(f'Downloading: {url}', DownloadWarning)\n\n\n\n\n\n\n\n\n\n2024-10-08 16:52:13 - Saving PNG  /content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Output_L3/20241005_Blended_AMSR2VIIRS_SIC_arctic.png"
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html",
    "href": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "",
    "text": "history | Updated September 2023\nNOAA PolarWatch distributes gridded and tabular oceanographic data for polar regions. Satellite data include geospatial information and most of them are in geographical coordinates (latitude and longitude). PolarWatch satellite data are often projected using Polar Stereographic Projections in x and y coordinates."
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#objective",
    "href": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#objective",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "Objective",
    "text": "Objective\nThis tutorial will demonstrate how to plot a polar stereographic projected data on a projected map, and to add another dataset with geographical coordinates (latitude and longitude) onto the map."
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nAccessing satellite data from ERDDAP\nMaking a projected map\nAdding polarstereographic data to the map\nAdding geographically referenced data (lat and lon) to the map"
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#datasets-used",
    "href": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#datasets-used",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "Datasets used",
    "text": "Datasets used\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\nThis dataset includes sea ice concentration data from the northern hemisphere, and is produced by the NOAA/NSIDC using the Climate Data Record algorithm. The resolution is 25km, meaning each grid in this data set represents a value that covers a 25km by 25km area. The dataset is avaialble from the NOAA PolarWatch Catalog.\nPolar bear tracking data  For the demonstrative purpose of adding a dataset in geographical coords (lat, lon) to the projected map, GPS data for a polar bear track were used. More information about the data can be found at https://borealisdata.ca/file.xhtml?fileId=151017&version=1.0"
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#import-packages",
    "href": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#import-packages",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "Import packages",
    "text": "Import packages\n\nimport netCDF4 as nc\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n \n\n\n# There are many ways to get data.  We will create a function that points to \n# NOAA PolarWatch ERDDAP Server gridded dataset page to get data with its unique ID\n\ndef point_to_dataset(dataset_id, base_url='https://polarwatch.noaa.gov/erddap/griddap'):\n    base_url = base_url.rstrip('/')\n    full_url = '/'.join([base_url, dataset_id])\n    return nc.Dataset(full_url)\n \n\n# 'nsidcG02202v4nhmday' is the unique ID of our interested data \n# from PolarWatch ERDDAP data server\nda = point_to_dataset('nsidcG02202v4nhmday')"
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#mapping-projected-data-on-a-projected-basemap",
    "href": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#mapping-projected-data-on-a-projected-basemap",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "Mapping projected data on a projected basemap",
    "text": "Mapping projected data on a projected basemap\nWe first need to create a basemap with the Polar Stereographic projection. Most of the netCDF data files include metadata about mapping. This can be used to set a projection and mapping boundaries for the data.\n\n# prints metadata embedded in netCDF file\nprint(da)\n\n&lt;class 'netCDF4._netCDF4.Dataset'&gt;\nroot group (NETCDF3_CLASSIC data model, file format DAP2):\n    _NCProperties: version=2,netcdf=4.8.1,hdf5=1.10.6\n    acknowledgement: This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.\n    cdm_data_type: Grid\n    cdr_variable: cdr_seaice_conc_monthly\n    comment: The variable melt_onset_day_cdr_seaice_conc_monthly is not available for this month.\n    contributor_name: Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fisher\n    contributor_role: principal investigator, author, author, software developer, software developer, software developer\n    Conventions: CF-1.6, ACDD-1.3, COARDS\n    creator_email: nsidc@nsidc.org\n    creator_name: NSIDC\n    creator_type: institution\n    creator_url: https://nsidc.org/\n    date_created: 2023-02-22T23:18:04Z\n    defaultGraphQuery: cdr_seaice_conc_monthly[last]%5B(-5337500.0)%5D%5B(3737500.0)%5D&.draw=surface\n    grid_mapping_false_easting: 0.0\n    grid_mapping_false_northing: 0.0\n    grid_mapping_GeoTransform: -3850000.0 25000.0 0 5850000.0 0 -25000.0\n    grid_mapping_grid_boundary_bottom_projected_y: -5350000.0\n    grid_mapping_grid_boundary_left_projected_x: -3850000.0\n    grid_mapping_grid_boundary_right_projected_x: 3750000.0\n    grid_mapping_grid_boundary_top_projected_y: 5850000.0\n    grid_mapping_latitude_of_projection_origin: 90.0\n    grid_mapping_longitude_of_projection_origin: -45.0\n    grid_mapping_name: polar_stereographic\n    grid_mapping_parent_grid_cell_column_subset_end: 304.0\n    grid_mapping_parent_grid_cell_column_subset_start: 0.0\n    grid_mapping_parent_grid_cell_row_subset_end: 448.0\n    grid_mapping_parent_grid_cell_row_subset_start: 0.0\n    grid_mapping_proj4text: +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defs\n    grid_mapping_scaling_factor: 1.0\n    grid_mapping_semimajor_radius: 6378273.0\n    grid_mapping_semiminor_radius: 6356889.449\n    grid_mapping_spatial_ref: PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3411\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]\n    grid_mapping_srid: urn:ogc:def:crs:EPSG::3411\n    grid_mapping_standard_parallel: 70.0\n    grid_mapping_straight_vertical_longitude_from_pole: 135.0\n    grid_mapping_units: meters\n    history: HISTORY_ATTRIBUTE\n2023-08-04T18:45:39Z (local files)\n2023-08-04T18:45:39Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.das\n    id: https://doi.org/10.7265/sr8p-kc62\n    infoUrl: https://nsidc.org/data/g02202/versions/4/\n    institution: NSIDC &gt; National Snow and Ice Data Center\n    keywords: algorithm, america, arctic, area, atlantic, barents, bay, beaufort, bering, bootstrap, canada, cdr_seaice_conc_monthly, center, chukchi, climate, common, concentration, continent, CONTINENT &gt; NORTH AMERICA &gt; CANADA &gt; HUDSON BAY, Continent &gt; North America &gt; Canada &gt; Hudson Bay, cryosphere, data, davis, day, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Arctic, Geographic Region &gt; Northern Hemisphere, Geographic Region &gt; Polar, goddard, gsfc, gulf, hemisphere, hudson, ice, ice distribution, lawrence, mayen, melt, melt_onset_day_cdr_seaice_conc_monthly, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, north, northern, norwegian, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Arctic Ocean, Ocean &gt; Arctic Ocean &gt; Barents Sea, Ocean &gt; Arctic Ocean &gt; Beaufort Sea, Ocean &gt; Arctic Ocean &gt; Chukchi Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Davis Straight, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; GULF OF ST LAWRENCE, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; North Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Norwegian Sea, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; SVALBARD AND JAN MAYEN, Ocean &gt; Pacific Ocean, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Bering Sea, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Sea Of Okhotsk, oceans, okhotsk, onset, over, pacific, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, straight, svalbard, tdim, team, version\n    keywords_vocabulary: GCMD Science Keywords\n    license: No constraints on data access or use\n    metadata_link: https://nsidc.org/data/g02202/versions/4/\n    naming_authority: org.doi.dx\n    platform: DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17\n    processing_level: NOAA Level 3\n    product_version: v04r00\n    program: NOAA Climate Data Record Program\n    proj_crs_code: EPSG:3411\n    proj_crs_code_description: The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.\n    project: NOAA/NSIDC passive microwave sea ice concentration climate data record\n    references: Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7): 15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251?2267, https://doi.org/10.1175/JCLI-D-16-0408.1\n    sensor: SSMI/S &gt; Special Sensor Microwave Imager/Sounder\n    software_version_id: git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897\n    source: ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220901_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220902_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220903_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220904_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220905_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220906_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220907_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220908_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220909_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220910_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220911_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220912_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220913_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220914_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220915_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220916_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220917_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220918_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220919_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220920_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220921_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220922_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220923_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220924_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220925_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220926_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220927_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220928_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220929_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220930_f17_v04r00.nc\n    sourceUrl: (local files)\n    spatial_resolution: 25km\n    standard_name_vocabulary: CF Standard Name Table v70\n    summary: This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).\n    time_coverage_duration: P1M\n    time_coverage_end: 2022-12-01T00:00:00Z\n    time_coverage_resolution: P1M\n    time_coverage_start: 1978-11-01T00:00:00Z\n    title: Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\n    dimensions(sizes): time(530), xgrid(304), ygrid(448)\n    variables(dimensions): float64 time(time), float32 ygrid(ygrid), float32 xgrid(xgrid), float32 cdr_seaice_conc_monthly(time, ygrid, xgrid), int8 melt_onset_day_cdr_seaice_conc_monthly(time, ygrid, xgrid), float32 nsidc_bt_seaice_conc_monthly(time, ygrid, xgrid), float32 nsidc_nt_seaice_conc_monthly(time, ygrid, xgrid), int8 qa_of_cdr_seaice_conc_monthly(time, ygrid, xgrid), float32 stdev_of_cdr_seaice_conc_monthly(time, ygrid, xgrid)\n    groups: \n\n\n\n# prints variable names\nda.variables.keys()\n\ndict_keys(['time', 'ygrid', 'xgrid', 'cdr_seaice_conc_monthly', 'melt_onset_day_cdr_seaice_conc_monthly', 'nsidc_bt_seaice_conc_monthly', 'nsidc_nt_seaice_conc_monthly', 'qa_of_cdr_seaice_conc_monthly', 'stdev_of_cdr_seaice_conc_monthly'])\n\n\n\nda['cdr_seaice_conc_monthly'][0][:].shape\n\n(448, 304)\n\n\n\n# set mapping crs to Cartopy's North Polar Stereo graphic\ncrs_epsg = ccrs.NorthPolarStereo(central_longitude=-45)\n\n# set figure size\nfig = plt.figure(figsize=[10, 10])\n\n# set the map projection and associated boundaries\nax = plt.axes(projection = crs_epsg)\nax.set_extent([-3850000.0, 3750000.0, -5350000, 5850000.0],crs_epsg)\nax.coastlines()\nax.add_feature(cfeature.LAND)\n\n# set the data crs using 'transform' \n# set the data crs as described in the netcdf metadata\ncs = ax.pcolormesh(da['xgrid'], da['ygrid'], da['cdr_seaice_conc_monthly'][0][:] , \n                   cmap=plt.cm.Blues,  transform= ccrs.NorthPolarStereo(true_scale_latitude=70, central_longitude=-45)) #transform default is basemap specs\n\nfig.colorbar(cs, ax=ax, location='bottom', shrink =0.8)\nax.set_title('Ice Concentration using Cartopy projection NorthPolarStereo()')\n\nplt.show()"
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#mapping-data-with-epsg-code",
    "href": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#mapping-data-with-epsg-code",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "Mapping data with EPSG Code",
    "text": "Mapping data with EPSG Code\nYou can set the data crs using the EPSG code. In our case, the metadata provides the projection crs (EPSG: 3411) In this exercise, we will use the same basemap projection, but set the data projection with the EPSG code.\n\n# Set data projection using EPSG Code \ndata_crs = ccrs.epsg('3411')\ncrs_epsg = ccrs.NorthPolarStereo(central_longitude=-45)\n\n# set the basemap \nfig = plt.figure(figsize=[10, 10])\nax = plt.axes(projection = crs_epsg)\nax.set_extent([-3850000.0, 3750000.0, -5350000, 5850000.0],ccrs.NorthPolarStereo(central_longitude=-45))\nax.add_feature(cfeature.LAND)\nax.coastlines()\n\n# transform= which projection data (coords) were defined \ncs = ax.pcolormesh(da['xgrid'], da['ygrid'], da['cdr_seaice_conc_monthly'][0][:], \n                   cmap=plt.cm.Blues,  transform= data_crs) \n\nfig.colorbar(cs, ax=ax, location='bottom', shrink =0.8)\nax.set_title('Ice Concentration using EPSG code (3411)')\n\nplt.show()"
  },
  {
    "objectID": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#references",
    "href": "tutorials/map-data-with-different-projections/python/map-data-with-different-projections.html#references",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "References",
    "text": "References\n\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nNOAA PolarWatch Data Product Page (download, preview)"
  },
  {
    "objectID": "tutorials/matchup-polar-satellite-data-to-buoy-data/python/matchup-polar-satellite-data-to-buoy-data_dh.html",
    "href": "tutorials/matchup-polar-satellite-data-to-buoy-data/python/matchup-polar-satellite-data-to-buoy-data_dh.html",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "In this exercise, you will combine satellite and buoy data by extracting satellite measurements around specific points defined by buoy locations and dates. The focus of this exercise is on matching two data sources from different projections.\nSimilar tutorials for mid to lower latitudes can be found at https://github.com/coastwatch-training/CoastWatch-Tutorials."
  },
  {
    "objectID": "tutorials/matchup-polar-satellite-data-to-buoy-data/python/matchup-polar-satellite-data-to-buoy-data_dh.html#this-exercise-demonstrates-the-following-techniques",
    "href": "tutorials/matchup-polar-satellite-data-to-buoy-data/python/matchup-polar-satellite-data-to-buoy-data_dh.html#this-exercise-demonstrates-the-following-techniques",
    "title": "Matching Satellite and Buoy Data",
    "section": "This exercise demonstrates the following techniques:",
    "text": "This exercise demonstrates the following techniques:\n\nUsing ERDDAP to retrieve buoy data in CSV format and satellite data in netCDF format\nImporting and manipulating data with the pandas and xarray libraries\nResampling data to lower-resolution time steps\nConverting latitude and longitude coordinates to the polar stereographic projection\n\n\nData used in this exercise\nIce Surface Temperature, NOAA-20 VIIRS, Near Real-Time, Polar Stereographic (North), 4-day\nThis dataset provides VIIRS sea ice surface temperature for the Arctic at a 750m resolution, collected by the NOAA-20 satellite. It includes near-real-time daily data and 4-day composites for the past three weeks. For this exercise, we will use 4-day composites data.\nInternational Arctic Buoy Programme (IABP) Buoy Data, Daily\nThis data set is from the US International Arctic Buoy Programme and includes meteorological and oceanographic data from buoys. Dataset is updated daily and includes multiple variables. For this exercise, we will extract surface temperature data.\nWhile both instruments measure surface temperatures, they do so at different locations and with different sensors.\nSatellite Ice Surface Temperature (IST) is measured by the Visible Infrared Imaging Radiometer Suite (VIIRS) and captures the temperature of the surface layer of ice.\nBuoy Surface Temperature (Ts) is measured from the bottom of the buoy hull. If the buoy is floating, the reported temperature is of the sea surface. If the buoy is frozen into the ice or sitting on top of it, the reported temperature is of the ground or ice. The freezing temperature of seawater is about -1.8°C, so temperature readings below this indicate ground or ice temperatures.\nMore details can be found in the metadata section of the data products (click on the data links above).\n\n\nLoad packages\n\nimport xarray as xr\nimport pandas as pd\nimport requests\nimport io\nimport pyproj\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\nfrom sklearn.metrics import r2_score \nimport cartopy.crs as ccrs # cartopy: geospatial data visualization\nimport cartopy.feature as cfeature\n\n\n\nLoad buoy data (IABP) from PolarWatch ERDDAP data server\n\nConstruct ERDDAP URL to query the IABP buoy for: buoy_id, longitude, latitude, time, and surface temperature that filters for data where surface_temp exists and for the date range between 2023-08-01 and 2023-09-30.\nDownload the data into a Pandas dataframe.\n\n\n# Construct ERDDAP URL\nbuoy_url = ''.join(['https://polarwatch.noaa.gov/erddap/tabledap/iabpv2_buoys.csv?',\n                    'buoy_id,longitude,latitude,time,surface_temp',\n                    '&has_surface_temp=\"yes\"&time&gt;=2023-08-01&time&lt;=2023-09-30'\n                    ])\n\n# Make a request to the ERDDAP server\nreq = requests.get(buoy_url).content\n\n# The response from the web service is read as a CSV file into a pandas DataFrame. \ndf = pd.read_csv(io.StringIO(req.decode('utf-8')), skiprows=[1], parse_dates=['time'])\n\ndf.head(3)\n\n\n\n\n\n\n\n\n\nbuoy_id\nlongitude\nlatitude\ntime\nsurface_temp\n\n\n\n\n0\n300234066034140\n-28.5226\n55.0168\n2023-08-01 00:00:00+00:00\n13.5\n\n\n1\n300234066034140\n-28.5226\n55.0168\n2023-08-01 01:00:02+00:00\n13.4\n\n\n2\n300234066034140\n-28.5226\n55.0168\n2023-08-01 01:59:57+00:00\n13.4\n\n\n\n\n\n\n\n\n\nSelect one buoy and process data\nSelect one buoy (buoy id = “300534062897730”). The buoy records measurements at intervals of minutes, resulting in a high-resolution dataset. , * Downsample the buoy data to align it with the daily resolution of the satellite dataset.\n* The time data is recorded in the UTC time zone. Pandas operations often encounter issues with time zones, so remove the time zone information for easier processing.\n\n# Select one buoy (buoy id = \"300534062897730\")\nbuoy_df = df.loc[df[\"buoy_id\"]== 300534062897730]\n\nprint('# of timesteps before =', buoy_df.shape[0] )\n\n# The resampling will put time as the df index\nbuoy_df_resampled = buoy_df.resample('D', on='time').mean()\nprint('# of timesteps after =', buoy_df_resampled.shape[0] )\n\n# Remove the timezone (UTC, GMT).\nbuoy_df_resampled = buoy_df_resampled.tz_localize(None)\n\n# Rename the variable\nbuoy_df_resampled.rename(columns={\"surface_temp\": \"temp_buoy\"},\n                         errors=\"raise\",\n                         inplace=True)\n\nbuoy_df_resampled.head(2)\n\n# of timesteps before = 8523\n# of timesteps after = 60\n\n\n\n\n\n\n\n\n\nbuoy_id\nlongitude\nlatitude\ntemp_buoy\n\n\ntime\n\n\n\n\n\n\n\n\n2023-08-01\n3.005341e+14\n-143.782008\n86.385202\n2.193916\n\n\n2023-08-02\n3.005341e+14\n-143.104535\n86.333932\n1.520208\n\n\n\n\n\n\n\n\n\nTransform buoy coordinates to polar projection\nThe buoy locations are provided in latitude and longitude coordinates. The satellite data is in polar stereographic projection, which provided location in columns and rows with units of meters. * Convert the buoy locations from latitude and longitude to the corresponding columns and rows values in the polar projection.\n\n# Define the projection using the PROJ4 string format\nproj4text = \"+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n\n# Initialize the projection object using pyproj with the given PROJ4 text\nproj = pyproj.Proj(proj4text)\n\n# Transform latitude and longitude to x, y coordinates\n# Longitude and latitude are passed as arrays, \n# pyproj returns the corresponding x (cols) and y (rows) values\nbuoy_df_resampled['cols'], buoy_df_resampled['rows'] = proj(buoy_df_resampled['longitude'].values, \n                                                            buoy_df_resampled['latitude'].values)\n\n# Verify that the 'cols' and 'rows' columns were added to dataframe\nbuoy_df_resampled.head(2)\n\n\n\n\n\n\n\n\nbuoy_id\nlongitude\nlatitude\ntemp_buoy\ncols\nrows\n\n\ntime\n\n\n\n\n\n\n\n\n\n\n2023-08-01\n3.005341e+14\n-143.782008\n86.385202\n2.193916\n-387113.857367\n59803.924517\n\n\n2023-08-02\n3.005341e+14\n-143.104535\n86.333932\n1.520208\n-393297.704017\n56006.315907\n\n\n\n\n\n\n\n\n# Select the first buoy location to pull corresponding satellite data\nbuoy_cols = buoy_df_resampled['cols'].iloc[0]\nbuoy_rows = buoy_df_resampled['rows'].iloc[0]\n\n\n\nLoad satellite data from PolarWatch\n\n# Construct ERDDAP data request\ngridded_url = \"https://polarwatch.noaa.gov/erddap/griddap/noaacwVIIRSn20icesrftempNP06Daily4Day\"\n\n# Open and load data into xarray dataset\nsrftemp_ds = xr.open_dataset(gridded_url)\n\n# The altitude dimension has a size of 1, remove it to reduce the dimensionality\nsrftemp_ds = srftemp_ds.squeeze()\n\n\n\nSelect satellite data to match buoy location and dates\nSubset the satellite data using the buoy locations and dates.\n\nbuoy_cols = buoy_df_resampled['cols'].values\nbuoy_rows = buoy_df_resampled['rows'].values\nbuoy_times = buoy_df_resampled.index.values\n\nsat_temps =[]\nfor ct, buoy_col in enumerate(buoy_cols):\n    sat_temp = srftemp_ds['IceSrfTemp'].sel(\n                     rows=buoy_rows[ct],\n                     cols=buoy_col, \n                     time=buoy_times[ct],\n                     method='nearest'\n                     )\n    \n    sat_temps.append(sat_temp.values.item())\n\n\n\nMerge satellite ice temperature data with buoy\nMerge the datasets by index (date). Not all buoy dates have corresponding satellite data. Unmatched dates will be filled with NaN values.\n\nmerged_df = buoy_df_resampled\n\nmerged_df['temp_sat'] = np.array(sat_temps) - 273.15\n\nmerged_df.head(3)\n\n\n\n\n\n\n\n\nbuoy_id\nlongitude\nlatitude\ntemp_buoy\ncols\nrows\ntemp_sat\n\n\ntime\n\n\n\n\n\n\n\n\n\n\n\n2023-08-01\n3.005341e+14\n-143.782008\n86.385202\n2.193916\n-387113.857367\n59803.924517\n-0.413336\n\n\n2023-08-02\n3.005341e+14\n-143.104535\n86.333932\n1.520208\n-393297.704017\n56006.315907\nNaN\n\n\n2023-08-03\n3.005341e+14\n-142.195432\n86.271987\n0.803264\n-400800.933610\n50600.465317\nNaN\n\n\n\n\n\n\n\n\n\nVisualize matched dataSets\nVisualize the matched buoy and satellite datasets to assess the data alignment.\n\nplt.figure(figsize = (10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(merged_df.index, merged_df.temp_buoy, \n              'o', markersize=3, \n              label='Buoy Surface Temperature', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(merged_df.index, merged_df.temp_sat,  \n              's', markersize=3, \n              label='VIIRS Sea Ice Surface Temperature', c='blue', \n              linestyle='-', linewidth=0) \n\n#plt.ylim([0, 3])\nplt.ylabel('Temperature (degrees C)') \nplt.xticks(rotation=45)\nplt.legend()"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "",
    "text": "History | Updated Feb 2026\n\nIn this exercise you will extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like that produced by an animal telemetry tag, and ship track, or a glider tract.\nPlease note that there may be more efficient ways, more Pythonic ways, to accomplish the tasks in this tutorial. The tutorial was developed to be easier to follow for less experienced users of Python.\n\n\n\nLoading data from a tab- or comma-separated file\nPlotting the latitude/longitude points onto a map\nExtracting satellite data along a track\nSummarizing satellite values using either a single nearest pixel or a small spatial window\nSaving results as a CSV file\nPlotting the satellite data onto a map\n\n\n\n\n\nChlorophyll a concentration from the European Space Agency’s Ocean Colour Climate Change Initiative Monthly dataset v6.0\nA loggerhead turtle telemetry track that has been subsample to reduce the data requests needed for this tutorial from over 1200 to 25. The turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. The track data can be downloaded from data folder in this project folder.\nDusky shark telemetry detections, consisting of longitude, latitude, date, and transmitter ID information from acoustic tags deployed along the U.S. East Coast. This example demonstrates matching satellite chlorophyll using a small spatial window (±0.2°) to better represent local environmental conditions experienced by the animal.\nChlorophyll-a, Aqua MODIS, NPP, L3SMI, Global, 4km, Science Quality, 2003-present (8 Day Composite)\n\n\n\n\n\npandas (reading and analyzing data)\n\nnumpy (data analysis, manipulation)\nxarray (multi-dimensional data analysis, manipulation)\nmatplotlib (mapping)\ncartopy (mapping)\ndatetime (date manipulation)"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#overview",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#overview",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "",
    "text": "History | Updated Feb 2026\n\nIn this exercise you will extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like that produced by an animal telemetry tag, and ship track, or a glider tract.\nPlease note that there may be more efficient ways, more Pythonic ways, to accomplish the tasks in this tutorial. The tutorial was developed to be easier to follow for less experienced users of Python.\n\n\n\nLoading data from a tab- or comma-separated file\nPlotting the latitude/longitude points onto a map\nExtracting satellite data along a track\nSummarizing satellite values using either a single nearest pixel or a small spatial window\nSaving results as a CSV file\nPlotting the satellite data onto a map\n\n\n\n\n\nChlorophyll a concentration from the European Space Agency’s Ocean Colour Climate Change Initiative Monthly dataset v6.0\nA loggerhead turtle telemetry track that has been subsample to reduce the data requests needed for this tutorial from over 1200 to 25. The turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. The track data can be downloaded from data folder in this project folder.\nDusky shark telemetry detections, consisting of longitude, latitude, date, and transmitter ID information from acoustic tags deployed along the U.S. East Coast. This example demonstrates matching satellite chlorophyll using a small spatial window (±0.2°) to better represent local environmental conditions experienced by the animal.\nChlorophyll-a, Aqua MODIS, NPP, L3SMI, Global, 4km, Science Quality, 2003-present (8 Day Composite)\n\n\n\n\n\npandas (reading and analyzing data)\n\nnumpy (data analysis, manipulation)\nxarray (multi-dimensional data analysis, manipulation)\nmatplotlib (mapping)\ncartopy (mapping)\ndatetime (date manipulation)"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#import-the-required-python-modules",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#import-the-required-python-modules",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Import the required Python modules",
    "text": "Import the required Python modules\n\nfrom IPython.display import clear_output\nimport pandas as pd\nimport numpy as np\nimport os\nimport warnings\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nfrom cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\nimport matplotlib.pyplot as plt\nimport xarray as xr\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#load-the-track-data-into-a-pandas-data-frame",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#load-the-track-data-into-a-pandas-data-frame",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Load the track data into a Pandas data frame",
    "text": "Load the track data into a Pandas data frame\nBelow, the track data will load using the Pandas “read_csv” method. * Then use the “.head()” method to view the column names and the first few rows of data.\n\ntrack_path = os.path.join('..',\n                          'data',\n                          '25317_05_subsampled.dat')\n\ndf = pd.read_csv(track_path)\nprint(df.head(2))\n\n     mean_lon   mean_lat  year  month  day\n0  176.619433  32.678728  2005      5    4\n1  175.860895  35.057734  2005      6   23"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#plot-the-track-on-a-map",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#plot-the-track-on-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot the track on a map",
    "text": "Plot the track on a map\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([120, 260, 15, 55], ccrs.PlateCarree())\n\n# Set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(125, 255, 20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(20, 60, 10), crs=ccrs.PlateCarree())\n\n# Add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# Format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# Bring the lon and lat data into a numpy array \nx, y = df.mean_lon.to_numpy(), df.mean_lat.to_numpy()\nax1 = plt.plot(x, y, transform=ccrs.PlateCarree(), color='k')\n# start point in green star\nax1 = plt.plot(x[0], y[0],\n               marker='*',\n               color='g',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\n# end point in red X\nax1 = plt.plot(x[-1], y[-1],\n               marker='X',\n               color='r',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\nplt.title('Animal Track for Turtle #25317', fontsize=20)\n\nplt.show()"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#prepare-track-data-for-use-to-extract-satellite-data",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#prepare-track-data-for-use-to-extract-satellite-data",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Prepare track data for use to extract satellite data",
    "text": "Prepare track data for use to extract satellite data\n\nCreate a column with Pandas date objects\nReload the “25317_05_subsampled.dat”. This time we will use the “parse_dates” option to create a Pandas date object column (year_month_day) from the ‘year’, ‘month’, and ‘day’ columns.\n\ndf = pd.read_csv(track_path,\n                 parse_dates=[['year', 'month', 'day']]\n                 )\n\nprint('The new year_month_day column contains the Pandas date objects')\nprint(df.head(2))\nprint(df.dtypes)\n\nThe new year_month_day column contains the Pandas date objects\n  year_month_day    mean_lon   mean_lat\n0     2005-05-04  176.619433  32.678728\n1     2005-06-23  175.860895  35.057734\nyear_month_day    datetime64[ns]\nmean_lon                 float64\nmean_lat                 float64\ndtype: object"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Extract data from a satellite dataset corresponding to points on the track",
    "text": "Extract data from a satellite dataset corresponding to points on the track\nWe are going to download data from an ERDDAP server using the following steps: * Select a dataset on an ERDDAP server * Open the dataset using the Xarray module * Loop though the track data and pull out the date, latitude and longitude coordinates from each row * Insert these coordinates into the Xarray open-dataset object to select and download the satellite data that corresponds to the coordinates. * Store the satellite data in a temporary Pandas data frame * Once all the satellite data has been added to the temporary data frame, merge it with the track data frame.\n\nSelect a dataset\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product that blends data from many ocean color sensors to create a long time series (1997-present) with better spatial coverage than any single sensor.\nIdeally we would use a daily dataset, selecting the day that corresponds to the track data date. However, chlorophyll measurements can have a lot of missing data, primarily due to cloud cover. To reduce data gaps and improve the likelihood of data for our matchups, we can use a dataset that combines all of the data from each month into the monthly average.\nThe ERDDAP URL to the monthly version of the OC-CCI product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\n\n\nOpen the satellite data in Xarray\n\nUse the ERDDAP URL with no extension (e.g. without .html or .graph…). This is the OPeNDAP URL, which allows viewing the dataset metadata and, when you select the data you want, downloading the data.\nUse the Xarray “open_dataset” function then view the metadata\n\n\nerddap_url = '/'.join(['https://oceanwatch.pifsc.noaa.gov',\n                       'erddap',\n                       'griddap',\n                       'esa-cci-chla-monthly-v6-0'])\n\nds = xr.open_dataset(erddap_url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 472GB\nDimensions:             (time: 316, latitude: 4320, longitude: 8640)\nCoordinates:\n  * time                (time) datetime64[ns] 3kB 1997-09-04 ... 2023-12-01\n  * latitude            (latitude) float64 35kB 89.98 89.94 ... -89.94 -89.98\n  * longitude           (longitude) float64 69kB 0.02083 0.0625 ... 359.9 360.0\nData variables:\n    chlor_a             (time, latitude, longitude) float32 47GB ...\n    MERIS_nobs_sum      (time, latitude, longitude) float32 47GB ...\n    MODISA_nobs_sum     (time, latitude, longitude) float32 47GB ...\n    OLCI_A_nobs_sum     (time, latitude, longitude) float32 47GB ...\n    OLCI_B_nobs_sum     (time, latitude, longitude) float32 47GB ...\n    SeaWiFS_nobs_sum    (time, latitude, longitude) float32 47GB ...\n    VIIRS_nobs_sum      (time, latitude, longitude) float32 47GB ...\n    chlor_a_log10_bias  (time, latitude, longitude) float32 47GB ...\n    chlor_a_log10_rmsd  (time, latitude, longitude) float32 47GB ...\n    total_nobs_sum      (time, latitude, longitude) float32 47GB ...\nAttributes: (12/53)\n    cdm_data_type:                     Grid\n    comment:                           See summary attribute\n    Conventions:                       CF-1.7, COARDS, ACDD-1.3\n    creation_date:                     Thu Jan 18 09:04:18 2024\n    creator_email:                     help@esa-oceancolour-cci.org\n    creator_name:                      Plymouth Marine Laboratory\n    ...                                ...\n    time_coverage_end:                 2023-12-01T00:00:00Z\n    time_coverage_resolution:          P1M\n    time_coverage_start:               1997-09-04T00:00:00Z\n    title:                             Chlorophyll a concentration, ESA OC CC...\n    tracking_id:                       abd52a4c-7009-464f-b1eb-958f7d333a1d\n    Westernmost_Easting:               0.020833333333314386xarray.DatasetDimensions:time: 316latitude: 4320longitude: 8640Coordinates: (3)time(time)datetime64[ns]1997-09-04 ... 2023-12-01_CoordinateAxisType :Timeactual_range :[8.7333120e+08 1.7013888e+09]axis :Tioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-04T00:00:00.000000000', '1997-10-01T00:00:00.000000000',\n       '1997-11-01T00:00:00.000000000', ..., '2023-10-01T00:00:00.000000000',\n       '2023-11-01T00:00:00.000000000', '2023-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float6489.98 89.94 89.9 ... -89.94 -89.98_CoordinateAxisType :Latactual_range :[-89.97916667  89.97916667]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.97916666666667valid_min :-89.97916666666666array([ 89.979167,  89.9375  ,  89.895833, ..., -89.895833, -89.9375  ,\n       -89.979167])longitude(longitude)float640.02083 0.0625 ... 359.9 360.0_CoordinateAxisType :Lonactual_range :[2.08333333e-02 3.59979167e+02]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :359.97918701171875valid_min :0.020829999819397926array([2.083333e-02, 6.250000e-02, 1.041667e-01, ..., 3.598958e+02,\n       3.599375e+02, 3.599792e+02])Data variables: (10)chlor_a(time, latitude, longitude)float32...ancillary_variables :chlor_a_log10_rmsd chlor_a_log10_biascolorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll-a concentration in seawater (not log-transformed), generated by as a blended combination of OCI, OCI2, OC2 and OCx algorithms, depending on water class membershipsparameter_vocab_uri :http://vocab.ndg.nerc.ac.uk/term/P011/current/CHLTVOLUstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m-3units_nonstandard :mg m^-3[11794636800 values with dtype=float32]MERIS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the MERIS sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]MODISA_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the MODIS (Aqua) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]OLCI_A_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the OLCI (Sentinel-3a) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]OLCI_B_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the OLCI (Sentinel-3b) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]SeaWiFS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the SeaWiFS (GAC and LAC) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]VIIRS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the VIIRS sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]chlor_a_log10_bias(time, latitude, longitude)float32...colorBarMaximum :0.1colorBarMinimum :-0.1comment :Uncertainty lookups derived from file: /data/datasets/CCI/v6.0-production/stage09b-uncertainty_tables/chlor_a/cci_chla_bias.datioos_category :Statisticslong_name :Bias of log10-transformed chlorophyll-a concentration in seawater.references :https://esa-oceancolour-cci.org/?q=webfm_send/581rel :uncertainty[11794636800 values with dtype=float32]chlor_a_log10_rmsd(time, latitude, longitude)float32...colorBarMaximum :0.002colorBarMinimum :0.0comment :Uncertainty lookups derived from file: /data/datasets/CCI/v6.0-production/stage09b-uncertainty_tables/chlor_a/cci_chla_rmsd.datioos_category :Statisticslong_name :Root-mean-square-difference of log10-transformed chlorophyll-a concentration in seawater.references :https://esa-oceancolour-cci.org/?q=webfm_send/581rel :uncertainty[11794636800 values with dtype=float32]total_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the total number of observations contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-04', '1997-10-01', '1997-11-01', '1997-12-01',\n               '1998-01-01', '1998-02-01', '1998-03-01', '1998-04-01',\n               '1998-05-01', '1998-06-01',\n               ...\n               '2023-03-01', '2023-04-01', '2023-05-01', '2023-06-01',\n               '2023-07-01', '2023-08-01', '2023-09-01', '2023-10-01',\n               '2023-11-01', '2023-12-01'],\n              dtype='datetime64[ns]', name='time', length=316, freq=None))latitudePandasIndexPandasIndex(Index([ 89.97916666666667,            89.9375,  89.89583333333333,\n        89.85416666666667,            89.8125,  89.77083333333333,\n        89.72916666666667,            89.6875,  89.64583333333333,\n        89.60416666666667,\n       ...\n       -89.60416666666666, -89.64583333333331,           -89.6875,\n       -89.72916666666666, -89.77083333333331,           -89.8125,\n       -89.85416666666666, -89.89583333333331,           -89.9375,\n       -89.97916666666666],\n      dtype='float64', name='latitude', length=4320))longitudePandasIndexPandasIndex(Index([0.020833333333314386,               0.0625,  0.10416666666665719,\n        0.14583333333331439,               0.1875,   0.2291666666666572,\n         0.2708333333333144,               0.3125,   0.3541666666666572,\n         0.3958333333333144,\n       ...\n         359.60416666666663,    359.6458333333333,             359.6875,\n         359.72916666666663,    359.7708333333333,             359.8125,\n         359.85416666666663,    359.8958333333333,             359.9375,\n         359.97916666666663],\n      dtype='float64', name='longitude', length=8640))Attributes: (53)cdm_data_type :Gridcomment :See summary attributeConventions :CF-1.7, COARDS, ACDD-1.3creation_date :Thu Jan 18 09:04:18 2024creator_email :help@esa-oceancolour-cci.orgcreator_name :Plymouth Marine Laboratorycreator_url :https://esa-oceancolour-cci.orgdate_created :2022-08-15T22:03:48ZEasternmost_Easting :359.97916666666663geospatial_lat_max :89.97916666666667geospatial_lat_min :-89.97916666666666geospatial_lat_resolution :0.041666666666666664geospatial_lat_units :degrees_northgeospatial_lon_max :359.97916666666663geospatial_lon_min :0.020833333333314386geospatial_lon_resolution :0.041666666666666664geospatial_lon_units :degrees_eastgit_commit_hash :27964270df6ae0b9bdd0af5672529dbebb4e7bd9history :Thu Jan 18 08:21:00 2024: ncatted -O -a geospatial_lon_max,global,o,f,360.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a geospatial_lon_min,global,o,f,0.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a valid_max,lon,o,f,359.9792 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a valid_min,lon,o,f,0.02083 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:20:41 2024: ncap2 -O -s where(lon&lt;0) lon=lon+360 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:20:20 2024: ncks -O --msa_usr_rdr -d lon,0.0,180.0 -d lon,-180.0,0.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0.nc ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nSource data were: ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231201-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231202-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231203-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231204-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231205-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231206-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231207-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231208-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231209-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231210-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231211-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231212-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231213-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231214-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231215-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231216-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231217-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231218-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231219-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231220-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231221-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231222-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231223-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231224-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231225-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231226-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231227-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231228-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231229-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231230-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231231-fv6.0.nc; netcdf_compositor_cci composites  Rrs_412, Rrs_412_bias, Rrs_443, Rrs_443_bias, Rrs_490, Rrs_490_bias, Rrs_510, Rrs_510_bias, Rrs_560, Rrs_560_bias, Rrs_665, Rrs_665_bias, adg_412, adg_412_bias, adg_443, adg_443_bias, adg_490, adg_490_bias, adg_510, adg_510_bias, adg_560, adg_560_bias, adg_665, adg_665_bias, aph_412, aph_412_bias, aph_443, aph_443_bias, aph_490, aph_490_bias, aph_510, aph_510_bias, aph_560, aph_560_bias, aph_665, aph_665_bias, atot_412, atot_443, atot_490, atot_510, atot_560, atot_665, bbp_412, bbp_443, bbp_490, bbp_510, bbp_560, bbp_665, chlor_a, chlor_a_log10_bias, kd_490, kd_490_bias, water_class1, water_class10, water_class11, water_class12, water_class13, water_class14, water_class2, water_class3, water_class4, water_class5, water_class6, water_class7, water_class8, water_class9 with --mean,  Rrs_412_rmsd, Rrs_443_rmsd, Rrs_490_rmsd, Rrs_510_rmsd, Rrs_560_rmsd, Rrs_665_rmsd, adg_412_rmsd, adg_443_rmsd, adg_490_rmsd, adg_510_rmsd, adg_560_rmsd, adg_665_rmsd, aph_412_rmsd, aph_443_rmsd, aph_490_rmsd, aph_510_rmsd, aph_560_rmsd, aph_665_rmsd, chlor_a_log10_rmsd, kd_490_rmsd with --root-mean-square, and  MERIS_nobs, MODISA_nobs, OLCI-A_nobs, OLCI-B_nobs, SeaWiFS_nobs, VIIRS_nobs, total_nobs - with --total\n1705571341 Subsetted from standardised_geo/ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1M_MONTHLY_4km_GEO_PML_OCx_QAA-202312-fv6.0.nc to only include variables MERIS_nobs_sum,MODISA_nobs_sum,OLCI-A_nobs_sum,OLCI-B_nobs_sum,SeaWiFS_nobs_sum,VIIRS_nobs_sum,chlor_a,chlor_a_log10_bias,chlor_a_log10_rmsd,crs,lat,lon,time,total_nobs_sum\n2024-03-15T14:27:48Z (local files)\n2024-03-15T14:27:48Z https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.dasid :ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0.ncinfoUrl :https://esa-oceancolour-cci.org/institution :Plymouth Marine Laboratorykeywords :algorithms, aqua, area, array, array-data, bias, bin, blended, cci, cell, chemistry, chlor_a, chlor_a_log10_bias, chlor_a_log10_rmsd, chlorophyll, chlorophyll-a, class, color, colour, combination, comprehensive, concentration, contributing, count, coverage, data, depending, difference, earth, Earth Science &gt; Oceans &gt; Ocean Chemistry &gt; Chlorophyll, esa, field, field-of-view, gac, generated, global, imager, imager/radiometer, imaging, infrared, laboratory, lac, large, local, log, log-transformed, log10, log10-transformed, marine, mass, mass_concentration_of_chlorophyll_a_in_sea_water, mean, memberships, meris, MERIS_nobs_sum, moderate, modis, MODISA_nobs_sum, not, number, observation, observations, oc2, ocean, ocean color, ocean colour, oceans, oci, oci2, ocx, olci, OLCI-A_nobs_sum, OLCI-B_nobs_sum, plymouth, product, radiometer, resolution, root, root-mean-square-difference, satellite, science, sea, sea-wide, seawater, seawifs, SeaWiFS_nobs_sum, sensor, sentinel, sentinel-3a, sentinel-3b, spectroradiometer, square, statistics, stewardship, suite, system, time, total, total_nobs_sum, transformed, view, viirs, VIIRS_nobs_sum, visible, water, widekeywords_vocabulary :GCMD Science Keywordslicense :ESA CCI Data Policy: free and open access.  When referencing, please use: Ocean Colour Climate Change Initiative dataset, Version &lt;Version Number&gt;, European Space Agency, available online at https://esa-oceancolour-cci.org.  We would also appreciate being notified of publications so that we can list them on the project website at https://esa-oceancolour-cci.org/?q=publicationsnaming_authority :uk.ac.pmlNCO :netCDF Operators version 4.7.5 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)nco_openmp_thread_number :1netcdf_file_type :NETCDF4_CLASSICNorthernmost_Northing :89.97916666666667number_of_bands_used_to_classify :4number_of_files_composited :31number_of_optical_water_types :14platform :Orbview-2,Aqua,Envisat,Suomi-NPP, Sentinel-3a, Sentinel-3bprocessing_level :Level-3product_version :6.0project :Climate Change Initiative - European Space Agencyreferences :https://esa-oceancolour-cci.org/sensor :SeaWiFS,MODIS,MERIS,VIIRS,OLCIsensors_present :OLCIa OLCIbsource :NASA SeaWiFS  L1A and L2 R2018.0 LAC and GAC, MODIS-Aqua L1A and L2 R2018.0, MERIS L1B 3rd reprocessing inc OCL corrections, NASA VIIRS L1A and L2 R2018.0, OLCI L1BsourceUrl :(local files)Southernmost_Northing :-89.97916666666666spatial_resolution :4km nominal at equatorstandard_name_vocabulary :CF Standard Name Table v70summary :Data products generated by the Ocean Colour component of the European Space Agency Climate Change Initiative project. These files are monthly composites of merged sensor (MERIS, Moderate Resolution Imaging Spectroradiometer (MODIS) Aqua, Sea-Wide Field-of-View Sensor (SeaWiFS) Local Area Coverage (LAC) & Global Area Coverage (GAC), Visible and Infrared Imager/Radiometer Suite (VIIRS), OLCI) products.  MODIS Aqua and SeaWiFS were band-shifted and bias-corrected to MERIS bands and values using a temporally and spatially varying scheme based on the overlap years of 2003-2007.  VIIRS was band-shifted and bias-corrected in a second stage against the MODIS Rrs that had already been corrected to MERIS levels, for the overlap period 2012-2014; at the third stage Sentinel-3A OLCI was bias corrected against already corrected MODIS, for overlap period 2016-07-01 to 2019-06-30;  at the fourth stage Sentinel-3B OLCI was bias corrected against already corrected Sentinel-3A OLCI, for overlap period 2018-07-01 to 2021-06-30.  VIIRS, MODIS, SeaWiFS and MERIS Rrs were derived from a combination of NASA's l2gen (for basic sensor geometry corrections, etc) and HYGEOS POLYMER (for atmospheric correction). OLCI Rrs were sourced at L1b (already geometrically corrected) and processed with POLYMER.  The Rrs were binned to a sinusoidal 4km level-3 grid, and later to 4km geographic projection, by Brockmann Consult's SNAP.  Derived products were generally computed with the standard algorithms through SeaDAS.  QAA IOPs were derived using the standard SeaDAS algorithm but with a modified backscattering table to match that used in the bandshifting.  The final chlorophyll is a combination of OCI, OCI2, OC2 and OCx, depending on the water class memberships.  Uncertainty estimates were added using the fuzzy water classifier and uncertainty estimation algorithm of Tim Moore as documented in Jackson et al (2017). and updated according to Jackson et al. (in prep).time_coverage_duration :P1Mtime_coverage_end :2023-12-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :1997-09-04T00:00:00Ztitle :Chlorophyll a concentration, ESA OC CCI - Monthly, 1997-present. v6.0tracking_id :abd52a4c-7009-464f-b1eb-958f7d333a1dWesternmost_Easting :0.020833333333314386\n\n\nOpening the dataset in Xarray lets you look at the dataset metadata.\n* The metadata are listed above. * No data is downloaded until you request it.\nFrom the metadata you can view: * The coordinates (time, latitude and longitude) that you will use to select the data to download. * A list of ten data variables. For this exercise, we want the “chlor_a” variable. If you want, you can find out about each variable with clicking the page icon to the right of each variable name.\nA note on dataset selection\nWe have preselected the OC-CCI monthly dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application.\nYou can find that information above by clicking the right arrow next to “Attribute”. Then look through the list to find: * ‘time_coverage_start’ and ‘time_coverage_end’: the time range * ‘geospatial_lat_min’ and ‘geospatial_lat_max’: the latitude range * ‘geospatial_lon_min’ and ‘geospatial_lon_max’: the longitude range\nThere are a lot of metadata attributes to look through. We can make it easier with a little code to print out the metadata of interest. Then compare these ranges to those found in your track data.\n\nprint('Temporal and spatial ranges of the satellite dataset')\nprint('time range', ds.attrs['time_coverage_start'], \n      ds.attrs['time_coverage_end'])\nprint('latitude range', ds.attrs['geospatial_lat_min'], \n      ds.attrs['geospatial_lat_max'])\nprint('longitude range', ds.attrs['geospatial_lon_min'], \n      ds.attrs['geospatial_lon_max'])\nprint(' ')\nprint('Temporal and spatial ranges of the track data')\nprint('time range', df.year_month_day.min(), df.year_month_day.max())\nprint('latitude range', \n      round(df.mean_lat.min(), 2), round(df.mean_lat.max(), 2))\nprint('longitude range', \n      round(df.mean_lon.min(), 2), round(df.mean_lon.max(), 2))\n\nTemporal and spatial ranges of the satellite dataset\ntime range 1997-09-04T00:00:00Z 2023-12-01T00:00:00Z\nlatitude range -89.97916666666666 89.97916666666667\nlongitude range 0.020833333333314386 359.97916666666663\n \nTemporal and spatial ranges of the track data\ntime range 2005-05-04 00:00:00 2008-08-16 00:00:00\nlatitude range 23.72 41.77\nlongitude range 175.86 248.57\n\n\n\n\nDownload the satellite data that corresponds to each track location\n\n# Create a temporary Pandas data frame to hold the downloaded satellite data\ncol_names = [\"erddap_date\", \"matched_lat\", \"matched_lon\", \"matched_chla\"]\ntot = pd.DataFrame(columns=col_names)\n\n# Finish each URL and download\nfor i in range(0, len(df)):\n    clear_output(wait=True)\n    print(i+1, 'of', len(df))\n    \n    # Crop the dataset to include data that corresponds to track locations\n    cropped_ds = ds['chlor_a'].sel(time=df.year_month_day[i],\n                                   latitude=df.mean_lat[i],\n                                   longitude=df.mean_lon[i],\n                                   method='nearest'\n                                   )\n     \n    # Downloaded the data and add it to a new line in the tot data frame\n    tot.loc[len(tot.index)] = [cropped_ds.time.values,\n                               np.round(cropped_ds.latitude.values, 5),  # round 5 dec\n                               np.round(cropped_ds.longitude.values, 5), # round 5 dec\n                               np.round(cropped_ds.values, 2)  # round 2 decimals\n                               ]\n    \n    print(tot.loc[[len(tot)-1]])\n\ntot.head(2)\n\n25 of 25\n   erddap_date  matched_lat  matched_lon  matched_chla\n24  2008-08-01     26.77083    245.77083          0.71\n\n\n\n\n\n\n\n\n\nerddap_date\nmatched_lat\nmatched_lon\nmatched_chla\n\n\n\n\n0\n2005-05-01\n32.6875\n176.60417\n0.29\n\n\n1\n2005-07-01\n35.0625\n175.85417\n0.11\n\n\n\n\n\n\n\n\n\nConsolidate the downloaded satellite data into the track data frame\n\n\ndf[['matched_lat', \n    'matched_lon', \n    'matched_chla', \n    'erddap_date']] = tot[['matched_lat',\n                           'matched_lon',\n                           'matched_chla',\n                           'erddap_date']]\n\ndf.head(2)\n\n\n\n\n\n\n\n\nyear_month_day\nmean_lon\nmean_lat\nmatched_lat\nmatched_lon\nmatched_chla\nerddap_date\n\n\n\n\n0\n2005-05-04\n176.619433\n32.678728\n32.6875\n176.60417\n0.29\n2005-05-01\n\n\n1\n2005-06-23\n175.860895\n35.057734\n35.0625\n175.85417\n0.11\n2005-07-01\n\n\n\n\n\n\n\n\n\nSave your work\n\ndf.to_csv('chl_matchup_turtle25327.csv', index=False, encoding='utf-8')"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#plot-chlorophyll-matchup-data-onto-a-map",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#plot-chlorophyll-matchup-data-onto-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot chlorophyll matchup data onto a map",
    "text": "Plot chlorophyll matchup data onto a map\n\nFirst plot a histogram of the chlorophyll data\n\nprint('Range:', df.matched_chla.min(), df.matched_chla.max())\n_ = df.matched_chla.hist(bins=40)\n\nRange: 0.06 0.71\n\n\n\n\n\n\n\n\n\nThe range of chlorophyll values can be large, with lots of very low values and a few very high values. Using a linear color bar, most of the lower values would have the same color. * To better visualize the data, we often plot the log or log10 of chlorophyll.\n\n\nPlot a histogram of the log of the chlorophyll data\n\nprint('Range:', np.log(df.matched_chla.min()), np.log(df.matched_chla.max()))\n_ = np.log(df.matched_chla).hist(bins=40)\n\nRange: -2.8134108 -0.34249032\n\n\n\n\n\n\n\n\n\n\nThe logarithmic transformation displays the range of values across the color bar range (above).\n\n\n\nMap the chlorophyll data\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\n\n# set the projection\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([120,255, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(120,255,20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(20,50,10), crs=ccrs.PlateCarree())\n\n# Add geographical features\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# build and plot coordinates onto map\nx,y = list(df.mean_lon),list(df.mean_lat)\nax1 = plt.scatter(x, y, transform=ccrs.PlateCarree(),\n                  marker='o',\n                  c=np.log(df.matched_chla),\n                  cmap=plt.get_cmap('jet')\n                  )\nax1=plt.plot(x[0],y[0],marker='*', transform=ccrs.PlateCarree(), markersize=10)\nax1=plt.plot(x[-1],y[-1],marker='X', transform=ccrs.PlateCarree(), markersize=10)\n\n\n\n# control color bar values spacing\nlevs2 = np.arange(-2.5, 0, 0.5)\ncbar=plt.colorbar(ticks=levs2, shrink=0.75, aspect=10)\ncbar.set_label(\"Chl a (mg/m^3)\", size=15, labelpad=20)\n\n# set the labels to be exp(levs2) so the label reflect values of chl-a, not log(chl-a)\ncbar.ax.set_yticklabels(np.around(np.exp(levs2), 2), size=10)\n\nplt.title(\"Chlorophyll Matchup to Animal Track #25317\", size=15)\nplt.show()"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#on-your-own",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#on-your-own",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "On your own!",
    "text": "On your own!\n\nExercise 1:\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the NOAA Geo-polar Blended Analysis SST, GHRSST dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html\n* This dataset is a different ERDDAP; It has a different base URL and dataset ID and variable name. * Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nExercise 2:\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/\n* This dataset will likely be on a different base URL and dataset ID and variable name. * Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nOptional\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v1_0.html"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#load-dusky-shark-telemetry-data",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#load-dusky-shark-telemetry-data",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Load Dusky shark telemetry data",
    "text": "Load Dusky shark telemetry data\nLoad the dusky shark acoustic telemetry detections, which include longitude, latitude, detection date, and transmitter ID. Each row represents a single shark detection that will be matched to satellite data.\n\n# Load shark tag data (lon, lat, date, transmitter ID)\ntag_path = os.path.join('..',\n                          'resources',\n                          'DuskyDaily_NOAAclass_sortedTransmitterDate.csv')\n\ntags = pd.read_csv(tag_path)\n\nprint(tags.head(3))\n\n      Transmitter       Date  Latitude  Longitude  Unnamed: 4  \\\n0  A69-1601-46065  9/15/2017  38.22503  -75.03418         NaN   \n1  A69-1601-46065  9/27/2017  38.30890  -75.01166         NaN   \n2  A69-1601-46065  10/2/2017  38.30890  -75.01166         NaN   \n\n  Unique Transmitters  \n0      A69-9006-16095  \n1      A69-9001-16950  \n2      A69-9006-16094"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#convert-telemetry-columns-to-coordinate-arrays",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#convert-telemetry-columns-to-coordinate-arrays",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Convert telemetry columns to coordinate arrays",
    "text": "Convert telemetry columns to coordinate arrays\nLongitude, latitude, and detection dates are extracted and converted into NumPy arrays and datetime objects. This format is required for iterating over detections and selecting satellite data by time.\n\n# Convert columns to arrays (same pattern used earlier in this tutorial)\nxcoord = tags[\"Longitude\"].to_numpy()\nycoord = tags[\"Latitude\"].to_numpy()\ntcoord = pd.to_datetime(tags[\"Date\"], format=\"%m/%d/%Y\").to_numpy()"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#open-a-satellite-dataset-using-xarray-opendap",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#open-a-satellite-dataset-using-xarray-opendap",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Open a satellite dataset using Xarray (OPeNDAP)",
    "text": "Open a satellite dataset using Xarray (OPeNDAP)\nFor this example, we use a CoastWatch MODIS 8-day chlorophyll dataset\n\nerddap_url2 = '/'.join(['https://coastwatch.pfeg.noaa.gov/',\n                       'erddap',\n                       'griddap',\n                       'erdMH1chla8day'])\n\nds_shark = xr.open_dataset(erddap_url2)\nds_shark\n\nprint(\"Temporal and spatial ranges of the satellite dataset\")\nprint(\"time range\", ds_shark.attrs[\"time_coverage_start\"], ds_shark.attrs[\"time_coverage_end\"])\nprint(\"latitude range\", ds_shark.attrs[\"geospatial_lat_min\"], ds_shark.attrs[\"geospatial_lat_max\"])\nprint(\"longitude range\", ds_shark.attrs[\"geospatial_lon_min\"], ds_shark.attrs[\"geospatial_lon_max\"])\n\nTemporal and spatial ranges of the satellite dataset\ntime range 2003-01-05T00:00:00Z 2022-06-14T00:00:00Z\nlatitude range -89.97917 89.97916\nlongitude range -179.9792 179.9792"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#match-each-shark-detection-to-a-local-satellite-window-0.2",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#match-each-shark-detection-to-a-local-satellite-window-0.2",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Match each shark detection to a local satellite window (±0.2°)",
    "text": "Match each shark detection to a local satellite window (±0.2°)\nThis function matches a single shark detection to satellite chlorophyll by selecting the nearest satellite time and extracting a ±0.2° spatial window. It summarizes local conditions by computing the mean, standard deviation, and number of valid pixels.\n\ndef match_one_point(ds, lon, lat, req_time, half_window=0.2):\n    \"\"\"\n    Match a single telemetry detection to satellite chlorophyll using\n    spatial averaging within a local window.\n\n    For a given longitude, latitude, and detection time, this function:\n    selects the nearest satellite time, extracts chlorophyll pixels within\n    a ±half_window degree box around the detection, and summarizes local\n    conditions using the mean, standard deviation, and number of valid pixels.\n\n    Parameters\n    ----------\n    ds : xarray.Dataset\n        ERDDAP gridded satellite dataset opened via Xarray/OPeNDAP.\n    lon : float\n        Longitude of the telemetry detection (decimal degrees).\n    lat : float\n        Latitude of the telemetry detection (decimal degrees).\n    req_time : datetime-like\n        Telemetry detection time; the nearest satellite time is used.\n    half_window : float, optional\n        Half-width of the spatial averaging window in degrees (default 0.2).\n\n    Returns\n    -------\n    dict\n        Dictionary containing mean chlorophyll, standard deviation, number\n        of valid pixels, the matched satellite time, spatial window bounds,\n        and the original detection time.\n    \"\"\"\n    # Nearest satellite time\n    ds_time = ds.sel(time=req_time, method=\"nearest\")\n    sat_time = pd.to_datetime(ds_time.time.values)\n\n    # Spatial bounds\n    lon_min = lon - half_window\n    lon_max = lon + half_window\n    lat_min = lat - half_window\n    lat_max = lat + half_window\n\n    # Latitude often runs descending in ERDDAP products\n    chl = ds_time[\"chlorophyll\"].sel(\n        longitude=slice(lon_min, lon_max),\n        latitude=slice(lat_max, lat_min)\n    )\n\n    return {\n        \"mean_chlorophyll\": float(chl.mean(skipna=True)),\n        \"stdev_chlorophyll\": float(chl.std(skipna=True)),\n        \"n\": int(chl.count()),\n        \"satellite_date\": sat_time,\n        \"requested_lon_min\": lon_min,\n        \"requested_lon_max\": lon_max,\n        \"requested_lat_min\": lat_min,\n        \"requested_lat_max\": lat_max,\n        \"requested_date\": pd.to_datetime(req_time),\n    }"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#run-the-matchup-for-all-shark-detections",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#run-the-matchup-for-all-shark-detections",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Run the matchup for all shark detections",
    "text": "Run the matchup for all shark detections\n\n# Run the matchup for every point:\nhalf_window = 0.2\n\nrows = [\n    match_one_point(ds_shark, lon, lat, t, half_window=half_window)\n    for lon, lat, t in zip(xcoord, ycoord, tcoord)\n]\n\nshark_matchups = pd.DataFrame.from_records(rows)\nshark_matchups.head()\n\n\n\n\n\n\n\n\nmean_chlorophyll\nstdev_chlorophyll\nn\nsatellite_date\nrequested_lon_min\nrequested_lon_max\nrequested_lat_min\nrequested_lat_max\nrequested_date\n\n\n\n\n0\n3.600632\n1.796631\n62\n2017-09-18\n-75.234180\n-74.834180\n38.025030\n38.425030\n2017-09-15\n\n\n1\n3.486308\n1.330631\n62\n2017-09-26\n-75.211660\n-74.811660\n38.108900\n38.508900\n2017-09-27\n\n\n2\n5.782278\n3.086404\n67\n2017-10-04\n-75.211660\n-74.811660\n38.108900\n38.508900\n2017-10-02\n\n\n3\n1.374190\n0.879763\n16\n2017-10-12\n-74.976897\n-74.576897\n38.474039\n38.874039\n2017-10-08\n\n\n4\n0.864735\n0.149003\n24\n2017-10-12\n-74.860156\n-74.460156\n38.324397\n38.724397\n2017-10-09"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#assemble-a-consolidated-telemetrysatellite-dataset",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#assemble-a-consolidated-telemetrysatellite-dataset",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Assemble a consolidated telemetry–satellite dataset",
    "text": "Assemble a consolidated telemetry–satellite dataset\nTelemetry coordinates, transmitter IDs, and matched chlorophyll values are combined into a single DataFrame. This unified table is used for all subsequent mapping and analysis steps.\n\nalltags = pd.DataFrame({\n    \"lon\": xcoord,\n    \"lat\": ycoord,\n    \"chlorophyll\": shark_matchups[\"mean_chlorophyll\"].to_numpy(),\n    \"transmitter\": tags[\"Transmitter\"].to_numpy(),\n    \"date\": shark_matchups[\"requested_date\"].to_numpy(),\n})\n\nprint(alltags.shape)\nalltags.head()\n\n(417, 5)\n\n\n\n\n\n\n\n\n\nlon\nlat\nchlorophyll\ntransmitter\ndate\n\n\n\n\n0\n-75.034180\n38.225030\n3.600632\nA69-1601-46065\n2017-09-15\n\n\n1\n-75.011660\n38.308900\n3.486308\nA69-1601-46065\n2017-09-27\n\n\n2\n-75.011660\n38.308900\n5.782278\nA69-1601-46065\n2017-10-02\n\n\n3\n-74.776897\n38.674039\n1.374190\nA69-1601-46065\n2017-10-08\n\n\n4\n-74.660156\n38.524397\n0.864735\nA69-1601-46065\n2017-10-09"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#map-of-all-sharks-colored-by-chlorophyll",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#map-of-all-sharks-colored-by-chlorophyll",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Map of all sharks colored by chlorophyll",
    "text": "Map of all sharks colored by chlorophyll\nPlot the locations of all tagged dusky sharks and color each detection by the mean satellite-derived chlorophyll-a concentration matched to that location and date.\nEach point represents a single shark detection, and the color scale highlights spatial differences in chlorophyll conditions encountered by sharks across the study area. A simple land mask and coastline provide geographic context, while latitude and longitude gridlines help orient the map.\nThis visualization provides a spatial overview of shark movements in relation to surface ocean productivity.\n\nfig = plt.figure(figsize=(8, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\n\nax.add_feature(cfeature.LAND, facecolor=\"lightgray\")\nax.add_feature(cfeature.COASTLINE)\n\nsc = ax.scatter(\n    alltags[\"lon\"],\n    alltags[\"lat\"],\n    c=alltags[\"chlorophyll\"],\n    cmap=\"YlGn\",\n    s=20,\n    transform=ccrs.PlateCarree()\n)\n\nplt.colorbar(sc, label=\"Chl-a (mg m$^{-3}$)\")\n\ngl = ax.gridlines(\n    draw_labels=True,\n    linewidth=0.5,\n    color=\"gray\",\n    alpha=0.7,\n    linestyle=\"--\"\n)\ngl.top_labels = False\ngl.right_labels = False\ngl.xformatter = LONGITUDE_FORMATTER\ngl.yformatter = LATITUDE_FORMATTER\n\nax.set_title(\"Mean chlorophyll at dusky shark locations\")\nplt.show()"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#subset-all-tags-for-a-single-shark",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#subset-all-tags-for-a-single-shark",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Subset all tags for a single shark",
    "text": "Subset all tags for a single shark\nThis step selects all detections associated with one transmitter ID. Focusing on a single shark allows individual movement patterns and environmental conditions to be examined.\n\nshark1 = alltags[\"transmitter\"].iloc[0]\nprint(\"Selected shark transmitter:\", shark1)\n\nsingle_shark = alltags.loc[alltags[\"transmitter\"] == shark1, [\"lon\", \"lat\", \"chlorophyll\"]].copy()\nsingle_shark.columns = [\"x_shark\", \"y_shark\", \"dataval_shark\"]\n\nsingle_shark.head()\n\nSelected shark transmitter: A69-1601-46065\n\n\n\n\n\n\n\n\n\nx_shark\ny_shark\ndataval_shark\n\n\n\n\n0\n-75.034180\n38.225030\n3.600632\n\n\n1\n-75.011660\n38.308900\n3.486308\n\n\n2\n-75.011660\n38.308900\n5.782278\n\n\n3\n-74.776897\n38.674039\n1.374190\n\n\n4\n-74.660156\n38.524397\n0.864735"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#plot-the-movement-track-for-a-single-shark",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#plot-the-movement-track-for-a-single-shark",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot the movement track for a single shark",
    "text": "Plot the movement track for a single shark\nSuccessive detections for one shark are connected with track lines and colored by chlorophyll concentration. This combined view highlights both movement pathways and changing environmental conditions along the track.\n\nx = single_shark[\"x_shark\"].to_numpy()\ny = single_shark[\"y_shark\"].to_numpy()\nchl = single_shark[\"dataval_shark\"].to_numpy()\n\npad = 0.5\nmaplonmin = x.min() - pad\nmaplonmax = x.max() + pad\nmaplatmin = y.min() - pad\nmaplatmax = y.max() + pad\n\nfig = plt.figure(figsize=(6, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\n\nax.add_feature(cfeature.LAND, facecolor=\"lightgrey\")\nax.add_feature(cfeature.COASTLINE)\n\nax.set_extent([maplonmin, maplonmax, maplatmin, maplatmax], crs=ccrs.PlateCarree())\n\n# Track polyline\nax.plot(\n    x, y,\n    color=\"black\",\n    linewidth=1,\n    alpha=0.7,\n    transform=ccrs.PlateCarree()\n)\n\n# Scatter points\nsc = ax.scatter(\n    x, y,\n    c=chl,\n    cmap=\"YlGn\",\n    s=25,\n    transform=ccrs.PlateCarree(),\n    zorder=3\n)\n\ngl = ax.gridlines(draw_labels=True, linewidth=0.5, color=\"gray\", alpha=0.7, linestyle=\"--\")\ngl.top_labels = False\ngl.right_labels = False\ngl.xformatter = LONGITUDE_FORMATTER\ngl.yformatter = LATITUDE_FORMATTER\ngl.xlabel_style = {\"size\": 9}\ngl.ylabel_style = {\"size\": 9}\n\ncbar = plt.colorbar(sc, ax=ax)\ncbar.set_label(\"Chl-a (mg m$^{-3}$)\")\n\nax.set_title(\"Mean chl-a values for dusky shark #1 (with tracks)\")\n\nplt.show()\nplt.close(fig)"
  },
  {
    "objectID": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#compare-chlorophyll-conditions-by-year-using-a-boxplot",
    "href": "tutorials/matchup-satellite-data-to-track-locations/python/satellite_matchups_to_track_locations_xarray.html#compare-chlorophyll-conditions-by-year-using-a-boxplot",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Compare chlorophyll conditions by year using a boxplot",
    "text": "Compare chlorophyll conditions by year using a boxplot\nMatched chlorophyll values for a single shark are grouped by calendar year and displayed as a boxplot. The boxplot summarizes interannual differences and variability in environmental conditions experienced by the shark.\n\ndf1 = alltags.loc[alltags[\"transmitter\"] == shark1, [\"date\", \"chlorophyll\"]].dropna()\ndf1[\"year\"] = pd.to_datetime(df1[\"date\"]).dt.year\n\nvals_2017 = df1.loc[df1[\"year\"] == 2017, \"chlorophyll\"].to_numpy()\nvals_2018 = df1.loc[df1[\"year\"] == 2018, \"chlorophyll\"].to_numpy()\n\nfig, ax = plt.subplots(figsize=(5, 6))\n\nax.boxplot(\n    [vals_2017, vals_2018],\n    positions=[1, 2],\n    patch_artist=True,                      # allow filled boxes\n    boxprops=dict(facecolor=\"green\", alpha=0.7),\n    medianprops=dict(color=\"black\"),\n    whiskerprops=dict(color=\"black\"),\n    capprops=dict(color=\"black\")\n)\n\nax.set_title(\"Chlorophyll conditions for a single dusky shark\")\nax.set_xlabel(\"Year\")\nax.set_ylabel(\"Chl-a (mg m$^{-3}$)\")\n\nax.set_xticks([1, 2])\nax.set_xticklabels([\"2017\", \"2018\"])\n\nplt.show()"
  },
  {
    "objectID": "tutorials/subset-polar-data-with-shapefile/python/subset-polar-data-with-shapefile.html",
    "href": "tutorials/subset-polar-data-with-shapefile/python/subset-polar-data-with-shapefile.html",
    "title": "Subset data in polar stereographic projection using a shape file fr",
    "section": "",
    "text": "Updated September 2024\n\n\nBackground\nRemote sensing data in polar regions commonly use a polar stereographic projection, where the georeferencing is in x and y coordinates instead of the more widely used latitudes and longitudes. Working with data from different projections can be challenging.\n\n\nObjectives\nIn this tutorial, we will demonstrate how to download remote sensing data in polar stereographic projection from PolarWatch and subset it within the boundaries of Lake Iliamna in Alaska, where the lake shape data is presented in a different projection.\nAs this tutorial focuses on satellite data transformation, a basic understanding of satellite data, map projections, and the ERDDAP data server is recommended. For additional learning, you can explore satellite data tutorials and video lectures available through introductory video lectures and tutorials hosted on the CoastWatch Learning Portal and GitHub repository.\n\nThe tutorial demonstrates the following techniques\n\nDownload sea ice satellite data from the PolarWatch ERDDAP data server\nImport geographical features of Lake Iliamna from a shapefile\nTransform data from one projection to another\nSubset the satellite data for Lake Iliamna\nVisualize data in different projection\n\n\n\n\nData Used\nWorld Lake shape data\nThe world lake shapefile can be downloaded from ArcGIS Hub at https://hub.arcgis.com, and is also available in the resource/ directory of this tutorial folder. The file includes geographical features of all world lakes. For this exercise, only the features of Lake Illemna will be used.\nIMS Snow and Ice Analysis, Arctic, 4km, 2004 - Present, Daily (PolarWatch Preview)\nThe IMS dataset includes daily snow and ice coverage data for the Arctic with a 4-km resolution, available starting from 2004. The values in the dataset are categorical, representing five categories: 0 for areas outside the coverage zone, 1 for open water, 2 for land without snow, 3 for sea ice or lake ice, and 4 for snow-covered land. Data with a 1-km resolution are also available. Please contact us for more information.\n\nLoad python packages\nFor this exercise, the following packages are required. The complete list of required packages for all CoastWatch tutorials is provided in the environment.yml located in the Python-setup/ folder.\n\n# Load packages\nimport xarray as xr\nimport geopandas as gpd\nimport pandas as pd\nimport rioxarray\nfrom shapely.geometry import mapping\n\n\n\nLoad Lake Illemna data\n\n# Load lake shape file into geopanda data frame\nshapefile_path = '../resources/Iliamna/Iliamna.shp'\nlakes_shp = gpd.read_file(shapefile_path)\n\n\n# Check column names\nprint(\"Lake Data Columns:\")\nprint(lakes_shp.columns)\nlakes_shp[\"Lake_name\"].unique()\n\nLake Data Columns:\nIndex(['Hylak_id', 'Lake_name', 'Country', 'Continent', 'Poly_src',\n       'Lake_type', 'Grand_id', 'Lake_area', 'Shore_len', 'Shore_dev',\n       'Vol_total', 'Vol_res', 'Vol_src', 'Depth_avg', 'Dis_avg', 'Res_time',\n       'Elevation', 'Slope_100', 'Wshd_area', 'Pour_long', 'Pour_lat',\n       'geometry'],\n      dtype='object')\n\n\narray([None, 'Iliamna'], dtype=object)\n\n\n\n# Look up Iliamna lake\nprint(\"Row(s) that contain lake name: Iliamna\")\nlakes_shp[lakes_shp['Lake_name'].str.contains('iliamna', case=False, na=False)]\n\nRow(s) that contain lake name: Iliamna\n\n\n\n\n\n\n\n\n\nHylak_id\nLake_name\nCountry\nContinent\nPoly_src\nLake_type\nGrand_id\nLake_area\nShore_len\nShore_dev\n...\nVol_src\nDepth_avg\nDis_avg\nRes_time\nElevation\nSlope_100\nWshd_area\nPour_long\nPour_lat\ngeometry\n\n\n\n\n287\n31\nIliamna\nUnited States of America\nNorth America\nNHD\n1\n0\n2634.62\n1006.79\n5.53\n...\n1\n43.8\n354.811\n3761.5\n13\n-1.0\n16869.4\n-155.884538\n59.331889\nPOLYGON ((-17336380.000 8247763.000, -17336837...\n\n\n\n\n1 rows × 22 columns\n\n\n\n\n# Extract Iliamna shape\niliamna_shp = lakes_shp[lakes_shp['Hylak_id'] == 31]\n\n# Examine coordinate referernce system (crs)\niliamna_shp.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n# Visualize the lake \niliamna_shp.plot()\n\n\n\n\n\n\n\n\n\n\nLoad IMS data from PolarWatch ERDDAP\n\n# Load IMS data from ERDDAP\nerddap_url = \"https://polarwatch.noaa.gov/erddap/griddap/usnic_ims_4km\"\nds = xr.open_dataset(erddap_url)\n\n# Select one day data\nds_date = '2024-07-30'\nds = ds.sel(time=ds_date)\n\n# Visualize the IMS data\nds[\"IMS_Surface_Values\"].plot()\n\n\n\n\n\n\n\n\n\n# Check the IMS data projection\nds.attrs['grid_mapping_proj4']\n\n'+proj=stere +lat_0=90 +lat_ts=60 +lon_0=-80 +k=1 +x_0=0 +y_0=0 +a=6378137 +b=6356257 +units=m +no_defs'\n\n\n\n\n\nTransform the lake data crs to match the satellite data crs\nThe helper functions are provided for the projection transformation process\n\n# from PolarWatch helper functions\n\ndef set_geo_specs(dat: xr.DataArray, xdim: str, ydim: str, crs: str) -&gt; xr.DataArray:\n    \"\"\"Update the spatial dimensions and coordinate reference system (CRS) of an xarray DataArray.\n\n    Args:\n        dat (xr.DataArray): The data array to modify.\n        xdim (str): Name of the dimension representing the x-coordinate.\n        ydim (str): Name of the dimension representing the y-coordinate.\n        crs (str): String representation of the coordinate reference system to assign.\n\n    Returns:\n        xr.DataArray: The updated data array with specified spatial dimensions and CRS.\n    \"\"\"\n    dat = dat.rio.set_spatial_dims(x_dim=xdim, y_dim=ydim)\n    try:\n        dat = dat.rio.write_crs(crs)\n        print('CRS setup successful')\n    except Exception as e:\n        print(f'Error during crs setup: {e}')\n\n    return dat\n\n\ndef clip_data_to_shapefile(data_array: xr.DataArray, shapefile_geom, crs: str)-&gt; xr.DataArray:\n    \"\"\"Clip data array to the specified shapefile geometry with CRS.\n    \n    Args:\n        data_array (xr.DataArray): The data array to modify.\n        shapefile_geom : Shapefile geometry.\n        crs (str): CRS of the data.\n\n    Returns:\n        xr.DataArray: The updated data array with specified spatial dimensions and CRS.  \n    \n    \"\"\"\n    try:\n        clipped_data = data_array.rio.clip(shapefile_geom.apply(mapping), crs)\n        print(\"Clipping successful\")\n        return clipped_data\n    except Exception as e:\n        print(f\"Error during clipping: {e}\")\n        raise\n\ndef transform_shapes(shp: gpd.GeoDataFrame, crs:str)-&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Transforms the projection of a GeoDataFrame to a specified coordinate reference system (CRS).\n    \n    This function takes a GeoDataFrame and transforms its projection to the specified CRS, typically used\n    for reprojecting geometries to match satellite data or other spatial datasets that require a specific CRS.\n    For example, transforming the shape to a Polar Stereographic Projection.\n    \n    Parameters:\n    shp : gpd.GeoDataFrame\n        The input GeoDataFrame containing geometries (e.g., shapes, boundaries) that need to be transformed.\n    crs : str\n        The target coordinate reference system (CRS) in string format (e.g., \"EPSG:3413\" for the Polar Stereographic Projection).\n    \n    Returns:\n    gpd.GeoDataFrame\n        A GeoDataFrame with geometries transformed to the specified CRS.\n\n    \"\"\"\n    try:\n        shp_proj_transformed = shp.to_crs(crs)\n        print(f\"Projection transformed to {crs}\")\n        return shp_proj_transformed\n    except Exception as e:\n        print(f\"Error transforming CRS: {e}\")\n        raise\n\n\n# Set crs_project as the data crs (based on xarray.Dataset.attrs)\ncrs_project = \"+proj=stere +lat_0=90 +lat_ts=60 +lon_0=-80 +k=1 +x_0=0 +y_0=0 +a=6378137 +b=6356257 +units=m +no_defs\"\n\n# Set data crs\nds = set_geo_specs(ds, xdim=\"x\", ydim=\"y\", crs=crs_project)\n\n# Transform the shape into the data crs\niliamna_transformed = transform_shapes(iliamna_shp, crs_project)\n\nCRS setup successful\nProjection transformed to +proj=stere +lat_0=90 +lat_ts=60 +lon_0=-80 +k=1 +x_0=0 +y_0=0 +a=6378137 +b=6356257 +units=m +no_defs\n\n\n\n# Examine lake shape crs\niliamna_transformed.crs\n\n&lt;Projected CRS: +proj=stere +lat_0=90 +lat_ts=60 +lon_0=-80 +k=1 + ...&gt;\nName: unknown\nAxis Info [cartesian]:\n- E[south]: Easting (metre)\n- N[south]: Northing (metre)\nArea of Use:\n- undefined\nCoordinate Operation:\n- name: unknown\n- method: Polar Stereographic (variant B)\nDatum: unknown\n- Ellipsoid: unknown\n- Prime Meridian: Greenwich\n\n\n\n# Visualized transformed iliamna shape\niliamna_transformed.plot()\n\n\n\n\n\n\n\n\n\nSubset the satellite data using the Lake shape\n\n# Clip data to the shape\nds_clipped = clip_data_to_shapefile(ds, iliamna_transformed.geometry, iliamna_transformed.crs)\n\nClipping successful\n\n\n\n# Visualized clipped data\nds_clipped[\"IMS_Surface_Values\"].plot()\n\n\n\n\n\n\n\n\n\n\n\nResources\n\nCoastWatch Learning Portal - Lectures, Videos, Other learning resources\nCoastWatch Tutorials on Github - Tutorial notebooks and code samples\nPolarWatch ERDDAP - Complete list of data available on PolarWatch ERDDAP Server\nPolarWatch Catalog - Preview data on polar map"
  }
]