[
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html",
    "href": "tutorials/python/timeseries_compare_sensors.html",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "",
    "text": "CoastWatch Python Exercises"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#background",
    "href": "tutorials/python/timeseries_compare_sensors.html#background",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Background",
    "text": "Background\nSeveral ocean color sensors have been launched since 1997 to provide continuous global coverage for ocean color data. The sensors have differences in design and calibration, and different algorithms may be applied to generate chlorophyll values. Consequently, chlorophyll-a values can vary among the sensors during periods where measurements overlap.\nTo examine this phenomenon, we will download and plot a time series of chlorophyll-a concentrations from various sensors that collected data between 1997 and the present to see how the measurements compare during periods of overlap."
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#objective",
    "href": "tutorials/python/timeseries_compare_sensors.html#objective",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show how to extract a time series from four different monthly satellite chlorophyll datasets for the period that each was in operation between 1997-present."
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/timeseries_compare_sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nUsing xarray to extract data from a rectangular area of the ocean over time\nRetrieving information about a dataset from ERDDAP\nComparing results from different sensors\nAveraging data spatially\nProducing time-series plots\nDrawing maps with satellite data"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#datasets-used",
    "href": "tutorials/python/timeseries_compare_sensors.html#datasets-used",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Datasets used",
    "text": "Datasets used\nSeaWiFS Chlorophyll-a, V.2018, Monthly, Global, 4km, 1997-2012\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nMODIS Aqua, Chlorophyll-a, V.2022, Monthly, Global, 4km, 2002-present\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022SQ\nNOAA VIIRS S-NPP, Chlorophyll-a, Monthly, Global, 4km, 2012-present\nhttps://coastwatch.noaa.gov/erddap/griddap/noaacwNPPVIIRSSQchlaMonthly\nESA CCI Ocean Colour Dataset, v6.0, Monthly, Global, 4km, 1997-Present\nThis dataset was developed by the European Space Agency’s Climate Change Initiative. The dataset merges data from multiple sensors (MERIS, MODIS, VIIRS and SeaWiFS) to create a long time series (1997 to present) with better spatial coverage than any single sensor. Parameters include chlorophyll a, remote sensing reflectance, diffuse attenuation coefficients, absorption coefficients, backscatter coefficients, and water classification.\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorMonthly"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#import-required-packages",
    "href": "tutorials/python/timeseries_compare_sensors.html#import-required-packages",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Import required packages",
    "text": "Import required packages\n\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#define-the-area-to-extract",
    "href": "tutorials/python/timeseries_compare_sensors.html#define-the-area-to-extract",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nFor each dataset we will extract data for an area in the Gulf of Mexico between -95 to -90°W longitude and 25-30°N latitude.\nSet up variables with the minimum and maximum values from the longitude and latitude ranges.\n\nlon_min = -95.\nlon_max = -90.\nlat_min = 25.\nlat_max = 30."
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#get-the-seawifs-data",
    "href": "tutorials/python/timeseries_compare_sensors.html#get-the-seawifs-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get the SeaWiFS data",
    "text": "Get the SeaWiFS data\n\nOpen a dataset object in xarray\n\nurl_sw = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday'\nsw_ds = xr.open_dataset(url_sw)\nsw_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:      (time: 157, latitude: 2160, longitude: 4320)\nCoordinates:\n  * time         (time) datetime64[ns] 1997-09-16 1997-10-16 ... 2010-12-16\n  * latitude     (latitude) float32 89.96 89.88 89.79 ... -89.79 -89.88 -89.96\n  * longitude    (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nData variables:\n    chlorophyll  (time, latitude, longitude) float32 ...\nAttributes: (12/50)\n    _lastModified:                     2018-01-31T04:58:26.000Z\n    _NCProperties:                     version=1|netcdflibversion=4.4.1.1|hdf...\n    cdm_data_type:                     Grid\n    Conventions:                       CF-1.6, COARDS, ACDD-1.3\n    creator_email:                     data@oceancolor.gsfc.nasa.gov\n    creator_name:                      NASA/GSFC/OBPG\n    ...                                ...\n    summary:                           NASA GSFC Ocean Color Web distributes ...\n    temporal_range:                    10-day\n    time_coverage_end:                 2010-12-16T00:00:00Z\n    time_coverage_start:               1997-09-16T00:00:00Z\n    title:                             Chlorophyll-a, Orbview-2 SeaWiFS, R201...\n    Westernmost_Easting:               -179.9583xarray.DatasetDimensions:time: 157latitude: 2160longitude: 4320Coordinates: (3)time(time)datetime64[ns]1997-09-16 ... 2010-12-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000', '1998-02-16T00:00:00.000000000',\n       '1998-03-16T00:00:00.000000000', '1998-04-16T00:00:00.000000000',\n       '1998-05-16T00:00:00.000000000', '1998-06-16T00:00:00.000000000',\n       '1998-07-16T00:00:00.000000000', '1998-08-16T00:00:00.000000000',\n       '1998-09-16T00:00:00.000000000', '1998-10-16T00:00:00.000000000',\n       '1998-11-16T00:00:00.000000000', '1998-12-16T00:00:00.000000000',\n       '1999-01-16T00:00:00.000000000', '1999-02-16T00:00:00.000000000',\n       '1999-03-16T00:00:00.000000000', '1999-04-16T00:00:00.000000000',\n       '1999-05-16T00:00:00.000000000', '1999-06-16T00:00:00.000000000',\n       '1999-07-16T00:00:00.000000000', '1999-08-16T00:00:00.000000000',\n       '1999-09-16T00:00:00.000000000', '1999-10-16T00:00:00.000000000',\n       '1999-11-16T00:00:00.000000000', '1999-12-16T00:00:00.000000000',\n       '2000-01-16T00:00:00.000000000', '2000-02-16T00:00:00.000000000',\n       '2000-03-16T00:00:00.000000000', '2000-04-16T00:00:00.000000000',\n       '2000-05-16T00:00:00.000000000', '2000-06-16T00:00:00.000000000',\n       '2000-07-16T00:00:00.000000000', '2000-08-16T00:00:00.000000000',\n       '2000-09-16T00:00:00.000000000', '2000-10-16T00:00:00.000000000',\n       '2000-11-16T00:00:00.000000000', '2000-12-16T00:00:00.000000000',\n       '2001-01-16T00:00:00.000000000', '2001-02-16T00:00:00.000000000',\n       '2001-03-16T00:00:00.000000000', '2001-04-16T00:00:00.000000000',\n       '2001-05-16T00:00:00.000000000', '2001-06-16T00:00:00.000000000',\n       '2001-07-16T00:00:00.000000000', '2001-08-16T00:00:00.000000000',\n       '2001-09-16T00:00:00.000000000', '2001-10-16T00:00:00.000000000',\n       '2001-11-16T00:00:00.000000000', '2001-12-16T00:00:00.000000000',\n       '2002-01-16T00:00:00.000000000', '2002-02-16T00:00:00.000000000',\n       '2002-03-16T00:00:00.000000000', '2002-04-16T00:00:00.000000000',\n       '2002-05-16T00:00:00.000000000', '2002-06-16T00:00:00.000000000',\n       '2002-07-16T00:00:00.000000000', '2002-08-16T00:00:00.000000000',\n       '2002-09-16T00:00:00.000000000', '2002-10-16T00:00:00.000000000',\n       '2002-11-16T00:00:00.000000000', '2002-12-16T00:00:00.000000000',\n       '2003-01-16T00:00:00.000000000', '2003-02-16T00:00:00.000000000',\n       '2003-03-16T00:00:00.000000000', '2003-04-16T00:00:00.000000000',\n       '2003-05-16T00:00:00.000000000', '2003-06-16T00:00:00.000000000',\n       '2003-07-16T00:00:00.000000000', '2003-08-16T00:00:00.000000000',\n       '2003-09-16T00:00:00.000000000', '2003-10-16T00:00:00.000000000',\n       '2003-11-16T00:00:00.000000000', '2003-12-16T00:00:00.000000000',\n       '2004-01-16T00:00:00.000000000', '2004-02-16T00:00:00.000000000',\n       '2004-03-16T00:00:00.000000000', '2004-04-16T00:00:00.000000000',\n       '2004-05-16T00:00:00.000000000', '2004-06-16T00:00:00.000000000',\n       '2004-07-16T00:00:00.000000000', '2004-08-16T00:00:00.000000000',\n       '2004-09-16T00:00:00.000000000', '2004-10-16T00:00:00.000000000',\n       '2004-11-16T00:00:00.000000000', '2004-12-16T00:00:00.000000000',\n       '2005-01-16T00:00:00.000000000', '2005-02-16T00:00:00.000000000',\n       '2005-03-16T00:00:00.000000000', '2005-04-16T00:00:00.000000000',\n       '2005-05-16T00:00:00.000000000', '2005-06-16T00:00:00.000000000',\n       '2005-07-16T00:00:00.000000000', '2005-08-16T00:00:00.000000000',\n       '2005-09-16T00:00:00.000000000', '2005-10-16T00:00:00.000000000',\n       '2005-11-16T00:00:00.000000000', '2005-12-16T00:00:00.000000000',\n       '2006-01-16T00:00:00.000000000', '2006-02-16T00:00:00.000000000',\n       '2006-03-16T00:00:00.000000000', '2006-04-16T00:00:00.000000000',\n       '2006-05-16T00:00:00.000000000', '2006-06-16T00:00:00.000000000',\n       '2006-07-16T00:00:00.000000000', '2006-08-16T00:00:00.000000000',\n       '2006-09-16T00:00:00.000000000', '2006-10-16T00:00:00.000000000',\n       '2006-11-16T00:00:00.000000000', '2006-12-16T00:00:00.000000000',\n       '2007-01-16T00:00:00.000000000', '2007-02-16T00:00:00.000000000',\n       '2007-03-16T00:00:00.000000000', '2007-04-16T00:00:00.000000000',\n       '2007-05-16T00:00:00.000000000', '2007-06-16T00:00:00.000000000',\n       '2007-07-16T00:00:00.000000000', '2007-08-16T00:00:00.000000000',\n       '2007-09-16T00:00:00.000000000', '2007-10-16T00:00:00.000000000',\n       '2007-11-16T00:00:00.000000000', '2007-12-16T00:00:00.000000000',\n       '2008-01-16T00:00:00.000000000', '2008-04-16T00:00:00.000000000',\n       '2008-05-16T00:00:00.000000000', '2008-06-16T00:00:00.000000000',\n       '2008-07-16T00:00:00.000000000', '2008-08-16T00:00:00.000000000',\n       '2008-09-16T00:00:00.000000000', '2008-10-16T00:00:00.000000000',\n       '2008-11-16T00:00:00.000000000', '2008-12-16T00:00:00.000000000',\n       '2009-01-16T00:00:00.000000000', '2009-02-16T00:00:00.000000000',\n       '2009-03-16T00:00:00.000000000', '2009-04-16T00:00:00.000000000',\n       '2009-06-16T00:00:00.000000000', '2009-07-16T00:00:00.000000000',\n       '2009-08-16T00:00:00.000000000', '2009-09-16T00:00:00.000000000',\n       '2009-10-16T00:00:00.000000000', '2009-11-16T00:00:00.000000000',\n       '2009-12-16T00:00:00.000000000', '2010-01-16T00:00:00.000000000',\n       '2010-02-16T00:00:00.000000000', '2010-03-16T00:00:00.000000000',\n       '2010-04-16T00:00:00.000000000', '2010-05-16T00:00:00.000000000',\n       '2010-06-16T00:00:00.000000000', '2010-07-16T00:00:00.000000000',\n       '2010-08-16T00:00:00.000000000', '2010-09-16T00:00:00.000000000',\n       '2010-10-16T00:00:00.000000000', '2010-11-16T00:00:00.000000000',\n       '2010-12-16T00:00:00.000000000'], dtype='datetime64[ns]')latitude(latitude)float3289.96 89.88 89.79 ... -89.88 -89.96_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([ 89.958336,  89.875   ,  89.79167 , ..., -89.791664, -89.87501 ,\n       -89.958336], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_CoordinateAxisType :Lonactual_range :[-179.9583  179.9584]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79166, ...,  179.79167,  179.87502,\n        179.95836], dtype=float32)Data variables: (1)chlorophyll(time, latitude, longitude)float32...colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll Concentration, OCI Algorithmreferences :Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.standard_name :concentration_of_chlorophyll_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001[1464998400 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16', '1998-02-16', '1998-03-16', '1998-04-16',\n               '1998-05-16', '1998-06-16',\n               ...\n               '2010-03-16', '2010-04-16', '2010-05-16', '2010-06-16',\n               '2010-07-16', '2010-08-16', '2010-09-16', '2010-10-16',\n               '2010-11-16', '2010-12-16'],\n              dtype='datetime64[ns]', name='time', length=157, freq=None))latitudePandasIndexPandasIndex(Index([ 89.95833587646484,             89.875,  89.79167175292969,\n        89.70833587646484,             89.625,  89.54167175292969,\n        89.45833587646484,             89.375,  89.29167175292969,\n        89.20833587646484,\n       ...\n       -89.20833587646484, -89.29166412353516, -89.37500762939453,\n       -89.45833587646484, -89.54166412353516, -89.62500762939453,\n       -89.70833587646484, -89.79166412353516, -89.87500762939453,\n       -89.95833587646484],\n      dtype='float32', name='latitude', length=2160))longitudePandasIndexPandasIndex(Index([ -179.9583282470703,            -179.875, -179.79165649414062,\n        -179.7083282470703,            -179.625, -179.54165649414062,\n        -179.4583282470703,            -179.375, -179.29165649414062,\n        -179.2083282470703,\n       ...\n        179.20835876464844,   179.2916717529297,  179.37501525878906,\n        179.45835876464844,   179.5416717529297,  179.62501525878906,\n        179.70835876464844,   179.7916717529297,  179.87501525878906,\n        179.95835876464844],\n      dtype='float32', name='longitude', length=4320))Attributes: (50)_lastModified :2018-01-31T04:58:26.000Z_NCProperties :version=1|netcdflibversion=4.4.1.1|hdf5libversion=1.8.18cdm_data_type :GridConventions :CF-1.6, COARDS, ACDD-1.3creator_email :data@oceancolor.gsfc.nasa.govcreator_name :NASA/GSFC/OBPGcreator_type :groupcreator_url :https://oceandata.sci.gsfc.nasa.govdate_created :2018-01-31T04:58:26.000ZEasternmost_Easting :179.9584geospatial_lat_max :89.95834geospatial_lat_min :-89.95834geospatial_lat_units :degrees_northgeospatial_lon_max :179.9584geospatial_lon_min :-179.9583geospatial_lon_units :degrees_eastgrid_mapping_name :latitude_longitudehistory :These R2018.0 data files were downloaded from https://oceandata.sci.gsfc.nasa.gov/SeaWiFS/Mapped/Monthly/9km/chlor_a to NOAA NMFS SWFSC by erd.data@noaa.gov ERD on 2018-03-05.\n2023-09-06T13:45:15Z (local files)\n2023-09-06T13:45:15Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday.dasidentifier_product_doi :10.5067/ORBVIEW-2/SEAWIFS/L3M/CHL/2018identifier_product_doi_authority :https://dx.doi.orginfoUrl :https://oceandata.sci.gsfc.nasa.govinstitution :NASA/GSFC OBPGinstrument :SeaWiFSkeywords :algorithm, biology, center, chemistry, chlor_a, chlorophyll, color, concentration, concentration_of_chlorophyll_in_sea_water, data, Earth Science &gt; Oceans &gt; Ocean Chemistry &gt; Chlorophyll, Earth Science &gt; Oceans &gt; Ocean Optics &gt; Ocean Color, field, field-of-view, flight, goddard, group, gsfc, image, L3, level, level-3, mapped, nasa, noaa, obpg, ocean, ocean color, oceans, oci, optics, orbview, orbview-2, palette, processing, sea, sea-wide, seawater, seawifs, sensor, smi, space, standard, view, water, widekeywords_vocabulary :GCMD Science Keywordsl2_flag_names :ATMFAIL,LAND,HILT,HISATZEN,STRAYLIGHT,CLDICE,COCCOLITH,LOWLW,CHLWARN,CHLFAIL,NAVWARN,MAXAERITER,ATMWARN,HISOLZEN,NAVFAIL,FILTER,HIGLINTlicense :https://science.nasa.gov/earth-science/earth-science-data/data-information-policy/\n\nPlease cite: NASA Goddard Space Flight Center, Ocean Ecology Laboratory, Ocean Biology Processing Group. Sea-viewing Wide Field-of-view Sensor (SeaWiFS) R2018.0 Chlorophyll Data; NASA OB.DAAC, Greenbelt, MD, USA. doi: https://dx.doi.org/10.5067/ORBVIEW-2/SEAWIFS/L3M/CHL/2018 .\n\nThe data may be used and redistributed for free but is not intended\nfor legal use, since it may contain inaccuracies. Neither the data\nContributor, ERD, NOAA, nor the United States Government, nor any\nof their employees or contractors, makes any warranty, express or\nimplied, including warranties of merchantability and fitness for a\nparticular purpose, or assumes any legal liability for the accuracy,\ncompleteness, or usefulness, of this information.map_projection :Equidistant Cylindricalmeasure :Meannaming_authority :gov.noaa.pfeg.coastwatchNorthernmost_Northing :89.95834platform :Orbview-2processing_level :L3 Mappedprocessing_version :2018.0project :Ocean Biology Processing Group (NASA/GSFC/OBPG)publisher_email :data@oceancolor.gsfc.nasa.govpublisher_name :NASA/GSFC/OBPGpublisher_type :grouppublisher_url :https://oceandata.sci.gsfc.nasa.govreferences :SeaWiFS information: https://oceancolor.gsfc.nasa.gov/SeaWiFS/ . NASA Ocean\nColor information: https://oceancolor.gsfc.nasa.gov/\nProcessing reference: O'Reilly, J.E., Maritorena, S., Mitchell, B.G., Siegel, D.A., Carder, K.L., Garver, S.A., Kahru, M. and McClain, C. (1998). Ocean color chlorophyll algorithms for SeaWiFS. J. Geophys. Res., 103: 24, 937-24, 953.\nProcessing reference: O'Reilly, J. E., and 21 others. 2000. Ocean color chlorophyll a algorithms for SeaWiFS, OC2 and OC4: Version 4. SeaWiFS Postlaunch Calibration and Validation Analyses, part 3. NASA SeaWiFS technical report series. pp. 8 226 22.\nProcessing reference: Fu, G., Baith, K. S., and McClain, C. R. (1998). SeaDAS: The SeaWiFS Data Analysis System. Proceedings of \"The 4th Pacific Ocean Remote Sensing Conference\", Qingdao, China, July 28-31, 1998, 73-79.\nValidation reference: Hooker, S.B., and C.R. McClain (2000). The Calibration and Validation of SeaWiFS Data. Prog. Oceanogr., 45, 427-465.\nR2014.0 processing reference: Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.\nR2018.0 reprocessing information: https://oceancolor.gsfc.nasa.gov/reprocessing/r2018/seawifs/sourceUrl :(local files)Southernmost_Northing :-89.95834spatialResolution :9.28 kmstandard_name_vocabulary :CF Standard Name Table v70summary :NASA GSFC Ocean Color Web distributes science-quality chlorophyll-a\nconcentration data from the Sea-viewing Wide Field-of-view Sensor (SeaWiFS)\non the Orbview-2 satellite. This version is the 2018.0 Reprocessing (R2018.0). https://oceancolor.gsfc.nasa.gov/reprocessing/r2018/seawifs/\n\nThe SeaWiFS instrument was launched by Orbital Sciences Corporation on the\nOrbView-2 (a.k.a. SeaStar) satellite in August 1997, and collected data from\nSeptember 1997 until the end of mission in December 2010. SeaWiFS had 8\nspectral bands from 412 to 865 nm. It collected global data at 4 km\nresolution, and local data (limited onboard storage and direct broadcast)\nat 1 km. The mission and sensor were optimized for ocean color measurements,\nwith a local noon (descending) equator crossing time orbit, fore-and-aft\ntilt capability, full dynamic range, and low polarization sensitivity.temporal_range :10-daytime_coverage_end :2010-12-16T00:00:00Ztime_coverage_start :1997-09-16T00:00:00Ztitle :Chlorophyll-a, Orbview-2 SeaWiFS, R2018.0, 0.1�, Global, 1997-2010 (Monthly Composite)Westernmost_Easting :-179.9583\n\n\n\n\nPrint out some useful metadata\nYou can view all of the metadata above in the dataset object. Let’s print out some metadata items to point a few things out: * The SeaWiFS dataset spans 13 years, from 1997 to 2010\n* The chlorophyll variable is called “chlorophyll”. Knowing this is important because variable names are not standardized, and we will need to know the exact variable name to extract the data. * Checking the first and last value of latitude can tell us if the latitude values are in ascending or descending order.\n\nprint('earliest date =', sw_ds.time.values[0])\nprint('most recent date =', sw_ds.time.values[-1], '\\n')\nprint('variable:', list(sw_ds.data_vars.keys()), '\\n')\n\nprint(\"Is latitude's first value --&gt;\", round(sw_ds.latitude[0].item(), 6))\nprint('greater than') \nprint(\"latitude's last value --&gt;\", round(sw_ds.latitude[-1].item(), 6))\n\nprint(sw_ds.latitude[0].item() &gt; sw_ds.latitude[-1].item())\n\n\nearliest date = 1997-09-16T00:00:00.000000000\nmost recent date = 2010-12-16T00:00:00.000000000 \n\nvariable: ['chlorophyll'] \n\nIs latitude's first value --&gt; 89.958336\ngreater than\nlatitude's last value --&gt; -89.958336\nTrue\n\n\n\n\nPay attention to the first and last values of latitude in the dataset\nIn a netCDF file that completely follows accepted standards, the latitude values are ascending; the values go from lowest to highest (south to north). Therefore, when we use the slice function (below) to subset the dataset we would list the lowest value in our subset followed by the highest.\n* slice(lat_min, lat_max)\nHowever, for some datasets the latitude values are in descending order, meaning the files were built with latitudes indexed from highest to lowest (north to south). It is a common occurrence and it impacts how we subset that dataset, so you need to be aware of it.\n* With latitude values in descending order, if you use “slice(lat_min, lat_max)” you will get no data, because there are no latitude values between lat_min and lat_max. * However, by reversing the order within slice by using “slice(lat_max, lat_min)” you will get data.\nFor the SeaWiFS dataset, the metadata above show that the first latitude value (89.958336) is greater than the last (-89.958336). The latitude values are in descending order.\n* There are methods in xarray to flip the latitude dimension. A simpler solution is to use a logic step that determines if latitude values are descending, then set slice values to use the higher value first (see below).\n\n# The lat1 and lat2 values are used in the slice function\n# At first we set them as if the dataset is compliant with standards\nlat1 = lat_min\nlat2 = lat_max\n\n# Then switch them if latitude values are descending\nif sw_ds.latitude[0].item() &gt; sw_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\n\n\nSubset the data from the dataset object.\nNote that so far we have not downloaded data. We have only set up how we want to download the data. * The download will happen when we request to use data, like when creating the map below.\n\n\nsw_subset = sw_ds['chlorophyll'].sel(time=slice(sw_ds.time[0], sw_ds.time[-1]),\n                                     latitude=slice(lat1, lat2),\n                                     longitude=slice(lon_min, lon_max)\n                                     )\nsw_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlorophyll' (time: 157, latitude: 60, longitude: 60)&gt;\n[565200 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 1997-09-16 1997-10-16 ... 2010-12-16\n  * latitude   (latitude) float32 29.96 29.87 29.79 29.71 ... 25.21 25.12 25.04\n  * longitude  (longitude) float32 -94.96 -94.88 -94.79 ... -90.21 -90.12 -90.04\nAttributes:\n    colorBarMaximum:  30.0\n    colorBarMinimum:  0.03\n    colorBarScale:    Log\n    ioos_category:    Ocean Color\n    long_name:        Chlorophyll Concentration, OCI Algorithm\n    references:       Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a a...\n    standard_name:    concentration_of_chlorophyll_in_sea_water\n    units:            mg m^-3\n    valid_max:        100.0\n    valid_min:        0.001xarray.DataArray'chlorophyll'time: 157latitude: 60longitude: 60...[565200 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]1997-09-16 ... 2010-12-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000', '1998-02-16T00:00:00.000000000',\n       '1998-03-16T00:00:00.000000000', '1998-04-16T00:00:00.000000000',\n       '1998-05-16T00:00:00.000000000', '1998-06-16T00:00:00.000000000',\n       '1998-07-16T00:00:00.000000000', '1998-08-16T00:00:00.000000000',\n       '1998-09-16T00:00:00.000000000', '1998-10-16T00:00:00.000000000',\n       '1998-11-16T00:00:00.000000000', '1998-12-16T00:00:00.000000000',\n       '1999-01-16T00:00:00.000000000', '1999-02-16T00:00:00.000000000',\n       '1999-03-16T00:00:00.000000000', '1999-04-16T00:00:00.000000000',\n       '1999-05-16T00:00:00.000000000', '1999-06-16T00:00:00.000000000',\n       '1999-07-16T00:00:00.000000000', '1999-08-16T00:00:00.000000000',\n       '1999-09-16T00:00:00.000000000', '1999-10-16T00:00:00.000000000',\n       '1999-11-16T00:00:00.000000000', '1999-12-16T00:00:00.000000000',\n       '2000-01-16T00:00:00.000000000', '2000-02-16T00:00:00.000000000',\n       '2000-03-16T00:00:00.000000000', '2000-04-16T00:00:00.000000000',\n       '2000-05-16T00:00:00.000000000', '2000-06-16T00:00:00.000000000',\n       '2000-07-16T00:00:00.000000000', '2000-08-16T00:00:00.000000000',\n       '2000-09-16T00:00:00.000000000', '2000-10-16T00:00:00.000000000',\n       '2000-11-16T00:00:00.000000000', '2000-12-16T00:00:00.000000000',\n       '2001-01-16T00:00:00.000000000', '2001-02-16T00:00:00.000000000',\n       '2001-03-16T00:00:00.000000000', '2001-04-16T00:00:00.000000000',\n       '2001-05-16T00:00:00.000000000', '2001-06-16T00:00:00.000000000',\n       '2001-07-16T00:00:00.000000000', '2001-08-16T00:00:00.000000000',\n       '2001-09-16T00:00:00.000000000', '2001-10-16T00:00:00.000000000',\n       '2001-11-16T00:00:00.000000000', '2001-12-16T00:00:00.000000000',\n       '2002-01-16T00:00:00.000000000', '2002-02-16T00:00:00.000000000',\n       '2002-03-16T00:00:00.000000000', '2002-04-16T00:00:00.000000000',\n       '2002-05-16T00:00:00.000000000', '2002-06-16T00:00:00.000000000',\n       '2002-07-16T00:00:00.000000000', '2002-08-16T00:00:00.000000000',\n       '2002-09-16T00:00:00.000000000', '2002-10-16T00:00:00.000000000',\n       '2002-11-16T00:00:00.000000000', '2002-12-16T00:00:00.000000000',\n       '2003-01-16T00:00:00.000000000', '2003-02-16T00:00:00.000000000',\n       '2003-03-16T00:00:00.000000000', '2003-04-16T00:00:00.000000000',\n       '2003-05-16T00:00:00.000000000', '2003-06-16T00:00:00.000000000',\n       '2003-07-16T00:00:00.000000000', '2003-08-16T00:00:00.000000000',\n       '2003-09-16T00:00:00.000000000', '2003-10-16T00:00:00.000000000',\n       '2003-11-16T00:00:00.000000000', '2003-12-16T00:00:00.000000000',\n       '2004-01-16T00:00:00.000000000', '2004-02-16T00:00:00.000000000',\n       '2004-03-16T00:00:00.000000000', '2004-04-16T00:00:00.000000000',\n       '2004-05-16T00:00:00.000000000', '2004-06-16T00:00:00.000000000',\n       '2004-07-16T00:00:00.000000000', '2004-08-16T00:00:00.000000000',\n       '2004-09-16T00:00:00.000000000', '2004-10-16T00:00:00.000000000',\n       '2004-11-16T00:00:00.000000000', '2004-12-16T00:00:00.000000000',\n       '2005-01-16T00:00:00.000000000', '2005-02-16T00:00:00.000000000',\n       '2005-03-16T00:00:00.000000000', '2005-04-16T00:00:00.000000000',\n       '2005-05-16T00:00:00.000000000', '2005-06-16T00:00:00.000000000',\n       '2005-07-16T00:00:00.000000000', '2005-08-16T00:00:00.000000000',\n       '2005-09-16T00:00:00.000000000', '2005-10-16T00:00:00.000000000',\n       '2005-11-16T00:00:00.000000000', '2005-12-16T00:00:00.000000000',\n       '2006-01-16T00:00:00.000000000', '2006-02-16T00:00:00.000000000',\n       '2006-03-16T00:00:00.000000000', '2006-04-16T00:00:00.000000000',\n       '2006-05-16T00:00:00.000000000', '2006-06-16T00:00:00.000000000',\n       '2006-07-16T00:00:00.000000000', '2006-08-16T00:00:00.000000000',\n       '2006-09-16T00:00:00.000000000', '2006-10-16T00:00:00.000000000',\n       '2006-11-16T00:00:00.000000000', '2006-12-16T00:00:00.000000000',\n       '2007-01-16T00:00:00.000000000', '2007-02-16T00:00:00.000000000',\n       '2007-03-16T00:00:00.000000000', '2007-04-16T00:00:00.000000000',\n       '2007-05-16T00:00:00.000000000', '2007-06-16T00:00:00.000000000',\n       '2007-07-16T00:00:00.000000000', '2007-08-16T00:00:00.000000000',\n       '2007-09-16T00:00:00.000000000', '2007-10-16T00:00:00.000000000',\n       '2007-11-16T00:00:00.000000000', '2007-12-16T00:00:00.000000000',\n       '2008-01-16T00:00:00.000000000', '2008-04-16T00:00:00.000000000',\n       '2008-05-16T00:00:00.000000000', '2008-06-16T00:00:00.000000000',\n       '2008-07-16T00:00:00.000000000', '2008-08-16T00:00:00.000000000',\n       '2008-09-16T00:00:00.000000000', '2008-10-16T00:00:00.000000000',\n       '2008-11-16T00:00:00.000000000', '2008-12-16T00:00:00.000000000',\n       '2009-01-16T00:00:00.000000000', '2009-02-16T00:00:00.000000000',\n       '2009-03-16T00:00:00.000000000', '2009-04-16T00:00:00.000000000',\n       '2009-06-16T00:00:00.000000000', '2009-07-16T00:00:00.000000000',\n       '2009-08-16T00:00:00.000000000', '2009-09-16T00:00:00.000000000',\n       '2009-10-16T00:00:00.000000000', '2009-11-16T00:00:00.000000000',\n       '2009-12-16T00:00:00.000000000', '2010-01-16T00:00:00.000000000',\n       '2010-02-16T00:00:00.000000000', '2010-03-16T00:00:00.000000000',\n       '2010-04-16T00:00:00.000000000', '2010-05-16T00:00:00.000000000',\n       '2010-06-16T00:00:00.000000000', '2010-07-16T00:00:00.000000000',\n       '2010-08-16T00:00:00.000000000', '2010-09-16T00:00:00.000000000',\n       '2010-10-16T00:00:00.000000000', '2010-11-16T00:00:00.000000000',\n       '2010-12-16T00:00:00.000000000'], dtype='datetime64[ns]')latitude(latitude)float3229.96 29.87 29.79 ... 25.12 25.04_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([29.958334, 29.874998, 29.791666, 29.708334, 29.624998, 29.541666,\n       29.458334, 29.374998, 29.291666, 29.208334, 29.124998, 29.041666,\n       28.958334, 28.874998, 28.791666, 28.708334, 28.624998, 28.541666,\n       28.458334, 28.374998, 28.291666, 28.208334, 28.124998, 28.041666,\n       27.958334, 27.874998, 27.791666, 27.708334, 27.624998, 27.541666,\n       27.458334, 27.374998, 27.291666, 27.208334, 27.124998, 27.041666,\n       26.958334, 26.874998, 26.791666, 26.708334, 26.624998, 26.541666,\n       26.458334, 26.374998, 26.291666, 26.208334, 26.124998, 26.041666,\n       25.958334, 25.874998, 25.791662, 25.708334, 25.624998, 25.541662,\n       25.458334, 25.374998, 25.291662, 25.208334, 25.124998, 25.041662],\n      dtype=float32)longitude(longitude)float32-94.96 -94.88 ... -90.12 -90.04_CoordinateAxisType :Lonactual_range :[-179.9583  179.9584]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-94.958336, -94.875   , -94.791664, -94.708336, -94.625   , -94.541664,\n       -94.458336, -94.375   , -94.291664, -94.208336, -94.125   , -94.041664,\n       -93.958336, -93.875   , -93.791664, -93.708336, -93.625   , -93.541664,\n       -93.458336, -93.375   , -93.291664, -93.208336, -93.125   , -93.041664,\n       -92.958336, -92.875   , -92.791664, -92.708336, -92.625   , -92.541664,\n       -92.458336, -92.375   , -92.291664, -92.208336, -92.125   , -92.041664,\n       -91.958336, -91.875   , -91.791664, -91.708336, -91.625   , -91.541664,\n       -91.458336, -91.375   , -91.291664, -91.208336, -91.125   , -91.041664,\n       -90.958336, -90.875   , -90.791664, -90.708336, -90.625   , -90.541664,\n       -90.458336, -90.375   , -90.291664, -90.208336, -90.125   , -90.041664],\n      dtype=float32)Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16', '1998-02-16', '1998-03-16', '1998-04-16',\n               '1998-05-16', '1998-06-16',\n               ...\n               '2010-03-16', '2010-04-16', '2010-05-16', '2010-06-16',\n               '2010-07-16', '2010-08-16', '2010-09-16', '2010-10-16',\n               '2010-11-16', '2010-12-16'],\n              dtype='datetime64[ns]', name='time', length=157, freq=None))latitudePandasIndexPandasIndex(Index([ 29.95833396911621, 29.874998092651367,  29.79166603088379,\n        29.70833396911621, 29.624998092651367,  29.54166603088379,\n        29.45833396911621, 29.374998092651367,  29.29166603088379,\n        29.20833396911621, 29.124998092651367,  29.04166603088379,\n        28.95833396911621, 28.874998092651367,  28.79166603088379,\n        28.70833396911621, 28.624998092651367,  28.54166603088379,\n        28.45833396911621, 28.374998092651367,  28.29166603088379,\n        28.20833396911621, 28.124998092651367,  28.04166603088379,\n        27.95833396911621, 27.874998092651367,  27.79166603088379,\n        27.70833396911621, 27.624998092651367,  27.54166603088379,\n        27.45833396911621, 27.374998092651367,  27.29166603088379,\n        27.20833396911621, 27.124998092651367,  27.04166603088379,\n        26.95833396911621, 26.874998092651367,  26.79166603088379,\n        26.70833396911621, 26.624998092651367,  26.54166603088379,\n        26.45833396911621, 26.374998092651367,  26.29166603088379,\n        26.20833396911621, 26.124998092651367,  26.04166603088379,\n        25.95833396911621, 25.874998092651367, 25.791662216186523,\n        25.70833396911621, 25.624998092651367, 25.541662216186523,\n        25.45833396911621, 25.374998092651367, 25.291662216186523,\n        25.20833396911621, 25.124998092651367, 25.041662216186523],\n      dtype='float32', name='latitude'))longitudePandasIndexPandasIndex(Index([-94.95833587646484,            -94.875, -94.79166412353516,\n       -94.70833587646484,            -94.625, -94.54166412353516,\n       -94.45833587646484,            -94.375, -94.29166412353516,\n       -94.20833587646484,            -94.125, -94.04166412353516,\n       -93.95833587646484,            -93.875, -93.79166412353516,\n       -93.70833587646484,            -93.625, -93.54166412353516,\n       -93.45833587646484,            -93.375, -93.29166412353516,\n       -93.20833587646484,            -93.125, -93.04166412353516,\n       -92.95833587646484,            -92.875, -92.79166412353516,\n       -92.70833587646484,            -92.625, -92.54166412353516,\n       -92.45833587646484,            -92.375, -92.29166412353516,\n       -92.20833587646484,            -92.125, -92.04166412353516,\n       -91.95833587646484,            -91.875, -91.79166412353516,\n       -91.70833587646484,            -91.625, -91.54166412353516,\n       -91.45833587646484,            -91.375, -91.29166412353516,\n       -91.20833587646484,            -91.125, -91.04166412353516,\n       -90.95833587646484,            -90.875, -90.79166412353516,\n       -90.70833587646484,            -90.625, -90.54166412353516,\n       -90.45833587646484,            -90.375, -90.29166412353516,\n       -90.20833587646484,            -90.125, -90.04166412353516],\n      dtype='float32', name='longitude'))Attributes: (10)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll Concentration, OCI Algorithmreferences :Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.standard_name :concentration_of_chlorophyll_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001\n\n\n\n\nPlot data to show where it is in the world.\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\nax1.set_extent([240, 300, 5, 45], ccrs.PlateCarree())\n\n# Set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(235, 305, 20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(0, 50, 10), crs=ccrs.PlateCarree())\n\n# Add features to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# Format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nnp.log10(sw_subset[-1]).plot.pcolormesh(ax=ax1, \n                                        transform=ccrs.PlateCarree(), \n                                        cmap='jet', \n                                        cbar_kwargs={'label': \"log chlorophyll (mg m-3)\"})\n\nplt.title('Time series data location - Gulf of Mexico')\n\nText(0.5, 1.0, 'Time series data location - Gulf of Mexico')\n\n\n\n\n\n\n\n\n\n\n\nCompute the monthly mean over the region\n\nswAVG = sw_subset.mean(dim=['latitude','longitude'])\nswAVG.head()\n\n# If you are running low on memory, uncomment the next line\n# del sw_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlorophyll' (time: 5)&gt;\narray([0.59386134, 0.59238297, 0.68359953, 0.81557316, 0.85900825],\n      dtype=float32)\nCoordinates:\n  * time     (time) datetime64[ns] 1997-09-16 1997-10-16 ... 1998-01-16xarray.DataArray'chlorophyll'time: 50.5939 0.5924 0.6836 0.8156 0.859array([0.59386134, 0.59238297, 0.68359953, 0.81557316, 0.85900825],\n      dtype=float32)Coordinates: (1)time(time)datetime64[ns]1997-09-16 ... 1998-01-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000'], dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#get-monthly-modis-data",
    "href": "tutorials/python/timeseries_compare_sensors.html#get-monthly-modis-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get monthly MODIS data",
    "text": "Get monthly MODIS data\n\nRepeat the steps above to get data for the MODIS Aqua chlorophyll dataset\n\nurl_modis = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                      'erddap',\n                      'griddap',\n                      'erdMH1chlamday_R2022SQ'\n                      ])\nmodis_ds = xr.open_dataset(url_modis)\nmodis_ds\n\nprint('earliest date =', modis_ds.time.values[0])\nprint('latest date =', modis_ds.time.values[-1], '\\n')\nprint('variables:', modis_ds.data_vars.keys(), '\\n')\nprint('Is the first latitude value --&gt;', modis_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', modis_ds.latitude[-1].item())\n\nprint(modis_ds.latitude[0].item() &gt; modis_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif modis_ds.latitude[0].item() &gt; modis_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\nmodis_subset = modis_ds['chlor_a'].sel(time=slice(modis_ds.time[0], modis_ds.time[-1]),\n                                       latitude=slice(lat1, lat2),\n                                       longitude=slice(lon_min, lon_max)\n                                       )\n\nmodisAVG = modis_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del modis_subset \n\nearliest date = 2002-07-16T00:00:00.000000000\nlatest date = 2023-07-16T00:00:00.000000000 \n\nvariables: KeysView(Data variables:\n    chlor_a  (time, latitude, longitude) float32 ...) \n\nIs the first latitude value --&gt; 89.97916412353516\ngreater than the last latitude value --&gt; -89.97917175292969\nTrue"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#get-monthly-viirs-data",
    "href": "tutorials/python/timeseries_compare_sensors.html#get-monthly-viirs-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get monthly VIIRS data",
    "text": "Get monthly VIIRS data\n\nRepeat the steps above to get data for the VIIRS SNPP chlorophyll dataset\n\nurl_viirs = '/'.join(['https://coastwatch.noaa.gov',\n                        'erddap',\n                        'griddap',\n                        'noaacwNPPVIIRSSQchlaMonthly'\n                        ])\nviirs_ds = xr.open_dataset(url_viirs)\nviirs_ds\n\nprint('earliest date =', viirs_ds.time.values[0])\nprint('latest date =', viirs_ds.time.values[-1], '\\n')\nprint('variables:', viirs_ds.data_vars.keys(), '\\n')\n\nprint('Is the first latitude value --&gt;', viirs_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', viirs_ds.latitude[-1].item())\n\nprint(viirs_ds.latitude[0].item() &gt; viirs_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif viirs_ds.latitude[0].item() &gt; viirs_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\nviirs_subset = modis_ds['chlor_a'].sel(time=slice(viirs_ds.time[0], viirs_ds.time[-1]),\n                                       latitude=slice(lat1, lat2),\n                                       longitude=slice(lon_min, lon_max)\n                                       )\nviirsAVG = viirs_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del viirs_subset \n\nearliest date = 2012-01-02T12:00:00.000000000\nlatest date = 2023-08-01T12:00:00.000000000 \n\nvariables: KeysView(Data variables:\n    chlor_a  (time, altitude, latitude, longitude) float32 ...) \n\nIs the first latitude value --&gt; 89.75625\ngreater than the last latitude value --&gt; -89.75625\nTrue"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#plot-the-time-series",
    "href": "tutorials/python/timeseries_compare_sensors.html#plot-the-time-series",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Plot the time series",
    "text": "Plot the time series\n\nPlot the result for three datasets\n\nplt.figure(figsize=(10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(swAVG.time, swAVG, \n              'o', markersize=3, \n              label='SeaWiFS', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(modisAVG.time, modisAVG, \n              'o', markersize=3, \n              label='MODIS', c='blue', \n              linestyle='-', linewidth=1) \n\n# Add VIIRS data\nplt.plot_date(viirsAVG.time, viirsAVG, \n              'o', markersize=3, \n              label='VIIRS', c='green', \n              linestyle='-', linewidth=1) \n\nplt.ylim([0, 3])\nplt.ylabel('Chl-a (mg m-3)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#get-oc-cci-data",
    "href": "tutorials/python/timeseries_compare_sensors.html#get-oc-cci-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get OC-CCI data",
    "text": "Get OC-CCI data\nIf you needed a single time series from 1997 to present, you would have to use the plot above to devise some method to reconcile the difference in values where two datasets overlap. Alternatively, you could use the ESA OC-CCI (Ocean Color Climate Change Initiative) dataset, which blends data from many satellite missions into a single dataset, including data from SeaWiFS, MODIS, and VIIRS.\nAdd the ESA OC-CCI dataset to the plot above to see how it compares with data from the individual satellite missions.\n### Repeat the steps above to get data from the ESA OC-CCI chlorophyll dataset\n\nurl_cci = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                    'erddap',\n                    'griddap',\n                    'pmlEsaCCI60OceanColorMonthly'\n                    ])\ncci_ds = xr.open_dataset(url_cci)\ncci_ds\n\nprint('earliest date =', cci_ds.time.values[0])\nprint('latest date =', cci_ds.time.values[-1])\n\n# From the 93 variables in the dataset, \n# display only those with chl in the name\nsubset_variables = [ln for ln in list(cci_ds.data_vars.keys()) if 'chl' in ln]\n\nprint('variables with chl in name:', subset_variables, '\\n')\n\n\nprint('Is the first latitude value --&gt;', cci_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', cci_ds.latitude[-1].item())\n\nprint(cci_ds.latitude[0].item() &gt; cci_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif cci_ds.latitude[0].item() &gt; cci_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\ncci_subset = cci_ds['chlor_a'].sel(time=slice(cci_ds.time[0], cci_ds.time[-1]),\n                                   latitude=slice(lat1, lat2),\n                                   longitude=slice(lon_min, lon_max)\n                                   )\ncciAVG = cci_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del cci_subset \n\nearliest date = 1997-09-04T00:00:00.000000000\nlatest date = 2023-03-01T00:00:00.000000000\nvariables with chl in name: ['chlor_a', 'chlor_a_log10_bias', 'chlor_a_log10_rmsd'] \n\nIs the first latitude value --&gt; 89.97916666666667\ngreater than the last latitude value --&gt; -89.97916666666666\nTrue"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#replot-the-results-using-data-from-all-four-datasets",
    "href": "tutorials/python/timeseries_compare_sensors.html#replot-the-results-using-data-from-all-four-datasets",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Replot the results using data from all four datasets",
    "text": "Replot the results using data from all four datasets\n\nplt.figure(figsize=(10, 5)) \n\n# Add SeaWiFS data\nplt.plot_date(swAVG.time, swAVG, \n              'o', markersize=0, \n              label='SeaWiFS', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(modisAVG.time, modisAVG, \n              's', markersize=0, \n              label='MODIS', c='blue', \n              linestyle='-', linewidth=1) \n\n# Add VIIRS data\nplt.plot_date(viirsAVG.time, viirsAVG, \n              '^', markersize=0, \n              label='VIIRS', c='green', \n              linestyle='-', linewidth=1) \n\n# Add CCI data\nplt.plot_date(cciAVG.time, cciAVG, \n              'o', markersize=3,\n              label='OC-CCI', c='black', \n              linestyle='-', linewidth=1) \n\nplt.ylim([0, 3])\nplt.ylabel('Chl-a (mg m-3)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#references",
    "href": "tutorials/python/timeseries_compare_sensors.html#references",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "References",
    "text": "References\n\nCoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html\nhttps://polarwatch.noaa.gov/catalog/"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html",
    "href": "tutorials/python/lis-chlora-dynamics.html",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "",
    "text": "History | Updated March 2025"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#objective",
    "href": "tutorials/python/lis-chlora-dynamics.html#objective",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab daily chlorophyll-a data hosted on an ERDDAP server from Python, how to make temporal composites in Python and how to make some maps and time-series of chlorophyll-a"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nLocating a satellite product in ERDDAP, manually changing the constraints and copying the URL defining the data request\nDownloading the resulting netCDF file\nOpening and examining the netCDF file\nCalculate temporal composites (8Day and monthly)\nSpatially subset the dataset\nMaking basic maps and time series plots"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#datasets-used",
    "href": "tutorials/python/lis-chlora-dynamics.html#datasets-used",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Datasets used",
    "text": "Datasets used\nLong Island Sound Optimized water quailty datasets from OLCI Products developed by academic collaborators that have partnered with NOAA CoastWatch through a Sea Grant project titled “Actionable satellite water-quality data products in Long Island Sound for improved management and societal benefits”. The dataset includes daily Sentinal-3 OLCI (300 m) water quality indicators: - Chlorophyll-a (Chla “chlor_a”) - Absorption coefficient of Chromophoric Dissolved Organic Material at 300 nm (aCDOM(300) “cdom”) - Dissolved Organic Carbon (DOC “doc”) - Suspended Particulate Matter (SPM “spm”). Chlor_a, cdom and doc are based on Long Island Sound optimized algorithms. Spm retrieved using the Nechad Algorithm.\nThis dataset covers the Long Island Sound region between 40.2° N - 41.5° N and 74° W - 71.8° W\nIn this tutorial we will use the daily Chlorophyll-a dataset The data will be downloaded from the CoastWatch ERRDAP server: https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.html\nfor more information on each product refer to: - Chla: https://www.sciencedirect.com/science/article/pii/S1569843223000456 - CDOM and DOC: https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2023JG007767 - SPM: https://www.sciencedirect.com/science/article/abs/pii/S0034425709003617"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#import-python-modules",
    "href": "tutorials/python/lis-chlora-dynamics.html#import-python-modules",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Import Python modules",
    "text": "Import Python modules\n\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#download-data-from-erddap-using-python",
    "href": "tutorials/python/lis-chlora-dynamics.html#download-data-from-erddap-using-python",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "1. Download data from ERDDAP using Python",
    "text": "1. Download data from ERDDAP using Python\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure.\nFor example, the following page allows you to download daily chlorophyll-a (chlor_a) https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.html\n\n\n\nimage.png\n\n\n\nSelect the date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\nIn this specific example, the URL we generated is :\nhttps://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.nc?chlor_a%5B(2022-01-01T00:00:00Z):1:(2022-12-31T00:00:00Z)%5D%5B(41.5):1:(40.204)%5D%5B(-74.0):1:(-71.8049)%5D\n\n\nWith Python, run the following to download the data using the generated URL .\n\nurl = ''.join(['https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.nc?',\n               'chlor_a',\n               '%5B(2022-01-01T00:00:00Z):1:(2022-12-31T00:00:00Z)%5D',\n               '%5B(41.5):1:(40.204)%5D',\n               '%5B(-74.0):1:(-71.8049)%5D'\n               ])\n\nurllib.request.urlretrieve(url, \"chlor_a_2022_LIS_tutorial.nc\")\n\n('chlor_a_2022_LIS_tutorial.nc', &lt;http.client.HTTPMessage at 0x7f0c9c31b220&gt;)"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#loading-netcdf4-data-into-python",
    "href": "tutorials/python/lis-chlora-dynamics.html#loading-netcdf4-data-into-python",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "2. Loading netCDF4 data into Python",
    "text": "2. Loading netCDF4 data into Python\nNow that we’ve downloaded the data locally, we can load it into Python and extract the variables of interest.\nThe xarray package makes it very convenient to work with NetCDF files. Documentation is available here: http://xarray.pydata.org/en/stable/why-xarray.html\n\nOpen the netCDF file as an xarray dataset object and examine the data structure.\n\nds = xr.open_dataset('chlor_a_2022_LIS_tutorial.nc', decode_cf=True)\n\n\n\nExamine which coordinates and variables are included in the dataset.\n\n# List the coordinates\nprint('The coordinates variables:', list(ds.coords), '\\n')\n\n# List the data variables\nprint('The data variables:', list(ds.data_vars))\n\nThe coordinates variables: ['time', 'latitude', 'longitude'] \n\nThe data variables: ['chlor_a']\n\n\n\n\nExamine the structure of chlor_a.\n\nds.chlor_a.shape\n\n(365, 481, 814)\n\n\nThe dataset is a 3-D array with 365 time steps, each with 481 rows corresponding to latitudes and 814 columns corresponding to longitudes.\n\n\nList the dates for each time step.\nThe dataset has 365 time steps, one for each day between January 2022 and December 2022.\n\nds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 365)&gt; Size: 3kB\narray(['2022-01-01T00:00:00.000000000', '2022-01-02T00:00:00.000000000',\n       '2022-01-03T00:00:00.000000000', ..., '2022-12-29T00:00:00.000000000',\n       '2022-12-30T00:00:00.000000000', '2022-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 3kB 2022-01-01 2022-01-02 ... 2022-12-31\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [1.6409952e+09 1.6724448e+09]\n    axis:                 T\n    ioos_category:        Time\n    long_name:            Start Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00xarray.DataArray'time'time: 3652022-01-01 2022-01-02 2022-01-03 ... 2022-12-29 2022-12-30 2022-12-31array(['2022-01-01T00:00:00.000000000', '2022-01-02T00:00:00.000000000',\n       '2022-01-03T00:00:00.000000000', ..., '2022-12-29T00:00:00.000000000',\n       '2022-12-30T00:00:00.000000000', '2022-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2022-01-01 ... 2022-12-31_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-01T00:00:00.000000000', '2022-01-02T00:00:00.000000000',\n       '2022-01-03T00:00:00.000000000', ..., '2022-12-29T00:00:00.000000000',\n       '2022-12-30T00:00:00.000000000', '2022-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04',\n               '2022-01-05', '2022-01-06', '2022-01-07', '2022-01-08',\n               '2022-01-09', '2022-01-10',\n               ...\n               '2022-12-22', '2022-12-23', '2022-12-24', '2022-12-25',\n               '2022-12-26', '2022-12-27', '2022-12-28', '2022-12-29',\n               '2022-12-30', '2022-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))Attributes: (7)_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00\n\n\n\n\nResample daily data monthly.\nUse Xarray’s resample function to group the data into a monthly dataset (“MS” = Month Start). You can then apply aggregation functions like .mean(), .median(), .sum(), .cumsum(), etc., to compute statistics for each month.\n\nds_mon = ds.resample(time=\"MS\").mean()\n\n\n\nList the dates for each time step after resampling\nThe dataset now has 12 time steps, one for each month between January 2022 and December 2022.\n\nds_mon.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 12)&gt; Size: 96B\narray(['2022-01-01T00:00:00.000000000', '2022-02-01T00:00:00.000000000',\n       '2022-03-01T00:00:00.000000000', '2022-04-01T00:00:00.000000000',\n       '2022-05-01T00:00:00.000000000', '2022-06-01T00:00:00.000000000',\n       '2022-07-01T00:00:00.000000000', '2022-08-01T00:00:00.000000000',\n       '2022-09-01T00:00:00.000000000', '2022-10-01T00:00:00.000000000',\n       '2022-11-01T00:00:00.000000000', '2022-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 96B 2022-01-01 2022-02-01 ... 2022-12-01\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [1.6409952e+09 1.6724448e+09]\n    axis:                 T\n    ioos_category:        Time\n    long_name:            Start Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00xarray.DataArray'time'time: 122022-01-01 2022-02-01 2022-03-01 ... 2022-10-01 2022-11-01 2022-12-01array(['2022-01-01T00:00:00.000000000', '2022-02-01T00:00:00.000000000',\n       '2022-03-01T00:00:00.000000000', '2022-04-01T00:00:00.000000000',\n       '2022-05-01T00:00:00.000000000', '2022-06-01T00:00:00.000000000',\n       '2022-07-01T00:00:00.000000000', '2022-08-01T00:00:00.000000000',\n       '2022-09-01T00:00:00.000000000', '2022-10-01T00:00:00.000000000',\n       '2022-11-01T00:00:00.000000000', '2022-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2022-01-01 ... 2022-12-01_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-01T00:00:00.000000000', '2022-02-01T00:00:00.000000000',\n       '2022-03-01T00:00:00.000000000', '2022-04-01T00:00:00.000000000',\n       '2022-05-01T00:00:00.000000000', '2022-06-01T00:00:00.000000000',\n       '2022-07-01T00:00:00.000000000', '2022-08-01T00:00:00.000000000',\n       '2022-09-01T00:00:00.000000000', '2022-10-01T00:00:00.000000000',\n       '2022-11-01T00:00:00.000000000', '2022-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-01', '2022-02-01', '2022-03-01', '2022-04-01',\n               '2022-05-01', '2022-06-01', '2022-07-01', '2022-08-01',\n               '2022-09-01', '2022-10-01', '2022-11-01', '2022-12-01'],\n              dtype='datetime64[ns]', name='time', freq='MS'))Attributes: (7)_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00\n\n\n\n\nExamine the latitude coordinate variable\nTypically, the latitude coordinate variable will be in ascending order. However, in some datasets the order is reversed, i.e the order is descending.\nBy examining the first and last values on our latitude array (below), we can see that the values are descending.\n* In practice what this means is that when you slice (subset) using latitude later in this tutorial, you will put the largest latitude value first.\n\nprint('First latitude value', ds.latitude[0].item())\nprint('Last latitude value', ds.latitude[-1].item())\n\nFirst latitude value 41.5\nLast latitude value 40.204"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#working-with-the-data",
    "href": "tutorials/python/lis-chlora-dynamics.html#working-with-the-data",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "3. Working with the data",
    "text": "3. Working with the data\n\nCreating a Faceted Plot of Monthly Mean Chlorophyll-a for 2022\nIn this example, we plot directly from an xarray object using its built-in .plot() method. This is a quick and convenient way to create faceted maps, though it offers limited control over layout and map styling compared to using matplotlib or cartopy directly.\nThe col and col_wrap arguments define which dimension to facet over (in this case, “time”) and how many panels to display per row. The cbar_kwargs dictionary gives access to colorbar customization, such as setting the label and size.\n\nds_mon.chlor_a.plot(col=\"time\",\n                    col_wrap=4,\n                    cmap=\"turbo\",\n                    vmin=0, vmax=20,\n                    figsize=(15, 10),\n                    aspect=1.5,\n                    cbar_kwargs={\n                        'label': 'Chlorophyll-a (mg m$^{-3}$)',\n                        'shrink': 0.7,\n                        }\n                        )"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#creating-a-map-of-average-chlorophyll-a-over-the-year",
    "href": "tutorials/python/lis-chlora-dynamics.html#creating-a-map-of-average-chlorophyll-a-over-the-year",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Creating a Map of Average Chlorophyll-a Over the Year",
    "text": "Creating a Map of Average Chlorophyll-a Over the Year\n\nCompute the yearly mean for the region\nHere we use NumPy’s mean function to calculate the average chlorophyll-a across the time dimension (axis 0), resulting in a xarray dataarray of yearly mean values.\n\nds_yearly = np.mean(ds_mon.chlor_a, axis=0)\n\n\n\nPlot the map of the 2022 average SST in the region\n\nplt.pcolormesh(ds_yearly.longitude, ds_yearly.latitude, ds_yearly, cmap=\"turbo\", vmin=0, vmax=20)\nplt.colorbar()\nplt.title(\"Mean Chl-a \" \n          + ds_mon.time[0].dt.strftime('%b %Y').item() \n          + ' - '\n          + ds_mon.time[11].dt.strftime('%b %Y').item())\n\nplt.show()"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "href": "tutorials/python/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound",
    "text": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound\nSubset the data - West Long Island Ssound bewteen -73.9o to -73.1o W longitude - East Long Island Ssound bewteen -72.9o to -71.8o W longitude\nWe are going to generate a time series of mean SST within each box.\n\nda_west = ds.sel(longitude=slice(-73.9, -73.1))\nda_east = ds.sel(longitude=slice(-72.9, -71.8))\n\n\nExamine the structure of the subsetted data.\nThe subsets are 3D arrays with 365 time steps, each with 481 rows corresponding to latitudes (full LIS latitudinal extent) and 296 / 406 columns corresponding to longitudes in the West and East, respectively.\n\nprint(f\"West shape: {da_west.chlor_a.shape}\")\nprint(f\"West shape: {da_east.chlor_a.shape}\")\n\nWest shape: (365, 481, 296)\nWest shape: (365, 481, 406)\n\n\n\n\nResmaple each subset to an 8-Day means\nPlotting a daily time series can often be messy, so we compute 8-day averages to smooth the data and highlight seasonal patterns.\n\nda_west = da_west.resample(time=\"8D\").mean()\nda_east = da_east.resample(time=\"8D\").mean()\n\n\n\nCompute a time series\nNow, we will average all data within each subset across the latitude and longitude dimensions to produce a single time series.\n\nwest_TS = da_west.chlor_a.mean(dim=(\"latitude\",\"longitude\"))\neast_TS = da_east.chlor_a.mean(dim=(\"latitude\",\"longitude\"))\n\n\n\nPlot the time-series\n\nplt.figure(figsize=(8, 4))\nplt.plot(west_TS.time, west_TS, label=\"West LIS\", marker=\"o\", c=\"tab:blue\")\nplt.plot(east_TS.time, east_TS, label=\"East LIS\", marker=\"o\", c=\"tab:red\")\n\n\nplt.ylabel('Chlorophyll-a (mg m$^{-3}$)')\nplt.legend()"
  },
  {
    "objectID": "tutorials/python/gl-timeseries-chloro-from-diff-sensors.html",
    "href": "tutorials/python/gl-timeseries-chloro-from-diff-sensors.html",
    "title": "Time series of chlorophyll data from different sensors",
    "section": "",
    "text": "Great Lakes color producing agents (CPA) are derived from two different sensors.\nAs an example, we are going to plot time-series of mean chlorophyll a concentration from different sensors from 2002 to 2023. We are going to download MODIS data (2002-2017) and VIIRS data (2018-2023).\nFirst, let’s load all the packages needed:\nimport urllib.request \nimport xarray as xr \nimport netCDF4 as nc\n\nimport pandas as pd \nimport numpy as np \nfrom matplotlib import pyplot as plt \nfrom matplotlib.colors import LinearSegmentedColormap \n\nimport warnings\n\nwarnings.filterwarnings('ignore')\n##Get Lake Erie Monthly Average MODIS data\nGo to ERDDAP to find the name of the dataset for dailly MODIS data: LE_CHL_MODIS_Daily\nYou should always examine the dataset in ERDDAP to check the date range, names of the variables and dataset ID, to make sure your griddap calls are correct:\nhttps://apps.glerl.noaa.gov/erddap/griddap/LE_CHL_MODIS_Daily.graph\n# in Python code replace coastwatch.glerl.noaa.gov with apps.glerl.noaa.gov\n\nurl='https://apps.glerl.noaa.gov/erddap/griddap/LE_CHL_MODIS_Daily.nc?chlorophyll%5B(2002-08-07T19:05:00Z):1:(2017-10-22T18:00:00Z)%5D%5B(41.0051550293714):1:(42.9950003885447)%5D%5B(-83.4950003885448):1:(-78.505388156246)%5D'\nurllib.request.urlretrieve(url, \"e_chl_modis.nc\")\n\n('e_chl_modis.nc', &lt;http.client.HTTPMessage at 0x1a2705704d0&gt;)"
  },
  {
    "objectID": "tutorials/python/gl-timeseries-chloro-from-diff-sensors.html#get-lake-erie-dailly-average-viirs-data",
    "href": "tutorials/python/gl-timeseries-chloro-from-diff-sensors.html#get-lake-erie-dailly-average-viirs-data",
    "title": "Time series of chlorophyll data from different sensors",
    "section": "Get Lake Erie Dailly Average VIIRS data",
    "text": "Get Lake Erie Dailly Average VIIRS data\n\nurl2='https://apps.glerl.noaa.gov/erddap/griddap/LE_CHL_VIIRS_Daily.nc?Chlorophyll%5B(2023-01-04T18:47:05Z):1:(2023-12-28T18:32:33Z)%5D%5B(41.2690208353804):1:(43.017997272827)%5D%5B(-83.6574899492178):1:(-78.4429490894234)%5D'\nurllib.request.urlretrieve(url2, \"e_viirs_chl.nc\")\n\n('e_viirs_chl.nc', &lt;http.client.HTTPMessage at 0x1a20d832610&gt;)\n\n\n\ne_v_ds = xr.open_dataset('e_viirs_chl.nc',decode_cf=False)\n\n\nprint(e_v_ds)\n\n&lt;xarray.Dataset&gt;\nDimensions:      (time: 544, latitude: 271, longitude: 806)\nCoordinates:\n  * time         (time) float64 1.673e+09 1.673e+09 ... 1.704e+09 1.704e+09\n  * latitude     (latitude) float64 41.27 41.28 41.28 ... 43.01 43.01 43.02\n  * longitude    (longitude) float64 -83.66 -83.65 -83.64 ... -78.45 -78.44\nData variables:\n    Chlorophyll  (time, latitude, longitude) float32 ...\nAttributes: (12/34)\n    cdm_data_type:                  Grid\n    colorBarMaximum:                30.0\n    colorBarMinimum:                1.0\n    colorBarScale:                  Log\n    Conventions:                    CF-1.6, COARDS, ACDD-1.3\n    Easternmost_Easting:            -78.4429490894234\n    ...                             ...\n    summary:                        Color Producing Agent (CPA) Chlorophyll, ...\n    testOutOfDate:                  now-18days\n    time_coverage_end:              2023-12-28T18:32:33Z\n    time_coverage_start:            2023-01-04T18:47:05Z\n    title:                          Color Producing Agent (CPA) Chlorophyll, ...\n    Westernmost_Easting:            -83.6574899492178\n\n\n\nnan_e_v_ds_chlorophyll = e_v_ds.Chlorophyll.where(e_v_ds.Chlorophyll.values != e_v_ds.Chlorophyll.attrs['_FillValue'])\n\nv_chl_avg = np.nanmean(nan_e_v_ds_chlorophyll,axis=(1,2))\n#print(v_chl_avg)\n#print(len(v_chl_avg))\n\n\ne_v_dates=nc.num2date(e_v_ds.time,e_v_ds.time.units, only_use_cftime_datetimes=False, \n                        only_use_python_datetimes=True )\ne_v_dates\n\narray([real_datetime(2023, 1, 4, 18, 47, 5),\n       real_datetime(2023, 1, 5, 18, 28, 10),\n       real_datetime(2023, 1, 7, 17, 50, 19),\n       real_datetime(2023, 1, 7, 19, 31, 19),\n       real_datetime(2023, 1, 8, 19, 12, 23),\n       real_datetime(2023, 1, 9, 17, 12, 27),\n       real_datetime(2023, 1, 9, 17, 13, 53),\n       real_datetime(2023, 1, 9, 18, 53, 28),\n       real_datetime(2023, 1, 10, 18, 34, 32),\n       real_datetime(2023, 1, 11, 18, 15, 36),\n       real_datetime(2023, 1, 14, 17, 18, 51),\n       real_datetime(2023, 1, 14, 18, 59, 52),\n       real_datetime(2023, 1, 15, 16, 59, 56),\n       real_datetime(2023, 1, 15, 17, 1, 21),\n       real_datetime(2023, 1, 15, 18, 40, 56),\n       real_datetime(2023, 1, 16, 18, 22),\n       real_datetime(2023, 1, 17, 18, 3, 5),\n       real_datetime(2023, 1, 19, 17, 25, 14),\n       real_datetime(2023, 1, 19, 19, 6, 14),\n       real_datetime(2023, 1, 24, 17, 31, 37),\n       real_datetime(2023, 1, 24, 19, 12, 38),\n       real_datetime(2023, 1, 31, 18, 41, 10),\n       real_datetime(2023, 2, 1, 18, 22, 15),\n       real_datetime(2023, 2, 2, 18, 3, 19),\n       real_datetime(2023, 2, 3, 17, 44, 23),\n       real_datetime(2023, 2, 3, 19, 25, 24),\n       real_datetime(2023, 2, 4, 17, 25, 28),\n       real_datetime(2023, 2, 4, 19, 6, 28),\n       real_datetime(2023, 2, 6, 18, 28, 37),\n       real_datetime(2023, 2, 7, 18, 9, 41),\n       real_datetime(2023, 2, 8, 17, 50, 47),\n       real_datetime(2023, 2, 8, 19, 31, 46),\n       real_datetime(2023, 2, 9, 17, 31, 52),\n       real_datetime(2023, 2, 9, 19, 12, 52),\n       real_datetime(2023, 2, 10, 18, 52, 31),\n       real_datetime(2023, 2, 10, 18, 53, 56),\n       real_datetime(2023, 2, 11, 18, 33, 35),\n       real_datetime(2023, 2, 11, 18, 35, 1),\n       real_datetime(2023, 2, 12, 18, 14, 40),\n       real_datetime(2023, 2, 12, 18, 16, 5),\n       real_datetime(2023, 2, 13, 17, 57, 9),\n       real_datetime(2023, 2, 13, 19, 36, 44),\n       real_datetime(2023, 2, 13, 19, 38, 10),\n       real_datetime(2023, 2, 14, 17, 38, 14),\n       real_datetime(2023, 2, 14, 19, 19, 14),\n       real_datetime(2023, 2, 15, 17, 19, 18),\n       real_datetime(2023, 2, 15, 18, 58, 53),\n       real_datetime(2023, 2, 15, 19, 0, 18),\n       real_datetime(2023, 2, 17, 18, 22, 29),\n       real_datetime(2023, 2, 18, 18, 2, 8),\n       real_datetime(2023, 2, 18, 18, 3, 33),\n       real_datetime(2023, 2, 19, 17, 44, 38),\n       real_datetime(2023, 2, 19, 19, 24, 12),\n       real_datetime(2023, 2, 19, 19, 25, 38),\n       real_datetime(2023, 2, 20, 17, 25, 42),\n       real_datetime(2023, 2, 20, 19, 5, 17),\n       real_datetime(2023, 2, 20, 19, 6, 42),\n       real_datetime(2023, 2, 21, 17, 6, 46),\n       real_datetime(2023, 2, 21, 18, 46, 21),\n       real_datetime(2023, 2, 21, 18, 47, 47),\n       real_datetime(2023, 2, 23, 18, 8, 30),\n       real_datetime(2023, 2, 24, 17, 51),\n       real_datetime(2023, 2, 24, 19, 30, 34),\n       real_datetime(2023, 2, 24, 19, 32),\n       real_datetime(2023, 2, 25, 19, 13, 4),\n       real_datetime(2023, 2, 26, 17, 13, 10),\n       real_datetime(2023, 2, 26, 18, 52, 45),\n       real_datetime(2023, 2, 28, 18, 14, 54),\n       real_datetime(2023, 3, 1, 17, 57, 23),\n       real_datetime(2023, 3, 1, 19, 38, 24),\n       real_datetime(2023, 3, 2, 17, 38, 28),\n       real_datetime(2023, 3, 2, 19, 18, 3),\n       real_datetime(2023, 3, 5, 18, 21, 17),\n       real_datetime(2023, 3, 5, 18, 22, 43),\n       real_datetime(2023, 3, 6, 18, 2, 22),\n       real_datetime(2023, 3, 7, 17, 44, 52),\n       real_datetime(2023, 3, 7, 19, 24, 26),\n       real_datetime(2023, 3, 7, 19, 25, 52),\n       real_datetime(2023, 3, 8, 17, 25, 56),\n       real_datetime(2023, 3, 11, 18, 10, 9),\n       real_datetime(2023, 3, 15, 16, 54, 28),\n       real_datetime(2023, 3, 15, 18, 35, 29),\n       real_datetime(2023, 3, 16, 18, 15, 8),\n       real_datetime(2023, 3, 16, 18, 16, 33),\n       real_datetime(2023, 3, 18, 19, 18, 16),\n       real_datetime(2023, 3, 19, 17, 19, 46),\n       real_datetime(2023, 3, 19, 18, 59, 21),\n       real_datetime(2023, 3, 20, 17, 0, 52),\n       real_datetime(2023, 3, 20, 18, 40, 25),\n       real_datetime(2023, 3, 21, 18, 21, 31),\n       real_datetime(2023, 3, 21, 18, 22, 57),\n       real_datetime(2023, 3, 24, 17, 26, 10),\n       real_datetime(2023, 3, 25, 17, 7, 14),\n       real_datetime(2023, 3, 25, 18, 46, 49),\n       real_datetime(2023, 3, 25, 18, 48, 14),\n       real_datetime(2023, 3, 26, 18, 27, 53),\n       real_datetime(2023, 3, 26, 18, 29, 19),\n       real_datetime(2023, 3, 27, 18, 10, 23),\n       real_datetime(2023, 3, 28, 17, 51, 29),\n       real_datetime(2023, 3, 29, 17, 32, 33),\n       real_datetime(2023, 3, 29, 19, 13, 34),\n       real_datetime(2023, 3, 30, 17, 13, 38),\n       real_datetime(2023, 3, 30, 18, 53, 13),\n       real_datetime(2023, 3, 30, 18, 54, 38),\n       real_datetime(2023, 4, 1, 18, 16, 47),\n       real_datetime(2023, 4, 2, 17, 57, 51),\n       real_datetime(2023, 4, 2, 19, 37, 26),\n       real_datetime(2023, 4, 2, 19, 38, 51),\n       real_datetime(2023, 4, 4, 17, 20, 2),\n       real_datetime(2023, 4, 4, 19, 1),\n       real_datetime(2023, 4, 6, 18, 23, 10),\n       real_datetime(2023, 4, 7, 18, 4, 15),\n       real_datetime(2023, 4, 8, 17, 45, 19),\n       real_datetime(2023, 4, 8, 19, 24, 54),\n       real_datetime(2023, 4, 8, 19, 26, 19),\n       real_datetime(2023, 4, 9, 17, 26, 23),\n       real_datetime(2023, 4, 9, 19, 5, 58),\n       real_datetime(2023, 4, 9, 19, 7, 24),\n       real_datetime(2023, 4, 10, 17, 7, 28),\n       real_datetime(2023, 4, 10, 18, 47, 3),\n       real_datetime(2023, 4, 10, 18, 48, 28),\n       real_datetime(2023, 4, 11, 18, 28, 7),\n       real_datetime(2023, 4, 11, 18, 29, 32),\n       real_datetime(2023, 4, 12, 18, 9, 13),\n       real_datetime(2023, 4, 12, 18, 10, 38),\n       real_datetime(2023, 4, 13, 17, 51, 43),\n       real_datetime(2023, 4, 13, 19, 31, 18),\n       real_datetime(2023, 4, 13, 19, 32, 43),\n       real_datetime(2023, 4, 14, 17, 32, 47),\n       real_datetime(2023, 4, 14, 19, 12, 22),\n       real_datetime(2023, 4, 14, 19, 13, 47),\n       real_datetime(2023, 4, 15, 17, 13, 52),\n       real_datetime(2023, 4, 15, 18, 53, 26),\n       real_datetime(2023, 4, 15, 18, 54, 52),\n       real_datetime(2023, 4, 16, 16, 54, 56),\n       real_datetime(2023, 4, 16, 18, 34, 31),\n       real_datetime(2023, 4, 16, 18, 35, 56),\n       real_datetime(2023, 4, 18, 17, 58, 5),\n       real_datetime(2023, 4, 19, 17, 39, 11),\n       real_datetime(2023, 4, 19, 19, 18, 44),\n       real_datetime(2023, 4, 19, 19, 20, 9),\n       real_datetime(2023, 4, 20, 18, 59, 50),\n       real_datetime(2023, 4, 21, 17, 1, 20),\n       real_datetime(2023, 4, 22, 18, 21, 59),\n       real_datetime(2023, 4, 23, 18, 3, 3),\n       real_datetime(2023, 4, 23, 18, 4, 28),\n       real_datetime(2023, 4, 24, 17, 44, 7),\n       real_datetime(2023, 4, 24, 17, 45, 33),\n       real_datetime(2023, 4, 24, 19, 25, 8),\n       real_datetime(2023, 4, 25, 17, 26, 37),\n       real_datetime(2023, 4, 26, 17, 7, 43),\n       real_datetime(2023, 4, 26, 18, 47, 16),\n       real_datetime(2023, 4, 27, 18, 28, 23),\n       real_datetime(2023, 4, 30, 17, 31, 36),\n       real_datetime(2023, 4, 30, 17, 33, 1),\n       real_datetime(2023, 4, 30, 19, 12, 36),\n       real_datetime(2023, 5, 1, 17, 14, 5),\n       real_datetime(2023, 5, 1, 18, 53, 40),\n       real_datetime(2023, 5, 3, 18, 15, 49),\n       real_datetime(2023, 5, 4, 17, 56, 53),\n       real_datetime(2023, 5, 4, 19, 37, 53),\n       real_datetime(2023, 5, 5, 17, 37, 59),\n       real_datetime(2023, 5, 5, 17, 39, 25),\n       real_datetime(2023, 5, 5, 19, 18, 58),\n       real_datetime(2023, 5, 6, 17, 19, 4),\n       real_datetime(2023, 5, 6, 17, 20, 29),\n       real_datetime(2023, 5, 6, 19, 0, 4),\n       real_datetime(2023, 5, 7, 18, 41, 8),\n       real_datetime(2023, 5, 8, 18, 22, 13),\n       real_datetime(2023, 5, 10, 17, 44, 21),\n       real_datetime(2023, 5, 10, 19, 25, 22),\n       real_datetime(2023, 5, 11, 17, 25, 26),\n       real_datetime(2023, 5, 11, 19, 6, 26),\n       real_datetime(2023, 5, 12, 17, 6, 32),\n       real_datetime(2023, 5, 12, 17, 7, 57),\n       real_datetime(2023, 5, 12, 18, 47, 30),\n       real_datetime(2023, 5, 13, 18, 28, 36),\n       real_datetime(2023, 5, 15, 17, 50, 45),\n       real_datetime(2023, 5, 15, 19, 31, 45),\n       real_datetime(2023, 5, 16, 19, 12, 50),\n       real_datetime(2023, 5, 17, 17, 12, 54),\n       real_datetime(2023, 5, 17, 18, 53, 54),\n       real_datetime(2023, 5, 18, 18, 34, 58),\n       real_datetime(2023, 5, 19, 18, 16, 3),\n       real_datetime(2023, 5, 20, 17, 57, 9),\n       real_datetime(2023, 5, 21, 17, 38, 13),\n       real_datetime(2023, 5, 23, 18, 41, 22),\n       real_datetime(2023, 5, 24, 18, 22, 27),\n       real_datetime(2023, 5, 25, 18, 3, 31),\n       real_datetime(2023, 5, 26, 17, 44, 35),\n       real_datetime(2023, 5, 26, 19, 24, 10),\n       real_datetime(2023, 5, 26, 19, 25, 35),\n       real_datetime(2023, 5, 27, 17, 25, 40),\n       real_datetime(2023, 5, 27, 19, 5, 14),\n       real_datetime(2023, 5, 27, 19, 6, 40),\n       real_datetime(2023, 5, 28, 18, 46, 19),\n       real_datetime(2023, 5, 28, 18, 47, 44),\n       real_datetime(2023, 5, 29, 18, 27, 25),\n       real_datetime(2023, 5, 29, 18, 28, 50),\n       real_datetime(2023, 5, 30, 18, 8, 29),\n       real_datetime(2023, 5, 30, 18, 9, 55),\n       real_datetime(2023, 5, 31, 17, 50, 59),\n       real_datetime(2023, 5, 31, 19, 30, 34),\n       real_datetime(2023, 5, 31, 19, 31, 59),\n       real_datetime(2023, 6, 1, 17, 32, 3),\n       real_datetime(2023, 6, 1, 19, 11, 38),\n       real_datetime(2023, 6, 1, 19, 13, 4),\n       real_datetime(2023, 6, 2, 17, 13, 8),\n       real_datetime(2023, 6, 2, 18, 52, 43),\n       real_datetime(2023, 6, 2, 18, 54, 8),\n       real_datetime(2023, 6, 3, 18, 33, 47),\n       real_datetime(2023, 6, 3, 18, 35, 12),\n       real_datetime(2023, 6, 4, 18, 14, 51),\n       real_datetime(2023, 6, 4, 18, 16, 17),\n       real_datetime(2023, 6, 5, 17, 57, 23),\n       real_datetime(2023, 6, 6, 17, 38, 27),\n       real_datetime(2023, 6, 6, 19, 18, 2),\n       real_datetime(2023, 6, 7, 17, 19, 32),\n       real_datetime(2023, 6, 7, 18, 59, 6),\n       real_datetime(2023, 6, 8, 18, 40, 11),\n       real_datetime(2023, 6, 9, 18, 21, 15),\n       real_datetime(2023, 6, 9, 18, 22, 40),\n       real_datetime(2023, 6, 10, 18, 2, 19),\n       real_datetime(2023, 6, 10, 18, 3, 45),\n       real_datetime(2023, 6, 11, 17, 44, 49),\n       real_datetime(2023, 6, 12, 19, 5, 28),\n       real_datetime(2023, 6, 13, 17, 7),\n       real_datetime(2023, 6, 13, 18, 46, 33),\n       real_datetime(2023, 6, 14, 18, 27, 39),\n       real_datetime(2023, 6, 15, 18, 8, 43),\n       real_datetime(2023, 6, 16, 17, 49, 48),\n       real_datetime(2023, 6, 17, 17, 30, 52),\n       real_datetime(2023, 6, 17, 17, 32, 17),\n       real_datetime(2023, 6, 17, 19, 11, 52),\n       real_datetime(2023, 6, 18, 17, 13, 22),\n       real_datetime(2023, 6, 18, 18, 52, 57),\n       real_datetime(2023, 6, 19, 18, 34, 1),\n       real_datetime(2023, 6, 20, 18, 15, 5),\n       real_datetime(2023, 6, 21, 17, 56, 10),\n       real_datetime(2023, 6, 21, 19, 37, 10),\n       real_datetime(2023, 6, 22, 17, 37, 16),\n       real_datetime(2023, 6, 22, 19, 18, 14),\n       real_datetime(2023, 6, 23, 18, 59, 20),\n       real_datetime(2023, 6, 24, 17, 0, 50),\n       real_datetime(2023, 6, 24, 18, 40, 25),\n       real_datetime(2023, 6, 25, 18, 21, 29),\n       real_datetime(2023, 6, 26, 18, 2, 34),\n       real_datetime(2023, 6, 27, 17, 43, 38),\n       real_datetime(2023, 6, 27, 19, 24, 38),\n       real_datetime(2023, 6, 28, 17, 24, 42),\n       real_datetime(2023, 6, 28, 17, 26, 8),\n       real_datetime(2023, 6, 28, 19, 5, 43),\n       real_datetime(2023, 6, 29, 17, 7, 14),\n       real_datetime(2023, 6, 29, 18, 46, 47),\n       real_datetime(2023, 6, 30, 18, 27, 53),\n       real_datetime(2023, 7, 2, 17, 50, 2),\n       real_datetime(2023, 7, 2, 19, 31, 2),\n       real_datetime(2023, 7, 3, 17, 31, 6),\n       real_datetime(2023, 7, 3, 17, 32, 32),\n       real_datetime(2023, 7, 3, 19, 12, 6),\n       real_datetime(2023, 7, 4, 17, 12, 10),\n       real_datetime(2023, 7, 4, 17, 13, 36),\n       real_datetime(2023, 7, 4, 18, 53, 11),\n       real_datetime(2023, 7, 5, 16, 54, 40),\n       real_datetime(2023, 7, 5, 18, 34, 15),\n       real_datetime(2023, 7, 6, 18, 15, 19),\n       real_datetime(2023, 7, 7, 17, 56, 24),\n       real_datetime(2023, 7, 7, 19, 37, 24),\n       real_datetime(2023, 7, 8, 17, 37, 30),\n       real_datetime(2023, 7, 8, 19, 18, 28),\n       real_datetime(2023, 7, 9, 17, 18, 34),\n       real_datetime(2023, 7, 9, 18, 59, 35),\n       real_datetime(2023, 7, 10, 17, 1, 4),\n       real_datetime(2023, 7, 10, 18, 40, 39),\n       real_datetime(2023, 7, 11, 18, 21, 43),\n       real_datetime(2023, 7, 12, 18, 2, 48),\n       real_datetime(2023, 7, 13, 17, 43, 52),\n       real_datetime(2023, 7, 13, 19, 24, 52),\n       real_datetime(2023, 7, 14, 17, 24, 56),\n       real_datetime(2023, 7, 14, 19, 5, 57),\n       real_datetime(2023, 7, 16, 18, 28, 5),\n       real_datetime(2023, 7, 17, 18, 9, 11),\n       real_datetime(2023, 7, 18, 17, 50, 16),\n       real_datetime(2023, 7, 18, 19, 31, 16),\n       real_datetime(2023, 7, 19, 17, 31, 20),\n       real_datetime(2023, 7, 19, 19, 12, 20),\n       real_datetime(2023, 7, 20, 17, 12, 25),\n       real_datetime(2023, 7, 20, 17, 13, 50),\n       real_datetime(2023, 7, 20, 18, 53, 25),\n       real_datetime(2023, 7, 21, 16, 54, 54),\n       real_datetime(2023, 7, 21, 18, 34, 29),\n       real_datetime(2023, 7, 22, 18, 15, 33),\n       real_datetime(2023, 7, 23, 17, 56, 38),\n       real_datetime(2023, 7, 24, 17, 37, 44),\n       real_datetime(2023, 7, 24, 19, 18, 42),\n       real_datetime(2023, 7, 25, 18, 59, 47),\n       real_datetime(2023, 7, 27, 18, 21, 56),\n       real_datetime(2023, 7, 28, 18, 3, 1),\n       real_datetime(2023, 7, 29, 17, 44, 7),\n       real_datetime(2023, 7, 29, 19, 25, 5),\n       real_datetime(2023, 7, 30, 17, 25, 11),\n       real_datetime(2023, 7, 30, 19, 6, 11),\n       real_datetime(2023, 7, 31, 17, 6, 16),\n       real_datetime(2023, 7, 31, 18, 47, 16),\n       real_datetime(2023, 8, 1, 18, 28, 20),\n       real_datetime(2023, 8, 2, 18, 9, 25),\n       real_datetime(2023, 8, 3, 17, 50, 29),\n       real_datetime(2023, 8, 3, 19, 31, 29),\n       real_datetime(2023, 8, 4, 17, 31, 33),\n       real_datetime(2023, 8, 4, 19, 12, 33),\n       real_datetime(2023, 8, 5, 18, 53, 38),\n       real_datetime(2023, 8, 6, 16, 53, 44),\n       real_datetime(2023, 8, 6, 18, 34, 44),\n       real_datetime(2023, 8, 7, 18, 15, 48),\n       real_datetime(2023, 8, 8, 17, 56, 53),\n       real_datetime(2023, 8, 8, 19, 37, 53),\n       real_datetime(2023, 8, 9, 17, 37, 57),\n       real_datetime(2023, 8, 10, 17, 19, 1),\n       real_datetime(2023, 8, 10, 18, 58, 36),\n       real_datetime(2023, 8, 10, 19, 0, 2),\n       real_datetime(2023, 8, 11, 17, 0, 6),\n       real_datetime(2023, 8, 11, 18, 39, 41),\n       real_datetime(2023, 8, 11, 18, 41, 6),\n       real_datetime(2023, 8, 12, 18, 20, 45),\n       real_datetime(2023, 8, 12, 18, 22, 10),\n       real_datetime(2023, 8, 13, 18, 3, 15),\n       real_datetime(2023, 8, 15, 17, 25, 25),\n       real_datetime(2023, 8, 15, 19, 5),\n       real_datetime(2023, 8, 15, 19, 6, 25),\n       real_datetime(2023, 8, 16, 17, 6, 30),\n       real_datetime(2023, 8, 16, 18, 46, 4),\n       real_datetime(2023, 8, 16, 18, 47, 30),\n       real_datetime(2023, 8, 17, 18, 27, 9),\n       real_datetime(2023, 8, 17, 18, 28, 34),\n       real_datetime(2023, 8, 18, 18, 8, 13),\n       real_datetime(2023, 8, 18, 18, 9, 39),\n       real_datetime(2023, 8, 19, 17, 50, 43),\n       real_datetime(2023, 8, 19, 19, 30, 18),\n       real_datetime(2023, 8, 19, 19, 31, 43),\n       real_datetime(2023, 8, 20, 17, 31, 47),\n       real_datetime(2023, 8, 20, 19, 11, 22),\n       real_datetime(2023, 8, 20, 19, 12, 47),\n       real_datetime(2023, 8, 21, 18, 52, 26),\n       real_datetime(2023, 8, 22, 16, 53, 58),\n       real_datetime(2023, 8, 22, 18, 33, 33),\n       real_datetime(2023, 8, 22, 18, 34, 56),\n       real_datetime(2023, 8, 24, 17, 55, 41),\n       real_datetime(2023, 8, 24, 17, 57, 7),\n       real_datetime(2023, 8, 25, 17, 38, 11),\n       real_datetime(2023, 8, 25, 19, 17, 46),\n       real_datetime(2023, 8, 26, 17, 19, 15),\n       real_datetime(2023, 8, 26, 18, 58, 50),\n       real_datetime(2023, 8, 26, 19, 0, 16),\n       real_datetime(2023, 8, 27, 17, 0, 20),\n       real_datetime(2023, 8, 27, 18, 39, 55),\n       real_datetime(2023, 8, 27, 18, 41, 20),\n       real_datetime(2023, 8, 28, 18, 20, 59),\n       real_datetime(2023, 8, 28, 18, 22, 24),\n       real_datetime(2023, 8, 29, 18, 2, 3),\n       real_datetime(2023, 8, 29, 18, 3, 29),\n       real_datetime(2023, 8, 30, 17, 44, 35),\n       real_datetime(2023, 8, 30, 19, 24, 8),\n       real_datetime(2023, 8, 31, 17, 25, 39),\n       real_datetime(2023, 8, 31, 19, 5, 14),\n       real_datetime(2023, 9, 1, 17, 6, 44),\n       real_datetime(2023, 9, 1, 18, 46, 18),\n       real_datetime(2023, 9, 2, 18, 27, 23),\n       real_datetime(2023, 9, 3, 18, 8, 27),\n       real_datetime(2023, 9, 4, 17, 49, 31),\n       real_datetime(2023, 9, 4, 17, 50, 57),\n       real_datetime(2023, 9, 4, 19, 30, 32),\n       real_datetime(2023, 9, 5, 17, 30, 36),\n       real_datetime(2023, 9, 5, 17, 32, 1),\n       real_datetime(2023, 9, 5, 19, 11, 36),\n       real_datetime(2023, 9, 6, 17, 13, 7),\n       real_datetime(2023, 9, 6, 18, 52, 40),\n       real_datetime(2023, 9, 7, 16, 54, 12),\n       real_datetime(2023, 9, 7, 18, 33, 47),\n       real_datetime(2023, 9, 8, 18, 14, 51),\n       real_datetime(2023, 9, 9, 17, 55, 55),\n       real_datetime(2023, 9, 10, 17, 37),\n       real_datetime(2023, 9, 10, 17, 38, 25),\n       real_datetime(2023, 9, 10, 19, 18),\n       real_datetime(2023, 9, 11, 17, 18, 4),\n       real_datetime(2023, 9, 11, 17, 19, 29),\n       real_datetime(2023, 9, 11, 18, 59, 4),\n       real_datetime(2023, 9, 12, 18, 40, 9),\n       real_datetime(2023, 9, 13, 18, 21, 13),\n       real_datetime(2023, 9, 14, 18, 2, 17),\n       real_datetime(2023, 9, 15, 17, 43, 23),\n       real_datetime(2023, 9, 15, 19, 24, 22),\n       real_datetime(2023, 9, 16, 17, 24, 28),\n       real_datetime(2023, 9, 16, 19, 5, 28),\n       real_datetime(2023, 9, 17, 17, 5, 32),\n       real_datetime(2023, 9, 17, 17, 6, 58),\n       real_datetime(2023, 9, 17, 18, 46, 32),\n       real_datetime(2023, 9, 18, 18, 27, 37),\n       real_datetime(2023, 9, 19, 18, 8, 41),\n       real_datetime(2023, 9, 20, 17, 49, 46),\n       real_datetime(2023, 9, 20, 19, 30, 46),\n       real_datetime(2023, 9, 21, 17, 30, 50),\n       real_datetime(2023, 9, 21, 19, 11, 50),\n       real_datetime(2023, 9, 22, 17, 11, 54),\n       real_datetime(2023, 9, 22, 18, 52, 54),\n       real_datetime(2023, 9, 23, 18, 33, 59),\n       real_datetime(2023, 9, 24, 18, 15, 5),\n       real_datetime(2023, 9, 25, 17, 56, 9),\n       real_datetime(2023, 9, 26, 17, 37, 14),\n       real_datetime(2023, 9, 26, 19, 18, 14),\n       real_datetime(2023, 9, 27, 18, 59, 18),\n       real_datetime(2023, 9, 28, 18, 40, 23),\n       real_datetime(2023, 9, 29, 18, 21, 27),\n       real_datetime(2023, 9, 30, 18, 2, 32),\n       real_datetime(2023, 10, 1, 17, 43, 36),\n       real_datetime(2023, 10, 1, 19, 23, 11),\n       real_datetime(2023, 10, 1, 19, 24, 36),\n       real_datetime(2023, 10, 2, 17, 24, 42),\n       real_datetime(2023, 10, 2, 19, 4, 15),\n       real_datetime(2023, 10, 2, 19, 5, 41),\n       real_datetime(2023, 10, 3, 17, 5, 46),\n       real_datetime(2023, 10, 3, 18, 45, 21),\n       real_datetime(2023, 10, 3, 18, 46, 47),\n       real_datetime(2023, 10, 4, 18, 26, 26),\n       real_datetime(2023, 10, 4, 18, 27, 51),\n       real_datetime(2023, 10, 5, 18, 8, 55),\n       real_datetime(2023, 10, 6, 17, 50),\n       real_datetime(2023, 10, 6, 19, 29, 35),\n       real_datetime(2023, 10, 6, 19, 31),\n       real_datetime(2023, 10, 7, 17, 31, 4),\n       real_datetime(2023, 10, 7, 19, 10, 39),\n       real_datetime(2023, 10, 7, 19, 12, 4),\n       real_datetime(2023, 10, 8, 17, 12, 9),\n       real_datetime(2023, 10, 8, 18, 51, 43),\n       real_datetime(2023, 10, 8, 18, 53, 9),\n       real_datetime(2023, 10, 9, 16, 53, 13),\n       real_datetime(2023, 10, 9, 18, 32, 48),\n       real_datetime(2023, 10, 9, 18, 34, 13),\n       real_datetime(2023, 10, 11, 17, 54, 57),\n       real_datetime(2023, 10, 11, 17, 56, 22),\n       real_datetime(2023, 10, 11, 19, 35, 57),\n       real_datetime(2023, 10, 12, 17, 37, 28),\n       real_datetime(2023, 10, 12, 19, 17, 1),\n       real_datetime(2023, 10, 13, 17, 18, 33),\n       real_datetime(2023, 10, 15, 18, 20, 16),\n       real_datetime(2023, 10, 16, 18, 1, 21),\n       real_datetime(2023, 10, 17, 17, 43, 50),\n       real_datetime(2023, 10, 18, 17, 24, 55),\n       real_datetime(2023, 10, 18, 19, 4, 30),\n       real_datetime(2023, 10, 20, 18, 26, 38),\n       real_datetime(2023, 10, 21, 18, 7, 43),\n       real_datetime(2023, 10, 21, 18, 9, 8),\n       real_datetime(2023, 10, 22, 17, 48, 49),\n       real_datetime(2023, 10, 22, 17, 50, 14),\n       real_datetime(2023, 10, 22, 19, 29, 47),\n       real_datetime(2023, 10, 23, 17, 29, 53),\n       real_datetime(2023, 10, 23, 17, 31, 19),\n       real_datetime(2023, 10, 23, 19, 10, 54),\n       real_datetime(2023, 10, 24, 17, 12, 23),\n       real_datetime(2023, 10, 24, 18, 51, 58),\n       real_datetime(2023, 10, 26, 18, 14, 7),\n       real_datetime(2023, 10, 27, 17, 55, 11),\n       real_datetime(2023, 10, 27, 17, 56, 37),\n       real_datetime(2023, 10, 27, 19, 36, 11),\n       real_datetime(2023, 10, 28, 17, 37, 41),\n       real_datetime(2023, 10, 28, 19, 17, 16),\n       real_datetime(2023, 10, 30, 18, 39, 25),\n       real_datetime(2023, 10, 31, 18, 20, 29),\n       real_datetime(2023, 11, 2, 17, 44, 4),\n       real_datetime(2023, 11, 2, 19, 23, 39),\n       real_datetime(2023, 11, 3, 17, 23, 45),\n       real_datetime(2023, 11, 3, 17, 25, 10),\n       real_datetime(2023, 11, 3, 19, 4, 43),\n       real_datetime(2023, 11, 4, 18, 45, 49),\n       real_datetime(2023, 11, 5, 18, 26, 54),\n       real_datetime(2023, 11, 6, 18, 7, 58),\n       real_datetime(2023, 11, 7, 17, 49, 2),\n       real_datetime(2023, 11, 7, 17, 50, 28),\n       real_datetime(2023, 11, 7, 19, 30, 3),\n       real_datetime(2023, 11, 9, 17, 12, 37),\n       real_datetime(2023, 11, 9, 18, 52, 11),\n       real_datetime(2023, 11, 10, 18, 33, 16),\n       real_datetime(2023, 11, 11, 18, 14, 20),\n       real_datetime(2023, 11, 12, 17, 55, 25),\n       real_datetime(2023, 11, 12, 17, 56, 50),\n       real_datetime(2023, 11, 12, 19, 36, 25),\n       real_datetime(2023, 11, 13, 17, 36, 31),\n       real_datetime(2023, 11, 13, 17, 37, 56),\n       real_datetime(2023, 11, 13, 19, 17, 29),\n       real_datetime(2023, 11, 14, 17, 17, 35),\n       real_datetime(2023, 11, 14, 17, 19, 1),\n       real_datetime(2023, 11, 14, 18, 58, 35),\n       real_datetime(2023, 11, 15, 17, 0, 5),\n       real_datetime(2023, 11, 15, 18, 39, 40),\n       real_datetime(2023, 11, 16, 18, 20, 44),\n       real_datetime(2023, 11, 18, 17, 42, 53),\n       real_datetime(2023, 11, 18, 17, 44, 19),\n       real_datetime(2023, 11, 18, 19, 23, 53),\n       real_datetime(2023, 11, 19, 17, 23, 58),\n       real_datetime(2023, 11, 19, 17, 25, 23),\n       real_datetime(2023, 11, 19, 19, 4, 58),\n       real_datetime(2023, 11, 20, 18, 46, 2),\n       real_datetime(2023, 11, 23, 17, 49, 15),\n       real_datetime(2023, 11, 23, 19, 30, 16),\n       real_datetime(2023, 11, 24, 17, 30, 22),\n       real_datetime(2023, 11, 24, 17, 31, 47),\n       real_datetime(2023, 11, 24, 19, 11, 20),\n       real_datetime(2023, 11, 25, 17, 11, 26),\n       real_datetime(2023, 11, 25, 17, 12, 51),\n       real_datetime(2023, 11, 25, 18, 52, 26),\n       real_datetime(2023, 11, 27, 18, 14, 35),\n       real_datetime(2023, 11, 28, 17, 55, 40),\n       real_datetime(2023, 11, 28, 19, 36, 40),\n       real_datetime(2023, 11, 29, 17, 36, 44),\n       real_datetime(2023, 11, 29, 19, 17, 44),\n       real_datetime(2023, 11, 30, 17, 17, 48),\n       real_datetime(2023, 11, 30, 18, 58, 49),\n       real_datetime(2023, 12, 3, 18, 2, 2),\n       real_datetime(2023, 12, 4, 17, 43, 6),\n       real_datetime(2023, 12, 6, 17, 5, 17),\n       real_datetime(2023, 12, 6, 18, 46, 17),\n       real_datetime(2023, 12, 7, 18, 27, 21),\n       real_datetime(2023, 12, 8, 18, 8, 26),\n       real_datetime(2023, 12, 9, 17, 49, 30),\n       real_datetime(2023, 12, 10, 17, 30, 35),\n       real_datetime(2023, 12, 11, 18, 52, 39),\n       real_datetime(2023, 12, 12, 18, 33, 44),\n       real_datetime(2023, 12, 13, 18, 14, 48),\n       real_datetime(2023, 12, 14, 17, 55, 53),\n       real_datetime(2023, 12, 15, 17, 36, 57),\n       real_datetime(2023, 12, 15, 19, 16, 32),\n       real_datetime(2023, 12, 15, 19, 17, 57),\n       real_datetime(2023, 12, 16, 17, 18, 3),\n       real_datetime(2023, 12, 16, 18, 57, 36),\n       real_datetime(2023, 12, 16, 18, 59, 2),\n       real_datetime(2023, 12, 19, 18, 2, 17),\n       real_datetime(2023, 12, 20, 17, 43, 21),\n       real_datetime(2023, 12, 20, 19, 22, 56),\n       real_datetime(2023, 12, 20, 19, 24, 21),\n       real_datetime(2023, 12, 21, 17, 24, 26),\n       real_datetime(2023, 12, 21, 19, 4),\n       real_datetime(2023, 12, 21, 19, 5, 26),\n       real_datetime(2023, 12, 25, 17, 49, 43),\n       real_datetime(2023, 12, 26, 19, 10, 23),\n       real_datetime(2023, 12, 28, 18, 32, 33)], dtype=object)\n\n\n\nv_chl_avg = np.nanmean(nan_e_v_ds_chlorophyll.values,axis=(1,2))\nv_chl_avg\n\narray([ 3.8245378 , 17.05229   ,  0.77159315,  1.6202371 ,  2.068805  ,\n        1.7207391 ,  2.0681734 ,  9.915978  , 12.000377  , 60.60568   ,\n        2.9275532 , 15.261721  ,  2.1003587 ,  2.5391452 , 15.000816  ,\n       18.150581  ,  4.041805  ,  5.558531  , 14.340515  ,  7.0143795 ,\n       24.486782  , 10.351516  ,  9.925964  ,  8.393265  ,  7.0230336 ,\n       19.298477  , 13.378698  , 17.380596  ,  8.412001  , 18.604963  ,\n        9.874779  , 34.36881   ,  2.2588596 ,  3.6034255 ,  2.506503  ,\n        7.9039016 , 28.500935  , 15.452688  , 18.463425  , 11.424103  ,\n        8.926837  , 29.18119   , 15.104329  ,  7.305774  , 12.944991  ,\n       28.979595  , 31.491842  , 17.951267  ,  4.4605803 , 14.379     ,\n       28.11916   ,  9.264345  , 26.880186  , 46.661022  , 14.642408  ,\n       13.05799   , 13.633649  ,  1.418521  , 13.829434  ,  5.444851  ,\n       16.703632  , 20.848345  ,  5.0073376 , 43.061474  ,  4.4501486 ,\n       10.821825  , 13.9933815 , 31.618942  , 18.309826  ,  0.626642  ,\n        1.3072004 ,  0.5550653 , 18.288877  ,  8.388084  , 84.72084   ,\n       21.264292  , 30.243666  ,  8.217334  , 26.758741  , 12.297731  ,\n        1.0648437 ,  7.8218217 ,  6.743732  ,  8.725778  ,  0.37988   ,\n       20.73484   , 37.852497  , 23.765854  , 36.893124  , 43.02589   ,\n       21.644255  ,  7.4811535 ,  0.56276786, 21.756771  ,  8.571441  ,\n       34.194794  , 24.734491  , 20.891743  , 19.614132  , 20.337917  ,\n        0.89833146, 15.468415  , 23.633438  , 12.742027  , 10.469747  ,\n       19.536373  , 63.70876   , 31.262995  , 12.08394   ,  6.5038023 ,\n       23.642673  , 15.831917  ,  9.192328  , 18.234331  , 18.983482  ,\n       12.585856  , 19.876034  , 10.024232  ,  6.4187565 , 11.187998  ,\n        5.847157  , 15.026388  , 13.55039   , 57.649048  , 10.104386  ,\n       10.101064  , 25.943897  ,  9.368579  ,  6.515471  , 10.244264  ,\n        1.1295458 ,  7.0011516 , 10.233358  ,  6.5892057 ,  5.111359  ,\n        5.5639024 ,  4.002067  ,  2.6186795 , 20.945406  , 22.75246   ,\n       22.861576  , 26.649107  ,  3.9389431 ,  6.8372855 ,  4.1539216 ,\n        7.945154  ,  2.4636204 ,  2.8101442 ,  2.9989738 ,  3.761499  ,\n        4.040188  ,  6.779965  ,  4.0392694 ,  5.058976  ,  3.642377  ,\n        5.0899043 ,  1.535409  ,  5.489851  , 12.624435  , 14.986074  ,\n       19.135656  ,  8.674835  ,  1.8120102 ,  6.0505404 ,  4.0770435 ,\n        4.2323365 ,  4.5445585 ,  6.407044  ,  4.4135103 , 10.111502  ,\n        2.559734  ,  6.3161306 ,  4.1022396 ,  5.3999968 ,  5.693675  ,\n        4.2225466 ,  4.975449  ,  5.87973   ,  1.8912128 ,  4.844044  ,\n        8.326566  , 21.682102  ,  5.796414  ,  4.81131   ,  1.6386082 ,\n        4.858289  ,  1.0573728 ,  5.3810554 , 19.722094  , 12.00176   ,\n       23.595955  , 31.021114  ,  6.9326816 ,  5.9504557 ,  3.3385806 ,\n        4.8724666 ,  2.2861915 , 12.186277  ,  3.0852036 , 30.52236   ,\n        4.891082  ,  4.0605354 , 27.45894   , 12.472047  ,  3.3337376 ,\n        3.500256  ,  0.65000206,  1.3446043 ,  5.6772294 ,  2.0434697 ,\n        6.4364944 ,  3.82695   , 26.283665  ,  6.5254254 ,  0.35209   ,\n        1.7417568 ,  0.323401  ,  1.3526874 , 19.266989  , 16.352032  ,\n        4.9344935 ,  4.533328  ,  1.8704015 ,  1.9660938 ,  2.0816095 ,\n        0.31560874,  2.6231666 ,  6.254045  ,  3.8463306 ,  1.3136346 ,\n        2.3147666 ,  3.226815  ,  3.4912894 ,  9.928331  ,  5.029834  ,\n        7.1034536 ,  2.6826584 ,  3.407092  ,  5.1383185 ,  4.0941634 ,\n        3.3249714 ,  2.8196743 ,  1.0019007 ,  0.4673027 ,  6.095398  ,\n        2.4684315 ,  2.894028  ,  1.7736832 ,  0.53535175,  2.3534393 ,\n        5.9133415 ,  1.4854542 ,  0.98389864,  2.8314965 ,  3.388785  ,\n        1.7273644 ,  1.4295217 ,  3.9137824 ,  0.8343511 ,  5.592705  ,\n        4.1189713 ,  4.519481  ,  4.514461  ,  1.216034  ,  4.9332423 ,\n        4.501184  ,  5.48342   ,  5.1219296 ,  1.8448588 ,  1.8978752 ,\n        2.399244  ,  4.452588  ,  2.9473898 ,  4.242     ,  5.101925  ,\n        3.4773014 ,  4.1459665 ,  3.9358723 ,  4.571998  ,  4.4941797 ,\n        1.8119017 ,  1.184782  ,  3.4886737 ,  1.7374743 ,  5.519011  ,\n        4.1905513 ,  2.60639   ,  0.7090206 ,  4.3053236 ,  0.48008502,\n        4.8589377 ,  5.2264676 ,  4.044144  ,  3.4191263 ,  1.1011882 ,\n        3.1120796 ,  6.7359877 ,  2.9646623 ,  2.554451  ,  2.4505644 ,\n        2.142144  ,  4.9301887 ,  1.2831734 ,  2.7954278 ,  1.5539587 ,\n        5.100337  ,  3.3232377 ,  1.7723247 ,  4.5153937 ,  3.388878  ,\n        6.257826  ,  1.1053416 ,  3.9824939 ,  0.76826215,  4.1770864 ,\n        5.84404   ,  3.564656  ,  4.186695  ,  3.18334   ,  4.3410416 ,\n        2.4948015 ,  5.7432327 ,  3.2015507 ,  4.697011  ,  8.011776  ,\n        6.00471   ,  1.4959276 ,  3.4044938 ,  2.7345881 ,  3.1861002 ,\n        6.807063  ,  3.672278  ,  4.4842434 ,  4.369128  , 10.34134   ,\n        7.659503  ,  4.640015  ,  2.260385  ,  2.9616964 ,  5.770283  ,\n        5.8344135 ,  3.0287185 ,  4.6171303 ,  1.8015864 ,  3.3256059 ,\n        4.025933  , 15.307446  , 24.68179   ,  5.1921005 ,  0.95913076,\n        2.531541  ,  3.3621345 ,  5.42665   ,  2.610918  ,  7.0007544 ,\n        4.5238733 ,  6.4797854 ,  7.7474403 ,  8.129336  ,  6.065284  ,\n        6.313556  , 23.959946  ,  6.9332256 ,  7.346444  ,  3.9448545 ,\n        7.4828005 ,  9.371148  ,  6.901665  ,  6.0786414 ,  7.611087  ,\n        4.072118  ,  5.4114847 ,  5.8930087 ,  6.2145314 ,  3.5961418 ,\n        3.5599902 ,  0.31376082,  4.7233195 ,  1.835947  ,  1.3035926 ,\n        3.0226147 ,  0.4981069 ,  6.3224025 ,  3.036155  ,  2.8434775 ,\n        4.545952  , 18.239357  ,  6.450544  ,  6.273684  ,  6.03156   ,\n        3.223308  ,  3.63122   ,  2.694837  ,  2.6652293 ,  1.1407009 ,\n        4.5644073 ,  6.183016  ,  4.285992  ,  4.728611  ,  1.2699568 ,\n        3.6176095 ,  2.5436394 ,  2.7925599 ,  3.8075545 ,  8.981911  ,\n       22.87494   ,  7.5639124 ,  1.6238711 ,  0.5307012 ,  6.469891  ,\n        3.0692794 ,  4.6451344 ,  7.6391034 ,  6.2791705 ,  7.3014994 ,\n        4.254345  ,  6.4056168 ,  7.458692  ,  3.457129  ,  5.2672634 ,\n        9.947004  ,  4.4163375 , 10.526679  ,  4.949929  ,  1.9953364 ,\n        8.43534   ,  8.067071  ,  5.2787495 ,  3.2672718 , 14.374089  ,\n        1.9808887 , 36.714443  , 25.423502  , 10.191787  ,  2.9083974 ,\n       13.615338  ,  7.3216214 , 16.14564   ,  7.027708  ,  8.500385  ,\n        4.132675  ,  3.6679573 ,  1.4386141 , 35.34755   , 27.14011   ,\n        0.611455  ,  9.363178  , 12.209044  ,  7.530161  ,  8.551426  ,\n        1.8653786 ,  4.8010054 ,  5.6198926 , 35.149426  , 30.55753   ,\n        5.9123573 ,  2.7006626 ,  3.9975345 ,  6.327705  ,  5.3463564 ,\n        6.5932918 ,  6.520323  ,  3.5866342 ,  0.6119649 ,  0.34683716,\n        4.459534  ,  5.4071994 ,  6.77416   , 20.245544  ,  1.24846   ,\n       16.727642  , 34.44699   ,  3.2000692 ,  6.9570527 ,  4.8707566 ,\n        0.85470015,  1.5286115 ,  1.4164749 , 16.511541  , 23.00998   ,\n       11.719736  , 10.880672  ,  6.8268065 ,  1.6250918 ,  8.308749  ,\n       11.111537  , 24.678076  , 11.334251  ,  3.5857413 ,  6.996021  ,\n        4.5214167 ,  8.312405  ,  7.4295473 ,  7.6591887 , 10.038146  ,\n        1.7212489 ,  8.699176  ,  8.796391  ,  9.621361  ,  9.075598  ,\n        0.19450001, 14.5820675 , 18.2731    , 15.891861  ,  5.1796503 ,\n       23.901497  ,  6.602838  ,  8.11695   ,  5.7776127 ,  0.9575611 ,\n       19.564034  , 44.46723   ,  6.194875  , 20.724203  , 18.15552   ,\n       36.427177  ,  3.437948  ,  0.62041324,  0.78566986,  7.326401  ,\n       13.820853  ,  4.118893  ,  0.77267   ,  0.74762917,  0.88341135,\n       20.338709  , 18.454927  , 13.954808  , 11.78991   , 11.854942  ,\n       14.00589   ,  9.306969  ,  9.987267  ,  6.9419265 , 10.148791  ,\n        8.151923  , 18.923534  , 18.946314  ,  1.1267239 ,  1.1251845 ,\n        1.3136889 , 71.61      ,  1.9791391 ,  0.40409204], dtype=float32)\n\n\n\nplt.figure(figsize=(12,5)) \nplt.plot(e_v_dates,v_chl_avg,label='VIIRS CHL',c='red',marker='.',linestyle='-')\nplt.ylabel('Chl-a (mg/m^3)')\nplt.title(\"Lake Erie Daily Average CHL - 2023\")\nplt.legend()\nprint(type(v_chl_avg))\nprint(v_chl_avg.shape)\nprint(e_v_dates.shape)\n\n&lt;class 'numpy.ndarray'&gt;\n(544,)\n(544,)\n\n\n\n\n\n\n\n\n\n\n#e_v_ds.close()\n!jupyter nbconvert --to html GL_python_tutorial2.ipynb\n\n[NbConvertApp] Converting notebook GL_python_tutorial2.ipynb to html\n[NbConvertApp] Writing 878306 bytes to GL_python_tutorial2.html"
  },
  {
    "objectID": "tutorials/python/gl-access-sat-surface-temp-data.html",
    "href": "tutorials/python/gl-access-sat-surface-temp-data.html",
    "title": "Python Tutorial - How to work with CoastWatch data in Python",
    "section": "",
    "text": "This tutorial is based on the OceanWatch tutorial meterial edited with Great Lakes data. This tutorial will show the steps to grab data in ERDDAP from Python, how to work with NetCDF files in Python and how to make some maps and time-series water surface temperature (sst) in Lake Erie."
  },
  {
    "objectID": "tutorials/python/gl-access-sat-surface-temp-data.html#downlading-data-from-python",
    "href": "tutorials/python/gl-access-sat-surface-temp-data.html#downlading-data-from-python",
    "title": "Python Tutorial - How to work with CoastWatch data in Python",
    "section": "1. Downlading data from Python",
    "text": "1. Downlading data from Python\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure. For example, the following page allows you to subset daily water surface temperature data from the dataset GLSEA_ACSPO_GCS\nIn this specific example, the URL we generated is :\nhttps://apps.glerl.noaa.gov/erddap/griddap/GLSEA_ACSPO_GCS.nc?sst%5B(2023-06-01T12:00:00Z):1:(2023-06-30T12:00:00Z)%5D%5B(41):1:(43)%5D%5B(-83.5):1:(-78.5)%5D\nIn Python, run the following to download the data using the generated URL. Note: replace coastwatch.glerl.noaa.gov with apps.glerl.noaa.gov) :\n\nimport urllib.request\n\nurl=\"https://apps.glerl.noaa.gov/erddap/griddap/GLSEA_ACSPO_GCS.nc?sst%5B(2023-06-01T12:00:00Z):1:(2023-06-30T12:00:00Z)%5D%5B(41):1:(43)%5D%5B(-83.5):1:(-78.5)%5D\"\nurllib.request.urlretrieve(url, \"e_sst.nc\")\n\n('e_sst.nc', &lt;http.client.HTTPMessage at 0x1b7d5152610&gt;)"
  },
  {
    "objectID": "tutorials/python/gl-access-sat-surface-temp-data.html#working-with-the-extracted-data",
    "href": "tutorials/python/gl-access-sat-surface-temp-data.html#working-with-the-extracted-data",
    "title": "Python Tutorial - How to work with CoastWatch data in Python",
    "section": "Working with the extracted data",
    "text": "Working with the extracted data\n\nCreating a map for one time step\nLet’s create a map of SST for June 1, 2021 (our first time step).\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n#np.warnings.filterwarnings('ignore')\n\n\n- Examine the values of sst:\n\nds.sst.values\n\narray([[[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       ...,\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]]],\n      dtype=float32)\n\n\n\nds.sst.attrs\n\n{'_FillValue': -99999.0,\n 'colorBarMaximum': 32.0,\n 'colorBarMinimum': 0.0,\n 'ioos_category': 'Temperature',\n 'long_name': 'Temperature',\n 'standard_name': 'sea_water_temperature',\n 'units': 'degree_C'}\n\n\n\nds.sst.attrs['_FillValue']\n\n-99999.0\n\n\n\n#ds.sst.dims\n#ds.sst.coords\n\n\n\n- Make a new sst DataArray and replace _fillValue with NaN\n\n#nan_sst = ds.sst.where(ds.sst.values != -99999.0)\nnan_sst = ds.sst.where(ds.sst.values != ds.sst.attrs['_FillValue'])\n\n# nan_sst[time][latitude][longitude]\n#print(nan_sst[10][100][200])\n\nprint(nan_sst)\n\n\n&lt;xarray.DataArray 'sst' (time: 30, latitude: 143, longitude: 358)&gt;\narray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)\nCoordinates:\n  * time       (time) float64 1.686e+09 1.686e+09 ... 1.688e+09 1.688e+09\n  * latitude   (latitude) float64 41.01 41.02 41.03 41.05 ... 42.97 42.98 43.0\n  * longitude  (longitude) float64 -83.51 -83.49 -83.48 ... -78.53 -78.52 -78.5\nAttributes:\n    _FillValue:       -99999.0\n    colorBarMaximum:  32.0\n    colorBarMinimum:  0.0\n    ioos_category:    Temperature\n    long_name:        Temperature\n    standard_name:    sea_water_temperature\n    units:            degree_C\n\n\n\n\n- Set some color breaks\n\nnp.nanmin(ds.sst)\n\n-99999.0\n\n\n\n# find min value in man_sst\nnp.nanmin(nan_sst)\n\n13.25\n\n\n\nnp.nanmax(nan_sst)\n\n23.35\n\n\n\nlevs = np.arange(13.25, 23.35, 0.05)\nlen(levs)\n\n203\n\n\n\n\n- Define a color palette\n\n# init a color list\njet=[\"blue\", \"#007FFF\", \"cyan\",\"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"]\n\n\n\n- Set color scale using the jet palette\n\ncm = LinearSegmentedColormap.from_list('my_jet', jet, N=len(levs))\n\n#https://www.youtube.com/watch?v=qk0n-YaKIkY\n\n\n\n- plot the SST map\n\nnp.linspace(-82.5,-80,num=4)\n\narray([-82.5       , -81.66666667, -80.83333333, -80.        ])\n\n\n\nplt.subplots(figsize=(10, 5))\n\n#plot first sst image: nan_sst[0,:,:]\nplt.contourf(nan_sst.longitude, nan_sst.latitude, nan_sst[0,:,:], levs,cmap=cm)\n\n#plot the color scale\nplt.colorbar()\n\n#example of how to add points to the map\nplt.scatter(np.linspace(-82,-80.5,num=4),np.repeat(42,4),c='black')\n\n#example of how to add a contour line\nstep = np.arange(9,26, 1)\n\nplt.contour(ds.longitude, ds.latitude, ds.sst[0,:,:],levels=step,linewidths=1)\n\n#plot title\nplt.title(\"Lake Erie Water Surface Temperature - \" + dates[0].strftime('%b %d, %Y'))\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPlotting a time series\nLet’s pick the following box : 41.75-42.0N, 83.0-83.5W. We are going to generate a time series of mean SST within that box.\n\n- first, let’s subset our data:\n\nlat_bnds, lon_bnds = [41.75, 42.0], [-83.5, -83.0]\na_sst=nan_sst.sel(latitude=slice(*lat_bnds), longitude=slice(*lon_bnds))\nprint(a_sst)\n\n&lt;xarray.DataArray 'sst' (time: 30, latitude: 17, longitude: 36)&gt;\narray([[[  nan,   nan,   nan, ..., 18.86, 18.84, 18.84],\n        [  nan,   nan,   nan, ..., 18.82, 18.8 , 18.8 ],\n        [  nan,   nan,   nan, ..., 18.78, 18.76, 18.76],\n        ...,\n        [  nan,   nan,   nan, ..., 18.5 , 18.46, 18.46],\n        [  nan,   nan,   nan, ..., 18.5 , 18.46, 18.46],\n        [  nan,   nan,   nan, ..., 18.53, 18.49, 18.49]],\n\n       [[  nan,   nan,   nan, ..., 19.45, 19.44, 19.44],\n        [  nan,   nan,   nan, ..., 19.42, 19.41, 19.41],\n        [  nan,   nan,   nan, ..., 19.39, 19.38, 19.38],\n        ...,\n        [  nan,   nan,   nan, ..., 19.13, 19.1 , 19.1 ],\n        [  nan,   nan,   nan, ..., 19.07, 19.06, 19.06],\n        [  nan,   nan,   nan, ..., 19.06, 19.04, 19.04]],\n\n       [[  nan,   nan,   nan, ..., 19.63, 19.61, 19.61],\n        [  nan,   nan,   nan, ..., 19.6 , 19.58, 19.58],\n        [  nan,   nan,   nan, ..., 19.56, 19.54, 19.54],\n        ...,\n...\n        ...,\n        [  nan,   nan,   nan, ..., 21.24, 21.31, 21.31],\n        [  nan,   nan,   nan, ..., 21.24, 21.34, 21.34],\n        [  nan,   nan,   nan, ..., 21.29, 21.42, 21.42]],\n\n       [[  nan,   nan,   nan, ..., 21.8 , 21.75, 21.75],\n        [  nan,   nan,   nan, ..., 21.7 , 21.67, 21.67],\n        [  nan,   nan,   nan, ..., 21.6 , 21.59, 21.59],\n        ...,\n        [  nan,   nan,   nan, ..., 21.36, 21.41, 21.41],\n        [  nan,   nan,   nan, ..., 21.36, 21.44, 21.44],\n        [  nan,   nan,   nan, ..., 21.44, 21.53, 21.53]],\n\n       [[  nan,   nan,   nan, ..., 21.93, 21.82, 21.82],\n        [  nan,   nan,   nan, ..., 21.86, 21.79, 21.79],\n        [  nan,   nan,   nan, ..., 21.78, 21.75, 21.75],\n        ...,\n        [  nan,   nan,   nan, ..., 21.49, 21.52, 21.52],\n        [  nan,   nan,   nan, ..., 21.51, 21.55, 21.55],\n        [  nan,   nan,   nan, ..., 21.63, 21.66, 21.66]]], dtype=float32)\nCoordinates:\n  * time       (time) float64 1.686e+09 1.686e+09 ... 1.688e+09 1.688e+09\n  * latitude   (latitude) float64 41.76 41.78 41.79 41.8 ... 41.96 41.97 41.99\n  * longitude  (longitude) float64 -83.49 -83.48 -83.46 ... -83.03 -83.02 -83.0\nAttributes:\n    _FillValue:       -99999.0\n    colorBarMaximum:  32.0\n    colorBarMinimum:  0.0\n    ioos_category:    Temperature\n    long_name:        Temperature\n    standard_name:    sea_water_temperature\n    units:            degree_C\n\n\n\n\n- let’s plot the subset:\n\n#plot first image of the a_sst array\nplt.contourf(a_sst.longitude, a_sst.latitude, a_sst[0,:,:], levs,cmap=cm)\nplt.colorbar()\nplt.title(\"Subset of Lake Erie Water Surface Temperature \" + dates[0].strftime('%b %d, %Y'))\nplt.show()\n\n\n\n\n\n\n\n\n\n\n- let’s compute the daily mean over the bounding region:\n\nres=np.nanmean(a_sst,axis=(1,2))\nres\n\narray([19.252283, 19.84715 , 20.109388, 20.06981 , 20.01454 , 20.00379 ,\n       19.958447, 19.921082, 19.963646, 19.956564, 19.885717, 19.525248,\n       19.253717, 19.179811, 19.149954, 19.190142, 19.41266 , 19.634283,\n       19.90713 , 20.220236, 20.525293, 20.747812, 21.015364, 21.460989,\n       21.71833 , 21.710024, 21.643694, 21.593224, 21.749012, 22.0068  ],\n      dtype=float32)\n\n\n\n\n- let’s plot the time-series:\n\nplt.figure(figsize=(8,4))\n\nplt.scatter(dates,res)\n\ndegree_sign = u\"\\N{DEGREE SIGN}\"\nplt.ylabel('SST (' + degree_sign + 'C)')\n\nplt.xlim(dates[0], dates[-1])\n\nplt.xticks(dates,rotation=70, fontsize=10 )\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCreating a map of average SST over a month\n\n- let’s compute the monthly mean for the region:\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\nmean_sst=np.nanmean(nan_sst,axis=0)\n\n\nmean_sst.shape\n\n(143, 358)\n\n\n\n\n- let’s plot the map of the average SST in the region for 2021 June:\n\nplt.subplots(figsize=(10, 5))\n\nplt.contourf(ds.longitude, ds.latitude, mean_sst, levs,cmap=cm)\n\ncbar = plt.colorbar()\ncbar.set_label('SST')\n\nplt.title(\"Mean SST \" + dates[0].strftime('%Y-%m-%d')+' - '+dates[-1].strftime('%Y-%m-%d'))\nplt.show()\n\n\n\n\n\n\n\n\n\n!jupyter nbconvert --to html GL_python_tutorial1.ipynb\n\n[NbConvertApp] Converting notebook GL_python_tutorial1.ipynb to html\n[NbConvertApp] Writing 974120 bytes to GL_python_tutorial1.html"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html",
    "href": "tutorials/python/define_marine_habitat.html",
    "title": "Define a marine habitat",
    "section": "",
    "text": "History | Updated Sep 2023 ## Background The TurtleWatch project investigated the overlap between loggerhead sea turtles habitat and fishing effort of the Hawaii-based shallow-set longline fishery in the Pacific Ocean north of the Hawaiian Islands. That fishery, which targets swordfish, used to experience high levels of bycatch of loggerhead turtles. Considerable changes in gear and operations lowered bycatch rate and TurtleWatch was designed as a tool to advise fishermen on areas to avoid to limit bycatch.\nResearch results indicated that 50% of interactions occurred between 17.5°C and 18.5°C."
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#objective",
    "href": "tutorials/python/define_marine_habitat.html#objective",
    "title": "Define a marine habitat",
    "section": "Objective",
    "text": "Objective\nHere we will draw the 17.5 and 18.5ºC temperature contours on a map of satellite sea surface temperature."
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#the-exercise-demonstrates-the-following-techniques",
    "href": "tutorials/python/define_marine_habitat.html#the-exercise-demonstrates-the-following-techniques",
    "title": "Define a marine habitat",
    "section": "The exercise demonstrates the following techniques:",
    "text": "The exercise demonstrates the following techniques:\n\nSubsetting and loading data from an ERDDAP server using xarray\n\nSet flag values for features of interest\n\nPlotting maps"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#datasets-used",
    "href": "tutorials/python/define_marine_habitat.html#datasets-used",
    "title": "Define a marine habitat",
    "section": "Datasets used",
    "text": "Datasets used\nCoralTemp Sea Surface Temperature product from the NOAA Coral Reef Watch program. The NOAA Coral Reef Watch (CRW) daily global 5km Sea Surface Temperature (SST) product, also known as CoralTemp, shows the nighttime ocean temperature measured at the surface. The SST scale ranges from -2 to 35 °C. The CoralTemp SST data product was developed from two related reanalysis (reprocessed) SST products and a near real-time SST product. Spanning January 1, 1985 to the present, the CoralTemp SST is one of the best and most internally consistent daily global 5km SST products available. More information about the product: https://coralreefwatch.noaa.gov/product/5km/index_5km_sst.php"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#install-required-packages",
    "href": "tutorials/python/define_marine_habitat.html#install-required-packages",
    "title": "Define a marine habitat",
    "section": "Install required packages",
    "text": "Install required packages\n\nimport xarray as xr    \nimport matplotlib.pyplot as plt\nimport matplotlib as mpl"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#download-the-sst-data",
    "href": "tutorials/python/define_marine_habitat.html#download-the-sst-data",
    "title": "Define a marine habitat",
    "section": "Download the SST data",
    "text": "Download the SST data\n\nSelect a geographical range\n\nSelect an area of the central North Pacific where the fishery operates: longitude range of 185 to 235 east and latitude range of 20 to 45 north\n\n\n\nSelect a date\n\nSelect a date in the first quarter of the year when bycatch typically occurs: 2023-01-06\n\n\n\nSet variables for the habitat temperature range\n\n# Longitude range\nlon_min = 185\nlon_max = 235\n\n# Latitude range\nlat_min = 20\nlat_max = 45\n\ndate_for_sat_data = '2023-01-06'\n\n# Turtle habitat temperature range\nhab_temp_min = 17.5\nhab_temp_max = 18.5"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#open-the-netcdf-file-to-create-an-xarray-dataset-object",
    "href": "tutorials/python/define_marine_habitat.html#open-the-netcdf-file-to-create-an-xarray-dataset-object",
    "title": "Define a marine habitat",
    "section": "Open the netCDF file to create an xarray dataset object",
    "text": "Open the netCDF file to create an xarray dataset object\n\nurl = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1\"\nds = xr.open_dataset(url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (time: 14130, latitude: 3600, longitude: 7200)\nCoordinates:\n  * time              (time) datetime64[ns] 1985-01-01T12:00:00 ... 2023-09-0...\n  * latitude          (latitude) float32 -89.97 -89.93 -89.88 ... 89.93 89.97\n  * longitude         (longitude) float32 0.025 0.075 0.125 ... 359.9 360.0\nData variables:\n    analysed_sst      (time, latitude, longitude) float64 ...\n    sea_ice_fraction  (time, latitude, longitude) float64 ...\nAttributes: (12/68)\n    acknowledgement:                  NOAA Coral Reef Watch Program\n    cdm_data_type:                    Grid\n    comment:                          This product is designed to improve on ...\n    contributor_name:                 NOAA Coral Reef Watch Program\n    contributor_role:                 Collecting source data and deriving pro...\n    Conventions:                      CF-1.6, ACDD-1.3, COARDS\n    ...                               ...\n    time_coverage_duration:           P1D\n    time_coverage_end:                2023-09-09T12:00:00Z\n    time_coverage_resolution:         P1D\n    time_coverage_start:              1985-01-01T12:00:00Z\n    title:                            Sea Surface Temperature, Coral Reef Wat...\n    Westernmost_Easting:              0.025xarray.DatasetDimensions:time: 14130latitude: 3600longitude: 7200Coordinates: (3)time(time)datetime64[ns]1985-01-01T12:00:00 ... 2023-09-..._CoordinateAxisType :Timeactual_range :[4.7342880e+08 1.6942608e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the sst fieldstandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1985-01-01T12:00:00.000000000', '1985-01-02T12:00:00.000000000',\n       '1985-01-03T12:00:00.000000000', ..., '2023-09-07T12:00:00.000000000',\n       '2023-09-08T12:00:00.000000000', '2023-09-09T12:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float32-89.97 -89.93 ... 89.93 89.97_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([-89.975, -89.925, -89.875, ...,  89.875,  89.925,  89.975],\n      dtype=float32)longitude(longitude)float320.025 0.075 0.125 ... 359.9 360.0_CoordinateAxisType :Lonactual_range :[2.50000e-02 3.59975e+02]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :359.975valid_min :0.025array([2.50000e-02, 7.50000e-02, 1.25000e-01, ..., 3.59875e+02, 3.59925e+02,\n       3.59975e+02], dtype=float32)Data variables: (2)analysed_sst(time, latitude, longitude)float64...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[366249600000 values with dtype=float64]sea_ice_fraction(time, latitude, longitude)float64...colorBarMaximum :1.0colorBarMinimum :0.0comment :0 is 0% ice, 1 is 100% icecoverage_content_type :physicalMeasurementioos_category :Ice Distributionlong_name :Sea Ice Fractionstandard_name :sea_ice_area_fractionunits :1valid_max :1.0valid_min :0.0[366249600000 values with dtype=float64]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1985-01-01 12:00:00', '1985-01-02 12:00:00',\n               '1985-01-03 12:00:00', '1985-01-04 12:00:00',\n               '1985-01-05 12:00:00', '1985-01-06 12:00:00',\n               '1985-01-07 12:00:00', '1985-01-08 12:00:00',\n               '1985-01-09 12:00:00', '1985-01-10 12:00:00',\n               ...\n               '2023-08-31 12:00:00', '2023-09-01 12:00:00',\n               '2023-09-02 12:00:00', '2023-09-03 12:00:00',\n               '2023-09-04 12:00:00', '2023-09-05 12:00:00',\n               '2023-09-06 12:00:00', '2023-09-07 12:00:00',\n               '2023-09-08 12:00:00', '2023-09-09 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=14130, freq=None))latitudePandasIndexPandasIndex(Float64Index([ -89.9749984741211, -89.92500305175781,            -89.875,\n              -89.82499694824219,  -89.7750015258789,  -89.7249984741211,\n              -89.67500305175781,            -89.625, -89.57499694824219,\n               -89.5250015258789,\n              ...\n                89.5250015258789,  89.57499694824219,             89.625,\n               89.67500305175781,   89.7249984741211,   89.7750015258789,\n               89.82499694824219,             89.875,  89.92500305175781,\n                89.9749984741211],\n             dtype='float64', name='latitude', length=3600))longitudePandasIndexPandasIndex(Float64Index([0.02500000037252903, 0.07500000298023224,               0.125,\n              0.17499999701976776, 0.22499999403953552,  0.2750000059604645,\n              0.32499998807907104,               0.375, 0.42500001192092896,\n               0.4749999940395355,\n              ...\n                359.5249938964844,  359.57501220703125,             359.625,\n               359.67498779296875,   359.7250061035156,   359.7749938964844,\n               359.82501220703125,             359.875,  359.92498779296875,\n                359.9750061035156],\n             dtype='float64', name='longitude', length=7200))Attributes: (68)acknowledgement :NOAA Coral Reef Watch Programcdm_data_type :Gridcomment :This product is designed to improve on and replace the use of AVHRR Pathfinder SST for use within the Coral Reef Watch Program.contributor_name :NOAA Coral Reef Watch Programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archiveConventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch Programcreator_name :NOAA Coral Reef Watch Programcreator_type :groupcreator_url :https://coralreefwatch.noaa.gov/data_source :NOAA Daily Global 5km Geo-Polar Blended Night-only Sea Surface Temperature Analysis from the date specified in the global attribute time_coverage_start. Note, if the text of this global attribute begins with \"Due to ...\", one of the following situations occurred: (1) the source data file for the CoralTemp of data file for the CoralTemp of the day was missing; (2) the sea_ice_fraction data array in the source data was missing, (3) some alternation was made on the source data to derive the CoralTemp data of the day.date_created :2018-01-01T00:00:00Zdate_issued :2021-04-04T13:40:08Zdate_metadata_modified :2020-11-18T00:00:00Zdate_modified :2018-01-01T00:00:00ZEasternmost_Easting :359.975geospatial_bounds :\"POLYGON((-90.0 360.0, 90.0 360.0, 90.0 0.0, -90.0 0.0, -90.0 360.0))\"geospatial_bounds_crs :EPSG:4326geospatial_lat_max :89.975geospatial_lat_min :-89.975geospatial_lat_resolution :0.049999999999999996geospatial_lat_units :degrees_northgeospatial_lon_max :359.975geospatial_lon_min :0.025geospatial_lon_resolution :0.05000000000000001geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:4326grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Sat Sep  9 06:30:11 2023: ncatted -O -a geospatial_bounds,global,o,c,\"POLYGON((-90.0 360.0, 90.0 360.0, 90.0 0.0, -90.0 0.0, -90.0 360.0))\" coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a geospatial_lon_max,global,o,f,359.975 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a geospatial_lon_min,global,o,f,0.025 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a valid_max,lon,o,f,359.975 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a valid_min,lon,o,f,0.025 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:10 2023: ncap2 -O -s where(lon&lt;0) lon=lon+360 coraltemp_v3.1_20230908-0-360.nc coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:08 2023: ncks -O --msa_usr_rdr -d lon,0.0,180.0 -d lon,-180.0,0.0 coraltemp_v3.1_20230908.nc coraltemp_v3.1_20230908-0-360.nc\nThis is the first version of CoralTemp. It was originally called v1.0 and then renamed to v3.1 with no change to the overall product)\n2023-09-11T14:46:38Z (local files)\n2023-09-11T14:46:38Z https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1.dasid :CoralTemp-v3.1infoUrl :https://coralreefwatch.noaa.gov/satellite/bleaching5kminstitution :NOAA/NESDIS/STAR Coral Reef Watch Programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, analysed_sst, analysis, area, coral, coraltemp, crw, cryosphere, daily, data, day, distribution, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, extent, fraction, global, ice, ice distribution, information, infrared, national, near, nesdis, noaa, nrt, ocean, oceans, operational, ostia, program, real, reef, satellite, science, sea, sea_ice_area_fraction, sea_ice_fraction, sea_surface_temperature, seawater, service, spectral, spectral/engineering, sst, star, surface, temperature, thermal, time, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :OSTIA Usage Statement (1985-2002): IMPORTANT usage statement. Unless otherwise agreed in writing, these data may be used for pure academic research only, with no commercial or other application and all usage must meet the Met Office Standard Terms and Conditions, which may be found here: https://www.metoffice.gov.uk/corporate/legal/tandc.html. The data may be used for a maximum period of 5 years. Reproduction of the data is permitted provided the following copyright statement is included: (C) Crown Copyright 2010, published by the Met Office. You must submit a completed reproduction license application form (here https://www.metoffice.gov.uk/corporate/legal/repro_licence.html) before using the data. This only needs to be completed once for each user. WARNING Some applications are unable to properly handle signed byte values. If values are encountered &gt; 127, please subtract 256 from this reported value. GHRSST statement (2002-present): GHRSST protocol describes data use as free and open. Coral Reef Watch program statement: The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of Coral Reef Watch's website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/satellite/bleaching5kmnaming_authority :gov.noaa.coralreefwatchNCO :netCDF Operators version 4.7.5 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)nco_openmp_thread_number :1Northernmost_Northing :89.975platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :L4product_version :3.1program :NOAA Coral Reef Watch Programproject :NOAA Coral Reef Watch Programpublisher_email :coralreefwatch@noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch Programpublisher_name :NOAA Coral Reef Watch Programpublisher_type :grouppublisher_url :https://coralreefwatch.noaa.gov/references :Donlon, et al., 2011. The Operational Sea Surface Temperature and Sea Ice analysis (OSTIA). Maturi, et al., 2017. A new high-resolution sea surface temperature analysis. https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :OSTIA Sea Surface Temperature Reanalysis (night-only), NOAA Geo-Polar Blended Night-only Sea Surface Temperature Reanalysis, NOAA Geo-Polar Blended Night-only Sea Surface Temperature (near real-time)sourceUrl :(local files)Southernmost_Northing :-89.975standard_name_vocabulary :CF Standard Name Table v27summary :NOAA Coral Reef Watch Daily Global 5km Satellite Sea Surface Temperature (CoralTemp). CoralTemp is derived from three different but related 5km daily gap-free SST data sets and provides an internally consistent SST product that stretches from 1985 to present: Operational Sea Surface Temperature and Sea Ice Analysis (OSTIA) Sea Surface Temperature Reanalysis (1985-2002), Geo-Polar Blended Night-only Sea Surface Temperature Reanalysis (2002-2016), Geo-Polar Blended Night-only Sea Surface Temperature Near Real-Time (2017 to present).time_coverage_duration :P1Dtime_coverage_end :2023-09-09T12:00:00Ztime_coverage_resolution :P1Dtime_coverage_start :1985-01-01T12:00:00Ztitle :Sea Surface Temperature, Coral Reef Watch, CoralTemp, v3.1 - Daily, 1985-presentWesternmost_Easting :0.025"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#subset-the-erddap-dataset",
    "href": "tutorials/python/define_marine_habitat.html#subset-the-erddap-dataset",
    "title": "Define a marine habitat",
    "section": "Subset the ERDDAP dataset",
    "text": "Subset the ERDDAP dataset\nThe code below does the following: * Trims the data to include only SST data\n* Selects the date. To avoid the need to match the exact date found in the dataset, include method='nearest'. * Slices within the latitude and longitude ranges\n\nds_subset = ds['analysed_sst'].sel(time=date_for_sat_data, \n                          method='nearest'\n                          ).sel(latitude=slice(lat_min, lat_max),\n                                longitude=slice(lon_min, lon_max)\n                                )"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#make-a-plot-to-view-the-data",
    "href": "tutorials/python/define_marine_habitat.html#make-a-plot-to-view-the-data",
    "title": "Define a marine habitat",
    "section": "Make a plot to view the data",
    "text": "Make a plot to view the data\nThis may take a few seconds. So far you have only set the parameters for download but not requested that the data be downloaded. However, downloading will be necessary to plot the data, so xarray will download it.\n\nds_subset.plot.pcolormesh(cmap=\"gist_rainbow_r\",\n                          vmin=5,\n                          vmax=30,\n                          aspect=2,\n                          size=4\n                          )"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#define-and-mask-the-turtlewatch-band",
    "href": "tutorials/python/define_marine_habitat.html#define-and-mask-the-turtlewatch-band",
    "title": "Define a marine habitat",
    "section": "Define and mask the TurtleWatch band",
    "text": "Define and mask the TurtleWatch band\n\nThe band is between 17.5°C and 18.5°C.\nUse the “where” function of xarray to flag all pixels in the habitat range by replacing their values with a value that is much smaller than the data range minimum.\n\n\nds_masked = xr.where((ds_subset &gt; hab_temp_min) & (ds_subset &lt; hab_temp_max), \n                     -999,  # Set flag value\n                     ds_subset  \n                     )"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#map-the-masked-data",
    "href": "tutorials/python/define_marine_habitat.html#map-the-masked-data",
    "title": "Define a marine habitat",
    "section": "Map the masked data",
    "text": "Map the masked data\nMake some adjustments to the color map:\n* Set the palette to be the reverse of the gist_rainbow\n* Set missing values (like land..) to gray\n* Set the flag value color\n\n# Create the color palette\ncmap = mpl.cm.get_cmap(\"gist_rainbow_r\").copy()\n\n# Set the color of the missing or masked data \ncmap.set_bad(color='gray')  # missing values color (like land..)\n\n# Set the color of flag value (-999)\ncmap.set_under(color='firebrick')  # flag value color\n\n# Plot the data\nds_masked.plot.pcolormesh(cmap=cmap,\n                          vmin=5,\n                          vmax=30,\n                          aspect=2,\n                          size=4\n                          )\n\n# Add plot annotation\nplt.title('TurtleWatch band - ' + date_for_sat_data)\nplt.ylabel('Latitude')\nplt.xlabel('Longitude')\n\nText(0.5, 0, 'Longitude')"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#references",
    "href": "tutorials/python/define_marine_habitat.html#references",
    "title": "Define a marine habitat",
    "section": "References",
    "text": "References\n\nTurtleWatch: https://oceanwatch.pifsc.noaa.gov/turtlewatch.html\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html\nhttps://polarwatch.noaa.gov/catalog/"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html",
    "title": "Working with data that crosses the antimeridian",
    "section": "",
    "text": "History | Updated Sep 2023"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#background",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#background",
    "title": "Working with data that crosses the antimeridian",
    "section": "Background",
    "text": "Background\nMany datasets use a system where longitude is numbered from -180 to +180 degrees east (see example below). This numbering system presents a problem for researchers working in a region that spans the antimeridian, because the parts of the data end up on the opposite ends of the map.\n\n\n\nmap_-180to180_500px.png\n\n\n\nFigure. Global map on -180/+180 longitude showing data region crossing the antimeridian."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#objectives",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#objectives",
    "title": "Working with data that crosses the antimeridian",
    "section": "Objectives",
    "text": "Objectives\nThis tutorial will demonstrate how to use datasets with -180 to +180 longitude values to work within regions that cross the antimeridian."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Working with data that crosses the antimeridian",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data that crosses the antimeridian from a dataset with -180 to +180 longitude values\n\nConvert the data to a 0-360 longitude values\nReordering the longitude axis so that the longitude values are in ascending order\nVisualizing data on a map"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#datasets-used",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#datasets-used",
    "title": "Working with data that crosses the antimeridian",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Chlorophyll Gap-filled, Blended NOAA-20 and S-NPP VIIRS, Science Quality, Global, 9km, 2018- recent, Daily\nThis NOAA dataset blends chlorophyll data from the Visible and Infrared Imager/Radiometer Suite (VIIRS) sensors aboard the Suomi-NPP and NOAA-20 spacecraft. The gaps in the data are then filled using an empirical orthogonal function (DINEOF). The dataset is available from the CoastWatch Central ERDDAP: https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily\n\nImport packages\n\nimport xarray as xr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#define-the-area-to-extract",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#define-the-area-to-extract",
    "title": "Working with data that crosses the antimeridian",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nWe will extract data for an area in the Bering Sea between Russia and the United States at 176°E to -152°E longitude and 50°N to 70°N latitude.\n\n\n\ninterest_area_500px.png\n\n\n\nSet up variables\n\nDate to extract\nMinimum and maximum values for the longitude and latitude ranges.\n\n\nmy_date = '2023-08-18'\nlon_min = -152.\nlon_max = 176.\nlat_min = 50.\nlat_max = 70."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#get-the-seawifs-data",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#get-the-seawifs-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Get the SeaWiFS data",
    "text": "Get the SeaWiFS data\n\nOpen an xarray dataset object\n\n#url = 'https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily'\n\nurl = '/'.join(['https://coastwatch.noaa.gov',\n                'erddap',\n                'griddap',\n                'noaacwNPPN20VIIRSSCIDINEOFDaily'\n                ])\n\nds = xr.open_dataset(url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:    (time: 1874, altitude: 1, latitude: 2160, longitude: 4320)\nCoordinates:\n  * time       (time) datetime64[ns] 2018-05-30T12:00:00 ... 2023-08-24T12:00:00\n  * altitude   (altitude) float64 0.0\n  * latitude   (latitude) float32 89.96 89.88 89.79 ... -89.79 -89.88 -89.96\n  * longitude  (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nData variables:\n    chlor_a    (time, altitude, latitude, longitude) float32 ...\nAttributes: (12/77)\n    _lastModified:                    2023-09-04T21:15:13.000Z\n    _NCProperties:                    version=2,netcdf=4.7.3,hdf5=1.12.0,\n    cdm_data_type:                    Grid\n    Conventions:                      CF-1.6, COARDS, ACDD-1.3\n    creator_email:                    coastwatch.info@noaa.gov\n    creator_name:                     NOAA CoastWatch\n    ...                               ...\n    testOutOfDate:                    now-4days\n    time_coverage_end:                2023-08-24T12:00:00Z\n    time_coverage_start:              2018-05-30T12:00:00Z\n    title:                            Chlorophyll (Gap-filled DINEOF), NOAA S...\n    Westernmost_Easting:              -179.9583\n    westernmost_longitude:            -180.0xarray.DatasetDimensions:time: 1874altitude: 1latitude: 2160longitude: 4320Coordinates: (4)time(time)datetime64[ns]2018-05-30T12:00:00 ... 2023-08-..._CoordinateAxisType :Timeactual_range :[1.5276816e+09 1.6928784e+09]axis :Tioos_category :Timelong_name :Timesource_name :timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2018-05-30T12:00:00.000000000', '2018-05-31T12:00:00.000000000',\n       '2018-06-01T12:00:00.000000000', ..., '2023-08-22T12:00:00.000000000',\n       '2023-08-23T12:00:00.000000000', '2023-08-24T12:00:00.000000000'],\n      dtype='datetime64[ns]')altitude(altitude)float640.0_CoordinateAxisType :Height_CoordinateZisPositive :upactual_range :[0. 0.]axis :Zioos_category :Locationlong_name :Altitudepositive :upstandard_name :altitudeunits :marray([0.])latitude(latitude)float3289.96 89.88 89.79 ... -89.88 -89.96_ChunkSizes :2160_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudesource_name :latstandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([ 89.958336,  89.875   ,  89.791664, ..., -89.79167 , -89.87501 ,\n       -89.958336], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_ChunkSizes :4320_CoordinateAxisType :Lonactual_range :[-179.9583  179.9583]axis :Xioos_category :Locationlong_name :Longitudesource_name :lonstandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79167, ...,  179.79167,  179.87502,\n        179.95834], dtype=float32)Data variables: (1)chlor_a(time, altitude, latitude, longitude)float32...C_format :%.4gcell_methods :time:mean(interval:1 day)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logcoverage_content_type :physicalMeasurementgrid_mapping :coord_refioos_category :Ocean Colorlong_name :Chlorophyll Concentration, DINEOF Gap-Filledstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001[17486668800 values with dtype=float32]Indexes: (4)timePandasIndexPandasIndex(DatetimeIndex(['2018-05-30 12:00:00', '2018-05-31 12:00:00',\n               '2018-06-01 12:00:00', '2018-06-02 12:00:00',\n               '2018-06-03 12:00:00', '2018-06-04 12:00:00',\n               '2018-06-05 12:00:00', '2018-06-06 12:00:00',\n               '2018-06-07 12:00:00', '2018-06-08 12:00:00',\n               ...\n               '2023-08-15 12:00:00', '2023-08-16 12:00:00',\n               '2023-08-17 12:00:00', '2023-08-18 12:00:00',\n               '2023-08-19 12:00:00', '2023-08-20 12:00:00',\n               '2023-08-21 12:00:00', '2023-08-22 12:00:00',\n               '2023-08-23 12:00:00', '2023-08-24 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=1874, freq=None))altitudePandasIndexPandasIndex(Index([0.0], dtype='float64', name='altitude'))latitudePandasIndexPandasIndex(Index([ 89.95833587646484,             89.875,  89.79166412353516,\n        89.70833587646484,             89.625,  89.54166412353516,\n        89.45833587646484,             89.375,  89.29166412353516,\n        89.20833587646484,\n       ...\n       -89.20833587646484, -89.29167175292969, -89.37500762939453,\n       -89.45833587646484, -89.54167175292969, -89.62500762939453,\n       -89.70833587646484, -89.79167175292969, -89.87500762939453,\n       -89.95833587646484],\n      dtype='float32', name='latitude', length=2160))longitudePandasIndexPandasIndex(Index([-179.9583282470703,           -179.875, -179.7916717529297,\n       -179.7083282470703,           -179.625, -179.5416717529297,\n       -179.4583282470703,           -179.375, -179.2916717529297,\n       -179.2083282470703,\n       ...\n       179.20834350585938,  179.2916717529297, 179.37501525878906,\n       179.45834350585938,  179.5416717529297, 179.62501525878906,\n       179.70834350585938,  179.7916717529297, 179.87501525878906,\n       179.95834350585938],\n      dtype='float32', name='longitude', length=4320))Attributes: (77)_lastModified :2023-09-04T21:15:13.000Z_NCProperties :version=2,netcdf=4.7.3,hdf5=1.12.0,cdm_data_type :GridConventions :CF-1.6, COARDS, ACDD-1.3creator_email :coastwatch.info@noaa.govcreator_name :NOAA CoastWatchcreator_type :groupcreator_url :https://coastwatch.noaa.gov/data_bins :4466138.0data_maximum :301.4826data_minimum :0.0022108806date_created :2023-09-04T21:15:13.000ZEasternmost_Easting :179.9583easternmost_longitude :180.0end_orbit_number :0geospatial_lat_max :89.95834geospatial_lat_min :-89.95834geospatial_lat_resolution :0.08333333950903196geospatial_lat_units :degrees_northgeospatial_lon_max :179.9583geospatial_lon_min :-179.9583geospatial_lon_resolution :0.0833333178976615geospatial_lon_units :degrees_eastgeospatial_vertical_max :0.0geospatial_vertical_min :0.0geospatial_vertical_positive :upgeospatial_vertical_units :mhistory :/data/data369/hgu/ocssw/bin/l3mapgen par=/data/data652/coastwatch/oc/L3/scripts/bin/../config/l3mapgen_par_dineof_chlor_a ifile=/data/data652/coastwatch/oc/L3/scripts/bin/../temp/Config_dineof/V2023236_oci_L3.nc ofile=/data/data369/viirs/L3_dineof/236/V2023236_A1_WW00_chlor_a.nc   Mon Sep  4 21:15:16 2023\n: /data/data652/coastwatch/oc/L3/scripts/bin/l3cnvtr -b -s Suomi-NPP,NOAA-20 /data/data369/viirs/L3_dineof/236/V2023236_A1_WW00_chlor_a.nc /data/aftp/socd1/mecb/coastwatch/viirs/science/L3/global/chlora/dineof/2023/V2023236_A1_WW00_chlora.nc\n2023-09-05T23:55:50Z (local files)\n2023-09-05T23:55:50Z https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily.dasid :L3//data/data540/DINEOF/EOF-global-daily4/reconstructed_mix_nsw/V2023236_oci_L3.ncinfoUrl :https://coastwatch.noaa.gov/institution :NOAA NESDIS CoastWatchinstrument :VIIRSkeywords :altitude, applications, baseline, center, chlorophyll, data, environmental, graphics, imager, imager/radiometer, imaging, information, infrared, latitude, leaving, longitude, mean, merged, n20, national, nesdis, noaa, NOAA-20, normalized, npp, optical, optical properties, orbiting, overlay, partnership, planes, polar, polar-orbiting, properties, radiance, radiometer, research, satellite, service, suite, time, viirs, visible, water, water-leaving, ww00l2_flag_names :ATMFAIL,LAND,HIGLINT,HILT,HISATZEN,CLOUD,HISOLZEN,LOWLW,CHLFAIL,NAVWARN,CLDSHDSTL,MAXAERITER,CHLWARN,ALGICE,SEAICE,NAVFAIL,FILTERlatitude_step :0.083333336latitude_units :degrees_northlicense :These data were produced by NOAA and are not subject to copyright protection in the United States. \nNOAA waives any potential copyright and related rights in these data worldwide through the Creative \nCommons Zero 1.0 Universal Public Domain Dedication (CC0-1.0). \nThe data may be used and redistributed for free but is not intended\n for legal use, since it may contain inaccuracies. Neither the data\n Contributor, ERD, NOAA, nor the United States Government, nor any\n of their employees or contractors, makes any warranty, express or\n implied, including warranties of merchantability and fitness for a\n particular purpose, or assumes any legal liability for the accuracy,\n completeness, or usefulness, of this information.longitude_step :0.083333336longitude_units :degrees_eastmap_projection :geographicmeasure :Meannaming_authority :gov.noaa.coastwatchnorthernmost_latitude :90.0Northernmost_Northing :89.95834number_of_columns :4320number_of_lines :2160platform :Suomi-NPP, NOAA-20processing_level :L3 Mappedprocessing_version :Unspecifiedproduct_name :V2023236_A1_WW00_chlora.ncproj4_string :+proj=eqc +lat_ts=0 +lat_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +lon_0=0.000000project :Ocean Color Science Team (NOAA/NESDIS/STAR/OCST)publisher_email :coastwatch.info@noaa.gov;ncei.info@noaa.govpublisher_name :NOAA CoastWatch;National Centers for Environmental Information (NCEI)publisher_url :https://coastwatch.noaa.gov;https://www.ncei.noaa.gov/Satellite :Suomi-NPP\n NOAA-20Sensor :VIIRSsourceUrl :(local files)southernmost_latitude :-90.0Southernmost_Northing :-89.95834spatialResolution :9.28 kmstandard_name_vocabulary :CF Standard Name Table v29start_orbit_number :0suggested_image_scaling_applied :Nosuggested_image_scaling_maximum :20.0suggested_image_scaling_minimum :0.01suggested_image_scaling_type :LOGsummary :Visible and Infrared Imager/Radiometer Suite/Suomi-NPP NOAA-20 (VIIRS) Level-3 (WW00), Chlorophyll, DINEOF, Gap filled, MSL12,  Science Quality,Global, Daily, processed by NOAA.  EXPERIMENTAL.sw_point_latitude :-89.958336sw_point_longitude :-179.95833temporal_range :dailytestOutOfDate :now-4daystime_coverage_end :2023-08-24T12:00:00Ztime_coverage_start :2018-05-30T12:00:00Ztitle :Chlorophyll (Gap-filled DINEOF), NOAA S-NPP NOAA-20, VIIRS, Science Quality, Global 9km, 2018-recent,  DailyWesternmost_Easting :-179.9583westernmost_longitude :-180.0\n\n\n\n\nSubset the data\nWe will do this in two steps to make the process easier to follow. 1. Subset the data for date and latitude range 2. Subset the area around the antimeridian * Request data &lt; the limit (-152) on the US side of the antimeridian, i.e. -180 to -152 * Request data &gt; the limit (176) on the Russian side of the antimeridian, i.e. 176 to 180\n\n# The lat1 and lat2 values are used in the slice function\n# At first we set them as if the dataset is compliant with standards\nlat1 = lat_min\nlat2 = lat_max\n\n# Then switch them if latitude values are descending\nif ds.latitude[0].item() &gt; ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\n# Subset the data in two steps to make it easier to understand\n# 1. Subset the date and latitude range\nds_subset = ds['chlor_a'].sel(time=my_date, \n                              method='nearest').sel(latitude=slice(lat1, lat2))\n\n# 2. Subset the around the antimeridian\nds_subset = ds_subset.sel(longitude=(ds.longitude &lt; lon_min) \n                          | (ds.longitude &gt; lon_max)\n                          )\n\nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlor_a' (altitude: 1, latitude: 240, longitude: 384)&gt;\n[92160 values with dtype=float32]\nCoordinates:\n    time       datetime64[ns] 2023-08-18T12:00:00\n  * altitude   (altitude) float64 0.0\n  * latitude   (latitude) float32 69.96 69.88 69.79 69.71 ... 50.21 50.12 50.04\n  * longitude  (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nAttributes: (12/13)\n    C_format:               %.4g\n    cell_methods:           time:mean(interval:1 day)\n    colorBarMaximum:        30.0\n    colorBarMinimum:        0.03\n    colorBarScale:          Log\n    coverage_content_type:  physicalMeasurement\n    ...                     ...\n    ioos_category:          Ocean Color\n    long_name:              Chlorophyll Concentration, DINEOF Gap-Filled\n    standard_name:          mass_concentration_of_chlorophyll_a_in_sea_water\n    units:                  mg m^-3\n    valid_max:              100.0\n    valid_min:              0.001xarray.DataArray'chlor_a'altitude: 1latitude: 240longitude: 384...[92160 values with dtype=float32]Coordinates: (4)time()datetime64[ns]2023-08-18T12:00:00_CoordinateAxisType :Timeactual_range :[1.5276816e+09 1.6928784e+09]axis :Tioos_category :Timelong_name :Timesource_name :timestandard_name :timetime_origin :01-JAN-1970 00:00:00array('2023-08-18T12:00:00.000000000', dtype='datetime64[ns]')altitude(altitude)float640.0_CoordinateAxisType :Height_CoordinateZisPositive :upactual_range :[0. 0.]axis :Zioos_category :Locationlong_name :Altitudepositive :upstandard_name :altitudeunits :marray([0.])latitude(latitude)float3269.96 69.88 69.79 ... 50.12 50.04_ChunkSizes :2160_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudesource_name :latstandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([69.958336, 69.875   , 69.791664, ..., 50.208332, 50.125   , 50.041664],\n      dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_ChunkSizes :4320_CoordinateAxisType :Lonactual_range :[-179.9583  179.9583]axis :Xioos_category :Locationlong_name :Longitudesource_name :lonstandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79167, ...,  179.79167,  179.87502,\n        179.95834], dtype=float32)Indexes: (3)altitudePandasIndexPandasIndex(Index([0.0], dtype='float64', name='altitude'))latitudePandasIndexPandasIndex(Index([ 69.95833587646484,             69.875,  69.79166412353516,\n        69.70833587646484,             69.625,  69.54166412353516,\n        69.45833587646484,             69.375,  69.29166412353516,\n        69.20833587646484,\n       ...\n       50.791664123535156,  50.70833206176758,             50.625,\n       50.541664123535156,  50.45833206176758,             50.375,\n       50.291664123535156,  50.20833206176758,             50.125,\n       50.041664123535156],\n      dtype='float32', name='latitude', length=240))longitudePandasIndexPandasIndex(Index([-179.9583282470703,           -179.875, -179.7916717529297,\n       -179.7083282470703,           -179.625, -179.5416717529297,\n       -179.4583282470703,           -179.375, -179.2916717529297,\n       -179.2083282470703,\n       ...\n       179.20834350585938,  179.2916717529297, 179.37501525878906,\n       179.45834350585938,  179.5416717529297, 179.62501525878906,\n       179.70834350585938,  179.7916717529297, 179.87501525878906,\n       179.95834350585938],\n      dtype='float32', name='longitude', length=384))Attributes: (13)C_format :%.4gcell_methods :time:mean(interval:1 day)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logcoverage_content_type :physicalMeasurementgrid_mapping :coord_refioos_category :Ocean Colorlong_name :Chlorophyll Concentration, DINEOF Gap-Filledstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-downloaded-data",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-downloaded-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Plot the downloaded data",
    "text": "Plot the downloaded data\n\n# Make plot area\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Set the color palette\ncmap = mpl.cm.get_cmap(\"jet\").copy()\ncmap.set_bad(color='gray')\n\n# Show image\nshw = ax.imshow(np.log10(ds_subset.squeeze()), cmap=cmap, vmin=-1, vmax=2)\n\nbar = plt.colorbar(shw, shrink=0.65)\n  \n# Show plot with labels\nbar.set_label('Chlorophyll (log mg m-3)')\nplt.show()\n\n\n\n\n\n\n\n\n\nThe plot of the data shows a discontinuity\nThe plot of subsetted data (above) shows that we downloaded the data we requested, but there is a discontinuity on the right side of the map. The data from the Russian side (west of the antimeridian) is mapped to the east of the data on the US side.\nTo fix the discontinuity, we need to:\n* Change the longitude values on the US side of the antimeridian (-180 to -152) to values on the 0-360 longitude indexing system (180-208). * Rearrange the longitude values so that the data on the Russian side is moved to the west of the data on the US side."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#change-to-0-360-longitude-numbering",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#change-to-0-360-longitude-numbering",
    "title": "Working with data that crosses the antimeridian",
    "section": "Change to 0-360 longitude numbering",
    "text": "Change to 0-360 longitude numbering\n\nds_360 = ds_subset.assign_coords(longitude=(ds_subset.longitude % 360))\n\nprint('minimum lon value =', ds_360.longitude.min().item())\nprint('minimum lon value =', ds_360.longitude.max().item(), end='\\n\\n')\n\nprint('first value in lon array =', ds_360.longitude[0].item())\nprint('last value in lon array =', ds_360.longitude[-1].item())\n\nminimum lat value = 176.0416717529297\nminimum lat value = 207.9583282470703\n\nfirst value in lat array = 180.0416717529297\nlast value in lat array = 179.95834350585938"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#reorder-the-longitude-axis",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#reorder-the-longitude-axis",
    "title": "Working with data that crosses the antimeridian",
    "section": "Reorder the longitude axis",
    "text": "Reorder the longitude axis\nThe output from the cell above shows that the longitude values have been converted to 0-360. However, the lowest longitude value is not at the beginning of the array and the highest longitude value is not at the end of the array.\nTo rearrange the longitude values, use the roll function of xarray. The roll function will push values along an axis by the number of steps you enter. The values that are “pushed off” of the end of the array will be put at the beginning of the array.\n\nFirst we need to find the position where the longitude discontinuity happens, i.e. where the most easterly longitude (208.0) abruptly meets the most easterly longitude value (176.0)\nNext, use the discontinuity position to determine how many positions to roll the longitude array to the right. Apply the number to the roll function.\n\n\n# This code finds the index where the absolute value between each longitude value \n# and the largest longitude value is maximal\ndiscont_index = max(range(len(ds_360.longitude)), \n                    key=lambda i: abs(ds_360.longitude[i] -\n                                      ds_360.longitude.max())\n                    )\nprint('the index marking the discontinuity is:', discont_index, end='\\n\\n')\n\n# Substract the discontinuity position from the length of the array \n# to obtain the number of positions to roll the longitude axis\npostions_to_roll = len(ds_360.longitude) - discont_index\n\n# Roll the dataset\nds_rolled = ds_360.roll(longitude=postions_to_roll, roll_coords=True)\n\nprint('minimum lon value =', ds_rolled.longitude.min().item())\nprint('minimum lon value =', ds_rolled.longitude.max().item(), end='\\n\\n')\n\nprint('first value in lon array =', ds_rolled.longitude[0].item())\nprint('last value in lon array =', ds_rolled.longitude[-1].item())\n\nthe index marking the discontinuity is: 336\n\nminimum lon value = 176.0416717529297\nminimum lon value = 207.9583282470703\n\nfirst value in lon array = 176.0416717529297\nlast value in lon array = 207.9583282470703\n\n\nThe output from the cell above shows that the longitude values have been converted to 0-360, and that the lowest longitude value is at the beginning of the array and the highest longitude value is at the end of the array."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-data",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Plot the data",
    "text": "Plot the data\n\nThe discontinuity has been corrected!\n\n# Make plot area\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Set the color palette\ncmap = mpl.cm.get_cmap(\"jet\").copy()\ncmap.set_bad(color='gray')\n\n# show image\nshw = ax.imshow(np.log10(ds_rolled.squeeze()), \n                cmap=cmap,\n                vmin=-1, \n                vmax=2)\n\nbar = plt.colorbar(shw, shrink=0.65)\n  \n# show plot with labels\nbar.set_label('Chlorophyll (log mg m-3)')\nplt.show()"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#save-the-corrected-dataset-as-a-netcdf-file",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#save-the-corrected-dataset-as-a-netcdf-file",
    "title": "Working with data that crosses the antimeridian",
    "section": "Save the corrected dataset as a netCDF file",
    "text": "Save the corrected dataset as a netCDF file\n\nds_rolled.to_netcdf('data_corrected_0_to_360.nc')"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html",
    "href": "tutorials/python/Tutorial1-basics.html",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "",
    "text": "History | Updated August 2023"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#objective",
    "href": "tutorials/python/Tutorial1-basics.html#objective",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab data hosted on an ERDDAP server from Python, how to work with NetCDF files in Python and how to make some maps and time-series of sea surface temperature."
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nLocating a satellite product in ERDDAP, manually changing the constraints and copying the URL defining the data request\nDownloading the resulting netCDF file\nOpening and examining the netCDF file\nMaking basic maps and time series plots"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#datasets-used",
    "href": "tutorials/python/Tutorial1-basics.html#datasets-used",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Datasets used",
    "text": "Datasets used\nCoralTemp Sea Surface Temperature product from the NOAA Coral Reef Watch program. The NOAA Coral Reef Watch (CRW) daily global 5km Sea Surface Temperature (SST) product, also known as CoralTemp, shows the nighttime ocean temperature measured at the surface. The SST scale ranges from -2 to 35 °C. The CoralTemp SST data product was developed from two, related reanalysis (reprocessed) SST products and a near real-time SST product. Spanning January 1, 1985 to the present, the CoralTemp SST is one of the best and most internally consistent daily global 5km SST products available. More information about the product: https://coralreefwatch.noaa.gov/product/5km/index_5km_sst.php\nWe will use the monthly composite of this product and download it from the NOAA CoastWatch ERDDAP server: https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.graph"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#import-python-modules",
    "href": "tutorials/python/Tutorial1-basics.html#import-python-modules",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Import Python modules",
    "text": "Import Python modules\n\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#download-data-from-erddap-using-python",
    "href": "tutorials/python/Tutorial1-basics.html#download-data-from-erddap-using-python",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "1. Download data from ERDDAP using Python",
    "text": "1. Download data from ERDDAP using Python\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure.\nFor example, the following page allows you to subset monthly sea surface temperature (SST) https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html\n\n\n\nerddap.png\n\n\n\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\nIn this specific example, the URL we generated is :\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D\n\n\nWith Python, run the following to download the data using the generated URL .\n\n# Below we have broken the url into parts and rejoin the them\n# to allow you to better see the url in the notebook.\nurl = ''.join(['https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?',\n               'sea_surface_temperature',\n               '%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D',\n               '%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D'\n               ])\n\nurllib.request.urlretrieve(url, \"sst.nc\")\n\n('sst.nc', &lt;http.client.HTTPMessage at 0x1ac0e35b0&gt;)"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#loading-netcdf4-data-into-python",
    "href": "tutorials/python/Tutorial1-basics.html#loading-netcdf4-data-into-python",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "2. Loading netCDF4 data into Python",
    "text": "2. Loading netCDF4 data into Python\nNow that we’ve downloaded the data locally, we can load it into Python and extract the variables of interest.\nThe xarray package makes it very convenient to work with NetCDF files. Documentation is available here: http://xarray.pydata.org/en/stable/why-xarray.html\n\nOpen the netCDF file as an xarray dataset object and examine the data structure.\n\nds = xr.open_dataset('sst.nc', decode_cf=True)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 12, latitude: 202, longitude: 201)\nCoordinates:\n  * time                     (time) datetime64[ns] 2022-01-16 ... 2022-12-16\n  * latitude                 (latitude) float32 40.03 39.97 ... 30.02 29.98\n  * longitude                (longitude) float32 -80.02 -79.97 ... -70.07 -70.02\nData variables:\n    sea_surface_temperature  (time, latitude, longitude) float32 ...\nAttributes: (12/65)\n    acknowledgement:                  NOAA Coral Reef Watch program\n    cdm_data_type:                    Grid\n    comment:                          This is a product of NOAA Coral Reef Wa...\n    contributor_name:                 NOAA Coral Reef Watch program\n    contributor_role:                 Collecting source data and deriving pro...\n    Conventions:                      CF-1.6, ACDD-1.3, COARDS\n    ...                               ...\n    time_coverage_duration:           P1M\n    time_coverage_end:                2022-12-16T00:00:00Z\n    time_coverage_resolution:         P1M\n    time_coverage_start:              2022-01-16T00:00:00Z\n    title:                            SST and SST Anomaly, NOAA Global Coral ...\n    Westernmost_Easting:              -80.024994xarray.DatasetDimensions:time: 12latitude: 202longitude: 201Coordinates: (3)time(time)datetime64[ns]2022-01-16 ... 2022-12-16_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3240.03 39.97 39.93 ... 30.02 29.98_CoordinateAxisType :Latactual_range :[29.975004 40.025   ]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([40.025   , 39.975   , 39.92501 , ..., 30.075003, 30.025   , 29.975004],\n      dtype=float32)longitude(longitude)float32-80.02 -79.97 ... -70.07 -70.02_CoordinateAxisType :Lonactual_range :[-80.024994 -70.024994]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-80.024994, -79.975   , -79.924995, ..., -70.125   , -70.075   ,\n       -70.024994], dtype=float32)Data variables: (1)sea_surface_temperature(time, latitude, longitude)float32...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[487224 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-16', '2022-02-16', '2022-03-16', '2022-04-16',\n               '2022-05-16', '2022-06-16', '2022-07-16', '2022-08-16',\n               '2022-09-16', '2022-10-16', '2022-11-16', '2022-12-16'],\n              dtype='datetime64[ns]', name='time', freq=None))latitudePandasIndexPandasIndex(Index([40.025001525878906, 39.974998474121094, 39.925010681152344,\n        39.87500762939453,  39.82500457763672, 39.775001525878906,\n       39.724998474121094, 39.675010681152344,  39.62500762939453,\n        39.57500457763672,\n       ...\n        30.42500114440918, 30.374998092651367, 30.325002670288086,\n       30.274999618530273, 30.225004196166992,  30.17500114440918,\n       30.124998092651367, 30.075002670288086, 30.024999618530273,\n       29.975004196166992],\n      dtype='float32', name='latitude', length=202))longitudePandasIndexPandasIndex(Index([-80.02499389648438,  -79.9749984741211, -79.92499542236328,\n                  -79.875, -79.82499694824219, -79.77499389648438,\n        -79.7249984741211, -79.67499542236328,            -79.625,\n       -79.57499694824219,\n       ...\n        -70.4749984741211, -70.42499542236328,            -70.375,\n       -70.32499694824219, -70.27499389648438,  -70.2249984741211,\n       -70.17499542236328,            -70.125, -70.07499694824219,\n       -70.02499389648438],\n      dtype='float32', name='longitude', length=201))Attributes: (65)acknowledgement :NOAA Coral Reef Watch programcdm_data_type :Gridcomment :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite Version 3.1, derived from CoralTemp v1.0.contributor_name :NOAA Coral Reef Watch programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archive.Conventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch programcreator_name :NOAA Coral Reef Watch programcreator_type :groupcreator_url :https://coralreefwatch.noaa.govdate_created :2018-03-01T12:00:00Zdate_issued :2019-01-19T20:32:23Zdate_metadata_modified :2018-09-01T12:00:00Zdate_modified :2018-03-01T12:00:00ZEasternmost_Easting :-70.024994geospatial_bounds :POLYGON((-90.0 180.0, 90.0 180.0, 90.0 -180.0, -90.0 -180.0, -90.0 180.0))geospatial_bounds_crs :EPSG:4326geospatial_lat_max :40.025geospatial_lat_min :29.975004geospatial_lat_units :degrees_northgeospatial_lon_max :-70.024994geospatial_lon_min :-80.024994geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:32663grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Tue Jul 27 10:37:54 2021: ncrename -d lon,longitude -d lat,latitude -v lon,longitude -v lat,latitude -v sea surface temperature anomaly,sea_surface_temperature_anomaly /cwdata/coralreef/work/temp.nc\nMonthly data files for mean sea surface temperature (SST) and sea surface temperature anomaly (SST anomaly) were downloaded from ftp.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1/nc/v1.0/monthly. Monthly files were created that contain both SST and SST anomaly data, and a mask of earth surface classifications.\n2023-09-06T14:23:22Z (local files)\n2023-09-06T14:23:22Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5Did :Satellite_Global_5km_CoralTemp_SST_SSTA_Monthly_Mean_CompositeinfoUrl :https://coralreefwatch.noaa.gov/product/5km/index.phpinstitution :NOAA/NESDIS/STAR Coral Reef Watch programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, anomaly, array, characteristics, coral, crw, data, earth, Earth Science &gt; Land Surface &gt; Land Temperature &gt; Land Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature Anomaly, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, flag, global, information, infrared, land, latitude, longitude, mask, mean, month, monthly, national, nesdis, noaa, ocean, oceans, pixel, program, quality, reef, satellite, science, sea, sea_surface_temperature, sea_surface_temperature_anomaly, seawater, service, spectral, spectral/engineering, sst, star, surface, surface_temperature_anomaly, temperature, thermal, time, v.3.1, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of the Coral Reef Watch website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/product/5km/index.phpnaming_authority :gov.noaa.coralreefwatchNCO :\"4.6.3\"Northernmost_Northing :40.025platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :Derived from L4 satellite sea surface temperature analysisproduct_version :3.1program :NOAA Coral Reef Watch programproject :NOAA Coral Reef Watch programpublisher_email :erd.data at noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch programpublisher_name :NOAA NMFS SWFSC ERD, CoastWatch West Coast Nodepublisher_type :institutionpublisher_url :https://coralreefwatch.noaa.gov, https://coastwatch.pfeg.noaa.gov/references :https://coralreefwatch.noaa.gov/product/5km/index.php and https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :Coral Reef Watch CoralTemp v1.0sourceUrl :(local files)Southernmost_Northing :29.975004spatial_resolution :0.05 degreestandard_name_vocabulary :CF Standard Name Table v27summary :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite, derived from CoralTemp v1.0.time_coverage_duration :P1Mtime_coverage_end :2022-12-16T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2022-01-16T00:00:00Ztitle :SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring, 5km, V.3.1, Monthly, 1985-PresentWesternmost_Easting :-80.024994\n\n\n\n\nExamine which coordinates and variables are included in the dataset.\n\n# List the coordinates\nprint('The coordinates variables:', list(ds.coords), '\\n')\n\n# List the data variables\nprint('The data variables:', list(ds.data_vars))\n\nThe coordinates variables: ['time', 'latitude', 'longitude'] \n\nThe data variables: ['sea_surface_temperature']\n\n\n\n\nExamine the structure of sea_surface_temperature.\n\nds.sea_surface_temperature.shape\n\n(12, 202, 201)\n\n\nThe dataset is a 3-D array with 12 time steps, each with 202 rows corresponding to latitudes and 201 columns corresponding to longitudes.\n\n\nList the dates for each time step.\nThe dataset has 12 time steps, one for each month between January 2022 and December 2022.\n\nds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 12)&gt;\narray(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 2022-01-16 2022-02-16 ... 2022-12-16\nAttributes:\n    _CoordinateAxisType:    Time\n    actual_range:           [1.6422912e+09 1.6711488e+09]\n    axis:                   T\n    coverage_content_type:  coordinate\n    ioos_category:          Time\n    long_name:              reference time of the last day of the composite t...\n    standard_name:          time\n    time_origin:            01-JAN-1970 00:00:00xarray.DataArray'time'time: 122022-01-16 2022-02-16 2022-03-16 ... 2022-10-16 2022-11-16 2022-12-16array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2022-01-16 ... 2022-12-16_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-16', '2022-02-16', '2022-03-16', '2022-04-16',\n               '2022-05-16', '2022-06-16', '2022-07-16', '2022-08-16',\n               '2022-09-16', '2022-10-16', '2022-11-16', '2022-12-16'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (8)_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00\n\n\n\n\nExamine the latitude coordinate variable\nTypically, the latitude coordinate variable will be in ascending order. However, in some datasets the order is reversed, i.e the order is descending.\nBy examining the first and last values on our latitude array (below), we can see that the values are descending.\n* In practice what this means is that when you slice (subset) using latitude later in this tutorial, you will put the largest latitude value first.\n\nprint('First latitude value', ds.latitude[0].item())\nprint('Last latitude value', ds.latitude[-1].item())\n\nFirst latitude value 40.025001525878906\nLast latitude value 29.975004196166992"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#working-with-the-data",
    "href": "tutorials/python/Tutorial1-basics.html#working-with-the-data",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "3. Working with the data",
    "text": "3. Working with the data\n\nCreating a map for for January 2022 (our first time step)\n\nFind the minimum and maximum SST values.\n\nprint('Minimum SST', np.nanmin(ds.sea_surface_temperature))\nprint('Maximum SST', np.nanmax(ds.sea_surface_temperature))\n\nMinimum SST 2.34\nMaximum SST 29.87\n\n\n\n\nUse the minimum and maximum SST to set some color breaks.\n\n# Sets color breaks from 2 to 30 with 0.05 steps\nlevs = np.arange(2, 30, 0.05)\n\n\n\nDefine a color palette.\n\njet = [\"blue\", \"#007FFF\", \"cyan\", \"#7FFF7F\",\n       \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"]\n\n\n\nSet color scale using the jet palette.\n\ncm = LinearSegmentedColormap.from_list('my_jet', jet, N=len(levs))\n\n\n\nPlot the SST map\nThe code also shows how to annotate the map by: - Adding points to the map (e.g. station locations) - Adding contour lines\n\nplt.contourf(ds.longitude, \n             ds.latitude, \n             ds.sea_surface_temperature[0, :, :], \n             levs,\n             cmap=cm)\n\n# Plot the colorbar\nplt.colorbar()\n\n# Annotation: Example of how to add points to the map\nplt.scatter(range(-74, -71), np.repeat(34, 3), c='black')\n\n# Annotation: Example of how to add a contour line\nplt.contour(ds.longitude, \n            ds.latitude, \n            ds.sea_surface_temperature[0, :, :], \n            levels=[14],\n            linewidths=1)\n\n# Add a title\nplt.title(\"Monthly Sea Surface Temperature - \" \n          + ds.time[0].dt.strftime('%b %Y').item())\nplt.show()"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#plotting-a-time-series",
    "href": "tutorials/python/Tutorial1-basics.html#plotting-a-time-series",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Plotting a time series",
    "text": "Plotting a time series\n\nSubset the following box from the data:\n\n36o to 38oN latitude\n-77o to -75oE longitude\n\nWe are going to generate a time series of mean SST within that box.\n\nFirst, subset the data:\n\nRemember!\nFor this product, latitudes are indexed in descending order (high to low). Therefore when you slice latitude, put the largest value first.\n\nda = ds.sel(latitude=slice(38, 36), longitude=slice(-77, -75))\n\n\n\nExamine the structure of the subsetted data.\nThe subset is a 3-D array with 12 time steps, each with 40 rows corresponding to latitudes and 40 columns corresponding to longitudes.\n\nda.sea_surface_temperature.shape\n\n(12, 40, 40)\n\n\n\n\nPlot the subsetted data\n\nplt.contourf(da.longitude, \n             da.latitude, \n             da.sea_surface_temperature[0, :, :], \n             levs,\n             cmap=cm)\nplt.colorbar()\nplt.title(\"Monthly Sea Surface Temperature \" \n          + ds.time[0].dt.strftime('%b %Y').item())\nplt.show()"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#compute-the-monthly-mean-for-each-month",
    "href": "tutorials/python/Tutorial1-basics.html#compute-the-monthly-mean-for-each-month",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Compute the monthly mean for each month",
    "text": "Compute the monthly mean for each month\n\nres = np.mean(da.sea_surface_temperature, axis=(1, 2))\n\n\nPlot the time-series\n\nplt.figure(figsize=(8, 4))\nplt.scatter(ds.time, res)\nplt.ylabel('SST (ºC)')\n\nText(0, 0.5, 'SST (ºC)')"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#creating-a-map-of-average-sst-over-a-year",
    "href": "tutorials/python/Tutorial1-basics.html#creating-a-map-of-average-sst-over-a-year",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Creating a map of average SST over a year",
    "text": "Creating a map of average SST over a year\n\nCompute the yearly mean for the region\n\nmean_sst = np.mean(ds.sea_surface_temperature, axis=0)\n\n\n\nPlot the map of the 2022 average SST in the region\n\nplt.contourf(ds.longitude, ds.latitude, mean_sst, levs, cmap=cm)\nplt.colorbar()\nplt.title(\"Mean SST \" \n          + ds.time[0].dt.strftime('%b %Y').item() \n          + ' - '\n          + ds.time[11].dt.strftime('%b %Y').item())\n\nplt.show()"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html",
    "href": "tutorials/r/lis-chlora-dynamics.html",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "",
    "text": "History | Updated Apr 2025"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#objective",
    "href": "tutorials/r/lis-chlora-dynamics.html#objective",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab daily chlorophyll-a data hosted on an ERDDAP server using the griddap function in the rerrdap package, how to make temporal composites in R and how to make some maps and time-series of chlorophyll-a."
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "The tutorial demonstrates the following techniques:",
    "text": "The tutorial demonstrates the following techniques:\n\nAccessing gridded satellite data from an ERDDAP server using the rerddap package.\nSubsetting spatial and temporal data using latitude, longitude, and date ranges.\nConverting gridded data to tidy format for analysis using dplyr and lubridate.\nCalculating monthly and annual spatial averages of chlorophyll-a concentrations.\nCreating faceted maps of monthly chlorophyll-a using ggplot2 and viridis color scales.\nCreating an 8-day time series to analyze seasonal chlorophyll-a patterns.\nComparing chlorophyll-a seasonal cycles between regions (West vs. East Long Island Sound)."
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#datasets-used",
    "href": "tutorials/r/lis-chlora-dynamics.html#datasets-used",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Datasets used",
    "text": "Datasets used\nLong Island Sound Optimized water quailty datasets from OLCI Products developed by academic collaborators that have partnered with NOAA CoastWatch through a Sea Grant project titled “Actionable satellite water-quality data products in Long Island Sound for improved management and societal benefits”. The dataset includes daily Sentinal-3 OLCI (300 m) water quality indicators:\n\nChlorophyll-a (Chla “chlor_a”)\nAbsorption coefficient of Chromophoric Dissolved Organic Material at 300 nm (aCDOM(300) “cdom”)\nDissolved Organic Carbon (DOC “doc”)\nSuspended Particulate Matter (SPM “spm”). Chlor_a, cdom and doc are based on Long Island Sound optimized algorithms. Spm retrieved using the Nechad Algorithm.\n\nThis dataset covers the Long Island Sound region between 40.2° N - 41.5° N and 74° W - 71.8° W\nIn this tutorial we will use the daily Chlorophyll-a dataset. The data will be downloaded from the CoastWatch ERRDAP server: https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.html\nFor more information on each product refer to:\n\nChla: https://www.sciencedirect.com/science/article/pii/S1569843223000456\nCDOM and DOC: https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2023JG007767\nSPM: https://www.sciencedirect.com/science/article/abs/pii/S0034425709003617"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#install-and-load-packages",
    "href": "tutorials/r/lis-chlora-dynamics.html#install-and-load-packages",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Install and load packages",
    "text": "Install and load packages\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"tidyverse\", \"lubridate\", \"viridis\", \"ggplot2\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#select-the-satellite-dataset",
    "href": "tutorials/r/lis-chlora-dynamics.html#select-the-satellite-dataset",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Select the satellite dataset",
    "text": "Select the satellite dataset\nWe will load the daily Chlorophyll-a dataset from the CoastWatch ERDDAP server. The dataset ID is noaacwappsS3ABcolorLISDaily.\nWe will use the info function from the rerddap package to first obtain information about the dataset of interest, then we will import the data.\n# Set the ERDDAP URL\nerddap_url &lt;- \"https://coastwatch.noaa.gov/erddap\"\n\n# Set the dataset ID\ndataset_id &lt;- \"noaacwappsS3ABcolorLISDaily\"\n\n# Obtain data info using the erddap url and dataset ID\ndataInfo &lt;- rerddap::info(dataset_id,url=erddap_url)  \n\n# Examine the metadata dataset info\ndataInfo\n## &lt;ERDDAP info&gt; noaacwappsS3ABcolorLISDaily \n## Base URL: https://coastwatch.noaa.gov/erddap \n## Dataset Type: griddap \n## Dimensions (range):  \n##     time: (2017-01-01T00:00:00Z, 2025-02-28T00:00:00Z) \n##     latitude: (40.204, 41.5) \n##     longitude: (-74.0, -71.8049) \n## Variables:  \n##     cdom: \n##         Units: m^-1 \n##     chlor_a: \n##         Units: mg m^-3 \n##     doc: \n##         Units: Âµmole/liter \n##     spm: \n##         Units: mg L^-1"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#subset-the-data",
    "href": "tutorials/r/lis-chlora-dynamics.html#subset-the-data",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Subset the data",
    "text": "Subset the data\nFor this tutorial, we will be focusing on chloropyhll-a throughout 2022 in the Long Island Sound Range.\n# Set the time range\ntime_range &lt;- c(\"2022-01-01\", \"2022-12-31\")\n\n# Set the ranges for latitude and longitude\nlat_range &lt;- c(40.204, 41.5)\nlon_range &lt;- c(-74.0, -71.8049)\n\n# Set the parameter\nparameter &lt;- 'chlor_a'"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#extract-the-dataset",
    "href": "tutorials/r/lis-chlora-dynamics.html#extract-the-dataset",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Extract the dataset",
    "text": "Extract the dataset\n# Download the chlorophyll-a data\nchlor_data &lt;- griddap(\n  datasetx = dataset_id,\n  url = erddap_url,\n  time = time_range,\n  latitude = lat_range,       \n  longitude = lon_range,\n  fields = parameter\n)\n\n# View the data\nhead(chlor_data)"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#convert-to-a-tibble-and-add-datemonth-columns",
    "href": "tutorials/r/lis-chlora-dynamics.html#convert-to-a-tibble-and-add-datemonth-columns",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Convert to a tibble and add date/month columns",
    "text": "Convert to a tibble and add date/month columns\nConverting to a tibble makes the dataset tidy-verse friendly, so we can manipulate the data without headaches.\n# Convert to tibble and add date/month columns\ndf &lt;- chlor_data$data %&gt;%\n  as_tibble() %&gt;%\n  mutate(\n    time = as.Date(time),\n    month = floor_date(time, \"month\")\n  )\n\n# View the data\nprint(df)"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#calculate-monthly-mean-chlorophyll-a",
    "href": "tutorials/r/lis-chlora-dynamics.html#calculate-monthly-mean-chlorophyll-a",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Calculate monthly mean chlorophyll-a",
    "text": "Calculate monthly mean chlorophyll-a\nWe group the data by month, latitude, and longitude and compute the average chlorophyll-a for each pixel for each month. We also remove any missing values.\n# Calculate monthly mean chlor_a\nmonthly_mean &lt;- df %&gt;%\n  group_by(month, latitude, longitude) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\")\n\n# View the data\nprint(monthly_mean)"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#list-the-dates-for-each-time-step-after-calculating-the-monthly-means",
    "href": "tutorials/r/lis-chlora-dynamics.html#list-the-dates-for-each-time-step-after-calculating-the-monthly-means",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "List the dates for each time step after calculating the monthly means",
    "text": "List the dates for each time step after calculating the monthly means\nThe dataset now has 12 time steps, one for each month between January 2022 and December 2022.\nunique(monthly_mean$month)\n##[1] \"2022-01-01\" \"2022-02-01\" \"2022-03-01\" \"2022-04-01\" \"2022-05-01\" \"2022-06-01\" \n##\"2022-07-01\" \"2022-08-01\" \"2022-09-01\" \"2022-10-01\" \"2022-11-01\"\n##[12] \"2022-12-01\""
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#create-a-faceted-plot-of-monthly-mean-chlorophyll-a-for-2022",
    "href": "tutorials/r/lis-chlora-dynamics.html#create-a-faceted-plot-of-monthly-mean-chlorophyll-a-for-2022",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Create a faceted plot of monthly mean chlorophyll-a for 2022",
    "text": "Create a faceted plot of monthly mean chlorophyll-a for 2022\nUsing ggplot, we create a faceted spatial plot of chlorophyll-a with tiles colored by value, and one map per month of 2022.\nfacet_wrap tells ggplot to split the plot in 12 facets (one for each month) and ncol = 4 puts the 12 plots into 3 rows and 4 columns.\nggplot(monthly_mean, aes(x = longitude, y = latitude, fill = chlor_a)) +\n  geom_tile() +\n  scale_fill_viridis(\n    name = bquote(\"Chlorophyll-a (mg \"*m^{-3}*\")\"),\n    option = \"turbo\",\n    limits = c(0, 20),\n    na.value = \"transparent\"\n  ) +\n  scale_x_continuous(\n    breaks = c(-74, -73, -72),\n    labels = c(\"-74\", \"-73\", \"-72\")\n  ) +\n  coord_equal() +\n  facet_wrap(~format(month, \"%Y-%m-%d\"), ncol = 4) +\n  labs(x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal(base_size = 12) +\n  theme(strip.text = element_text(size = 10))\n\n\n\nimages"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#compute-the-annual-average-for-the-region",
    "href": "tutorials/r/lis-chlora-dynamics.html#compute-the-annual-average-for-the-region",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Compute the annual average for the region",
    "text": "Compute the annual average for the region\nCalculate the annual average chlorophyll-a at each pixel by grouping the monthly data by latitude and longitude, then taking the mean across all months. We also remove any missing values.\nyearly_mean &lt;- monthly_mean %&gt;%\n  group_by(latitude, longitude) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\")"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#plot-the-map-of-the-2022-average-chlorophyll-a-in-the-region",
    "href": "tutorials/r/lis-chlora-dynamics.html#plot-the-map-of-the-2022-average-chlorophyll-a-in-the-region",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Plot the map of the 2022 average chlorophyll-a in the region",
    "text": "Plot the map of the 2022 average chlorophyll-a in the region\nggplot(yearly_mean, aes(x = longitude, y = latitude, fill = chlor_a)) +\n  geom_tile() +\n  scale_fill_viridis(\n    name = bquote(\"Chlorophyll-a (mg \"*m^{-3}*\")\"),\n    option = \"turbo\",\n    limits = c(0, 20),\n    na.value = \"transparent\"\n  ) +\n  coord_equal() +\n  labs(\n    title = \"Mean Chlorophyll-a\\nJan 2022 – Dec 2022\",\n    x = \"Longitude\", y = \"Latitude\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\nimages"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "href": "tutorials/r/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound",
    "text": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound\nSubset the data\n\nWest Long Island Sound between -73.9° to -73.1° W longitude\nEast Long Island Sound between -72.9° to -71.8° W longitude\n\nWe are going to generate a time series of mean chlorophyll-a within each box.\n# Subset West Long Island\nwest_df &lt;- df %&gt;%\n  filter(longitude &gt;= -73.9, longitude &lt;= -73.1)\n\n# Subset East Long Island\neast_df &lt;- df %&gt;%\n  filter(longitude &gt;= -72.9, longitude &lt;= -71.8)"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#examine-the-structure-of-the-subsetted-data",
    "href": "tutorials/r/lis-chlora-dynamics.html#examine-the-structure-of-the-subsetted-data",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Examine the structure of the subsetted data",
    "text": "Examine the structure of the subsetted data\nstr(west_df)\n\nstr(east_df)"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#resample-each-subset-to-8-day-means",
    "href": "tutorials/r/lis-chlora-dynamics.html#resample-each-subset-to-8-day-means",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Resample each subset to 8-day means",
    "text": "Resample each subset to 8-day means\n# Resample west_df\nwest_df &lt;- west_df %&gt;%\n  mutate(\n    period = as.Date(\"2022-01-01\") +\n      floor(as.numeric(difftime(time, as.Date(\"2022-01-01\"), units = \"days\")) / 8) * 8\n  )\n\n# Resample east_df\neast_df &lt;- east_df %&gt;%\n  mutate(\n    period = as.Date(\"2022-01-01\") +\n      floor(as.numeric(difftime(time, as.Date(\"2022-01-01\"), units = \"days\")) / 8) * 8\n  )"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#compute-a-time-series",
    "href": "tutorials/r/lis-chlora-dynamics.html#compute-a-time-series",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Compute a time series",
    "text": "Compute a time series\nNow, we will average all data within each subset across the latitude and longitude dimensions to produce a single time series.\nwest_ts &lt;- west_df %&gt;%\n  group_by(period) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(region = \"West LIS\")\n\neast_ts &lt;- east_df %&gt;%\n  group_by(period) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(region = \"East LIS\")"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#plot-the-time-series",
    "href": "tutorials/r/lis-chlora-dynamics.html#plot-the-time-series",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Plot the time series",
    "text": "Plot the time series\n# Combine for plotting\nts_combined &lt;- bind_rows(west_ts, east_ts)\n\n# Plot the time series\nggplot(ts_combined, aes(x = period, y = chlor_a, color = region)) +\n  geom_line() +\n  geom_point(size = 1) +\n  scale_color_manual(values = c(\"West LIS\" = \"blue\", \"East LIS\" = \"red\")) +\n  labs(\n    title = \"Seasonal Cycle of Chlorophyll-a in Long Island Sound (2022)\",\n    x = \"Date\",\n    y = bquote(\"Chlorophyll-a (mg \"*m^{-3}*\")\"),\n    color = \"Region\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\nimages"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html",
    "href": "tutorials/r/define_marine_habitat.html",
    "title": "Define a marine habitat",
    "section": "",
    "text": "notebook filename | define_marine_habitat.Rmd"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#install-required-packages-and-load-libraries",
    "href": "tutorials/r/define_marine_habitat.html#install-required-packages-and-load-libraries",
    "title": "Define a marine habitat",
    "section": "Install required packages and load libraries",
    "text": "Install required packages and load libraries\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ncdf4\", \"rerddap\", \"plotdap\", \"RCurl\",  \n                       \"raster\", \"colorRamps\", \"maps\", \"mapdata\",\n                       \"ggplot2\", \"RColorBrewer\", \"rerddapXtracto\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#select-the-satellite-data",
    "href": "tutorials/r/define_marine_habitat.html#select-the-satellite-data",
    "title": "Define a marine habitat",
    "section": "Select the Satellite Data",
    "text": "Select the Satellite Data\n\nUse the CoralTemp SST dataset (ID CRW_sst_v3_1) from the OceanWatch ERDDAP server (https://oceanwatch.pifsc.noaa.gov/erddap/index.html)\n\nGather information about the dataset (metadata) using rerddap\n\nDisplay the information\n\n# Let's look at the metadata\n\n\nurl = \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\ndataInfo &lt;- rerddap::info('CRW_sst_v3_1',url=url)\nparameter &lt;- 'analysed_sst'\ndataInfo\n## &lt;ERDDAP info&gt; CRW_sst_v3_1 \n##  Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1985-01-01T12:00:00Z, 2023-09-09T12:00:00Z) \n##      latitude: (-89.975, 89.975) \n##      longitude: (0.025, 359.975) \n##  Variables:  \n##      analysed_sst: \n##          Units: degree_C \n##      sea_ice_fraction: \n##          Units: 1"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#get-satellite-data",
    "href": "tutorials/r/define_marine_habitat.html#get-satellite-data",
    "title": "Define a marine habitat",
    "section": "Get Satellite Data",
    "text": "Get Satellite Data\n\nSelect an area of the central North Pacific where the fishery operates: longitude range of 185 to 235 east and latitude range of 20 to 45 north\n\nSelect a date in the first quarter of the year when bycatch typically occurs: tcoord=c('2023-01-06', '2023-01-06')). tcoord needs to be a vector even if we are pulling only one day of data.\n\n# latitude and longitude of the vertices\nylim&lt;-c(20,45)\nxlim&lt;-c(185,235)\n\n# Extract the data\nSST &lt;- rxtracto_3D(dataInfo,xcoord=xlim,ycoord=ylim,parameter=parameter, \n                   tcoord=c('2023-01-06','2023-01-06'))\n\n# Drop command needed to reduce SST from a 3D variable to a 2D  one  \nSST$analysed_sst &lt;- drop(SST$analysed_sst)"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#make-a-quick-plot-using-plotbbox",
    "href": "tutorials/r/define_marine_habitat.html#make-a-quick-plot-using-plotbbox",
    "title": "Define a marine habitat",
    "section": "Make a quick plot using plotBBox",
    "text": "Make a quick plot using plotBBox\nplotBBox(SST, plotColor = 'thermal')\n\n         #,maxpixels=1000000)"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#define-and-plot-the-turtlewatch-temperature-band",
    "href": "tutorials/r/define_marine_habitat.html#define-and-plot-the-turtlewatch-temperature-band",
    "title": "Define a marine habitat",
    "section": "Define and plot the TurtleWatch temperature band",
    "text": "Define and plot the TurtleWatch temperature band\nSet the temperature band to 17.5-18.5 degrees C, as determined by the TurtleWatch program.\n## Define turtle temperature range\nmin.temp &lt;- 17.5\nmax.temp &lt;- 18.5\nCreate another variable for habitat temperature\nSet the habitat temperature to equal NA\nSST2 &lt;- SST\nSST2$analysed_sst[SST2$analysed_sst &gt;= min.temp & SST2$analysed_sst &lt;= max.temp] &lt;- NA\nplotBBox(SST2, plotColor = 'thermal')\n\nIt would be nicer to color in the TurtleWatch band (the NA values) with a different color. If you want to customize graphs, it’s better to use ggplot than the plotBBox that comes with the rerrdapXtracto package. Here we will use ggplot to plot the data. But first the data is reformatted for use in ggplot.\nRestructure the data\ndims &lt;- dim(SST2$analysed_sst)\nSST2.lf &lt;- expand.grid(x=SST$longitude,y=SST$latitude)\nSST2.lf$sst&lt;-array(SST2$analysed_sst,dims[1]*dims[2])"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#plot-the-data-using-ggplot",
    "href": "tutorials/r/define_marine_habitat.html#plot-the-data-using-ggplot",
    "title": "Define a marine habitat",
    "section": "Plot the Data using ‘ggplot’",
    "text": "Plot the Data using ‘ggplot’\ncoast &lt;- map_data(\"worldHires\", ylim = ylim, xlim = xlim)\n\npar(mar=c(3,3,.5,.5), las=1, font.axis=10)\n\nmyplot&lt;-ggplot(data = SST2.lf, aes(x = x, y = y, fill = sst)) +\n  geom_tile(na.rm=T) +\n  geom_polygon(data = coast, aes(x=long, y = lat, group = group), fill = \"grey80\") +\n  theme_bw(base_size = 15) + ylab(\"Latitude\") + xlab(\"Longitude\") +\n  coord_fixed(1.3,xlim = xlim, ylim = ylim) +\n  ggtitle(unique(as.Date(SST2$time))) +\n  scale_fill_gradientn(colours = rev(rainbow(12)),limits=c(5,30),na.value = \"firebrick4\") \n\nmyplot"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "A tidyverse/ggplot version is also available here: https://github.com/jebyrnes/noaa_coastwatch_tutorial_1/blob/main/tutorial2-1.md Links to an external site.\ncourtesy of Jarrett Byrnes from UMass Boston - http://byrneslab.net (Thank you Jarrett!!)"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#background",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#background",
    "title": "CoastWatch Training Materials",
    "section": "Background",
    "text": "Background\nSeveral ocean color sensors have been launched since 1997 to provide continuous global coverage for ocean color data. The sensors have differences in design and calibration, and different algorithms may be applied to generate chlorophyll values. Consequently, chlorophyll-a values can vary among the sensors during periods where measurements overlap.\nTo examine this phenomenon, we will download and plot time-series of chlorophyll-a concentrations from various sensors from 1997 to the present and see how the measurements compare during periods of overlap."
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#objective",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#objective",
    "title": "CoastWatch Training Materials",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show how to extract a time-series from four different monthly satellite chlorophyll datasets for the period that each was in operation between 1997-present. It will showcase the use of the rerddap and rerddapXtracto packages, which have been developed to make it easier to interact with ERDDAP servers from R.\nMore information about the rerddap package can be found here: https://cran.r-project.org/web/packages/rerddap/index.html\nand here: https://cran.r-project.org/web/packages/rerddap/vignettes/Using_rerddap.html\nMore information about the rerddapXtracto package can be found here: https://cran.r-project.org/web/packages/rerddapXtracto/index.html\nand here: https://cran.r-project.org/web/packages/rerddapXtracto/vignettes/UsingrerddapXtracto.html"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "CoastWatch Training Materials",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nUsing rerddapXtracto package to extract data from a rectangular area of the ocean over time\nUsing rerddap to retrieving information about a dataset from ERDDAP\nComparing results from different sensors\nAveraging data spatially\nProducing timeseries plots\nDrawing maps with satellite data"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "title": "CoastWatch Training Materials",
    "section": "Datasets used",
    "text": "Datasets used\nSeaWiFS Chlorophyll-a, V.2018, Monthly, Global, 4km, 1997-2012 https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nMODIS Aqua, Chlorophyll-a, V.2022, Monthly, Global, 4km, 2002-present https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022SQ\nNOAA VIIRS S-NPP, Chlorophyll-a, Monthly, Global, 4km, 2012-present https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisVHNSQchlaMonthly\nESA CCI Ocean Colour Dataset, v6.0, Monthly, Global, 4km, 1997-Present This dataset was developed by the European Space Agency’s Climate Change Initiative. The dataset merges data from multiple sensors (MERIS, MODIS, VIIRS and SeaWiFS) to create a long timeseries (1997 to present) with better spatial coverage than any single sensor. Parameters include chlorophyll-a, remote sensing reflectance, diffuse attenuation coefficients, absorption coefficients, backscatter coefficients, and water classification. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorMonthly"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#load-packages",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#load-packages",
    "title": "CoastWatch Training Materials",
    "section": "Load packages",
    "text": "Load packages\npackages &lt;- c( \"ncdf4\",\"plyr\",\"lubridate\",\"rerddap\",\"ggplot2\",\"plotdap\",\n               \"rerddapXtracto\",\"maps\", \"mapdata\",\"grid\", \"reshape2\", \"gridExtra\")\n\n# Install packages not yet installed\ninstalled_packages &lt;- packages %in% rownames(installed.packages())\n\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages])\n}\n\n# Load packages \ninvisible(lapply(packages, library, character.only = TRUE))"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "title": "CoastWatch Training Materials",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nFirst we define the longitude-latitude boundaries of the region. The coordinates used here, between -95 to -90°W longitude and 25-30°N latitude, define an area in teh Gulf of Mexico.\nxcoord &lt;- c(-95,-90)\nycoord &lt;- c(25,30)"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#get-information-about-the-dataset-we-will-be-downloading",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#get-information-about-the-dataset-we-will-be-downloading",
    "title": "CoastWatch Training Materials",
    "section": "Get information about the dataset we will be downloading",
    "text": "Get information about the dataset we will be downloading\nDefine the URL of the ERDDAP we will be using:\nERDDAP_Node &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/\"\n\nGet monthly SeaWiFS data, which starts in 1997.\nGo to ERDDAP to find the name of the dataset for monthly SeaWIFS data: erdSW2018chlamday\nYou should always examine the dataset in ERDDAP to check the date range, names of the variables and dataset ID, to make sure your griddap calls are correct: https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nFirst we need to know what our variable is called. Let’s retrieve some metadata using the info function of the rerddap package:\ndataInfo &lt;- rerddap::info('erdSW2018chlamday', url=ERDDAP_Node)\nvar &lt;- dataInfo$variable$variable_name\n\n# Display the dataset metadata\ndataInfo\n\n## &lt;ERDDAP info&gt; erdSW2018chlamday \n##  Base URL: https://coastwatch.pfeg.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-16T00:00:00Z, 2010-12-16T00:00:00Z) \n##      latitude: (-89.95834, 89.95834) \n##      longitude: (-179.9583, 179.9584) \n##  Variables:  \n##      chlorophyll: \n##          Units: mg m^-3\n\n\nExtract satellite data with rxtracto_3D\nFor each dataset, we will extract satellite data for the entire length of the available timeseries.\n\nDates must be defined separately for each dataset. rxtracto_3D will crash if dates are entered that are not part of the timeseries.\n\nThe beginning (earliest) date to use in timeseries is obtained from the information returned in dataInfo.\n\nTo get the end (most recent) date to use in the timeseries, use the last option for time.\nThe variable name can change between datasets. For this dataset, the chloropyll variable is called chlorophyll, as seen in the metadata returned by dataInfo\n\n\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n# Set the altitude coordinate to zero\nzcoord &lt;- 0.\n\n# Extract the beginning and ending dates of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntcoord &lt;- c(tt[2],\"last\")\n** Run the SeaWiFS data extraction with rxtracto_3D:\n# Extract the timeseries data using rxtracto_3D\nchlSeaWiFS&lt;-rxtracto_3D(dataInfo,\n                        parameter=parameter,\n                        tcoord=tcoord,\n                        xcoord=xcoord,\n                        ycoord=ycoord)\n\n\nPlot data to show where it is in the world\nWe will use the plotBBox function of the rerddapXtracto package to make a quick map of the data\nmyFunc &lt;- function(x) log(x)\nplotBBox(chlSeaWiFS, plotColor = 'algae', myFunc = myFunc)\n\n\n\nGet monthly MODIS data, which starts in 2002.\ndataInfo &lt;- rerddap::info('erdMH1chlamday_R2022SQ', url=ERDDAP_Node)\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n#Extract the start and end times of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\n#Run rxtracto_3D\nchlMODIS&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord)\n\n\nGet monthly VIIRS data, which starts in 2012.\ndataInfo &lt;- rerddap::info('nesdisVHNSQchlaMonthly', url=ERDDAP_Node)\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n#Extract the start and end times of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\n\n# This dataset has an altitude dimensionm, so must include zcoord as an argument in the rxtracto_3D function Set the altitude coordinate to zero\nzcoord &lt;- 0.\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\n#Run rxtracto_3D\nchlVIIRS &lt;- rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord,\n                      zcoord=zcoord)\n\n# Remove extraneous zcoord dimension for chlorophyll \nchlVIIRS$chlor_a &lt;- drop(chlVIIRS$chlor_a)\n\n\nAverage data spatially and temporally\n\nspatially averages data for each time step within the area boundaries for each dataset.\n\ntemporally averages data for data in each timeseries onto a map, for each dataset.\n\n\n## Spatially average all the data within the box for each dataset.\n## The c(3) indicates the dimension to keep - in this case time \nchlSeaWiFS$avg &lt;- apply(chlSeaWiFS$chlorophyll, c(3),function(x) mean(x,na.rm=TRUE))\nchlMODIS$avg &lt;- apply(chlMODIS$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\nchlVIIRS$avg &lt;- apply(chlVIIRS$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\n\n## Temporally average all of the data into one map \n## The c(1,2) indicates the dimensions to keep - in this case latitude and longitude  \nchlSeaWiFS$avgmap &lt;- apply(chlSeaWiFS$chlorophyll,c(1,2),function(x) mean(x,na.rm=TRUE))\nchlMODIS$avgmap &lt;- apply(chlMODIS$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\nchlVIIRS$avgmap &lt;- apply(chlVIIRS$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\n\n\nPlot time series for the three datasets\nplot(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg, type='l', col=2,lwd=2, \n     xlab=\"\", xlim=as.Date(c(\"1997-12-01\",\"2024-06-01\")), \n     ylim=c(0.5,3.5), ylab=\"CHL\")\naxis(2)\npoints(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg,pch=20,col=2)\n\nlines(as.Date(chlMODIS$time), chlMODIS$avg, col=4, lwd=2)\npoints(as.Date(chlMODIS$time), chlMODIS$avg,pch=20,col=4)\n\nlines(as.Date(chlVIIRS$time), chlVIIRS$avg, col=3, lwd=2)\npoints(as.Date(chlVIIRS$time), chlVIIRS$avg,pch=20,col=3)\n\nlegend('topleft',legend=c('SeaWiFS','MODIS','VIIRS'),cex=0.6,col=c(2,4,3),lwd=2)\n\nYou can see that the values of chl-a concentration doesn’t always match between sensors.\n\n\nGet OC-CCI data (September 1997 to Dec 2022)\nIf you needed a single time series from 1997 to present, you would have to use the plot above to devise some method to reconcile the difference in values where two datasets overlap. Alternatively, you could use the ESA OC-CCI (ocean color climate change initiative) dataset, which blends data from many satellite missions into a single dataset, including data from SeaWiFS, MODIS, and VIIRS.\nAdd the ESA OC-CCI dataset to the plot above to see how it compares with data from the individual satellite missions.\ndataInfo &lt;- rerddap::info('pmlEsaCCI60OceanColorMonthly', url=ERDDAP_Node)\n\n# This identifies the parameter to choose - there are &gt; 60 in this dataset!\nparameter &lt;- 'chlor_a'\n\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\nchlOCCCI&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord)\n\n# Now spatially average the data into a timeseries\nchlOCCCI$avg &lt;- apply(chlOCCCI$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\n\n# Now temporally average the data into one map \nchlOCCCI$avgmap &lt;- apply(chlOCCCI$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\n\n\nMake another plot with CCI as well to compare\nplot(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg, type='l', col=2,lwd=2, \n     xlab=\"\", xlim=as.Date(c(\"1997-12-01\",\"2024-06-01\")), \n     ylim=c(0.5,3.5), ylab=\"CHL\")\naxis(2)\npoints(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg,pch=20,col=2)\npoints(as.Date(chlMODIS$time), chlMODIS$avg,pch=20,col=4)\npoints(as.Date(chlVIIRS$time), chlVIIRS$avg,pch=20,col=3)\nlines(as.Date(chlOCCCI$time),chlOCCCI$avg,lwd=2)\n\nlegend('topleft',legend=c('SeaWiFS','MODIS','VIIRS','OC-CCI'),cex=0.6,col=c(2,4,3,1),\n       pch=c(20,20,20,NA),lty=c(NA,NA,NA,1),lwd=2)\n\ncoast &lt;- map_data(\"worldHires\", ylim = ycoord, xlim = xcoord)\n\n# Put arrays into format for ggplot\nmelt_map &lt;- function(lon,lat,var) {\n  dimnames(var) &lt;- list(Longitude=lon, Latitude=lat)\n  ret &lt;- melt(var,value.name=\"Chl\")\n}\n\n# Loop for making 4 maps\ndatasetnames &lt;- c(\"SeaWiFS\",\"MODIS\",\"VIIRS\",\"OC-CCI\")\n\nplot_list = list()\n\nfor(i in 1:4) {\n  \n  if(i == 1) chl &lt;- chlSeaWiFS\n  if(i == 2) chl &lt;- chlMODIS\n  if(i == 3) chl &lt;- chlVIIRS\n  if(i == 4) chl &lt;- chlOCCCI\n  \n   chlmap &lt;- melt_map(chl$longitude, chl$latitude, chl$avgmap)\n\n   p = ggplot(\n     data = chlmap, \n     aes(x = Longitude, y = Latitude, fill = log(Chl))) +\n         geom_tile(na.rm=T) +\n         geom_polygon(data = coast, aes(x=long, y = lat, group = group), fill = \"grey80\") +\n         theme_bw(base_size = 12) + ylab(\"Latitude\") + xlab(\"Longitude\") +\n         coord_fixed(1.3, xlim = c(-95,-90), ylim = ycoord) +\n         scale_fill_viridis_c(limits=c(-2.5,3)) +\n         ggtitle(paste(\"Average\", datasetnames[i])\n      ) \n\n  plot_list[[i]] = p\n}\n\n# Now print out maps into a png file.  Can't use par function with **ggplpot** to get \n# multiple plots per page.  Here using a function in the **grid** package\n\ngrid.arrange(plot_list[[1]],plot_list[[2]],plot_list[[3]],plot_list[[4]], nrow = 2)"
  },
  {
    "objectID": "tutorials/matlab/matlab_basics_gl.html",
    "href": "tutorials/matlab/matlab_basics_gl.html",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands.\nNote: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset daily SST data:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.html\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nERDDAP\n\n\nIn this specific example, the URL we generated is:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.nc?sst%5B(2021-07-21T12:00:00Z):1:(2021-07-28T12:00:00Z)%5D%5B(38.8749871947229):1:(50.6059751976437)%5D%5B(-92.4199507342304):1:(-75.8816402880577)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n% View data attributes and variables\nncdisp('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS');\nNotice that the full data set has four variables: time, latitude, longitude, and sst. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\n\n\nNotice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the week we’re interested in: 21 - 28 July 2021.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2021 & time_full_ymdhms(:,2) == 7 ...\n    & time_full_ymdhms(:,3) &gt;= 21 & time_full_ymdhms(:,3) &lt;= 28);\n\n\n\nBefore we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'latitude');\nlon = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'longitude');\nNotice in the output above that sst has the dimensions of longitude x latitude x time which means it has a size of 1181 x 838 x 9961.\n\n\n\nNow, we’ll access just the small amount of sst data we’re interested in. We’ll do this by telling the computer to access the variable ‘sst’, beginning at a specific time and spanning our time of interest.\n% Start coordinates\naoi_start = [1 1 time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon) length(lat) length(time_aoi)];\nsst = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'sst', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 1181 x 838 x 8. Before we see what these data look like, let’s create indices for the timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi*  % Delete every variable with 'aoi' in its name\n\n\n\n\nLet’s create a map for a single day, 21 July 2021, the first day in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 10:0.5:25.5, 'fill', 'on');\ntitle(sprintf('Daily SST %s', datestr(time_ymdhms(1,:), 'dd-mmm-yyyy')));\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(45,5), -83:0.5:-81, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 15\ncontourm(lat, lon, sst(:,:,1)', [15 15], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Example of how to add a marker to tutorial author's home town, just for\n% fun\nplotm(45.8527, -87.0218, 'p');\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\ndaily SST\n\n\n\n\n\nLet’s pick a box encompassing Lake Superior: north of 46N and west of 84W. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above for time to identify a subsetted area of interest.\n% Find longitudes west of 84 W\nlon_aoi = find(lon &lt;= -84);\n\n% Find latitudes north of 46 N\nlat_aoi = find(lat &gt;= 46);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 8 days\nsst_ts(1:8,1) = NaN;\nfor d = 1:1:8 \n    sst_ts(d,1) = mean(sst_subset(:,:,d), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,3), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\nset(gca, 'XTick', time_ymdhms(:,3));\nset(gca, 'XTickLabel', datestr(time_ymdhms(:,:), 'mm/dd'))\n\n\n\ntime series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n% Average over time, which is the third dimention of our data\nsst_wk = mean(sst, 3, \"omitnan\");\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_wk', 10:0.5:25.5, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'dd-mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(8,:),'dd-mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nmean SST"
  },
  {
    "objectID": "tutorials/matlab/matlab_basics_gl.html#how-to-work-with-satellite-data-in-matlab",
    "href": "tutorials/matlab/matlab_basics_gl.html#how-to-work-with-satellite-data-in-matlab",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands.\nNote: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset daily SST data:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.html\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nERDDAP\n\n\nIn this specific example, the URL we generated is:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.nc?sst%5B(2021-07-21T12:00:00Z):1:(2021-07-28T12:00:00Z)%5D%5B(38.8749871947229):1:(50.6059751976437)%5D%5B(-92.4199507342304):1:(-75.8816402880577)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n% View data attributes and variables\nncdisp('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS');\nNotice that the full data set has four variables: time, latitude, longitude, and sst. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\n\n\nNotice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the week we’re interested in: 21 - 28 July 2021.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2021 & time_full_ymdhms(:,2) == 7 ...\n    & time_full_ymdhms(:,3) &gt;= 21 & time_full_ymdhms(:,3) &lt;= 28);\n\n\n\nBefore we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'latitude');\nlon = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'longitude');\nNotice in the output above that sst has the dimensions of longitude x latitude x time which means it has a size of 1181 x 838 x 9961.\n\n\n\nNow, we’ll access just the small amount of sst data we’re interested in. We’ll do this by telling the computer to access the variable ‘sst’, beginning at a specific time and spanning our time of interest.\n% Start coordinates\naoi_start = [1 1 time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon) length(lat) length(time_aoi)];\nsst = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'sst', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 1181 x 838 x 8. Before we see what these data look like, let’s create indices for the timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi*  % Delete every variable with 'aoi' in its name\n\n\n\n\nLet’s create a map for a single day, 21 July 2021, the first day in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 10:0.5:25.5, 'fill', 'on');\ntitle(sprintf('Daily SST %s', datestr(time_ymdhms(1,:), 'dd-mmm-yyyy')));\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(45,5), -83:0.5:-81, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 15\ncontourm(lat, lon, sst(:,:,1)', [15 15], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Example of how to add a marker to tutorial author's home town, just for\n% fun\nplotm(45.8527, -87.0218, 'p');\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\ndaily SST\n\n\n\n\n\nLet’s pick a box encompassing Lake Superior: north of 46N and west of 84W. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above for time to identify a subsetted area of interest.\n% Find longitudes west of 84 W\nlon_aoi = find(lon &lt;= -84);\n\n% Find latitudes north of 46 N\nlat_aoi = find(lat &gt;= 46);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 8 days\nsst_ts(1:8,1) = NaN;\nfor d = 1:1:8 \n    sst_ts(d,1) = mean(sst_subset(:,:,d), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,3), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\nset(gca, 'XTick', time_ymdhms(:,3));\nset(gca, 'XTickLabel', datestr(time_ymdhms(:,:), 'mm/dd'))\n\n\n\ntime series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n% Average over time, which is the third dimention of our data\nsst_wk = mean(sst, 3, \"omitnan\");\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_wk', 10:0.5:25.5, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'dd-mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(8,:),'dd-mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nmean SST"
  },
  {
    "objectID": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html",
    "href": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "As an example, we are going to plot time-series of mean chlorophyll-a concentration from various sensors from 1997 to 2018 to look at the periods of overlap.\nWe are going to download data from SeaWiFS (1997-2010), MODIS (2002-present) and VIIRS (2012-present) and compare it to the ESA-CCI data which combines all 3 sensors into a homogeneous time-series.\nIn this tutorial, the URLs to the data are provided so you don’t have to search for them. But, if you weren’t sure what the URLs were, you could find them by searing the list of datasets hosted on the OceanWatch ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/index.html) and following the steps at the beginning of Tutoral 1.\nFor this tutoral, we’re interested in all time steps in the area bounded by 15 - 25N, 198 - 208E.\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nsw_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'time');\n\n% Convert this to [Y M D H M S]\nsw_time_ymdhms = datevec(sw_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(sw_time)];\n% Download the data of interest\nsw = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nswAVG(1:length(sw_time),1) = NaN;\nfor m = 1:1:length(sw_time)\n    swAVG(m,1) = mean(sw(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* sw m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nmodis_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'time'); \n\n% Convert this to [Y M D H M S]\nmodis_time_ymdhms = datevec(modis_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(modis_time)];\n\n% Download the data of interest\nmodis = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nmodisAVG(1:length(modis_time),1) = NaN;\nfor m = 1:1:length(modis_time)\n    modisAVG(m,1) = mean(modis(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* modis m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nviirs_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'time');\n\n% Convert this to [Y M D H M S]\nviirs_time_ymdhms = datevec(viirs_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(viirs_time)];\n% Download the data of interest\nviirs = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nviirsAVG(1:length(viirs_time),1) = NaN;\nfor m = 1:1:length(viirs_time)\n    viirsAVG(m,1) = mean(viirs(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* viirs m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nesa_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'time');\n\n% Convert this to [Y M D H M S]\nesa_time_ymdhms = datevec(esa_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(esa_time)];\n\n% Download the data of interest\nesa = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nesaAVG(1:length(esa_time),1) = NaN;\nfor m = 1:1:length(esa_time)\n    esaAVG(m,1) = mean(esa(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* esa m \n\n\n\nNow we can compare the spatial averages across the three sensors: SeaWiFS, MODIS, and VIIRS. We’ll do this by generating a plot the includes all three time series, which overlap to varying degrees.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'Color', [0 70 127]/255);\nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'Color', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'Color', [127 127 255]/255);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChloraophyll-a from MODIS and VIIRS\n\n\nYou can see that the values of chlorophyll-a concentration don’t match across sensors.\n\n\n\nThe OC-CCI data are from a blended product, that merges the three sensors.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'o', 'MarkerFaceColor', [0 70 127]/255, 'MarkerEdgeColor', ...\n    [0 70 127]/255); \nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'o', 'MarkerFaceColor', [147 213 0]/255, ...\n    'MarkerEdgeColor', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'o', 'MarkerFaceColor', [127 127 255]/255, ...\n    'MarkerEdgeColor', [127 127 255]/255);\nplot(datenum(esa_time_ymdhms), esaAVG, 'k', 'LineWidth', 2);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'OC-CCI', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChlorphyll from ESA OC-CCI"
  },
  {
    "objectID": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html#tutorial-2.-comparison-of-chlorophyll-data-from-different-sensors",
    "href": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html#tutorial-2.-comparison-of-chlorophyll-data-from-different-sensors",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "As an example, we are going to plot time-series of mean chlorophyll-a concentration from various sensors from 1997 to 2018 to look at the periods of overlap.\nWe are going to download data from SeaWiFS (1997-2010), MODIS (2002-present) and VIIRS (2012-present) and compare it to the ESA-CCI data which combines all 3 sensors into a homogeneous time-series.\nIn this tutorial, the URLs to the data are provided so you don’t have to search for them. But, if you weren’t sure what the URLs were, you could find them by searing the list of datasets hosted on the OceanWatch ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/index.html) and following the steps at the beginning of Tutoral 1.\nFor this tutoral, we’re interested in all time steps in the area bounded by 15 - 25N, 198 - 208E.\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nsw_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'time');\n\n% Convert this to [Y M D H M S]\nsw_time_ymdhms = datevec(sw_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(sw_time)];\n% Download the data of interest\nsw = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nswAVG(1:length(sw_time),1) = NaN;\nfor m = 1:1:length(sw_time)\n    swAVG(m,1) = mean(sw(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* sw m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nmodis_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'time'); \n\n% Convert this to [Y M D H M S]\nmodis_time_ymdhms = datevec(modis_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(modis_time)];\n\n% Download the data of interest\nmodis = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nmodisAVG(1:length(modis_time),1) = NaN;\nfor m = 1:1:length(modis_time)\n    modisAVG(m,1) = mean(modis(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* modis m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nviirs_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'time');\n\n% Convert this to [Y M D H M S]\nviirs_time_ymdhms = datevec(viirs_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(viirs_time)];\n% Download the data of interest\nviirs = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nviirsAVG(1:length(viirs_time),1) = NaN;\nfor m = 1:1:length(viirs_time)\n    viirsAVG(m,1) = mean(viirs(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* viirs m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nesa_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'time');\n\n% Convert this to [Y M D H M S]\nesa_time_ymdhms = datevec(esa_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(esa_time)];\n\n% Download the data of interest\nesa = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nesaAVG(1:length(esa_time),1) = NaN;\nfor m = 1:1:length(esa_time)\n    esaAVG(m,1) = mean(esa(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* esa m \n\n\n\nNow we can compare the spatial averages across the three sensors: SeaWiFS, MODIS, and VIIRS. We’ll do this by generating a plot the includes all three time series, which overlap to varying degrees.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'Color', [0 70 127]/255);\nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'Color', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'Color', [127 127 255]/255);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChloraophyll-a from MODIS and VIIRS\n\n\nYou can see that the values of chlorophyll-a concentration don’t match across sensors.\n\n\n\nThe OC-CCI data are from a blended product, that merges the three sensors.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'o', 'MarkerFaceColor', [0 70 127]/255, 'MarkerEdgeColor', ...\n    [0 70 127]/255); \nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'o', 'MarkerFaceColor', [147 213 0]/255, ...\n    'MarkerEdgeColor', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'o', 'MarkerFaceColor', [127 127 255]/255, ...\n    'MarkerEdgeColor', [127 127 255]/255);\nplot(datenum(esa_time_ymdhms), esaAVG, 'k', 'LineWidth', 2);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'OC-CCI', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChlorphyll from ESA OC-CCI"
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Tutorials will live here.",
    "crumbs": [
      "Training Tutorials",
      "Software Tutorials"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CoastWatch Training Tutorials",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "tutorials/codegallery.html",
    "href": "tutorials/codegallery.html",
    "title": "Code Gallery",
    "section": "",
    "text": "This page lists CoastWatch code gallery tutorials.\nClick the eye icon to view the tutorial or download to get the source file.\n\n\n\n\n\n\n\n\n\n  \n    Category\n    \n      All\n      Data Access & SubsettingERDDAP BasicsSpatial Analysis & MappingTime Series\n    \n  \n\n  \n    Software\n\n    \n      Python ×\n    \n\n    \n      R ×\n    \n\n    \n      Matlab ×\n    \n\n    \n      Clear\n    \n  \n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nCategory\nPreview\nPython ↓\nR ↓\nMatlab ↓\n\n\n\n\nBasics of working with satellite data\nERDDAP Basics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompare time series from different sensors\nTime Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMake a virtual buoy with satellite data\nTime Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nCalculating sea ice area and extent\nSpatial Analysis & Mapping\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nWorking with data that crosses the antimeridian\nSpatial Analysis & Mapping\n\n\n\n\n\n\n\n\n\n\n—\n—\n\n\nDefine a marine habitat\nSpatial Analysis & Mapping\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nExtract data within a boundary\nData Access & Subsetting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to work with satellite data in Matlab in the Great Lakes\nERDDAP Basics\n\n\n\n\n\n—\n—\n\n\n\n\n\n\n\nWorking with Great Lakes Surface Temperature Data\nData Access & Subsetting\n\n\n\n\n\n\n\n\n\n\n—\n—\n\n\nAnalyze Great Lakes Ice Concentration\nTime Series\n\n\n\n\n\n\n\n\n\n\n—\n—\n\n\nMulti-Sensor chlorophyll time series analysis for Lake Erie\nTime Series\n\n\n\n\n\n\n\n\n\n\n—\n—\n\n\nLong-term lake surface temperature variability from Great Lakes Satellite Records\nTime Series\n\n\n\n\n\n\n\n\n\n\n—\n—\n\n\nVisualizing JPSS Sea Ice Concentration products using Google Colab\nTime Series\n\n\n\n\n\n\n\n\n\n\n—\n—\n\n\nLong Island Sound Chlorophyll-a Dynamics\nTime Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n    \n      Basics of working with satellite data\n      Access and analyze satellite-derived sea surface temperature using ERDDAP and NetCDF-based workflows. This tutorial demonstrates how to locate and subset a satellite SST product in ERDDAP, download gridded NetCDF data, examine its structure, and create basic spatial maps and regional time series. Users work with the NOAA Coral Reef Watch CoralTemp monthly sea surface temperature product to explore coordinate conventions, generate SST maps, compute regional averages, and visualize temporal variability.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature in the western North Atlantic Ocean along the US East Coast in 2022.\n          \n          \n          \n            \n              \n            \n            Map of the 2022 average sea surface temperature in the western North Atlantic Ocean along the US East Coast.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature in the western North Atlantic Ocean along the US East Coast in 2022.\n          \n          \n          \n            \n              \n            \n            Map of the 2022 average sea surface temperature in the western North Atlantic Ocean along the US East Coast.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature around the Hawaiian Islands in 2018.\n          \n          \n          \n            \n              \n            \n            Map of the 2018 average sea surface temperature in the Hawaiian Islands.\n          \n            ◀  1 / 2  ▶\n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      Compare time series from different sensors\n      Compare satellite chlorophyll-a time series from multiple ocean color sensors to understand differences during overlapping observation periods. This tutorial demonstrates how to use ERDDAP to extract spatially averaged chlorophyll-a time series from a defined region, examine dataset metadata, handle differences in coordinate conventions, and compare measurements across sensors through visualization. Monthly chlorophyll-a data from SeaWiFS, MODIS Aqua, NOAA VIIRS S-NPP, and the ESA Ocean Colour Climate Change Initiative (OC-CCI) are used to evaluate consistency and variability among sensors from 1997 to the present.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          \n            \n              \n            \n            Mean log-transformed chlorophyll-a concentration for the Gulf of Mexico region derived from SeaWiFS, MODIS Aqua, NOAA VIIRS S-NPP, and the ESA OC-CCI blended dataset.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      Make a virtual buoy with satellite data\n      Create a virtual ocean buoy using satellite data to extend or replace discontinued in situ observations. This tutorial demonstrates how to use ERDDAP to extract satellite sea surface temperature at a fixed location, build and clean a virtual buoy time series, resample the data to a lower temporal resolution, and analyze trends through visualization and linear regression. Data from NDBC Buoy 46259 are used alongside the NOAA GeoPolar Blended SST satellite dataset.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            National Data Buoy Center buoy 46259 matched up with sea surface temperature data.\n          \n          \n          \n            \n              \n            \n             Trend analysis of buoy and satellite data.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            National Data Buoy Center buoy 46259 matched up with sea surface temperature data.\n          \n          \n          \n            \n              \n            \n             Trend analysis of buoy and satellite data.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Calculating sea ice area and extent\n      Calculate sea ice area and extent from satellite-derived sea ice concentration to quantify seasonal and interannual variability in Arctic ice cover. This tutorial demonstrates how to use PolarWatch ERDDAP to retrieve gridded sea ice concentration data, incorporate grid cell area information, and apply standard concentration thresholds to compute sea ice area and extent. Users visualize sea ice concentration maps and generate monthly time series to examine changes in Arctic sea ice over time. Data from the NOAA/NSIDC Sea Ice Concentration Climate Data Record (Version 4) and a polar stereographic grid cell area dataset are used to perform the calculations for the Northern Hemisphere.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly mean sea ice concentration in the Northern Hemisphere derived from the NOAA/NSIDC Sea Ice Concentration Climate Data Record.\n          \n          \n          \n            \n              \n            \n            Monthly time series of Arctic sea ice area and sea ice extent computed from satellite-derived sea ice concentration using a 15% concentration threshold.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly mean sea ice concentration for the Arctic in 2021 shown in a Northern Polar Stereographic projection.\n          \n          \n          \n            \n              \n            \n            Monthly time series of Arctic sea ice area and sea ice extent for 2021 computed from satellite-derived sea ice concentration using a 15% concentration threshold.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Working with data that crosses the antimeridian\n      Work with satellite datasets that span the antimeridian by correcting longitude discontinuities for analysis and visualization. This tutorial demonstrates how to retrieve gridded satellite data defined on a −180° to +180° longitude system, subset regions that cross the antimeridian, convert longitude coordinates to a 0–360° system, and reorder the longitude axis to create a continuous spatial domain. The corrected data are then visualized on a map and saved for downstream analysis. Chlorophyll-a data from the NOAA gap-filled blended VIIRS ocean color dataset are used to illustrate antimeridian handling in the Bering Sea region.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Subset of satellite chlorophyll-a data crossing the antimeridian plotted using a −180° to +180° longitude convention. The map shows a visible discontinuity where data from opposite sides of the antimeridian are split and displayed at opposite edges of the domain.\n          \n          \n          \n            \n              \n            \n            The same satellite chlorophyll-a data after converting longitudes to a 0–360° convention and reordering the longitude axis. The antimeridian discontinuity is removed, resulting in a continuous spatial representation suitable for mapping and analysis.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Define a marine habitat\n      Define a marine habitat using satellite sea surface temperature to identify regions associated with species–environment interactions. This tutorial demonstrates how to retrieve satellite SST from ERDDAP, subset data for a region and time of interest, and apply temperature-based thresholds to delineate a habitat band. The resulting temperature contours are visualized on a map to highlight areas associated with increased likelihood of interaction. Sea surface temperature data from the NOAA Coral Reef Watch CoralTemp product are used to illustrate habitat definition in the central North Pacific as part of the TurtleWatch framework.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature map with the TurtleWatch habitat band highlighted. The red band marks SST values between 17.5 °C and 18.5 °C, identifying regions associated with increased loggerhead sea turtle interactions based on the TurtleWatch framework.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature map with the TurtleWatch habitat band highlighted. The red band marks SST values between 17.5 °C and 18.5 °C, identifying regions associated with increased loggerhead sea turtle interactions based on the TurtleWatch framework.\n          \n          \n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Extract data within a boundary\n      Extract and analyze satellite data within an irregular geographic boundary to better represent real-world marine regions. This tutorial demonstrates how to download sea surface temperature data from ERDDAP, subset it using a bounding box, and apply a polygon mask to retain values only within a defined boundary. The masked data are then used to compute and visualize a seasonal temperature cycle for the region of interest. Sea surface temperature data from the NOAA Geo-Polar Blended SST product are combined with Longhurst Marine Province boundaries to illustrate region-based satellite analysis.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature masked to the Gulf Stream Longhurst Province (GFST).\n          \n          \n          \n            \n              \n            \n            Monthly mean sea surface temperature within the Gulf Stream Province for 2020.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature masked to the Gulf Stream Longhurst Province (GFST).\n          \n          \n          \n            \n              \n            \n            Monthly mean sea surface temperature within the Gulf Stream Province for 2020.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Monthly sea surface temperature within the Papahānaumokuākea Marine National Monument (PMNM) for April 2015.\n          \n          \n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      How to work with satellite data in Matlab in the Great Lakes\n      Access and analyze satellite sea surface temperature data in MATLAB using ERDDAP and NetCDF workflows. This tutorial demonstrates how to construct ERDDAP download URLs, read NetCDF variables directly into MATLAB, convert time coordinates, and subset data spatially and temporally. The workflow includes creating daily SST maps, generating regional mean time series, and computing average SST over a selected period. Satellite sea surface temperature data from NOAA CoastWatch are used to illustrate spatial and temporal analysis across the Great Lakes region.\n\n      \n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Daily satellite sea surface temperature (SST) across the Great Lakes on 21 July 2021, extracted from ERDDAP and visualized in a Mercator projection.\n          \n          \n          \n            \n              \n            \n            Time series of mean SST within a Lake Superior subregion showing daily temperature variability from 21–28 July 2021.\n          \n          \n          \n            \n              \n            \n            Mean satellite SST across the Great Lakes averaged over 21–28 July 2021, illustrating spatial temperature patterns derived from ERDDAP data.\n          \n            ◀  1 / 3  ▶\n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      Working with Great Lakes Surface Temperature Data\n      Access and analyze Great Lakes surface temperature using satellite observations in Python. This tutorial demonstrates how to download water surface temperature data from an ERDDAP server, open and inspect NetCDF files using xarray, and convert time variables into usable date formats. The extracted data are used to generate spatial maps of surface temperature, compute regional averages within user-defined bounding boxes, and visualize temporal variability through daily time series and monthly mean maps. Water surface temperature data from the Great Lakes Surface Environmental Analysis (GLSEA) ACSPO dataset are used to illustrate satellite-based analysis of Lake Erie.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Spatial subset of Lake Erie water surface temperature on June 1, 2023, extracted from ERDDAP and visualized for a focused region of interest.\n          \n          \n          \n            \n              \n            \n            Daily mean water surface temperature time series for a selected Lake Erie subregion during June 2023, illustrating short-term temporal variability.\n          \n          \n          \n            \n              \n            \n            Monthly mean water surface temperature across Lake Erie for June 2023, computed from daily satellite observations downloaded via ERDDAP.\n          \n            ◀  1 / 3  ▶\n          View Python tutorial\n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Analyze Great Lakes Ice Concentration \n      Extract and summarize satellite-derived ice concentration to characterize seasonal ice conditions in the Great Lakes. This tutorial demonstrates how to download ice concentration data from ERDDAP, subset the data spatially and temporally for a region of interest, and handle missing values in NetCDF files. The extracted data are used to generate maps of ice concentration for specific dates and to compute regional daily mean ice concentration time series. Ice concentration data from the NOAA Great Lakes Surface Environmental Analysis (GLSEA) product are used to illustrate regional ice variability in western Lake Erie.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Spatial distribution of ice concentration (%) in western Lake Erie on March 1, 2019, derived from the Great Lakes Ice Concentration product and visualized after subsetting the ERDDAP dataset to the region of interest.\n          \n          \n          \n            \n              \n            \n            Time series of daily mean ice concentration (%) for western Lake Erie during March 2019, calculated by averaging satellite-derived ice concentration over the selected spatial domain.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Multi-Sensor chlorophyll time series analysis for Lake Erie\n      Analyze long-term changes in lake chlorophyll concentrations by combining satellite observations from multiple sensors. This tutorial demonstrates how to download chlorophyll-a data from ERDDAP for Lake Erie, process daily observations from MODIS (2002–2017) and VIIRS (2018–2023), and compute spatially averaged monthly and daily time series. The workflow shows how to handle fill values, aggregate data across space and time, and visualize chlorophyll variability across the sensor transition. By merging MODIS and VIIRS records, the tutorial provides a practical approach for creating a continuous multi-sensor time series to support long-term water quality analysis in the Great Lakes.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly mean chlorophyll-a concentration across Lake Erie for August 2009, illustrating the spatial distribution of phytoplankton biomass derived from satellite observations.\n          \n          \n          \n            \n              \n            \n            Spatially averaged monthly chlorophyll-a time series for Lake Erie from 2002–2017, showing seasonal variability and interannual changes captured by the MODIS sensor.\n          \n          \n          \n            \n              \n            \n            Daily spatially averaged chlorophyll-a concentrations for Lake Erie in 2023, highlighting short-term variability and bloom dynamics observed by the VIIRS sensor.\n          \n            ◀  1 / 3  ▶\n          View Python tutorial\n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Long-term lake surface temperature variability from Great Lakes Satellite Records\n      Analyze long-term patterns in Great Lakes water surface temperature using lakewide satellite-derived averages. This tutorial demonstrates how to retrieve daily average surface temperature data from ERDDAP, assemble a multi-year record spanning 2007 to the present, and visualize seasonal temperature variability across years. Daily temperature records are aligned by day of year to highlight the warmest, coldest, and average conditions for a given date, with the current year shown in context of the historical record. Using Great Lakes Surface Environmental Analysis (GLSEA) satellite products, the workflow illustrates how long-term lake temperature climatologies can be used to assess seasonal extremes and interannual variability across the Great Lakes.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Seasonal evolution of Lake Michigan average surface water temperature from 2007–2024, showing the current year in context of the long-term mean and highlighting the historically warmest and coldest years for the selected calendar day based on GLSEA satellite records.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Visualizing JPSS Sea Ice Concentration products using Google Colab\n      Visualize polar sea ice conditions by converting JPSS Sea Ice Concentration files into mapped images for quick inspection and reporting. This tutorial demonstrates how to obtain either Level-2 swath VIIRS ice concentration data or Level-3 daily gridded blended sea ice concentration products, load them into an analysis environment, and generate publication-ready maps for the Arctic or Antarctic. The workflow resamples swath observations onto a common polar grid when needed, applies consistent color scaling in percent ice concentration, and exports the final figures as PNGs.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Blended JPSS sea ice concentration for the Arctic on October 5, 2024, showing the spatial extent and intensity of ice cover derived from combined satellite observations and mapped onto a polar projection with ice concentration expressed as percent.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Long Island Sound Chlorophyll-a Dynamics\n      Analyze seasonal and spatial patterns in coastal chlorophyll-a by working with daily satellite observations from Long Island Sound. This tutorial demonstrates how to download chlorophyll-a data from ERDDAP, generate temporal composites at monthly and 8-day intervals, and subset the data to compare regional variability within the Sound. The workflow illustrates how to examine gridded satellite datasets, compute spatial averages, and visualize chlorophyll dynamics through maps and time-series plots. Chlorophyll-a data from Sentinel-3 OLCI, processed with Long Island Sound–optimized algorithms, are used to highlight differences between western and eastern regions and to explore seasonal water-quality variability in a complex coastal environment.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly mean chlorophyll-a concentrations in Long Island Sound during 2022, illustrating the seasonal evolution of phytoplankton biomass derived from daily Sentinel-3 OLCI observations.\n          \n          \n          \n            \n              \n            \n            Spatial distribution of mean chlorophyll-a concentration in Long Island Sound averaged over January–December 2022, highlighting persistent regional gradients across the estuary.\n          \n          \n          \n            \n              \n            \n            Eight-day averaged chlorophyll-a time series comparing western and eastern Long Island Sound, showing contrasting seasonal cycles and peak bloom timing during 2022.\n          \n            ◀  1 / 3  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly mean chlorophyll-a concentrations in Long Island Sound during 2022, illustrating the seasonal evolution of phytoplankton biomass derived from daily Sentinel-3 OLCI observations.\n          \n          \n          \n            \n              \n            \n            Spatial distribution of mean chlorophyll-a concentration in Long Island Sound averaged over January–December 2022, highlighting persistent regional gradients across the estuary.\n          \n          \n          \n            \n              \n            \n            Eight-day averaged chlorophyll-a time series comparing western and eastern Long Island Sound, showing contrasting seasonal cycles and peak bloom timing during 2022.\n          \n            ◀  1 / 3  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n\n\n\n\n\n\n✕",
    "crumbs": [
      "Training Tutorials",
      "Code Gallery"
    ]
  },
  {
    "objectID": "tutorials/matlab/Tutorial1-basics.html",
    "href": "tutorials/matlab/Tutorial1-basics.html",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands. Note: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset monthly SST data: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.html Select your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nerddap interface\n\n\nIn this specific example, the URL we generated is: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.nc?sea_surface_temperature%5B(2018-1-31T12:00:00Z):1:(2018-12-31T12:00:00Z)%5D%5B(17):1:(30)%5D%5B(195):1:(210)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly'); \nNotice that the full data set has four variables: time, latitude, longitude, and sea_surface_temperature. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\nTime Notice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'time');\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the year we’re interested in: 2018.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2018);\nLatitude and Longitude Before we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'longitude');\nNotice in the output above that sea_surface_temperature has the dimensions of longitude x latitude x time which means it has a size of 7200 x 3600 x 444. In the code below, we’ll create indices for our particular area of interest in the central North Pacific.\n% Find longitudes from 195 - 210 E\nlon_aoi = find(lon_full &gt;= 195 & lon_full &lt;= 210);\n\n% Find latitudes from 17 - 30 N\nlat_aoi = find(lat_full &gt;= 17 & lat_full &lt;= 30);\nSea Surface Temperature Now, we’ll access just the small amount of sea_surface_temperature data we’re interested in. We’ll do this by telling the computer to access the variable ‘sea_surface_temperature’, beginning at a specific location and time, and spanning our area and time of interest.\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', ...\n    'sea_surface_temperature', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 300 x 260 x 12. Before we see what these data look like, let’s create indices for the area and timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* % Delete every variable with 'aoi' or with 'full' in its name\n\n\n\nLet’s create a map for a single month, January 2018, the first month in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 100, 'fill', 'on');\ntitle(sprintf('Monthly SST %s', datestr(time_ymdhms(1,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(26,4), 202:1:205, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 20\ncontourm(lat, lon, sst(:,:,1)', [20 20], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\nJanuary SST\n\n\n\n\n\nLet’s pick the following box: 24-26N, 200-206E. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above to identify a subsetted area of interest.\n% Find longitudes from 200 - 206 E\nlon_aoi = find(lon &gt;= 200 & lon &lt;= 206);\n\n% Find latitudes from 24 - 26 N\nlat_aoi = find(lat &gt;= 24 & lat &lt;= 26);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 12 months\nsst_ts(1:12,1) = NaN;\nfor m = 1:1:12 \n    sst_ts(m,1) = mean(sst_subset(:,:,m), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,2), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\n\n\n\nSST time series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n\n% Average over time, which is the third dimention of our data\nsst_yr = mean(sst, 3, \"omitnan\");\n\n% Plot\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_yr', 100, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(12,:),'mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nJan mean sst"
  },
  {
    "objectID": "tutorials/matlab/Tutorial1-basics.html#tutorial-1.-how-to-work-with-satellite-data-in-matlab",
    "href": "tutorials/matlab/Tutorial1-basics.html#tutorial-1.-how-to-work-with-satellite-data-in-matlab",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands. Note: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset monthly SST data: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.html Select your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nerddap interface\n\n\nIn this specific example, the URL we generated is: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.nc?sea_surface_temperature%5B(2018-1-31T12:00:00Z):1:(2018-12-31T12:00:00Z)%5D%5B(17):1:(30)%5D%5B(195):1:(210)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly'); \nNotice that the full data set has four variables: time, latitude, longitude, and sea_surface_temperature. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\nTime Notice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'time');\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the year we’re interested in: 2018.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2018);\nLatitude and Longitude Before we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'longitude');\nNotice in the output above that sea_surface_temperature has the dimensions of longitude x latitude x time which means it has a size of 7200 x 3600 x 444. In the code below, we’ll create indices for our particular area of interest in the central North Pacific.\n% Find longitudes from 195 - 210 E\nlon_aoi = find(lon_full &gt;= 195 & lon_full &lt;= 210);\n\n% Find latitudes from 17 - 30 N\nlat_aoi = find(lat_full &gt;= 17 & lat_full &lt;= 30);\nSea Surface Temperature Now, we’ll access just the small amount of sea_surface_temperature data we’re interested in. We’ll do this by telling the computer to access the variable ‘sea_surface_temperature’, beginning at a specific location and time, and spanning our area and time of interest.\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', ...\n    'sea_surface_temperature', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 300 x 260 x 12. Before we see what these data look like, let’s create indices for the area and timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* % Delete every variable with 'aoi' or with 'full' in its name\n\n\n\nLet’s create a map for a single month, January 2018, the first month in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 100, 'fill', 'on');\ntitle(sprintf('Monthly SST %s', datestr(time_ymdhms(1,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(26,4), 202:1:205, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 20\ncontourm(lat, lon, sst(:,:,1)', [20 20], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\nJanuary SST\n\n\n\n\n\nLet’s pick the following box: 24-26N, 200-206E. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above to identify a subsetted area of interest.\n% Find longitudes from 200 - 206 E\nlon_aoi = find(lon &gt;= 200 & lon &lt;= 206);\n\n% Find latitudes from 24 - 26 N\nlat_aoi = find(lat &gt;= 24 & lat &lt;= 26);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 12 months\nsst_ts(1:12,1) = NaN;\nfor m = 1:1:12 \n    sst_ts(m,1) = mean(sst_subset(:,:,m), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,2), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\n\n\n\nSST time series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n\n% Average over time, which is the third dimention of our data\nsst_yr = mean(sst, 3, \"omitnan\");\n\n% Plot\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_yr', 100, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(12,:),'mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nJan mean sst"
  },
  {
    "objectID": "tutorials/matlab/extract-satellite-data-within-boundary.html",
    "href": "tutorials/matlab/extract-satellite-data-within-boundary.html",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "This tutorial uses the Xtractomatic package to download data from within the boundaries of the Papahanaumokuakea Marine National Monument (PMNM).\nThis tutorial will teach you how to extract and display SST values for a particular time period or average SST over the whole time-series available within a shapefile.\nThe shapefile for the PMNM boundaries can be downloaded here: http://sanctuaries.noaa.gov/library/imast_gis.html. Save the file https://sanctuaries.noaa.gov/library/imast/pmnm_py.zip on your computer and extract it. It would be easiest for the purposes of this tutorial if you place the pmnm_py folder in the directory you’re working in. But, if you want to keep it elsewhere, you’ll just need to edit the path name accordingly.\n\n\nWe’ll do this in two steps. First, we’ll download the satellite data for a footprint that’s slightly larger than our area of interest. Then, we’ll clip these data to only those which fall within the Monument.\n\n\n% As always, it's helpful it take a look at what we're working with: \nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN');\n```matlab\n\n\nWe can see in the information above that longitude is in the 0 - 360 degree format.  And we know from reading the ReadMe file for the monument boundaries that the shapefile longitude is in the -180 - 180 degree format.  This means we need convert the shapefile longitudes to a 0 - 360 format for indexing puposes (the native format will plot just fine). \n\n```matlab\n% Access the Lat and Lon coordinates\nPMNM = shaperead('pmnm_py/PMNM_py_files/PMNM_py.shp','UseGeoCoords',true);\n\n% Convert negative longitudes to positive values\nneg_lon = find(PMNM.Lon &lt; 0);\nPMNM.Lon(neg_lon) = PMNM.Lon(neg_lon) + 360;\nclear neg_lon\n\n% Find the minimum and maximum lat and lon values, for using to download\n% SST data\n[Lon_min, Lon_max] = bounds(PMNM.Lon);\n[Lat_min, Lat_max] = bounds(PMNM.Lat);\n\n% Now we can follow the steps we used in the earlier tutorials to download\n% the SST data\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n   'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \n\n% In this particular example, we're interested in March - November 2015\ntime_aoi = find(time_full_ymdhms(:,1) == 2015 & time_full_ymdhms(:,2) &gt;= 3 & ...\n    time_full_ymdhms(:,2) &lt;= 11);\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'longitude');\n\n% Find longitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlon_aoi = find(lon_full &gt;= floor(Lon_min) & lon_full &lt;= ceil(Lon_max));\n% Find latitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlat_aoi = find(lat_full &gt;= floor(Lat_min) & lat_full &lt;= ceil(Lat_max));\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\n\n% Download the data of interest\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'analysed_sst', aoi_start, aoi_span);\n\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* *min *max\n\n\n\nNow we have everything we need to clip the SST data to just those within the boundaries of the Monument. The code below borrows from the no-longer-supported xtractoMatlab: https://github.com/rmendels/xtractoMatlab. You can learn about other avenues to use this tool at: https://coastwatch.pfeg.noaa.gov/xtracto/.\n% The general premise here is that we're going to create a mesh grid of our\n% full domain (what we downloaded), identify all the points that are within\n% or on the polygon that defines the Monument, and set to NaN those that\n% are not.\n% Make the meshgrid and the mask\n[XLON, XLAT] = meshgrid(lon, lat);\n[IN ON] = inpolygon(XLON, XLAT, PMNM.Lon, PMNM.Lat);\nmask2D = IN | ON;\n\n% Replicate it over the number of time steps, which is the third dimension\n% of our sst variable\nmask3D = permute(repmat(mask2D,[1 1 size(sst,3)]),[2 1 3]);\n\n% Set to NaN all points not within the polygon\nsst(~mask3D) = NaN;\n\n\n\n\nThe extracted data contains several time steps (months) of sst data in the monument boundaries. Let’s make a plot of the second time step. Also, we can see above where we used ‘ncdisp’, that the units for these data are Kelvin. Let’s changes this to degrees Celsius when we make our map.\nfigure\naxesm('mercator', 'MapLatLimit', [18 32], 'MapLonLimit', [177 207], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -180:5:-155, 'PLabelLocation', 20:5:30, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Plot SST for the second time step, in degrees C, with 50 contour levels\ncontourm(lat, lon, sst(:,:,2)'-273.15, 50, 'fill', 'on'); \n\n% Title the map\ntitle(sprintf('SST %s', datestr(time_ymdhms(2,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 50 levels\ncolormap(jet(50));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\nOn your own! Plot the average SST for the period we downloaded. Here’s a hint to get you started:\nsst_avg = mean(sst, 3, \"omitnan\");\n\n\n\nSST"
  },
  {
    "objectID": "tutorials/matlab/extract-satellite-data-within-boundary.html#extract-data-within-a-shapefile-using-erddap",
    "href": "tutorials/matlab/extract-satellite-data-within-boundary.html#extract-data-within-a-shapefile-using-erddap",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "This tutorial uses the Xtractomatic package to download data from within the boundaries of the Papahanaumokuakea Marine National Monument (PMNM).\nThis tutorial will teach you how to extract and display SST values for a particular time period or average SST over the whole time-series available within a shapefile.\nThe shapefile for the PMNM boundaries can be downloaded here: http://sanctuaries.noaa.gov/library/imast_gis.html. Save the file https://sanctuaries.noaa.gov/library/imast/pmnm_py.zip on your computer and extract it. It would be easiest for the purposes of this tutorial if you place the pmnm_py folder in the directory you’re working in. But, if you want to keep it elsewhere, you’ll just need to edit the path name accordingly.\n\n\nWe’ll do this in two steps. First, we’ll download the satellite data for a footprint that’s slightly larger than our area of interest. Then, we’ll clip these data to only those which fall within the Monument.\n\n\n% As always, it's helpful it take a look at what we're working with: \nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN');\n```matlab\n\n\nWe can see in the information above that longitude is in the 0 - 360 degree format.  And we know from reading the ReadMe file for the monument boundaries that the shapefile longitude is in the -180 - 180 degree format.  This means we need convert the shapefile longitudes to a 0 - 360 format for indexing puposes (the native format will plot just fine). \n\n```matlab\n% Access the Lat and Lon coordinates\nPMNM = shaperead('pmnm_py/PMNM_py_files/PMNM_py.shp','UseGeoCoords',true);\n\n% Convert negative longitudes to positive values\nneg_lon = find(PMNM.Lon &lt; 0);\nPMNM.Lon(neg_lon) = PMNM.Lon(neg_lon) + 360;\nclear neg_lon\n\n% Find the minimum and maximum lat and lon values, for using to download\n% SST data\n[Lon_min, Lon_max] = bounds(PMNM.Lon);\n[Lat_min, Lat_max] = bounds(PMNM.Lat);\n\n% Now we can follow the steps we used in the earlier tutorials to download\n% the SST data\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n   'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \n\n% In this particular example, we're interested in March - November 2015\ntime_aoi = find(time_full_ymdhms(:,1) == 2015 & time_full_ymdhms(:,2) &gt;= 3 & ...\n    time_full_ymdhms(:,2) &lt;= 11);\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'longitude');\n\n% Find longitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlon_aoi = find(lon_full &gt;= floor(Lon_min) & lon_full &lt;= ceil(Lon_max));\n% Find latitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlat_aoi = find(lat_full &gt;= floor(Lat_min) & lat_full &lt;= ceil(Lat_max));\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\n\n% Download the data of interest\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'analysed_sst', aoi_start, aoi_span);\n\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* *min *max\n\n\n\nNow we have everything we need to clip the SST data to just those within the boundaries of the Monument. The code below borrows from the no-longer-supported xtractoMatlab: https://github.com/rmendels/xtractoMatlab. You can learn about other avenues to use this tool at: https://coastwatch.pfeg.noaa.gov/xtracto/.\n% The general premise here is that we're going to create a mesh grid of our\n% full domain (what we downloaded), identify all the points that are within\n% or on the polygon that defines the Monument, and set to NaN those that\n% are not.\n% Make the meshgrid and the mask\n[XLON, XLAT] = meshgrid(lon, lat);\n[IN ON] = inpolygon(XLON, XLAT, PMNM.Lon, PMNM.Lat);\nmask2D = IN | ON;\n\n% Replicate it over the number of time steps, which is the third dimension\n% of our sst variable\nmask3D = permute(repmat(mask2D,[1 1 size(sst,3)]),[2 1 3]);\n\n% Set to NaN all points not within the polygon\nsst(~mask3D) = NaN;\n\n\n\n\nThe extracted data contains several time steps (months) of sst data in the monument boundaries. Let’s make a plot of the second time step. Also, we can see above where we used ‘ncdisp’, that the units for these data are Kelvin. Let’s changes this to degrees Celsius when we make our map.\nfigure\naxesm('mercator', 'MapLatLimit', [18 32], 'MapLonLimit', [177 207], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -180:5:-155, 'PLabelLocation', 20:5:30, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Plot SST for the second time step, in degrees C, with 50 contour levels\ncontourm(lat, lon, sst(:,:,2)'-273.15, 50, 'fill', 'on'); \n\n% Title the map\ntitle(sprintf('SST %s', datestr(time_ymdhms(2,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 50 levels\ncolormap(jet(50));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\nOn your own! Plot the average SST for the period we downloaded. Here’s a hint to get you started:\nsst_avg = mean(sst, 3, \"omitnan\");\n\n\n\nSST"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html",
    "href": "tutorials/r/Tutorial1-basics.html",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "A tidyverse/ggplot version is also available here: https://github.com/jebyrnes/noaa_coastwatch_tutorial_1/blob/main/tutorial1-1.md\ncourtesy of Jarrett Byrnes from UMass Boston - http://byrneslab.net (Thank you Jarrett!!)"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#objective",
    "href": "tutorials/r/Tutorial1-basics.html#objective",
    "title": "CoastWatch Training Materials",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab data hosted on an ERDDAP server from R, how to work with NetCDF files in R and how to make some maps and time-series of sea surface temperature."
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "CoastWatch Training Materials",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nLocating a satellite product in ERDDAP, manually changing the constraints and copying the URL defining the data request\nDownloading the resulting NetCDF file\nOpening and examining the NetCDF file\nMaking basic maps and time series plots"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#datasets-used",
    "href": "tutorials/r/Tutorial1-basics.html#datasets-used",
    "title": "CoastWatch Training Materials",
    "section": "Datasets used",
    "text": "Datasets used\nCoralTemp Sea Surface Temperature product from the NOAA Coral Reef Watch program. The NOAA Coral Reef Watch (CRW) daily global 5km Sea Surface Temperature (SST) product, also known as CoralTemp, shows the nighttime ocean temperature measured at the surface. The SST scale ranges from -2 to 35 °C. The CoralTemp SST data product was developed from two, related reanalysis (reprocessed) SST products and a near real-time SST product. Spanning January 1, 1985 to the present, the CoralTemp SST is one of the best and most internally consistent daily global 5km SST products available. More information about the product: https://coralreefwatch.noaa.gov/product/5km/index_5km_sst.php\nWe will use the monthly composite of this product and download it from the NOAA CoastWatch ERDDAP server: https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.graph\n# Package names\npackages &lt;- c( \"ncdf4\",\"httr\")\n\n# Install packages not yet installed\ninstalled_packages &lt;- packages %in% rownames(installed.packages())\n\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages])\n}\n\n# Load packages \ninvisible(lapply(packages, library, character.only = TRUE))"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#downloading-data-from-r",
    "href": "tutorials/r/Tutorial1-basics.html#downloading-data-from-r",
    "title": "CoastWatch Training Materials",
    "section": "1. Downloading data from R",
    "text": "1. Downloading data from R\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from R using the URL structure.\nFor example, the following page allows you to subset monthly sea surface temperature (SST) https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n NOTE: Notice that the latitudes are indexed from North to South (negative spacing)\nIn this specific example, the URL we generated is : https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D\nYou can also edit this URL manually.\nIn R, run the following to download the data using the generated URL (you need to copy it from your browser):\njunk &lt;- GET('https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D', write_disk(\"sst.nc\", overwrite=TRUE))"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#importing-the-downloaded-file-in-r",
    "href": "tutorials/r/Tutorial1-basics.html#importing-the-downloaded-file-in-r",
    "title": "CoastWatch Training Materials",
    "section": "2. Importing the downloaded file in R",
    "text": "2. Importing the downloaded file in R\nNow that we’ve downloaded the data locally, we can import it and extract our variables of interest:\n\nopen the file\n\n\nnc &lt;- nc_open('sst.nc')\n\nexamine which variables are included in the dataset:\n\n\nnames(nc$var)\n\n## [1] \"sea_surface_temperature\"\n\nExtract sea_surface_temperature:\n\n\nv1 &lt;- nc$var[[1]]\nsst &lt;- ncvar_get(nc,v1)\n\nexamine the structure of sst:\n\n\ndim(sst)\n\n## [1] 201 202  12\nOur dataset is a 3-D array with 201 rows corresponding to longitudes, 202 columns corresponding to latitudes for each of the 12 time steps.\n\nget the dates for each time step:\n\n\ndates &lt;- as.POSIXlt(v1$dim[[3]]$vals,origin='1970-01-01',tz='GMT')\ndates\n\n##  [1] \"2022-01-16 GMT\" \"2022-02-16 GMT\" \"2022-03-16 GMT\" \"2022-04-16 GMT\"\n##  [5] \"2022-05-16 GMT\" \"2022-06-16 GMT\" \"2022-07-16 GMT\" \"2022-08-16 GMT\"\n##  [9] \"2022-09-16 GMT\" \"2022-10-16 GMT\" \"2022-11-16 GMT\" \"2022-12-16 GMT\"\n\nget the longitude and latitude values\n\n\nlon &lt;- v1$dim[[1]]$vals\nlat &lt;- v1$dim[[2]]$vals\n\nClose the netcdf file and remove the data and files that are not needed anymore.\n\n\nnc_close(nc)\nrm(junk,v1)\nfile.remove('sst.nc')\n\n## [1] TRUE"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#working-with-the-extracted-data",
    "href": "tutorials/r/Tutorial1-basics.html#working-with-the-extracted-data",
    "title": "CoastWatch Training Materials",
    "section": "3. Working with the extracted data",
    "text": "3. Working with the extracted data\n\nCreating a map for one time step\nLet’s create a map of SST for January 2022 (our first time step).\nYou will need to download the scale.R file and copy it to your working directory to plot the color scale properly.\n\nset some color breaks\n\n\nh &lt;- hist(sst[,,1], 100, plot=FALSE)\nbreaks &lt;- h$breaks\nn &lt;- length(breaks)-1\n\ndefine a color palette\n\n\njet.colors &lt;- colorRampPalette(c(\"blue\", \"#007FFF\", \"cyan\",\"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"))\n\nset color scale using the jet.colors palette\n\n\nc &lt;- jet.colors(n)\n\nprepare graphic window : left side for map, right side for color scale\n\n\nlayout(matrix(c(1,2), nrow=1, ncol=2), widths=c(7,2), heights=4)\npar(mar=c(3,3,3,1))\n\n#plot the SST map. Because this product was built with latitudes going from North to South, we need to reverse the lat vector because the 'image' function needs increasing values for the coordinates. We also need to flip the sst matrix along the 2d dimension so it plots correctly\nimage(lon,rev(lat),sst[,dim(sst)[2]:1,1],col=c,breaks=breaks,xlab='',ylab='',axes=TRUE,xaxs='i',yaxs='i',asp=1, main=paste(\"Monthly SST\", dates[1]))\n\n#example of how to add points to the map\npoints(-74:-71,rep(34,4), pch=20, cex=2)\n\n#example of how to add a contour (this is considered a new plot, not a feature, so you need to use par(new=TRUE)) to overlay it on top of the SST map\npar(new=TRUE)\ncontour(lon,rev(lat),sst[,dim(sst)[2]:1,1],levels=14,xaxs='i',yaxs='i',labcex=0.8,vfont = c(\"sans serif\", \"bold\"),axes=FALSE,asp=1)\n\n#plot color scale using 'image.scale' function from 'scale.R' script)\npar(mar=c(3,1,3,3))\nsource('scale.R')\nimage.scale(sst[,,1], col=c, breaks=breaks, horiz=FALSE, yaxt=\"n\",xlab='',ylab='',main='SST')\naxis(4, las=1)\nbox()\n\n\n\nPlotting a time series\nLet’s pick the following box : 36-38N, -77 to -75W.. We are going to generate a time series of mean SST within that box.\nI=which(lon&gt;=-77 & lon&lt;=-75)\nJ=which(lat&gt;=36 & lat&lt;=38)\nsst2=sst[I,J,]\nn=dim(sst2)[3]\nres=rep(NA,n)\nfor (i in 1:n)\nres[i]=mean(sst2[,,i],na.rm=TRUE)\nplot(1:n,res,axes=FALSE,type='o',pch=20,xlab='',ylab='SST (ºC)')\naxis(2)\naxis(1,1:n,format(dates,'%m'))\nbox()\n\n\n\nCreating a map of average SST over a year\nsst.yr=apply(sst[,,1:12],c(1,2),mean,na.rm=TRUE)\nh=hist(sst.yr, 100, plot=FALSE)\nbreaks=h$breaks\nn=length(breaks)-1\nc=jet.colors(n)\nlayout(matrix(c(1,2), nrow=1, ncol=2), widths=c(7,2), heights=4)\npar(mar=c(3,3,3,1))\nimage(lon,rev(lat),sst.yr[,dim(sst.yr)[2]:1],col=c,breaks=breaks,xlab='',ylab='',axes=TRUE,xaxs='i',yaxs='i',asp=1,main=paste(\"Mean SST\", format(dates[1],'%Y/%m/%d'),' - ',format(dates[12],'%Y/%m/%d')))\npar(mar=c(3,1,3,3))\nimage.scale(sst.yr, col=c, breaks=breaks, horiz=FALSE, yaxt=\"n\",xlab='',ylab='',main='SST')\naxis(4)\nbox()"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html",
    "href": "tutorials/r/calculate-seaice-extent.html",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "notebook filename | sea_ice_extent.Rmd\n\n\n\nSea ice cover measurements are key to polar ecological and climatological research. This measurement has gained attention because of the recent decrease in the Arctic sea ice cover. Satellite observations are essential for tracking sea ice cover, providing continuous global coverage extending back to 1978. Typically, sea ice cover is reported as sea ice concentration, which is the percent areal coverage of ice within a grid cell. Depending on the application, additional parameters of interest can be calculated from sea ice cover:\n\nSea ice area - the cumulative coverage of all gridded sections (area), including each grid that contains a minimum ice concentration of 15%.\n\nSea ice extent - the cumulative coverage of all griddedthe sum of the areas of all grid cells with at least 15% ice concentration\n\n\n\n\nThis tutorial will demonstrate how to calculate the sea ice area and extent using sea ice concentration and grid cell area data. Please visit the NSIDC website for more detailed descriptions of the calculations.\n\n\n\n\nDownloading and saving a netcdf file from the PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nDownloading and adding grid cell area data to the satellite data\nVisualizing data on a map\nComputing sea ice area and extent using sea ice concentration data\nPlotting a time series of sea ice area and extent\n\n\n\n\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere.\nThe Sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. Near-Real-Time data are also available at PolarWatch. (SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Northern Polar Stereographic projection (EPSG:3413). The resolution is 25km, meaning each grid cell in this data set represents a value that covers a 25km by 25km area. The dataset is available on the PolarWatch data portal and can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.graph\nPolar Stereographic Grid Cell Area Values of 25km grid, Polar Stereographic (North), NSIDC Ancillary Data.\nThis dataset includes the area (in m2) of each grid cell in the 25km resolution Northern Polar Stereographic projection. This dataset is available on the PolarWatch ERDDAP\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ggplot2\" ,\"ncdf4\",  \"RColorBrewer\", \"scales\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# Set up download method as libcurl, this is only needed for Windows machines\noptions(download.file.method=\"libcurl\", url.method=\"libcurl\")\n\n\n\nHere we download the average monthly sea ice concentration for the Arctic for 2021 (January to December). We are using the NSIDC Sea Ice Concentration Climate Data Record (NSIDC ID: G002202).\nThe ERDDAP data request URL for this data subset is presented below.\nhttps://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nThe following table shows the component parts of the ERDDAP data request URL.\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID of the dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nNetCDF (there are many other available file formats)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariables from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]\nTemporal\n\n\nspatial_range\n[(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nSpatial coverage\n\n\n\n` Note The metadata states that the _FillValue for this dataset is set to -999, however when the _FillValue attribute is found, the ncdf4 package maps all the missing values (_FillValue) to NA’s.\n# Set data request URL for PolarWatch ERDDAP data server\ndata_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\"\n\n\n# Send data request and download file to the file name\nf &lt;- 'sic.nc'\ndownload.file(data_url, destfile=f, mode=\"wb\")\n# Open netcdf file\nnc=nc_open('sic.nc')\n\n# Examine file metadata\n#print(nc)\n\n# Examine names of variables\nnames(nc$var)\n\n# Get first variable metadata\nvar1 &lt;- nc$var[[1]]\n\n# Examine variable metadata\n#print(var1)\n\n# Get variable values\nsic &lt;- ncvar_get(nc,var1$name)\n\n# Examine dimension of variables\ndim(sic)\n\n# Based on metadata, set xgrid, ygrid\nxgrid &lt;- var1$dim[[1]]$vals\nygrid &lt;- var1$dim[[2]]$vals\n\n# convert time variable to date format\ndates &lt;- as.POSIXlt(var1$dim[[3]]$vals,origin='1970-01-01',tz='GMT')\n# Close and remove the netCDF file and clear memories\nnc_close(nc)\nfile.remove('sic.nc')\n## [1] TRUE\n\n\n\nTo plot sea ice concentration data that are in xgrid and ygrid dimensions, we will create a data frame with coordinates (xgrid, ygrid) and associated sea ice concentration values.\n# Create a data frame with all combinations of xgrid and ygrid\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\n\n# Add sic data array to the data frame\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude the _FillValue listed in the metadata (2.53999) which corresponds to various pixels with no data (land, coast, missing data, etc...)\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# Map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous() + \n       scale_x_continuous() +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\") +\n      ggtitle(\"Sea Ice Concentration on Polar Steregraphic projection\")\n\n\n\n\nWhile the resolution of this data set is 25km, the actual area of each grid cell depends on the grid projection. We will download the grid cell area values from the PolarWatch ERDDAP.\ncell_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k.nc?cell_area%5B(5837500.0):1:(-5337500.0)%5D%5B(-3837500.0):1:(3737500.0)%5D\"\nf &lt;- 'gridcell.nc'\ndownload.file(cell_url, destfile=f, mode=\"wb\")\n\n\n\nJust like for the sea ice concentration dataset, we will examine the metadata and extract the variables of grid cell areas along with x and y grids.\n# Open netcdf file\nnc1=nc_open('gridcell.nc')\n\n# Examine names of variables\nnames(nc1$var)\n\n# Get first variable metadata\narea_var &lt;- nc1$var[[1]]\n\n# Examine area_var\nnames(area_var)\n\n# Get variable values\ncellarea =ncvar_get(nc1,area_var$name)\n\n# Examine dimension of variable values\ndim(cellarea)\n\n# Based on metadata, set xgrid, ygrid, time\nx_area &lt;- area_var$dim[[1]]$vals\ny_area &lt;- area_var$dim[[2]]$vals\n\n# Close and remove the netCDF file and clear memories\nnc_close(nc1)\nfile.remove('gridcell.nc')\n\n\n\nNow we have two data sets: sea ice concentration and grid cell areas for each grid of northern polar stereographic projection. While the spatial coverage of both data sets is identical, we will ensure the x and y coordinates of both data sets are correctly aligned.\n# Get indices in areas where x and y grids equal those of sic\nx_indices &lt;- match(xgrid, x_area)\ny_indices &lt;- match(ygrid, y_area)\n\n# Extract grid area\ngrid.match &lt;- cellarea[x_indices, y_indices]\n\n\n\nWe need to clean the data before computing the sea ice area and extent.\n\nThe dataset includes flag values indicating non-sea ice area such as land, lakes, etc.\n\ntask: remove flag values (2 and higher) by setting the flag values as Nan.\n\nFor this example of the sea ice area and extent calculations, a value of 0.15 of sea ice concentration value will be used as a threshold.\n\ntask: set sic value to 0 if the value is less than 0.15\n\n\nFor more detailed information about the flag values, go to the user guide. For the calculation of sea ice area and extent with a threshold, go to the NSIDC article.\n# Set sic values less than 0.15 to (applying 0.15 threshold)\nsic[sic &lt; 0.15] &lt;- 0\n\n# Set 0 for all flag values (&gt;2)\nsic[sic &gt; 1] &lt;- 0\n\n# Set NA to 0\nsic[is.na(sic)] &lt;- 0\n\n# Sic for extent calc\nsic_ext &lt;- sic\nsic_ext[sic_ext &gt;= 0.15] &lt;- 1\n\n\n# Perform element-wise multiplication for the first time step\narea_total &lt;- sic[,,1] * grid.match\next_total &lt;- sic_ext[,,1] * grid.match\n\n# Sum area and extent over all grid cells and convert from m^2 to km^2\narea &lt;- sum(area_total) / 1000000\nextent &lt;- sum(ext_total) / 1000000\n\nprint(paste(\"Sea Ice Area (km^2): \", floor(area)))\n## [1] \"Sea Ice Area (km^2):  12564015\"\nprint(paste(\"Sea Ice Extent (km^2): \", floor(extent)))\n## [1] \"Sea Ice Extent (km^2):  13905993\"\n\n\n\n# Replicate grid areas for all timestep\nrep_grid_areas &lt;- array(rep(grid.match, each=dim(sic)[3]), dim=dim(sic))\n\n# Perform element-wise multiplication\narea_total12 &lt;- sic * rep_grid_areas\next_total12 &lt;- sic_ext * rep_grid_areas\n\narea12 &lt;- apply(area_total12, c(3), sum)\next12 &lt;- apply(ext_total12, c(3), sum)\n\n\n\nupper = max(max(ext12), max(area12))\nlower = min(min(ext12), min(area12))\nplot(dates,ext12,type='o',pch=20,xlab='Date',ylab='Area (km^2)', col=\"orange\" , ylim=c(lower, upper),  main=\"2021 Monthly Sea ice area and sea ice extent\")\nlines(dates, area12, type='o', pch=20, col=\"blue\")\nlegend(\"topright\", legend=c(\"Sea ice Area\", \"Sea ice Extent\"),\n       col=c(\"blue\", \"orange\"), lty=1:1, cex=0.8)\nbox()\n\n\n\n\n\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nPolarWatch Data Catalog\nWhat’s the difference between Sea ice area and extent?\nNSIDC Arctic Sea Ice News & Analysis\nClimate.gov Understanding Climate: sea ice extent\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#background",
    "href": "tutorials/r/calculate-seaice-extent.html#background",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Sea ice cover measurements are key to polar ecological and climatological research. This measurement has gained attention because of the recent decrease in the Arctic sea ice cover. Satellite observations are essential for tracking sea ice cover, providing continuous global coverage extending back to 1978. Typically, sea ice cover is reported as sea ice concentration, which is the percent areal coverage of ice within a grid cell. Depending on the application, additional parameters of interest can be calculated from sea ice cover:\n\nSea ice area - the cumulative coverage of all gridded sections (area), including each grid that contains a minimum ice concentration of 15%.\n\nSea ice extent - the cumulative coverage of all griddedthe sum of the areas of all grid cells with at least 15% ice concentration"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#objective",
    "href": "tutorials/r/calculate-seaice-extent.html#objective",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "This tutorial will demonstrate how to calculate the sea ice area and extent using sea ice concentration and grid cell area data. Please visit the NSIDC website for more detailed descriptions of the calculations."
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/calculate-seaice-extent.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Downloading and saving a netcdf file from the PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nDownloading and adding grid cell area data to the satellite data\nVisualizing data on a map\nComputing sea ice area and extent using sea ice concentration data\nPlotting a time series of sea ice area and extent"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#datasets-used",
    "href": "tutorials/r/calculate-seaice-extent.html#datasets-used",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere.\nThe Sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. Near-Real-Time data are also available at PolarWatch. (SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Northern Polar Stereographic projection (EPSG:3413). The resolution is 25km, meaning each grid cell in this data set represents a value that covers a 25km by 25km area. The dataset is available on the PolarWatch data portal and can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.graph\nPolar Stereographic Grid Cell Area Values of 25km grid, Polar Stereographic (North), NSIDC Ancillary Data.\nThis dataset includes the area (in m2) of each grid cell in the 25km resolution Northern Polar Stereographic projection. This dataset is available on the PolarWatch ERDDAP\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ggplot2\" ,\"ncdf4\",  \"RColorBrewer\", \"scales\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# Set up download method as libcurl, this is only needed for Windows machines\noptions(download.file.method=\"libcurl\", url.method=\"libcurl\")"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#get-the-sea-ice-data-from-erddap",
    "href": "tutorials/r/calculate-seaice-extent.html#get-the-sea-ice-data-from-erddap",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Here we download the average monthly sea ice concentration for the Arctic for 2021 (January to December). We are using the NSIDC Sea Ice Concentration Climate Data Record (NSIDC ID: G002202).\nThe ERDDAP data request URL for this data subset is presented below.\nhttps://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nThe following table shows the component parts of the ERDDAP data request URL.\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID of the dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nNetCDF (there are many other available file formats)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariables from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]\nTemporal\n\n\nspatial_range\n[(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nSpatial coverage\n\n\n\n` Note The metadata states that the _FillValue for this dataset is set to -999, however when the _FillValue attribute is found, the ncdf4 package maps all the missing values (_FillValue) to NA’s.\n# Set data request URL for PolarWatch ERDDAP data server\ndata_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\"\n\n\n# Send data request and download file to the file name\nf &lt;- 'sic.nc'\ndownload.file(data_url, destfile=f, mode=\"wb\")\n# Open netcdf file\nnc=nc_open('sic.nc')\n\n# Examine file metadata\n#print(nc)\n\n# Examine names of variables\nnames(nc$var)\n\n# Get first variable metadata\nvar1 &lt;- nc$var[[1]]\n\n# Examine variable metadata\n#print(var1)\n\n# Get variable values\nsic &lt;- ncvar_get(nc,var1$name)\n\n# Examine dimension of variables\ndim(sic)\n\n# Based on metadata, set xgrid, ygrid\nxgrid &lt;- var1$dim[[1]]$vals\nygrid &lt;- var1$dim[[2]]$vals\n\n# convert time variable to date format\ndates &lt;- as.POSIXlt(var1$dim[[3]]$vals,origin='1970-01-01',tz='GMT')\n# Close and remove the netCDF file and clear memories\nnc_close(nc)\nfile.remove('sic.nc')\n## [1] TRUE"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#plot-sea-ice-concentration-data",
    "href": "tutorials/r/calculate-seaice-extent.html#plot-sea-ice-concentration-data",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "To plot sea ice concentration data that are in xgrid and ygrid dimensions, we will create a data frame with coordinates (xgrid, ygrid) and associated sea ice concentration values.\n# Create a data frame with all combinations of xgrid and ygrid\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\n\n# Add sic data array to the data frame\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude the _FillValue listed in the metadata (2.53999) which corresponds to various pixels with no data (land, coast, missing data, etc...)\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# Map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous() + \n       scale_x_continuous() +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\") +\n      ggtitle(\"Sea Ice Concentration on Polar Steregraphic projection\")"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#download-grid-cell-area-values",
    "href": "tutorials/r/calculate-seaice-extent.html#download-grid-cell-area-values",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "While the resolution of this data set is 25km, the actual area of each grid cell depends on the grid projection. We will download the grid cell area values from the PolarWatch ERDDAP.\ncell_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k.nc?cell_area%5B(5837500.0):1:(-5337500.0)%5D%5B(-3837500.0):1:(3737500.0)%5D\"\nf &lt;- 'gridcell.nc'\ndownload.file(cell_url, destfile=f, mode=\"wb\")"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#examine-grid-cell-dataset-metadata-and-extract-values",
    "href": "tutorials/r/calculate-seaice-extent.html#examine-grid-cell-dataset-metadata-and-extract-values",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Just like for the sea ice concentration dataset, we will examine the metadata and extract the variables of grid cell areas along with x and y grids.\n# Open netcdf file\nnc1=nc_open('gridcell.nc')\n\n# Examine names of variables\nnames(nc1$var)\n\n# Get first variable metadata\narea_var &lt;- nc1$var[[1]]\n\n# Examine area_var\nnames(area_var)\n\n# Get variable values\ncellarea =ncvar_get(nc1,area_var$name)\n\n# Examine dimension of variable values\ndim(cellarea)\n\n# Based on metadata, set xgrid, ygrid, time\nx_area &lt;- area_var$dim[[1]]$vals\ny_area &lt;- area_var$dim[[2]]$vals\n\n# Close and remove the netCDF file and clear memories\nnc_close(nc1)\nfile.remove('gridcell.nc')"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#match-cell-area-grids-with-sic-grids",
    "href": "tutorials/r/calculate-seaice-extent.html#match-cell-area-grids-with-sic-grids",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Now we have two data sets: sea ice concentration and grid cell areas for each grid of northern polar stereographic projection. While the spatial coverage of both data sets is identical, we will ensure the x and y coordinates of both data sets are correctly aligned.\n# Get indices in areas where x and y grids equal those of sic\nx_indices &lt;- match(xgrid, x_area)\ny_indices &lt;- match(ygrid, y_area)\n\n# Extract grid area\ngrid.match &lt;- cellarea[x_indices, y_indices]"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#clean-sea-ice-concentration-data-for-sea-ice-area-calculation",
    "href": "tutorials/r/calculate-seaice-extent.html#clean-sea-ice-concentration-data-for-sea-ice-area-calculation",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "We need to clean the data before computing the sea ice area and extent.\n\nThe dataset includes flag values indicating non-sea ice area such as land, lakes, etc.\n\ntask: remove flag values (2 and higher) by setting the flag values as Nan.\n\nFor this example of the sea ice area and extent calculations, a value of 0.15 of sea ice concentration value will be used as a threshold.\n\ntask: set sic value to 0 if the value is less than 0.15\n\n\nFor more detailed information about the flag values, go to the user guide. For the calculation of sea ice area and extent with a threshold, go to the NSIDC article.\n# Set sic values less than 0.15 to (applying 0.15 threshold)\nsic[sic &lt; 0.15] &lt;- 0\n\n# Set 0 for all flag values (&gt;2)\nsic[sic &gt; 1] &lt;- 0\n\n# Set NA to 0\nsic[is.na(sic)] &lt;- 0\n\n# Sic for extent calc\nsic_ext &lt;- sic\nsic_ext[sic_ext &gt;= 0.15] &lt;- 1\n\n\n# Perform element-wise multiplication for the first time step\narea_total &lt;- sic[,,1] * grid.match\next_total &lt;- sic_ext[,,1] * grid.match\n\n# Sum area and extent over all grid cells and convert from m^2 to km^2\narea &lt;- sum(area_total) / 1000000\nextent &lt;- sum(ext_total) / 1000000\n\nprint(paste(\"Sea Ice Area (km^2): \", floor(area)))\n## [1] \"Sea Ice Area (km^2):  12564015\"\nprint(paste(\"Sea Ice Extent (km^2): \", floor(extent)))\n## [1] \"Sea Ice Extent (km^2):  13905993\""
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#generate-the-sea-ice-area-and-extent-time-series",
    "href": "tutorials/r/calculate-seaice-extent.html#generate-the-sea-ice-area-and-extent-time-series",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "# Replicate grid areas for all timestep\nrep_grid_areas &lt;- array(rep(grid.match, each=dim(sic)[3]), dim=dim(sic))\n\n# Perform element-wise multiplication\narea_total12 &lt;- sic * rep_grid_areas\next_total12 &lt;- sic_ext * rep_grid_areas\n\narea12 &lt;- apply(area_total12, c(3), sum)\next12 &lt;- apply(ext_total12, c(3), sum)"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#plot-the-sea-ice-area-and-extent-time-series",
    "href": "tutorials/r/calculate-seaice-extent.html#plot-the-sea-ice-area-and-extent-time-series",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "upper = max(max(ext12), max(area12))\nlower = min(min(ext12), min(area12))\nplot(dates,ext12,type='o',pch=20,xlab='Date',ylab='Area (km^2)', col=\"orange\" , ylim=c(lower, upper),  main=\"2021 Monthly Sea ice area and sea ice extent\")\nlines(dates, area12, type='o', pch=20, col=\"blue\")\nlegend(\"topright\", legend=c(\"Sea ice Area\", \"Sea ice Extent\"),\n       col=c(\"blue\", \"orange\"), lty=1:1, cex=0.8)\nbox()"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#references",
    "href": "tutorials/r/calculate-seaice-extent.html#references",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "NSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nPolarWatch Data Catalog\nWhat’s the difference between Sea ice area and extent?\nNSIDC Arctic Sea Ice News & Analysis\nClimate.gov Understanding Climate: sea ice extent\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html",
    "title": "Extract data within a boundary",
    "section": "",
    "text": "history | Updated August 2023"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#background",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#background",
    "title": "Extract data within a boundary",
    "section": "Background",
    "text": "Background\nOne use for satellite observations is to supplement in situ sampling of geographical locations where the timespan, frequency measurements, spatial dimensions or remoteness of the locations, make physical sampling impossible or impractical. One drawback is that satellite data are often rectangular, whereas geographical locations can have irregular boundaries. Examples of boundaries include marine protected areas or marine physical, biological, and ecological divisions like the Longhurst Marine Provinces."
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#objectives",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#objectives",
    "title": "Extract data within a boundary",
    "section": "Objectives",
    "text": "Objectives\nIn this tutorial we will learn how to download a timeseries of SST satellite data from an ERDDAP server, and then mask the data to retain only the data within an irregular geographical boundary (polygon). We will then plot a yearly seasonal cycle from within the boundary."
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Extract data within a boundary",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data from an ERDDAP data server for a non-rectangular region using the rerddapXtracto package\nVisualizing data on a map\nPlotting a time-series of mean SST"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#datasets-used",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#datasets-used",
    "title": "Extract data within a boundary",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Geo-polar Blended Analysis Sea-Surface Temperature, Global, Monthlyly, 5km, 2019-Present\nThe NOAA geo-polar blended SST is a high resolution satellite-based gap-free sea surface temperature (SST) product that combines SST data from US, Japanese and European geostationary infrared imagers, and low-earth orbiting infrared (U.S. and European) SST data, into a single product. We will use the monthly composite. https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly\nLonghurst Marine Provinces\nThe dataset represents the division of the world oceans into provinces as defined by Longhurst (1995; 1998; 2006). This division has been based on the prevailing role of physical forcing as a regulator of phytoplankton distribution. The Longhurst Marine Provinces dataset is available online (https://www.marineregions.org/downloads.php) and within the shapes folder associated with this repository. For this tutorial we will use the Gulf Stream province (ProvCode: GFST)\n\n\n\n../images/longhurst.png"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#install-packages-and-load-libraries",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#install-packages-and-load-libraries",
    "title": "Extract data within a boundary",
    "section": "Install packages and load libraries",
    "text": "Install packages and load libraries\npkges = installed.packages()[,\"Package\"]\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n# create list of required packages\nlist.of.packages &lt;- c(\"ncdf4\", \"rerddap\",\"plotdap\", \"parsedate\", \n                      \"sp\", \"ggplot2\", \"RColorBrewer\", \"sf\", \n                      \"reshape2\", \"maps\", \"mapdata\", \n                      \"jsonlite\", \"rerddapXtracto\")\n\n# Run install and load function\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#load-boundary-coordinates",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#load-boundary-coordinates",
    "title": "Extract data within a boundary",
    "section": "Load boundary coordinates",
    "text": "Load boundary coordinates\nThe shapefile for the Longhurst marine provinces includes a list of regions. For this exercise, we will only use the boundary of one province, the Gulf Stream region (“GFST”).\n# Set directory path\ndir_path &lt;- '../resources/longhurst_v4_2010/'\n\n# Import shape files (Longhurst coordinates)\nshapes &lt;- read_sf(dsn = dir_path, layer = \"Longhurst_world_v4_2010\")\n\n# Example List of all the province names\nshapes$ProvCode\n##  [1] \"BPLR\" \"ARCT\" \"SARC\" \"NADR\" \"GFST\" \"NASW\" \"NATR\" \"WTRA\" \"ETRA\" \"SATL\"\n## [11] \"NECS\" \"CNRY\" \"GUIN\" \"GUIA\" \"NWCS\" \"MEDI\" \"CARB\" \"NASE\" \"BRAZ\" \"FKLD\"\n## [21] \"BENG\" \"MONS\" \"ISSG\" \"EAFR\" \"REDS\" \"ARAB\" \"INDE\" \"INDW\" \"AUSW\" \"BERS\"\n## [31] \"PSAE\" \"PSAW\" \"KURO\" \"NPPF\" \"NPSW\" \"TASM\" \"SPSG\" \"NPTG\" \"PNEC\" \"PEQD\"\n## [41] \"WARM\" \"ARCH\" \"ALSK\" \"CCAL\" \"CAMR\" \"CHIL\" \"CHIN\" \"SUND\" \"AUSE\" \"NEWZ\"\n## [51] \"SSTC\" \"SANT\" \"ANTA\" \"APLR\"\n# Get boundary coordinates for Gulf Stream region (GFST)\nGFST &lt;- shapes[shapes$ProvCode == \"GFST\",]\n\nxcoord &lt;- st_coordinates(GFST)[,1]\nycoord &lt;- st_coordinates(GFST)[,2]"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#select-the-satellite-dataset",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#select-the-satellite-dataset",
    "title": "Extract data within a boundary",
    "section": "Select the satellite dataset",
    "text": "Select the satellite dataset\nWe will load the sea surface temperature data from the geo-polar blended SST satellite data product hosted on the CoastWatch ERDDAP. The dataset ID for this data product is nesdisBLENDEDsstDNDaily.\nWe will use the info function from the rerddap package to first obtain information about the dataset of interest, then we will import the data.\n# Set ERDDAP URL\nerd_url = \"http://coastwatch.pfeg.noaa.gov/erddap/\"\n\n# Obtain data info using the erddap url and dataset ID\ndataInfo &lt;- rerddap::info('NOAA_DHW_monthly',url=erd_url)  \n\n# Examine the metadata dataset info\ndataInfo\n## &lt;ERDDAP info&gt; NOAA_DHW_monthly \n##  Base URL: http://coastwatch.pfeg.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1985-01-16T00:00:00Z, 2023-08-16T00:00:00Z) \n##      latitude: (-89.975, 89.975) \n##      longitude: (-179.975, 179.975) \n##  Variables:  \n##      mask: \n##          Units: pixel_classification \n##      sea_surface_temperature: \n##          Units: degree_C \n##      sea_surface_temperature_anomaly: \n##          Units: degree_C"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#set-the-options-for-the-polygon-data-extract",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#set-the-options-for-the-polygon-data-extract",
    "title": "Extract data within a boundary",
    "section": "Set the options for the polygon data extract",
    "text": "Set the options for the polygon data extract\nUsing the rxtractogon function, we will import the satellite data from erddap. The rxtractogon function takes the variable(s) of interest and the coordinates as input.\n\nFor the coordinates: determine the range of x, y, z, and time.\ntime coordinate: select the entire year of 2020\n\n# set the parameter to extract\nparameter &lt;- 'sea_surface_temperature'\n# set the time range\ntcoord &lt;- c(\"2020-01-16\", \"2020-12-16\")\n\n# We already extracted the xcoord (longitude) and ycoord (latitude) from the shapefiles \n# The dummy code below is just a placeholder indicating it is necessary to define what the longitude and latitude vectors are that make up the boundary of the polygon.\nxcoord &lt;- xcoord\nycoord &lt;- ycoord"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#extract-data-and-mask-it-using-rxtractogon",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#extract-data-and-mask-it-using-rxtractogon",
    "title": "Extract data within a boundary",
    "section": "Extract data and mask it using rxtractogon",
    "text": "Extract data and mask it using rxtractogon\n\nthe rxtractogon function automatically extracts data from the satellite dataset and masks out any data outside the polygon boundary.\n\nList the data\n\n## Request the data\nsatdata &lt;- rxtractogon(dataInfo, parameter=parameter, xcoord=xcoord, ycoord=ycoord,tcoord=tcoord)\n\n## List the returned data\nstr(satdata)\n## List of 6\n##  $ sea_surface_temperature: num [1:601, 1:202, 1:12] NA NA NA NA NA NA NA NA NA NA ...\n##  $ datasetname            : chr \"NOAA_DHW_monthly\"\n##  $ longitude              : num [1:601(1d)] -73.5 -73.5 -73.4 -73.4 -73.3 ...\n##  $ latitude               : num [1:202(1d)] 33.5 33.5 33.6 33.6 33.7 ...\n##  $ altitude               : logi NA\n##  $ time                   : POSIXlt[1:12], format: \"2020-01-16 00:00:00\" \"2020-02-16 00:00:00\" ...\n##  - attr(*, \"class\")= chr [1:2] \"list\" \"rxtracto3D\"\n\nPlot the data\n\nUse the plotBBox function in the rerddapXtracto package to quickly plot the data\n\nplotBBox(satdata, plotColor = 'thermal',maxpixels=1000000)\n\n\n\nPlot the mean seasonal temperature for the province\nsst_mean=apply(satdata$sea_surface_temperature,3,mean,na.rm=TRUE)\nplot(satdata$time,sst_mean,main='Gulf Stream Province Monthly Mean Temperature 2020',ylab='SSt (ºC)',xlab='',type='b')"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html",
    "href": "tutorials/r/virtual_buoy_example.html",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Updated August 2023 \n\nThere are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov), ARGO floats program (http://www.argo.ucsd.edu) or CoastWatch ERDDAP data servers (https://coastwatch.pfeg.noaa.gov/erddap/). In situ buoy data are widely used to monitor environmental conditions. In the absence of in situ buoy data - whether the buoy operation is discontinued, interrupted, or limited - satellite data within temporal and spatial coverage of the desired locationcan be used to create a time series of a parameter of interest.\n\n\nThis tutorial will demonstrate how to create a time series from satellite data to gap-fill or replace buoy data.\n\n\n\n\nDownloading the satellite and buoy data from ERDDAP data server\nVisualizing the datasets\nReshaping the satellite data into a buoy data format\nResampling buoy data (aggregation) to match satellite data temporal resolution\nValidating the satellite data with the actual buoy data\nPerforming a linear regression of satellite vs. buoy data\nCreating a scatter plot of satellite vs. buoy data with the regression line\n\n\n\n\nSea-Surface Temperature, NOAA Geo-polar Blended Analysis Day+Night, GHRSST,Near Real-Time, Global 5km, 2019-Present, Daily\n.\nNDBC Standard Meteorological Buoy Data, 1970-present  NDBC Standard Meteorological Buoy Data  from the buoy station no. 46259 are from off the California coast at 34.737N latitude and 121.664E longitude.\n\n\n\n\nNOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center\n\n\n\n\n# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"utils\", \"ggplot2\", \"dplyr\", \"lubridate\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\nWe will download NDBC buoy data between January 16, 2022 and August 16, 2022 from the CoastWatch ERDDAP server.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\n# Set the ERDDAP data request URL\n \nbuoy_url &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?time%2Clongitude%2Clatitude%2Cwtmp&station%3E=%2246259%22&station%3C=%2246259%22&time%3E=2022-01-16T00%3A00%3A00Z&time%3C=2022-08-16T17%3A52%3A00Z\"\n\n# Set file name\nfname = 'buoy.csv'\n\n# Download file\ndownload.file(buoy_url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\n \nbuoy_df &lt;- read.csv(fname, skip=2, header=TRUE)\n\n# Name the columns\nnames(buoy_df) &lt;- c(\"utc\", \"lon\", \"lat\", \"sst\" )\n\n# Add additional date column\nbuoy_df$date &lt;- as.Date(buoy_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(buoy_df, 3)\n\n##                    utc      lon    lat  sst       date\n## 1 2022-01-16T00:56:00Z -121.664 34.732 13.4 2022-01-16\n## 2 2022-01-16T01:26:00Z -121.664 34.732 13.4 2022-01-16\n## 3 2022-01-16T01:56:00Z -121.664 34.732 13.3 2022-01-16\n\n\n\noptions(repr.plot.width = 10)\n\nggplot(buoy_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n # geom_point(size=.2, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celsius)\", title=\"SST from NDBC Buoy Station: 46259 (Aug 2022- Aug 2023) \")\n\n\n\n\nThe satellite Sea Surface Temperature (SST) product we will use is the NOAA GeoPolar Blended SST dataset (in Celsius), which blends data from many satellite sensors to obtain good daily coverage of the globe at 5km resolution, and then an interpolation method is applied to fill in data gaps.\nThe data request can be sent to a CoastWatch ERDDAP server via URL with a query string to specify the temporal and spatial coverage of interest. In this case, we want to subset the satellite data to match the buoy station location and time range.\n\n\n# Set ERDDAP URL for the satellite data\nurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisBLENDEDsstDNDaily.csv?analysed_sst%5B(2022-01-16T12:00:00Z):1:(2022-08-16T12:00:00Z)%5D%5B(34.737):1:(34.737)%5D%5B(-121.664):1:(-121.664)%5D\"\n\n# Set file name\nfname = 'sst.csv'\n\n# Download file\ndownload.file(url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\nsst_df &lt;- read.csv(fname, skip=2, header=TRUE)\nnames(sst_df) &lt;- c(\"utc\", \"lat\", \"lon\", \"sst\")\n\n# Add formatted data column\nsst_df$date &lt;- as.Date(sst_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(sst_df, 3)\n\n##                    utc    lat      lon      sst       date\n## 1 2022-01-18T12:00:00Z 34.725 -121.675 13.49999 2022-01-18\n## 2 2022-01-19T12:00:00Z 34.725 -121.675 13.44999 2022-01-19\n## 3 2022-01-20T12:00:00Z 34.725 -121.675 13.53999 2022-01-20\n\n\n\n\nApply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, a value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Filter data that are within the valid range (-2 and 45)\nsst_df_clean = sst_df %&gt;%\n  filter(sst &gt;=-2 & sst &lt;= 45)\n\n\n\n# Plot sea surface temperature values from satellite\np &lt;- ggplot(sst_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"Sea surface temperature from satellite\")\np\n\n\n\n\nThe sampling resolution for the buoy data is a sample every 30 minutes. However, the temporal resolution for the satellite dataset is daily. We will downsample the buoy data by computing daily mean to match the temporal resolution of the satellite data.\n# Aggregating (taking a mean value) grouped by day\nbuoy_ds &lt;- buoy_df %&gt;%\n  group_by(date = floor_date(date, unit=\"days\")) %&gt;%\n  summarise(mean_sst = mean(sst))\n\n# Show first 3 rows\nhead(buoy_ds, 3)\n\n## # A tibble: 3 × 2\n##   date       mean_sst\n##   &lt;date&gt;        &lt;dbl&gt;\n## 1 2022-01-16     13.4\n## 2 2022-01-17     13.5\n## 3 2022-01-18     13.6\n\n\n\nApply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Remove outliers sst values outside of -2 and 45 deg C\nbuoy_ds_clean = buoy_ds %&gt;%\n  filter(mean_sst &gt;=-2 & mean_sst &lt;= 45)\n\n\n\n# Plot daily mean sst\nggplot(buoy_ds_clean, aes(x = date, y = mean_sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"2022 Aug- 2023 Aug Downsampled Buoy SST\")\n\n\n\n\nWe will use dplyr::inner_join() function to merge the two data frames (satellite and buoy data) based on the dates that appear in both data frames.\n# Combine two data frames with date column where dates exist in both data frames\nmerged_df &lt;- inner_join(sst_df_clean[c(\"date\", \"sst\")],  buoy_ds_clean, by = \"date\")\n\n\n\n# Plot satellite sst and buoy daily mean sst \np &lt;- ggplot(merged_df, aes(x = date)) +  \n    geom_line(aes(y = sst, color = \"Satellite\")) +   \n    geom_line(aes(y = mean_sst, color = \"NDBC Buoy\")) +   \n    scale_color_manual(name = \"Data source\", \n                       values = c(\"Satellite\" = \"blue\", \"NDBC Buoy\" = \"orange\"))+\n    labs( x = \"Date\", y = \"Temperature (in Celsius)\", title=\"SST from Satellite and NDBC Buoy\" )+\n    theme(axis.text.x = element_text(angle = 0),plot.title=element_text(hjust=0.5))\np\n ## Perform a simple linear regression\n# Run linear regression \nmodel &lt;- lm(mean_sst ~ sst, data = merged_df)   \nsummary(model)\n\n## \n## Call:\n## lm(formula = mean_sst ~ sst, data = merged_df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.48812 -0.21354 -0.02782  0.14581  1.67408 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.54793    0.30272    1.81   0.0718 .  \n## sst          0.96142    0.02221   43.29   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4462 on 203 degrees of freedom\n## Multiple R-squared:  0.9023, Adjusted R-squared:  0.9018 \n## F-statistic:  1874 on 1 and 203 DF,  p-value: &lt; 2.2e-16\n\n\n\nggplot(merged_df, aes(x=sst, y=mean_sst)) +\n  geom_point(color=\"black\", size=1) +                      # Plot the data points\n  geom_smooth(method=\"lm\", se=FALSE) +\n  labs(x = \"SST from Buoy\", y = \"SST from Satellite\", title = \"Satellite vs Buoy data with regression line\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n## `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#objective",
    "href": "tutorials/r/virtual_buoy_example.html#objective",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "This tutorial will demonstrate how to create a time series from satellite data to gap-fill or replace buoy data."
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/virtual_buoy_example.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Downloading the satellite and buoy data from ERDDAP data server\nVisualizing the datasets\nReshaping the satellite data into a buoy data format\nResampling buoy data (aggregation) to match satellite data temporal resolution\nValidating the satellite data with the actual buoy data\nPerforming a linear regression of satellite vs. buoy data\nCreating a scatter plot of satellite vs. buoy data with the regression line"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#datasets-used",
    "href": "tutorials/r/virtual_buoy_example.html#datasets-used",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Sea-Surface Temperature, NOAA Geo-polar Blended Analysis Day+Night, GHRSST,Near Real-Time, Global 5km, 2019-Present, Daily\n.\nNDBC Standard Meteorological Buoy Data, 1970-present  NDBC Standard Meteorological Buoy Data  from the buoy station no. 46259 are from off the California coast at 34.737N latitude and 121.664E longitude."
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#references",
    "href": "tutorials/r/virtual_buoy_example.html#references",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "NOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#install-required-packages-and-load-libraries",
    "href": "tutorials/r/virtual_buoy_example.html#install-required-packages-and-load-libraries",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"utils\", \"ggplot2\", \"dplyr\", \"lubridate\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#download-ndbc-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#download-ndbc-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "We will download NDBC buoy data between January 16, 2022 and August 16, 2022 from the CoastWatch ERDDAP server.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\n# Set the ERDDAP data request URL\n \nbuoy_url &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?time%2Clongitude%2Clatitude%2Cwtmp&station%3E=%2246259%22&station%3C=%2246259%22&time%3E=2022-01-16T00%3A00%3A00Z&time%3C=2022-08-16T17%3A52%3A00Z\"\n\n# Set file name\nfname = 'buoy.csv'\n\n# Download file\ndownload.file(buoy_url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\n \nbuoy_df &lt;- read.csv(fname, skip=2, header=TRUE)\n\n# Name the columns\nnames(buoy_df) &lt;- c(\"utc\", \"lon\", \"lat\", \"sst\" )\n\n# Add additional date column\nbuoy_df$date &lt;- as.Date(buoy_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(buoy_df, 3)\n\n##                    utc      lon    lat  sst       date\n## 1 2022-01-16T00:56:00Z -121.664 34.732 13.4 2022-01-16\n## 2 2022-01-16T01:26:00Z -121.664 34.732 13.4 2022-01-16\n## 3 2022-01-16T01:56:00Z -121.664 34.732 13.3 2022-01-16"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#visualize-sst-from-the-buoy",
    "href": "tutorials/r/virtual_buoy_example.html#visualize-sst-from-the-buoy",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "options(repr.plot.width = 10)\n\nggplot(buoy_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n # geom_point(size=.2, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celsius)\", title=\"SST from NDBC Buoy Station: 46259 (Aug 2022- Aug 2023) \")"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#download-the-satellite-sea-surface-temperature-sst-data",
    "href": "tutorials/r/virtual_buoy_example.html#download-the-satellite-sea-surface-temperature-sst-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "The satellite Sea Surface Temperature (SST) product we will use is the NOAA GeoPolar Blended SST dataset (in Celsius), which blends data from many satellite sensors to obtain good daily coverage of the globe at 5km resolution, and then an interpolation method is applied to fill in data gaps.\nThe data request can be sent to a CoastWatch ERDDAP server via URL with a query string to specify the temporal and spatial coverage of interest. In this case, we want to subset the satellite data to match the buoy station location and time range.\n\n\n# Set ERDDAP URL for the satellite data\nurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisBLENDEDsstDNDaily.csv?analysed_sst%5B(2022-01-16T12:00:00Z):1:(2022-08-16T12:00:00Z)%5D%5B(34.737):1:(34.737)%5D%5B(-121.664):1:(-121.664)%5D\"\n\n# Set file name\nfname = 'sst.csv'\n\n# Download file\ndownload.file(url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\nsst_df &lt;- read.csv(fname, skip=2, header=TRUE)\nnames(sst_df) &lt;- c(\"utc\", \"lat\", \"lon\", \"sst\")\n\n# Add formatted data column\nsst_df$date &lt;- as.Date(sst_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(sst_df, 3)\n\n##                    utc    lat      lon      sst       date\n## 1 2022-01-18T12:00:00Z 34.725 -121.675 13.49999 2022-01-18\n## 2 2022-01-19T12:00:00Z 34.725 -121.675 13.44999 2022-01-19\n## 3 2022-01-20T12:00:00Z 34.725 -121.675 13.53999 2022-01-20"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#clean-up-the-data",
    "href": "tutorials/r/virtual_buoy_example.html#clean-up-the-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Apply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, a value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Filter data that are within the valid range (-2 and 45)\nsst_df_clean = sst_df %&gt;%\n  filter(sst &gt;=-2 & sst &lt;= 45)"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#visualize-the-satellite-sst-data",
    "href": "tutorials/r/virtual_buoy_example.html#visualize-the-satellite-sst-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot sea surface temperature values from satellite\np &lt;- ggplot(sst_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"Sea surface temperature from satellite\")\np"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#resample-the-buoy-data-to-match-the-satellite-data",
    "href": "tutorials/r/virtual_buoy_example.html#resample-the-buoy-data-to-match-the-satellite-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "The sampling resolution for the buoy data is a sample every 30 minutes. However, the temporal resolution for the satellite dataset is daily. We will downsample the buoy data by computing daily mean to match the temporal resolution of the satellite data.\n# Aggregating (taking a mean value) grouped by day\nbuoy_ds &lt;- buoy_df %&gt;%\n  group_by(date = floor_date(date, unit=\"days\")) %&gt;%\n  summarise(mean_sst = mean(sst))\n\n# Show first 3 rows\nhead(buoy_ds, 3)\n\n## # A tibble: 3 × 2\n##   date       mean_sst\n##   &lt;date&gt;        &lt;dbl&gt;\n## 1 2022-01-16     13.4\n## 2 2022-01-17     13.5\n## 3 2022-01-18     13.6"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#clean-up-the-downsampled-data",
    "href": "tutorials/r/virtual_buoy_example.html#clean-up-the-downsampled-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Apply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Remove outliers sst values outside of -2 and 45 deg C\nbuoy_ds_clean = buoy_ds %&gt;%\n  filter(mean_sst &gt;=-2 & mean_sst &lt;= 45)"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#visualize-the-downsampled-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#visualize-the-downsampled-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot daily mean sst\nggplot(buoy_ds_clean, aes(x = date, y = mean_sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"2022 Aug- 2023 Aug Downsampled Buoy SST\")"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#merge-satellite-and-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#merge-satellite-and-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "We will use dplyr::inner_join() function to merge the two data frames (satellite and buoy data) based on the dates that appear in both data frames.\n# Combine two data frames with date column where dates exist in both data frames\nmerged_df &lt;- inner_join(sst_df_clean[c(\"date\", \"sst\")],  buoy_ds_clean, by = \"date\")"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#plot-both-satellite-and-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#plot-both-satellite-and-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot satellite sst and buoy daily mean sst \np &lt;- ggplot(merged_df, aes(x = date)) +  \n    geom_line(aes(y = sst, color = \"Satellite\")) +   \n    geom_line(aes(y = mean_sst, color = \"NDBC Buoy\")) +   \n    scale_color_manual(name = \"Data source\", \n                       values = c(\"Satellite\" = \"blue\", \"NDBC Buoy\" = \"orange\"))+\n    labs( x = \"Date\", y = \"Temperature (in Celsius)\", title=\"SST from Satellite and NDBC Buoy\" )+\n    theme(axis.text.x = element_text(angle = 0),plot.title=element_text(hjust=0.5))\np\n ## Perform a simple linear regression\n# Run linear regression \nmodel &lt;- lm(mean_sst ~ sst, data = merged_df)   \nsummary(model)\n\n## \n## Call:\n## lm(formula = mean_sst ~ sst, data = merged_df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.48812 -0.21354 -0.02782  0.14581  1.67408 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.54793    0.30272    1.81   0.0718 .  \n## sst          0.96142    0.02221   43.29   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4462 on 203 degrees of freedom\n## Multiple R-squared:  0.9023, Adjusted R-squared:  0.9018 \n## F-statistic:  1874 on 1 and 203 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#plot-satellite-vs.-buoy-data-and-overlay-the-regression-line",
    "href": "tutorials/r/virtual_buoy_example.html#plot-satellite-vs.-buoy-data-and-overlay-the-regression-line",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "ggplot(merged_df, aes(x=sst, y=mean_sst)) +\n  geom_point(color=\"black\", size=1) +                      # Plot the data points\n  geom_smooth(method=\"lm\", se=FALSE) +\n  labs(x = \"SST from Buoy\", y = \"SST from Satellite\", title = \"Satellite vs Buoy data with regression line\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n## `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html",
    "href": "tutorials/python/calculating-sea-ice-extent.html",
    "title": "Calculating sea ice area and extent",
    "section": "",
    "text": "History | Created Sep 2023"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#background",
    "href": "tutorials/python/calculating-sea-ice-extent.html#background",
    "title": "Calculating sea ice area and extent",
    "section": "Background",
    "text": "Background\nSea ice cover is one of the key components of polar ecological and climatological research. This measurement has gained attention because of the recent decrease in the Arctic sea ice cover. Satellite observations are a key tool in tracking sea ice cover, providing continuous global coverage extending back to 1978. Typically for satellite data, sea ice cover is reported as sea ice concentration, which is the percent areal coverage of ice within a grid cell. Depending on the application, additional parameters of interest can be calculated from sea ice cover:\n* Sea ice area - the sum of the product of ice concentration and area of all grid cells with at least 15% ice concentration.\n* Sea ice extent - the sum of the areas of all grid cells with at least 15% ice concentration"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#objective",
    "href": "tutorials/python/calculating-sea-ice-extent.html#objective",
    "title": "Calculating sea ice area and extent",
    "section": "Objective",
    "text": "Objective\nThis tutorial will demonstrate how to calculate the sea ice area and extent using sea ice concentration and grid cell area data. Please visit the NSIDC website for more detailed descriptions of the calculations."
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#this-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/calculating-sea-ice-extent.html#this-tutorial-demonstrates-the-following-techniques",
    "title": "Calculating sea ice area and extent",
    "section": "This tutorial demonstrates the following techniques",
    "text": "This tutorial demonstrates the following techniques\n\nDownloading and saving a netCDF file from PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nDownloading and adding grid cell area using OPeNDAP web services\nVisualizing data on a map\nComputing sea ice area and extent using sea ice concentration data\nPlotting a time series of sea ice area and extent"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#datasets-used",
    "href": "tutorials/python/calculating-sea-ice-extent.html#datasets-used",
    "title": "Calculating sea ice area and extent",
    "section": "Datasets used",
    "text": "Datasets used\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere\nThe Sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Northern Polar Stereographic projection (EPSG:3413). The resolution is 25km, meaning each grid in this data set represents a value that covers a 25km by 25km area. The dataset is available on the PolarWatch data portal and can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.graph\nPolar Stereographic Ancillary Grid Information\nThis dataset includes area values (m2) of each grid cell in the 25km resolution Northern Polar Stereographic projection (EPSG:3413). The file for this exercise is available in the resources folder or can be downloaded from the NSIDC website at https://nsidc.org/data/nsidc-0771/versions/1. For this tutorial, we will access the dataset directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k\n\nImport packages\n\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#download-the-arctic-sea-ice-concentration-data",
    "href": "tutorials/python/calculating-sea-ice-extent.html#download-the-arctic-sea-ice-concentration-data",
    "title": "Calculating sea ice area and extent",
    "section": "Download the Arctic Sea Ice Concentration Data",
    "text": "Download the Arctic Sea Ice Concentration Data\n\nReview of the ERDDAP data request URL\nFor our first exercise, we will download sea ice concentration data that has been temporally subsetted: * A single month, December 2021\nand spatially subsetted: * Y grid values that have been subsetted from the full range (5337500m to -5337500m) to a reduced range (4843696m to -4858210m).\nThe ERDDAP data request URL for this data subset is presented below.\nhttps://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\"\nThe following table shows the component parts of the ERDDAP data request URL.\n\n\n\n\n\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID for dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nformat of file to download (netCDF)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariable from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)]\nTemporal range (2021-01-01)\n\n\nspatial_range\n[(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\nY and X axes ranges\n\n\n\n\n\nGenerate the ERDDAP data query URL from its component parts\n\nbase_url = 'https://polarwatch.noaa.gov/erddap/griddap/'\ndatasetID = 'nsidcG02202v4nhmday'\nfile_type = '.nc'\nquery_start = '?'\nvariable_name = 'cdr_seaice_conc_monthly'\ndate_range = '[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)]'\nspatial_range = '[(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]'\n\nurl = ''.join([base_url,\n               datasetID,\n               file_type,\n               query_start,\n               variable_name,\n               date_range,\n               spatial_range\n               ])\nurl\n\n'https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]'\n\n\n\n\nDownload the data as a netCDF file and load file data into Python\n\n# Download the data from ERDDAP URL as a netCDF file\nurllib.request.urlretrieve(url, \"sic.nc\")\n\n# Open the netCDF file to create an xarray dataset object\nds = xr.open_dataset(\"sic.nc\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 1, ygrid: 389, xgrid: 304)\nCoordinates:\n  * time                     (time) datetime64[ns] 2021-01-01\n  * ygrid                    (ygrid) float32 4.838e+06 4.812e+06 ... -4.862e+06\n  * xgrid                    (xgrid) float32 -3.838e+06 -3.812e+06 ... 3.738e+06\nData variables:\n    cdr_seaice_conc_monthly  (time, ygrid, xgrid) float32 ...\nAttributes: (12/65)\n    acknowledgement:                                     This project was sup...\n    cdm_data_type:                                       Grid\n    cdr_variable:                                        cdr_seaice_conc_monthly\n    comment:                                             The variable melt_on...\n    contributor_name:                                    Walter N. Meier, Flo...\n    contributor_role:                                    principal investigat...\n    ...                                                  ...\n    summary:                                             This data set provid...\n    time_coverage_duration:                              P1M\n    time_coverage_end:                                   2021-01-01T00:00:00Z\n    time_coverage_resolution:                            P1M\n    time_coverage_start:                                 2021-01-01T00:00:00Z\n    title:                                               Sea Ice Concentratio...xarray.DatasetDimensions:time: 1ygrid: 389xgrid: 304Coordinates: (3)time(time)datetime64[ns]2021-01-01_ChunkSizes :1024_CoordinateAxisType :Timeactual_range :[1.6094592e+09 1.6094592e+09]axis :Tioos_category :Timelong_name :ANSI datestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2021-01-01T00:00:00.000000000'], dtype='datetime64[ns]')ygrid(ygrid)float324.838e+06 4.812e+06 ... -4.862e+06_ChunkSizes :448actual_range :[-4862500.  4837500.]axis :Yioos_category :Locationlong_name :projection_grid_y_centersstandard_name :projection_y_coordinateunits :metersvalid_range :[-5350000.  5850000.]array([ 4837500.,  4812500.,  4787500., ..., -4812500., -4837500., -4862500.],\n      dtype=float32)xgrid(xgrid)float32-3.838e+06 -3.812e+06 ... 3.738e+06_ChunkSizes :304actual_range :[-3837500.  3737500.]axis :Xioos_category :Locationlong_name :projection_grid_x_centersstandard_name :projection_x_coordinateunits :metersvalid_range :[-3850000.  3750000.]array([-3837500., -3812500., -3787500., ...,  3687500.,  3712500.,  3737500.],\n      dtype=float32)Data variables: (1)cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...ancillary_variables :stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthlycolorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole lakes coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Northern Hemisphere Sea Ice Concentrationreferences :https://nsidc.org/data/g02202/versions/4/standard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][118256 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2021-01-01'], dtype='datetime64[ns]', name='time', freq=None))ygridPandasIndexPandasIndex(Float64Index([ 4837500.0,  4812500.0,  4787500.0,  4762500.0,  4737500.0,\n               4712500.0,  4687500.0,  4662500.0,  4637500.0,  4612500.0,\n              ...\n              -4637500.0, -4662500.0, -4687500.0, -4712500.0, -4737500.0,\n              -4762500.0, -4787500.0, -4812500.0, -4837500.0, -4862500.0],\n             dtype='float64', name='ygrid', length=389))xgridPandasIndexPandasIndex(Float64Index([-3837500.0, -3812500.0, -3787500.0, -3762500.0, -3737500.0,\n              -3712500.0, -3687500.0, -3662500.0, -3637500.0, -3612500.0,\n              ...\n               3512500.0,  3537500.0,  3562500.0,  3587500.0,  3612500.0,\n               3637500.0,  3662500.0,  3687500.0,  3712500.0,  3737500.0],\n             dtype='float64', name='xgrid', length=304))Attributes: (65)acknowledgement :This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.cdm_data_type :Gridcdr_variable :cdr_seaice_conc_monthlycomment :The variable melt_onset_day_cdr_seaice_conc_monthly is not available for this month.contributor_name :Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fishercontributor_role :principal investigator, author, author, software developer, software developer, software developerConventions :CF-1.6, ACDD-1.3, COARDScreator_email :nsidc@nsidc.orgcreator_name :NSIDCcreator_type :institutioncreator_url :https://nsidc.org/date_created :2023-02-22T23:18:04ZdefaultGraphQuery :cdr_seaice_conc_monthly[last]%5B(-5337500.0)%5D%5B(3737500.0)%5D&.draw=surfacegrid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3850000.0 25000.0 0 5850000.0 0 -25000.0grid_mapping_grid_boundary_bottom_projected_y :-5350000.0grid_mapping_grid_boundary_left_projected_x :-3850000.0grid_mapping_grid_boundary_right_projected_x :3750000.0grid_mapping_grid_boundary_top_projected_y :5850000.0grid_mapping_latitude_of_projection_origin :90.0grid_mapping_longitude_of_projection_origin :-45.0grid_mapping_name :polar_stereographicgrid_mapping_parent_grid_cell_column_subset_end :304.0grid_mapping_parent_grid_cell_column_subset_start :0.0grid_mapping_parent_grid_cell_row_subset_end :448.0grid_mapping_parent_grid_cell_row_subset_start :0.0grid_mapping_proj4text :+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_scaling_factor :1.0grid_mapping_semimajor_radius :6378273.0grid_mapping_semiminor_radius :6356889.449grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3411\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3411grid_mapping_standard_parallel :70.0grid_mapping_straight_vertical_longitude_from_pole :135.0grid_mapping_units :metershistory :HISTORY_ATTRIBUTE\n2023-09-13T18:20:14Z (local files)\n2023-09-13T18:20:14Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]id :https://doi.org/10.7265/sr8p-kc62infoUrl :https://nsidc.org/data/g02202/versions/4/institution :NSIDC &gt; National Snow and Ice Data Centerkeywords :algorithm, america, arctic, area, atlantic, barents, bay, beaufort, bering, bootstrap, canada, cdr_seaice_conc_monthly, center, chukchi, climate, common, concentration, continent, CONTINENT &gt; NORTH AMERICA &gt; CANADA &gt; HUDSON BAY, Continent &gt; North America &gt; Canada &gt; Hudson Bay, cryosphere, data, davis, day, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Arctic, Geographic Region &gt; Northern Hemisphere, Geographic Region &gt; Polar, goddard, gsfc, gulf, hemisphere, hudson, ice, ice distribution, lawrence, mayen, melt, melt_onset_day_cdr_seaice_conc_monthly, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, north, northern, norwegian, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Arctic Ocean, Ocean &gt; Arctic Ocean &gt; Barents Sea, Ocean &gt; Arctic Ocean &gt; Beaufort Sea, Ocean &gt; Arctic Ocean &gt; Chukchi Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Davis Straight, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; GULF OF ST LAWRENCE, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; North Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Norwegian Sea, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; SVALBARD AND JAN MAYEN, Ocean &gt; Pacific Ocean, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Bering Sea, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Sea Of Okhotsk, oceans, okhotsk, onset, over, pacific, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, straight, svalbard, tdim, team, versionkeywords_vocabulary :GCMD Science Keywordslicense :No constraints on data access or usemetadata_link :https://nsidc.org/data/g02202/versions/4/naming_authority :org.doi.dxplatform :DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17processing_level :NOAA Level 3product_version :v04r00program :NOAA Climate Data Record Programproj_crs_code :EPSG:3411proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.project :NOAA/NSIDC passive microwave sea ice concentration climate data recordreferences :Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7): 15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1sensor :SSMI/S &gt; Special Sensor Microwave Imager/Soundersoftware_version_id :git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897source :ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220901_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220902_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220903_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220904_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220905_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220906_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220907_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220908_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220909_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220910_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220911_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220912_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220913_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220914_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220915_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220916_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220917_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220918_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220919_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220920_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220921_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220922_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220923_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220924_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220925_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220926_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220927_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220928_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220929_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220930_f17_v04r00.ncsourceUrl :(local files)spatial_resolution :25kmstandard_name_vocabulary :CF Standard Name Table v70summary :This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).time_coverage_duration :P1Mtime_coverage_end :2021-01-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2021-01-01T00:00:00Ztitle :Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\n\n\n\n\nDisplay the sea ice cover data as a map\nThe sea ice concentration values range from zero (no ice cover) to 1 (100% ice cover). However, this dataset also includes values above 1 to flag features like lakes, coastline, and land. Therefore, included in the code below is a step to remove those flag values from the mapping workflow.\n\nimg = ds['cdr_seaice_conc_monthly'].squeeze()\n\n# Remove flag values\nimg = img.where(img &lt;= 1)\n\n# Make plot area\nfig, ax = plt.subplots(figsize=(8, 10))\n\n# Set the color palette\ncmap = mpl.cm.get_cmap(\"Blues_r\").copy()\ncmap.set_bad(color='gray')\n\n# show image\nshw = ax.imshow(img, cmap=cmap, vmin=0, vmax=1)\n\n# Make the colorbar\nbar = plt.colorbar(shw, shrink=0.75)\n\n# show plot with labels\nplt.xlabel('X Grid (m)')\nplt.ylabel('Y Grid (m)')\nbar.set_label('Sea Ice Cover (fractional coverage)')\nplt.show()"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#get-area-information-from-the-ancillary-grid-dataset",
    "href": "tutorials/python/calculating-sea-ice-extent.html#get-area-information-from-the-ancillary-grid-dataset",
    "title": "Calculating sea ice area and extent",
    "section": "Get area information from the ancillary grid dataset",
    "text": "Get area information from the ancillary grid dataset\nWhile the resolution of this data set is 25km (25km by 25km grid), the actual area of the grid depends on the grid projection. To obtain area value, we will need to:\n* Subset the Polar Stereographic Ancillary Grid Information dataset to match our SIC dataset and * Extract the area values for each grid cell.\n\nAccess the Ancillary Grid with OPeNDAP web services\nERDDAP allows you to access data using OPeNDAP web services. The OPeNDAP protocol allows you to create the xarray dataset object directly from the remote server, without downloading a data file onto your computer. When you request the subset of the dataset (e.g. the sub_area object below), the data are uploaded directly into an xarray data array.\n\n# Open xarray dataset object via an OPeNDAP connection\ngrid_url = 'https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k'\ngrid_area = xr.open_dataset(grid_url)\n\n# Subset grid area to match SIC data grids\nsub_area = grid_area.sel(x=slice(ds['xgrid'].min(), ds['xgrid'].max()),\n                         y=slice(ds['ygrid'].max(), ds['ygrid'].min())\n                         )\nsub_area\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:    (y: 389, x: 304)\nCoordinates:\n  * y          (y) float64 4.838e+06 4.812e+06 ... -4.838e+06 -4.862e+06\n  * x          (x) float64 -3.838e+06 -3.812e+06 ... 3.712e+06 3.738e+06\nData variables:\n    cell_area  (y, x) float64 ...\nAttributes: (12/52)\n    acknowledgement:                                     These data are produ...\n    cdm_data_type:                                       Grid\n    contributor_name:                                    J. Scott Stewart, Wa...\n    contributor_role:                                    Scientific Programme...\n    Conventions:                                         CF-1.6, ACDD-1.3, CO...\n    creator_name:                                        NASA National Snow a...\n    ...                                                  ...\n    publisher_type:                                      institution\n    publisher_url:                                       https://nsidc.org/daac\n    sourceUrl:                                           (local files)\n    standard_name_vocabulary:                            CF Standard Name Tab...\n    summary:                                             This data set provid...\n    title:                                               Polar Stereographic ...xarray.DatasetDimensions:y: 389x: 304Coordinates: (2)y(y)float644.838e+06 4.812e+06 ... -4.862e+06actual_range :[-5337500.  5837500.]axis :Yioos_category :Locationlong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metersvalid_range :[-5350000.  5850000.]array([ 4837500.,  4812500.,  4787500., ..., -4812500., -4837500., -4862500.])x(x)float64-3.838e+06 -3.812e+06 ... 3.738e+06actual_range :[-3837500.  3737500.]axis :Xioos_category :Locationlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metersvalid_range :[-3850000.  3750000.]array([-3837500., -3812500., -3787500., ...,  3687500.,  3712500.,  3737500.])Data variables: (1)cell_area(y, x)float64...colorBarMaximum :700000000.0colorBarMinimum :300000000.0comment :Surface area of grid cellcoverage_content_type :imageioos_category :Unknownlong_name :Grid Cell areastandard_name :cell_areaunits :meters^2valid_range :[3.82658854e+08 6.64448303e+08][118256 values with dtype=float64]Indexes: (2)yPandasIndexPandasIndex(Float64Index([ 4837500.0,  4812500.0,  4787500.0,  4762500.0,  4737500.0,\n               4712500.0,  4687500.0,  4662500.0,  4637500.0,  4612500.0,\n              ...\n              -4637500.0, -4662500.0, -4687500.0, -4712500.0, -4737500.0,\n              -4762500.0, -4787500.0, -4812500.0, -4837500.0, -4862500.0],\n             dtype='float64', name='y', length=389))xPandasIndexPandasIndex(Float64Index([-3837500.0, -3812500.0, -3787500.0, -3762500.0, -3737500.0,\n              -3712500.0, -3687500.0, -3662500.0, -3637500.0, -3612500.0,\n              ...\n               3512500.0,  3537500.0,  3562500.0,  3587500.0,  3612500.0,\n               3637500.0,  3662500.0,  3687500.0,  3712500.0,  3737500.0],\n             dtype='float64', name='x', length=304))Attributes: (52)acknowledgement :These data are produced and supported by the NASA National Snow and Ice Data Center Distributed Active Archive Center.cdm_data_type :Gridcontributor_name :J. Scott Stewart, Walter N. Meier, Donna J. Scottcontributor_role :Scientific Programmer, Project Scientist, Project LeadConventions :CF-1.6, ACDD-1.3, COARDScreator_name :NASA National Snow and Ice Data Center Distributed Active Archive Centercreator_type :groupcreator_url :https://www.nasa.gov/date_created :2022-03-21date_metadata_modified :2022-03-21date_modified :2022-03-21geospatial_bounds :POLYGON ((-3850000 5850000, 3750000 5850000, 3750000 -5350000, -3850000 -5350000, -3850000 5850000))geospatial_bounds_crs :EPSG:3411geospatial_x_resolution :25000 metersgeospatial_x_units :metersgeospatial_y_resolution :25000 metersgeospatial_y_units :metersgrid_mapping_crs_wkt :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],AUTHORITY[\"EPSG\",\"3411\"]]grid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3850000 25000 0 5850000 0 -25000grid_mapping_inverse_flattening :298.279411123064grid_mapping_latitude_of_projection_origin :90.0grid_mapping_long_name :NSIDC_NH_PolarStereo_25kmgrid_mapping_longitude_of_prime_meridian :0.0grid_mapping_name :polar_stereographicgrid_mapping_proj4text :+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_semi_major_axis :6378273.0grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],AUTHORITY[\"EPSG\",\"3411\"]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3411grid_mapping_standard_parallel :70.0grid_mapping_straight_vertical_longitude_from_pole :-45.0history :2023-09-13T18:20:35Z (local files)\n2023-09-13T18:20:35Z https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k.dasid :10.5067/N6INPBT8Y104infoUrl :https://doi.org/10.5067/N6INPBT8Y104institution :NASA National Snow and Ice Data Center Distributed Active Archive Centerkeywords :active, analysis, ancillary, archive, area, cell, cell_area, center, data, distributed, earth, EARTH SCIENCE SERVICES &gt; DATA ANALYSIS AND VISUALIZATION &gt; GEOGRAPHIC INFORMATION SYSTEMS, geographic, grid, ice, information, nasa, national, nsidc, polar, science, services, snow, stereo, systems, visualizationkeywords_vocabulary :GCMD Science Keywordslicense :Access Constraint: These data are freely, openly, and fully accessible, provided that you are logged into your NASA Earthdata profile (https://urs.earthdata.nasa.gov/);  Use Constraint: These data are freely, openly, and fully available to use without restrictions, provided that you cite the data according to the recommended citation at https://nsidc.org/about/use_copyright.html. For more information on the NASA EOSDIS Data Use Policy, see https://earthdata.nasa.gov/earth-observation-data/data-use-policy.metadata_link :https://doi.org/10.5067/N6INPBT8Y104naming_authority :org.doi.dxproduct_version :1.0program :NASA Earth Science Data and Information System (ESDIS)publisher_email :nsidc@nsidc.orgpublisher_institution :National Snow and Ice Data Center; Cooperative Institute for Research in Environmental Sciences; University of Colorado at Boulder; Boulder, COpublisher_name :NASA National Snow and Ice Data Center Distributed Active Archive Centerpublisher_type :institutionpublisher_url :https://nsidc.org/daacsourceUrl :(local files)standard_name_vocabulary :CF Standard Name Table v70summary :This data set provides the total on-Earth surface area values at the center of each grid cell of 25km polar stereographic gridded data sets (North) distributed by The National Snow and Ice Data Centertitle :Polar Stereographic Grid Cell Area Values of 25km gridded data sets , Polar Stereographic (North), Ancillary Data\n\n\n\n\nCombine the subsetted grid to the SIC dataset\nAdd subsetted area values from grid_area dataset as a new layer in the sea ice concentration dataset.\n\n# Add agrid area to the dataset\nds['area'] = (('ygrid', 'xgrid'), sub_area.cell_area.values)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 1, ygrid: 389, xgrid: 304)\nCoordinates:\n  * time                     (time) datetime64[ns] 2021-01-01\n  * ygrid                    (ygrid) float32 4.838e+06 4.812e+06 ... -4.862e+06\n  * xgrid                    (xgrid) float32 -3.838e+06 -3.812e+06 ... 3.738e+06\nData variables:\n    cdr_seaice_conc_monthly  (time, ygrid, xgrid) float32 ...\n    area                     (ygrid, xgrid) float64 4.266e+08 ... 4.289e+08\nAttributes: (12/65)\n    acknowledgement:                                     This project was sup...\n    cdm_data_type:                                       Grid\n    cdr_variable:                                        cdr_seaice_conc_monthly\n    comment:                                             The variable melt_on...\n    contributor_name:                                    Walter N. Meier, Flo...\n    contributor_role:                                    principal investigat...\n    ...                                                  ...\n    summary:                                             This data set provid...\n    time_coverage_duration:                              P1M\n    time_coverage_end:                                   2021-01-01T00:00:00Z\n    time_coverage_resolution:                            P1M\n    time_coverage_start:                                 2021-01-01T00:00:00Z\n    title:                                               Sea Ice Concentratio...xarray.DatasetDimensions:time: 1ygrid: 389xgrid: 304Coordinates: (3)time(time)datetime64[ns]2021-01-01_ChunkSizes :1024_CoordinateAxisType :Timeactual_range :[1.6094592e+09 1.6094592e+09]axis :Tioos_category :Timelong_name :ANSI datestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2021-01-01T00:00:00.000000000'], dtype='datetime64[ns]')ygrid(ygrid)float324.838e+06 4.812e+06 ... -4.862e+06_ChunkSizes :448actual_range :[-4862500.  4837500.]axis :Yioos_category :Locationlong_name :projection_grid_y_centersstandard_name :projection_y_coordinateunits :metersvalid_range :[-5350000.  5850000.]array([ 4837500.,  4812500.,  4787500., ..., -4812500., -4837500., -4862500.],\n      dtype=float32)xgrid(xgrid)float32-3.838e+06 -3.812e+06 ... 3.738e+06_ChunkSizes :304actual_range :[-3837500.  3737500.]axis :Xioos_category :Locationlong_name :projection_grid_x_centersstandard_name :projection_x_coordinateunits :metersvalid_range :[-3850000.  3750000.]array([-3837500., -3812500., -3787500., ...,  3687500.,  3712500.,  3737500.],\n      dtype=float32)Data variables: (2)cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...ancillary_variables :stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthlycolorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole lakes coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Northern Hemisphere Sea Ice Concentrationreferences :https://nsidc.org/data/g02202/versions/4/standard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][118256 values with dtype=float32]area(ygrid, xgrid)float644.266e+08 4.274e+08 ... 4.289e+08array([[4.26553150e+08, 4.27406844e+08, 4.28257483e+08, ...,\n        4.31628701e+08, 4.30790677e+08, 4.29949439e+08],\n       [4.27630452e+08, 4.28487364e+08, 4.29341214e+08, ...,\n        4.32725186e+08, 4.31883987e+08, 4.31039565e+08],\n       [4.28706202e+08, 4.29566333e+08, 4.30423392e+08, ...,\n        4.33820117e+08, 4.32975743e+08, 4.32128138e+08],\n       ...,\n       [4.27630452e+08, 4.28487364e+08, 4.29341214e+08, ...,\n        4.32725186e+08, 4.31883987e+08, 4.31039565e+08],\n       [4.26553150e+08, 4.27406844e+08, 4.28257483e+08, ...,\n        4.31628701e+08, 4.30790677e+08, 4.29949439e+08],\n       [4.25474341e+08, 4.26324815e+08, 4.27172243e+08, ...,\n        4.30530704e+08, 4.29695856e+08, 4.28857803e+08]])Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2021-01-01'], dtype='datetime64[ns]', name='time', freq=None))ygridPandasIndexPandasIndex(Float64Index([ 4837500.0,  4812500.0,  4787500.0,  4762500.0,  4737500.0,\n               4712500.0,  4687500.0,  4662500.0,  4637500.0,  4612500.0,\n              ...\n              -4637500.0, -4662500.0, -4687500.0, -4712500.0, -4737500.0,\n              -4762500.0, -4787500.0, -4812500.0, -4837500.0, -4862500.0],\n             dtype='float64', name='ygrid', length=389))xgridPandasIndexPandasIndex(Float64Index([-3837500.0, -3812500.0, -3787500.0, -3762500.0, -3737500.0,\n              -3712500.0, -3687500.0, -3662500.0, -3637500.0, -3612500.0,\n              ...\n               3512500.0,  3537500.0,  3562500.0,  3587500.0,  3612500.0,\n               3637500.0,  3662500.0,  3687500.0,  3712500.0,  3737500.0],\n             dtype='float64', name='xgrid', length=304))Attributes: (65)acknowledgement :This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.cdm_data_type :Gridcdr_variable :cdr_seaice_conc_monthlycomment :The variable melt_onset_day_cdr_seaice_conc_monthly is not available for this month.contributor_name :Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fishercontributor_role :principal investigator, author, author, software developer, software developer, software developerConventions :CF-1.6, ACDD-1.3, COARDScreator_email :nsidc@nsidc.orgcreator_name :NSIDCcreator_type :institutioncreator_url :https://nsidc.org/date_created :2023-02-22T23:18:04ZdefaultGraphQuery :cdr_seaice_conc_monthly[last]%5B(-5337500.0)%5D%5B(3737500.0)%5D&.draw=surfacegrid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3850000.0 25000.0 0 5850000.0 0 -25000.0grid_mapping_grid_boundary_bottom_projected_y :-5350000.0grid_mapping_grid_boundary_left_projected_x :-3850000.0grid_mapping_grid_boundary_right_projected_x :3750000.0grid_mapping_grid_boundary_top_projected_y :5850000.0grid_mapping_latitude_of_projection_origin :90.0grid_mapping_longitude_of_projection_origin :-45.0grid_mapping_name :polar_stereographicgrid_mapping_parent_grid_cell_column_subset_end :304.0grid_mapping_parent_grid_cell_column_subset_start :0.0grid_mapping_parent_grid_cell_row_subset_end :448.0grid_mapping_parent_grid_cell_row_subset_start :0.0grid_mapping_proj4text :+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_scaling_factor :1.0grid_mapping_semimajor_radius :6378273.0grid_mapping_semiminor_radius :6356889.449grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3411\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3411grid_mapping_standard_parallel :70.0grid_mapping_straight_vertical_longitude_from_pole :135.0grid_mapping_units :metershistory :HISTORY_ATTRIBUTE\n2023-09-13T18:20:14Z (local files)\n2023-09-13T18:20:14Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]id :https://doi.org/10.7265/sr8p-kc62infoUrl :https://nsidc.org/data/g02202/versions/4/institution :NSIDC &gt; National Snow and Ice Data Centerkeywords :algorithm, america, arctic, area, atlantic, barents, bay, beaufort, bering, bootstrap, canada, cdr_seaice_conc_monthly, center, chukchi, climate, common, concentration, continent, CONTINENT &gt; NORTH AMERICA &gt; CANADA &gt; HUDSON BAY, Continent &gt; North America &gt; Canada &gt; Hudson Bay, cryosphere, data, davis, day, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Arctic, Geographic Region &gt; Northern Hemisphere, Geographic Region &gt; Polar, goddard, gsfc, gulf, hemisphere, hudson, ice, ice distribution, lawrence, mayen, melt, melt_onset_day_cdr_seaice_conc_monthly, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, north, northern, norwegian, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Arctic Ocean, Ocean &gt; Arctic Ocean &gt; Barents Sea, Ocean &gt; Arctic Ocean &gt; Beaufort Sea, Ocean &gt; Arctic Ocean &gt; Chukchi Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Davis Straight, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; GULF OF ST LAWRENCE, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; North Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Norwegian Sea, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; SVALBARD AND JAN MAYEN, Ocean &gt; Pacific Ocean, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Bering Sea, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Sea Of Okhotsk, oceans, okhotsk, onset, over, pacific, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, straight, svalbard, tdim, team, versionkeywords_vocabulary :GCMD Science Keywordslicense :No constraints on data access or usemetadata_link :https://nsidc.org/data/g02202/versions/4/naming_authority :org.doi.dxplatform :DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17processing_level :NOAA Level 3product_version :v04r00program :NOAA Climate Data Record Programproj_crs_code :EPSG:3411proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.project :NOAA/NSIDC passive microwave sea ice concentration climate data recordreferences :Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7): 15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1sensor :SSMI/S &gt; Special Sensor Microwave Imager/Soundersoftware_version_id :git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897source :ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220901_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220902_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220903_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220904_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220905_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220906_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220907_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220908_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220909_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220910_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220911_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220912_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220913_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220914_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220915_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220916_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220917_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220918_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220919_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220920_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220921_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220922_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220923_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220924_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220925_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220926_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220927_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220928_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220929_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220930_f17_v04r00.ncsourceUrl :(local files)spatial_resolution :25kmstandard_name_vocabulary :CF Standard Name Table v70summary :This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).time_coverage_duration :P1Mtime_coverage_end :2021-01-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2021-01-01T00:00:00Ztitle :Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#compute-sea-ice-area-and-extent",
    "href": "tutorials/python/calculating-sea-ice-extent.html#compute-sea-ice-area-and-extent",
    "title": "Calculating sea ice area and extent",
    "section": "Compute sea ice area and extent",
    "text": "Compute sea ice area and extent\nAlthough area and extent may sound the same, they are different measurements. * Sea ice area is the total region covered by ice, i.e. area that is 100% covered by ice. * Sea ice extent is the total region with at least 15 percent sea ice cover.\nTherefore, extent will give higher values than area.\n\n# Subset the dataset to exclude flag values (value &gt; 1)\nseaice_ds = ds.where(ds.cdr_seaice_conc_monthly &lt;= 1)\n\n# Set all cell with &lt; 15% ice cover to zero\n# Leave the other cells unchanged\ncells_15ice_andup = xr.where(seaice_ds.cdr_seaice_conc_monthly.squeeze() &lt; 0.15, \n                             0,  # Set to 0\n                             seaice_ds.cdr_seaice_conc_monthly.squeeze()   # Set to 1\n                             )\n\n# Calculate sea ice area\nicearea = seaice_ds.area * cells_15ice_andup\n\n# Convert the units from m^2 to km^2\nicearea_km = np.sum(icearea) / 1000000\nprint(\"Sea Ice Area (km^2): \", icearea_km.item())\n\n# Compute sea ice extent\n# Find all cells with &lt; 0.15 ice cover and set to 0, Set all other cells to 1\ncells_15ice_andup = xr.where(seaice_ds.cdr_seaice_conc_monthly.squeeze() &lt; 0.15,\n                             0,  # Set to 0\n                             1  # Set to 1\n                             )\n\n# Calculate sea ice extent\nextent = seaice_ds.area * cells_15ice_andup\nextent_km = np.sum(extent)/1000000\nprint(\"Sea Ice Extent (km^2):\", extent_km.item())\n\nSea Ice Area (km^2):  12528341.191722928\nSea Ice Extent (km^2): 13808725.557170859"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#create-a-time-series-with-12-months-of-data",
    "href": "tutorials/python/calculating-sea-ice-extent.html#create-a-time-series-with-12-months-of-data",
    "title": "Calculating sea ice area and extent",
    "section": "Create a time series with 12 months of data",
    "text": "Create a time series with 12 months of data\n\nFor the next exercise, download 12 months of SIC data from 2021. Then, compute sea ice area and extent for each month and plot the time series.\nThe first step is to change our ERDDAP data query URL to request the 12 month time period. To do this, change the second part of the Time coverage component of the URL December of 2021 (see the table below).\n\n\n\n\n\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID for dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nNetCDF (there are many other available file formats)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariables from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]\nTemporal range\n\n\nspatial_range\n[(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\nSpatial range\n\n\n\nThe modified ERDDAP data request URL for this data subset is presented below:\nurl=“https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:( 2021-12-01T00:00:00Z )][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\nWe can generate the URL quickly by changing the “date_range” variable\n* From: date_range = '[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)]'\n* To: date_range = '[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]'\nThen rerunning the code to generate the ERDDAP data query URL.\n\ndate_range = '[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]'\n\nurl = ''.join([base_url,\n               datasetID,\n               file_type,\n               query_start,\n               variable_name,\n               date_range,\n               spatial_range\n               ])\nurl\n\n'https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]'\n\n\n\n\nGenerate the sea ice area and extent time series\n\n# Download 12 months of data\nurllib.request.urlretrieve(url, \"sic12.nc\")\n\n# Open the netCDF file to create an Xarray dataset object\nds = xr.open_dataset(\"sic12.nc\")\n\n# Add grid area to the dataset\ncell_area = sub_area.cell_area.values\nds['area'] = (('ygrid', 'xgrid'), cell_area)\n\n# Subset the dataset to exclude flag values\nseaice_ds = ds.where(ds.cdr_seaice_conc_monthly &lt;= 1)\n\n# Find all cells with &lt; 0.15 ice cover and set to 0.\n# Leave the other cells unchanged\ncells_15ice_andup_ts = xr.where(seaice_ds.cdr_seaice_conc_monthly &lt; 0.15, \n                                0,  # Set to 0\n                                seaice_ds.cdr_seaice_conc_monthly\n                                )\n\n# Calculate sea ice area for each time layer\nicearea_timeseries = seaice_ds.area * cells_15ice_andup_ts\n\n# Sum area for each time step and convert to km^2\nicearea_timeseries_km = icearea_timeseries.sum(dim=['xgrid', 'ygrid']) / 1000000\n\n# Find all cells with &lt; 0.15 ice cover and set to 0. Set all other cells to 1\ncells_15ice_andup_ts = xr.where(seaice_ds.cdr_seaice_conc_monthly &lt; 0.15,\n                                0,  # Set to 0\n                                1  # Set to 1\n                                )\n\n# Calculate sea ice extent by month\nextent_timeseries = seaice_ds.area * cells_15ice_andup_ts\n\n# # Sum extent for each time step and convert units to km^2\nextent_timeseries_km = extent_timeseries.sum(dim=['xgrid', 'ygrid']) / 1000000\n\n\n\nPlot the sea ice area and extent time series\n\n\nfig, ax = plt.subplots(figsize=(10, 4))\n\n# Plot the data as a line\nax.plot(icearea_timeseries_km.time, \n        icearea_timeseries_km,\n        label='Sea ice area',\n        marker='o', \n        linestyle='-')\n\nax.plot(extent_timeseries_km.time,\n        extent_timeseries_km,\n        label='Sea ice extent',\n        marker='s', \n        linestyle='-')\n\n# Add a title and labels\nax.set_title('2021 Monthly Sea ice area and sea ice extent')\nax.set_xlabel('Date')\nax.set_ylabel('Area (km^2)')\n\n# Display the legend\nax.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#references",
    "href": "tutorials/python/calculating-sea-ice-extent.html#references",
    "title": "Calculating sea ice area and extent",
    "section": "References",
    "text": "References\n\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nPolarWatch Data Catalog\nWhat’s the difference between Sea ice area and extent?\nNSIDC Arctic Sea Ice News & Analysis\nClimate.gov Understanding Climate: sea ice extent\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html",
    "title": "Make a virtual buoy with satellite data",
    "section": "",
    "text": "History | Updated August 2023 ## Background There are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov) and ARGO floats program (http://www.argo.ucsd.edu). Despite these impressive efforts to monitor environmental conditions, in situ buoy data may not be available for your area of interest. Some locations are hard to access, making deploying and maintaining a buoy impractical. In addition, buoys are expensive to purchase, deploy and maintain. Therefore, limited funding may prevent installation of a buoy or the continued operation of a buoy already in place.\nUsing satellite data to create virtual buoys can provide a solution to monitoring surface environmental conditions at locations where it is not feasible to install a buoy. For example, the University of South Florida has developed a virtual buoy system for locations off the Florida coast (https://optics.marine.usf.edu/projects/vbs.html)."
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#objectives",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#objectives",
    "title": "Make a virtual buoy with satellite data",
    "section": "Objectives",
    "text": "Objectives\nThe following exercise will demonstrate the use of the ERDDAP data server to create a virtual buoy. For the scenario, we will envision that a virtual buoy is needed to continue the datastream for an in situ buoy that was discontinued at the end of 2019. For this exercise we will use the National Data Buoy Center (NDBC) buoy # 46259, which is located off the California coast at 34.767N latitude and -121.497E longitude, and pretend that it was discontinued at the end of 2019. The buoy measures several oceanic variables, but we will continue the sea surface temperature (SST) datastream using NOAA GeoPolar Blended SST satellite dataset."
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#the-tutorial-demonstrates-the-following-skills",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#the-tutorial-demonstrates-the-following-skills",
    "title": "Make a virtual buoy with satellite data",
    "section": "The tutorial demonstrates the following skills:",
    "text": "The tutorial demonstrates the following skills:\n\nThe use of ERDDAP to create a virtual buoy\n\nThe use of the pandas and xarray modules to import and manipulate data\n\nResampling data to bin them into a lower resolution time steps\nGenerating a linear regression and statistics\nPlotting time-series data\n\nCleaning data to remove outlying data points"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#datasets-used",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#datasets-used",
    "title": "Make a virtual buoy with satellite data",
    "section": "Datasets used",
    "text": "Datasets used\nNDBC Buoy Data\nThe National Data Buoy Center (NDBC) distributes meteorological data from moored buoys maintained by NDBC and others. They are deployed in the coastal and offshore waters from the western Atlantic to the Pacific Ocean around Hawaii, and from the Bering Sea to the South Pacific. For this tutorial we will use buoy number 46259. NDBC data are available from the CoastWatch West Coast Node ERDDAP. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#import-required-modules",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#import-required-modules",
    "title": "Make a virtual buoy with satellite data",
    "section": "Import required modules",
    "text": "Import required modules\n\nimport numpy as np\nimport xarray as xr\nfrom datetime import datetime\nimport os\nimport pandas as pd\nimport io\nimport requests\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\nfrom sklearn.metrics import r2_score\n\n# the %matplotlib is a magic function allow displaying results in notebooks\n%matplotlib inline\n\n# some tools for Pandas to work will with matplotlib\nfrom pandas.plotting import register_matplotlib_converters"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#a-note-about-tabledap",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#a-note-about-tabledap",
    "title": "Make a virtual buoy with satellite data",
    "section": "A note about tabledap",
    "text": "A note about tabledap\nMost of our examples in this course use gridded datasets. The NDBC data for this tutorial is a tabular dataset, served via the tabledap part of ERDDAP. The API for tabledap is a little different than for gridded datasets. You can go to the following URL and play around with subsetting. Then push the “Just generate the URL” button, copy the link, put it in a browser. See if you get what you expected. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet\nA quick primer is below\nThe data request URL has three parts: 1. Base URL: https://url/erddap/tabledap/datasetID.fileType? * e.g. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?\n\nA list of variables you want to download that are separated by commas\n\n\n\ne.g. station,longitude,latitude,time,wtmp\n\n\nA list of constraints, each starting with an ampersand (&).\n\n\nThe constraints use =, &gt;, &gt;=, &lt;, and &lt;= to subset the data\ne.g. &station=“46259”, mean station # 46259\ne.g. &time&gt;=2017-01-01T&time&lt;=2020-12-31’, means time between and including Jan. 1, 2017 and Dec. 31, 2020.\n\nThe data request URL we will use for the NDBC data:\nndbc_url = 'https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?station,longitude,latitude,time,wtmp&station=\"46259\"&time&gt;=2017-01-01T&time&lt;=2020-12-31"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#download-the-data-into-a-pandas-dataframe",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#download-the-data-into-a-pandas-dataframe",
    "title": "Make a virtual buoy with satellite data",
    "section": "Download the data into a Pandas dataframe",
    "text": "Download the data into a Pandas dataframe\n\n# Break the url into part and rejoin it so that it is easier to see.\nndbc_url = ''.join(['https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?',\n                    'station,longitude,latitude,time,wtmp',\n                    '&station=\"46259\"&time&gt;=2018-01-01&time&lt;=2019-12-31'\n                    ])\n\nreq = requests.get(ndbc_url).content\nbuoy_df = pd.read_csv(io.StringIO(req.decode('utf-8')), skiprows=[1], parse_dates=['time'])\nbuoy_df.head(2)\n\n\n\n\n\n\n\n\nstation\nlongitude\nlatitude\ntime\nwtmp\n\n\n\n\n0\n46259\n-121.664\n34.732\n2018-01-01 00:22:00+00:00\n14.6\n\n\n1\n46259\n-121.664\n34.732\n2018-01-01 00:52:00+00:00\n14.6\n\n\n\n\n\n\n\n\nExtract the longitude and latitude coordinates for the station\nAfter, clean up the dataframe by deleting unneeded columns.\n\nbuoy_lat = buoy_df.latitude[0]\nbuoy_lon = buoy_df.longitude[0]\n\n# Clean up the dataset by removing unneeded columns\ndel buoy_df['station']\ndel buoy_df['latitude']\ndel buoy_df['longitude'] \n\nprint('latitude', buoy_lat)\nprint('longitude', buoy_lon)\n\nlatitude 34.732\nlongitude -121.664"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-buoy-data",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-buoy-data",
    "title": "Make a virtual buoy with satellite data",
    "section": "Process the buoy data",
    "text": "Process the buoy data\nThe measurement rate of the buoy is on the order of minutes. We need to downsample the dataset to the daily resolution of the satellite dataset.\nThere are a few cleanup steps that are needed:\n* The time data are associated with the UTC time zone. Panda operations often don’t like time zones so let’s get rid of it. * Rename the SST variable to something more intuitive\n\nprint('# of timesteps before =', buoy_df.shape[0] )\n\n# The resampling will put time as the df index\nbuoy_df_resampled = buoy_df.resample('D', on='time').mean()\nprint('# of timesteps after =', buoy_df_resampled.shape[0] )\n\n# Remove the timezone (UTC, GMT).\nbuoy_df_resampled = buoy_df_resampled.tz_localize(None)\n\n# Rename the SST variable\nbuoy_df_resampled.rename(columns={\"wtmp\": \"sst_buoy\"}, errors=\"raise\", inplace=True)\nbuoy_df_resampled\n\nbuoy_df_resampled.head(2)\n\n# of timesteps before = 34455\n# of timesteps after = 730\n\n\n\n\n\n\n\n\n\nsst_buoy\n\n\ntime\n\n\n\n\n\n2018-01-01\n14.679167\n\n\n2018-01-02\n14.891489"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#load-the-satellite-data-into-xarray-and-subset",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#load-the-satellite-data-into-xarray-and-subset",
    "title": "Make a virtual buoy with satellite data",
    "section": "Load the satellite data into xarray and subset",
    "text": "Load the satellite data into xarray and subset\n\n# Put satellite data xarray dataset object\nsst_url = 'https://coastwatch.noaa.gov/erddap/griddap/noaacwBLENDEDCsstDaily'\nsst_ds = xr.open_dataset(sst_url)\n\n# Subset the dataset\nsst_ds_subset = sst_ds['analysed_sst'].sel(latitude=buoy_lat,\n                            longitude = buoy_lon, method='nearest'\n                            ).sel(time=slice('2018-01-01', \n                                             '2019-12-31'\n                                             ))\n\nsst_ds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'analysed_sst' (time: 692)&gt;\n[692 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 2018-01-01T12:00:00 ... 2019-12-31T12:00:00\n    latitude   float32 34.72\n    longitude  float32 -121.7\nAttributes:\n    colorBarMaximum:  35.0\n    colorBarMinimum:  0.0\n    comment:          nighttime analysed SST for each ocean grid point\n    ioos_category:    Temperature\n    long_name:        analysed sea surface temperature\n    references:       Fieguth,P.W. et al. \"Mapping Mediterranean altimeter da...\n    standard_name:    sea_surface_foundation_temperature\n    units:            degree_Cxarray.DataArray'analysed_sst'time: 692...[692 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]2018-01-01T12:00:00 ... 2019-12-..._CoordinateAxisType :Timeactual_range :[1.0308816e+09 1.6938288e+09]axis :Tcomment :Nominal time of Level 4 analysisioos_category :Timelong_name :reference time of sst fieldstandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2018-01-01T12:00:00.000000000', '2018-01-02T12:00:00.000000000',\n       '2018-01-03T12:00:00.000000000', ..., '2019-12-29T12:00:00.000000000',\n       '2019-12-30T12:00:00.000000000', '2019-12-31T12:00:00.000000000'],\n      dtype='datetime64[ns]')latitude()float3234.72_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projectionioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array(34.725, dtype=float32)longitude()float32-121.7_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projectionioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array(-121.675, dtype=float32)Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2018-01-01 12:00:00', '2018-01-02 12:00:00',\n               '2018-01-03 12:00:00', '2018-01-04 12:00:00',\n               '2018-01-05 12:00:00', '2018-01-06 12:00:00',\n               '2018-01-07 12:00:00', '2018-01-08 12:00:00',\n               '2018-01-09 12:00:00', '2018-02-09 12:00:00',\n               ...\n               '2019-12-22 12:00:00', '2019-12-23 12:00:00',\n               '2019-12-24 12:00:00', '2019-12-25 12:00:00',\n               '2019-12-26 12:00:00', '2019-12-27 12:00:00',\n               '2019-12-28 12:00:00', '2019-12-29 12:00:00',\n               '2019-12-30 12:00:00', '2019-12-31 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=692, freq=None))Attributes: (8)colorBarMaximum :35.0colorBarMinimum :0.0comment :nighttime analysed SST for each ocean grid pointioos_category :Temperaturelong_name :analysed sea surface temperaturereferences :Fieguth,P.W. et al. \"Mapping Mediterranean altimeter data with a multiresolution optimal interpolation algorithm\", J. Atmos. Ocean Tech, 15\n (2): 535-546, 1998.     Fieguth, P. Multiply-Rooted Multiscale Models for Large-Scale Estimation, IEEE Image Processing, 10(11), 1676-1686, 2001.     Khellah, F., P.W. Fieguth, M.J. M\nurray and M.R. Allen, \"Statistical Processing of Large Image Sequences\", IEEE Transactions on Geoscience and Remote Sensing, 12 (1), 80-93, 2005.standard_name :sea_surface_foundation_temperatureunits :degree_C"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-satellite-data-to-make-them-compatible-with-the-buoy-data",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-satellite-data-to-make-them-compatible-with-the-buoy-data",
    "title": "Make a virtual buoy with satellite data",
    "section": "Process the satellite data to make them compatible with the buoy data",
    "text": "Process the satellite data to make them compatible with the buoy data\n\nPut the satellite data into a Pandas dataframe\nResample the data to daily bins: The data are already daily, but resampling them makes the timestamp format the same as for the buoy data, and puts time into the index column of the dataframe.\nRemove the timezone localization from time\n\n\n# Initialize data\nsat_data = {'time': sst_ds_subset.time.values,\n            'sst_sat': sst_ds_subset.to_numpy()\n            }\n\n# Creates pandas DataFrame.\nsat_df = pd.DataFrame(sat_data)\n\n# Resample\nsat_df = sat_df.resample('D', on='time').mean()\n\n# Remove timezone\nsat_df = sat_df.tz_localize(None)\n\n\nsat_df.head(2)\n\n\n\n\n\n\n\n\nsst_sat\n\n\ntime\n\n\n\n\n\n2018-01-01\n14.18\n\n\n2018-01-02\n14.76"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#merge-the-datasets",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#merge-the-datasets",
    "title": "Make a virtual buoy with satellite data",
    "section": "Merge the datasets",
    "text": "Merge the datasets\n\nmerged_df = pd.merge(buoy_df_resampled, \n                     sat_df, \n                     left_index=True, \n                     right_index=True).reset_index()\nmerged_df.head(2)\n\n\n\n\n\n\n\n\ntime\nsst_buoy\nsst_sat\n\n\n\n\n0\n2018-01-01\n14.679167\n14.18\n\n\n1\n2018-01-02\n14.891489\n14.76"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#plot-the-data-along-the-same-time-x-axis",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#plot-the-data-along-the-same-time-x-axis",
    "title": "Make a virtual buoy with satellite data",
    "section": "Plot the data along the same time (x) axis",
    "text": "Plot the data along the same time (x) axis\nThe data from the buoy and satellite seem to track each other very well (below). * You will want to at least run a linear regression to determine how well satellite data reflects the in situ buoy measurements.\n\nplt.figure(figsize = (10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(merged_df.index, merged_df.sst_buoy, \n              'o', markersize=3, \n              label='Buoy', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(merged_df.index, merged_df.sst_sat,  \n              's', markersize=3, \n              label='Satellite', c='blue', \n              linestyle='-', linewidth=1) \n\n#plt.ylim([0, 3])\nplt.ylabel('SST (degrees C)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#clean-up-the-merged-dataset",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#clean-up-the-merged-dataset",
    "title": "Make a virtual buoy with satellite data",
    "section": "Clean up the merged dataset",
    "text": "Clean up the merged dataset\nRegression packages typically do not like nan’s. * Delete rows with nan\nThe data could contain data points that are outliers. Let’s remove those points from the data frame. * Apply a conservative allowable data range. - For the lower end of the range, the freezing point of seawater (ca. -2).\n- For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n\n# Drop nan\nclean_merged_df = merged_df.dropna()\n\n# Drop &lt; -2 and &gt; 45\nclean_merged_df = clean_merged_df.drop(clean_merged_df[(clean_merged_df['sst_sat'] &lt; -2) \n                                       | (clean_merged_df['sst_sat'] &gt; 45)].index)"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#run-the-regression",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#run-the-regression",
    "title": "Make a virtual buoy with satellite data",
    "section": "Run the regression",
    "text": "Run the regression\n\n# Regression packages typically do not like nan's. Delete rows with nan\nclean_merged_df = merged_df.dropna()\n\n# Generate the regression plot\nsns.regplot(x='sst_buoy', y='sst_sat', data=clean_merged_df)\n\n# Calculate the slope and intercept\nslope, intercept = np.polyfit(clean_merged_df[\"sst_buoy\"], clean_merged_df[\"sst_sat\"], 1)\n\n# Calculate R2\nr2 = r2_score(clean_merged_df[\"sst_sat\"], clean_merged_df[\"sst_buoy\"])\n\n# Annotate the plot\nplt.annotate(f\"y = {slope:.2f}x + {intercept:.2f},  R2 = {r2:.2f}\", \n             xy=(12, 18), \n             #xytext=(30, 5), \n             fontsize=12, \n             color=\"black\", \n             ha=\"left\")\n\nprint(slope, intercept)\n\n# To save your data, uncomment the next line\n# clean_merged_df.to_csv(\"virtual_buoy_example.csv\", index=False)\n\n0.9338037509902803 0.9930764222028932"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#it-looks-like-your-virtual-buoy-is-ready-for-operations",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#it-looks-like-your-virtual-buoy-is-ready-for-operations",
    "title": "Make a virtual buoy with satellite data",
    "section": "It looks like your virtual buoy is ready for operations",
    "text": "It looks like your virtual buoy is ready for operations\n\nThere is essentially a one-to-one relationship between buoy and satellite SST. The slope (0.93) is very close to 1\nThe R2 indicates that 90% of the variability of satellite SST is explained by the regression."
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html",
    "title": "Extract data within a boundary",
    "section": "",
    "text": "History | Updated Sep 2023"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#background",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#background",
    "title": "Extract data within a boundary",
    "section": "Background",
    "text": "Background\nOne use for satellite observations is to supplement in situ sampling of geographical locations where the timespan or frequency measurements, or spatial dimensions or remoteness of the locations, make physical sampling impossible or impractical. One drawback is that satellite data are often rectangular, whereas geographical locations can have irregular boundaries. Examples of locations with boundaries include Marine Protected Areas or marine physical, biological, and ecological divisions like the Longhurst Marine Provinces."
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#objectives",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#objectives",
    "title": "Extract data within a boundary",
    "section": "Objectives",
    "text": "Objectives\nIn this tutorial we will learn how to download a timeseries of SST satellite data from an ERDDAP server, and then mask the data to retain only the data within an irregular geographical boundary (polygon). We will then plot a yearly seasonal cycle from within the boundary."
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Extract data within a boundary",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data from an ERDDAP data server\nVisualizing data on a map\nMasking satellite data using a shape file"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#datasets-used",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#datasets-used",
    "title": "Extract data within a boundary",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Geo-polar Blended Analysis Sea-Surface Temperature, Global, Monthly, 5km, 2019-Present\nThe NOAA geo-polar blended SST is a high resolution satellite-based sea surface temperature (SST) product that combines SST data from US, Japanese and European geostationary infrared imagers, and low-earth orbiting infrared (U.S. and European) SST data, into a single product. We will use the monthly composite. https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly\nLonghurst Marine Provinces\nThe dataset represents the division of the world oceans into provinces as defined by Longhurst (1995; 1998; 2006). This division has been based on the prevailing role of physical forcing as a regulator of phytoplankton distribution. The Longhurst Marine Provinces dataset is available online (https://www.marineregions.org/downloads.php) and within the shapes folder associated with this repository. For this tutorial we will use the Gulf Stream province (ProvCode: GFST)\n\n\n\n../images/longhurst.png"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#import-packages",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#import-packages",
    "title": "Extract data within a boundary",
    "section": "Import packages",
    "text": "Import packages\nNote: Make sure you have at least version 0.10.0 of regionmask * To install with conda use “conda install -c conda-forge regionmask=0.10.0 cartopy”\n\nimport matplotlib.pyplot as plt\nimport xarray as xr\nimport geopandas\nimport regionmask\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport warnings\nimport os\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#load-the-longhurst-provinces-shape-files-into-a-geopandas-dataframe",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#load-the-longhurst-provinces-shape-files-into-a-geopandas-dataframe",
    "title": "Extract data within a boundary",
    "section": "Load the Longhurst Provinces shape files into a geopandas dataframe",
    "text": "Load the Longhurst Provinces shape files into a geopandas dataframe\n\n#shape_path = '../resources/longhurst_v4_2010/Longhurst_world_v4_2010.shp'\nshape_path = os.path.join('..',\n                          'resources',\n                          'longhurst_v4_2010',\n                          'Longhurst_world_v4_2010.shp'\n                          )\nshapefiles = geopandas.read_file(shape_path)\nshapefiles.head(8)\n\n\n\n\n\n\n\n\nProvCode\nProvDescr\ngeometry\n\n\n\n\n0\nBPLR\nPolar - Boreal Polar Province (POLR)\nMULTIPOLYGON (((-161.18426 63.50000, -161.5000...\n\n\n1\nARCT\nPolar - Atlantic Arctic Province\nMULTIPOLYGON (((-21.51305 64.64409, -21.55945 ...\n\n\n2\nSARC\nPolar - Atlantic Subarctic Province\nMULTIPOLYGON (((11.26472 63.96082, 11.09548 63...\n\n\n3\nNADR\nWesterlies - N. Atlantic Drift Province (WWDR)\nPOLYGON ((-11.50000 57.50000, -11.50000 56.500...\n\n\n4\nGFST\nWesterlies - Gulf Stream Province\nPOLYGON ((-43.50000 43.50000, -43.50000 42.500...\n\n\n5\nNASW\nWesterlies - N. Atlantic Subtropical Gyral Pro...\nPOLYGON ((-39.50000 25.50000, -40.50000 25.500...\n\n\n6\nNATR\nTrades - N. Atlantic Tropical Gyral Province (...\nMULTIPOLYGON (((-72.34673 18.53597, -72.36877 ...\n\n\n7\nWTRA\nTrades - Western Tropical Atlantic Province\nPOLYGON ((-19.50000 -6.50000, -20.50000 -6.500..."
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#isolate-the-gulf-stream-province",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#isolate-the-gulf-stream-province",
    "title": "Extract data within a boundary",
    "section": "Isolate the Gulf Stream Province",
    "text": "Isolate the Gulf Stream Province\nThe Gulf Stream Province can be isolated using its ProvCode (GFST)\n\nProvCode = \"GFST\"\n\n# Locate the row with the ProvCode code\ngulf_stream = shapefiles.loc[shapefiles[\"ProvCode\"] == ProvCode]\ngulf_stream\n\n\n\n\n\n\n\n\nProvCode\nProvDescr\ngeometry\n\n\n\n\n4\nGFST\nWesterlies - Gulf Stream Province\nPOLYGON ((-43.50000 43.50000, -43.50000 42.500..."
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#find-the-coordinates-of-the-bounding-box",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#find-the-coordinates-of-the-bounding-box",
    "title": "Extract data within a boundary",
    "section": "Find the coordinates of the bounding box",
    "text": "Find the coordinates of the bounding box\n\nThe bounding box is the smallest rectangle that will completely enclose the province.\nWe will use the bounding box coordinates to subset the satellite data\n\n\ngs_bnds = gulf_stream.bounds\ngs_bnds\n\n\n\n\n\n\n\n\nminx\nminy\nmaxx\nmaxy\n\n\n\n\n4\n-73.5\n33.5\n-43.5\n43.5"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#open-the-satellite-dataset-into-a-xarray-dataset-object",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#open-the-satellite-dataset-into-a-xarray-dataset-object",
    "title": "Extract data within a boundary",
    "section": "Open the satellite dataset into a xarray dataset object",
    "text": "Open the satellite dataset into a xarray dataset object\n\nerddap_url = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                       'erddap',\n                       'griddap',\n                       'NOAA_DHW_monthly'\n                       ])\n\nds = xr.open_dataset(erddap_url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                          (time: 464, latitude: 3600, longitude: 7200)\nCoordinates:\n  * time                             (time) datetime64[ns] 1985-01-16 ... 202...\n  * latitude                         (latitude) float32 89.97 89.93 ... -89.97\n  * longitude                        (longitude) float32 -180.0 -179.9 ... 180.0\nData variables:\n    sea_surface_temperature          (time, latitude, longitude) float32 ...\n    mask                             (time, latitude, longitude) float32 ...\n    sea_surface_temperature_anomaly  (time, latitude, longitude) float32 ...\nAttributes: (12/66)\n    _NCProperties:                    version=2,netcdf=4.8.1,hdf5=1.12.2\n    acknowledgement:                  NOAA Coral Reef Watch program\n    cdm_data_type:                    Grid\n    comment:                          This is a product of NOAA Coral Reef Wa...\n    contributor_name:                 NOAA Coral Reef Watch program\n    contributor_role:                 Collecting source data and deriving pro...\n    ...                               ...\n    time_coverage_duration:           P1M\n    time_coverage_end:                2023-08-16T00:00:00Z\n    time_coverage_resolution:         P1M\n    time_coverage_start:              1985-01-16T00:00:00Z\n    title:                            SST and SST Anomaly, NOAA Global Coral ...\n    Westernmost_Easting:              -179.975xarray.DatasetDimensions:time: 464latitude: 3600longitude: 7200Coordinates: (3)time(time)datetime64[ns]1985-01-16 ... 2023-08-16_CoordinateAxisType :Timeactual_range :[4.746816e+08 1.692144e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1985-01-16T00:00:00.000000000', '1985-02-16T00:00:00.000000000',\n       '1985-03-16T00:00:00.000000000', ..., '2023-06-16T00:00:00.000000000',\n       '2023-07-16T00:00:00.000000000', '2023-08-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3289.97 89.93 89.88 ... -89.92 -89.97_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([ 89.975   ,  89.92501 ,  89.87501 , ..., -89.875   , -89.924995,\n       -89.975   ], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-179.975  , -179.925  , -179.875  , ...,  179.875  ,  179.92499,\n        179.975  ], dtype=float32)Data variables: (3)sea_surface_temperature(time, latitude, longitude)float32...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[12026880000 values with dtype=float32]mask(time, latitude, longitude)float32...colorBarMaximum :5.0colorBarMinimum :0.0comment :A 2D array, in the same size as the data array in the X and Y directions, the classifies land, ice pixels, and water (data) pixelscoverage_content_type :thematicClassificationflag_meanings :valid-water land missing iceflag_values :[0 1 2 4]ioos_category :Qualitylong_name :Pixel characteristics flag arrayunits :pixel_classification[12026880000 values with dtype=float32]sea_surface_temperature_anomaly(time, latitude, longitude)float32...colorBarMaximum :3.0colorBarMinimum :-3.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :sea surface temperature anomalystandard_name :surface_temperature_anomalyunits :degree_Cvalid_max :15.0valid_min :-15.0[12026880000 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1985-01-16 00:00:00', '1985-02-16 00:00:00',\n               '1985-03-16 00:00:00', '1985-04-16 00:00:00',\n               '1985-05-15 23:00:00', '1985-06-15 23:00:00',\n               '1985-07-15 23:00:00', '1985-08-15 23:00:00',\n               '1985-09-15 23:00:00', '1985-10-15 23:00:00',\n               ...\n               '2022-11-16 00:00:00', '2022-12-16 00:00:00',\n               '2023-01-16 00:00:00', '2023-02-16 00:00:00',\n               '2023-03-16 00:00:00', '2023-04-16 00:00:00',\n               '2023-05-16 00:00:00', '2023-06-16 00:00:00',\n               '2023-07-16 00:00:00', '2023-08-16 00:00:00'],\n              dtype='datetime64[ns]', name='time', length=464, freq=None))latitudePandasIndexPandasIndex(Index([  89.9749984741211,  89.92501068115234,  89.87500762939453,\n        89.82500457763672,   89.7750015258789,   89.7249984741211,\n        89.67501068115234,  89.62500762939453,  89.57500457763672,\n         89.5250015258789,\n       ...\n        -89.5250015258789, -89.57499694824219,            -89.625,\n       -89.67499542236328,  -89.7249984741211,  -89.7750015258789,\n       -89.82499694824219,            -89.875, -89.92499542236328,\n        -89.9749984741211],\n      dtype='float32', name='latitude', length=3600))longitudePandasIndexPandasIndex(Index([-179.97500610351562,  -179.9250030517578,            -179.875,\n       -179.82501220703125, -179.77500915527344, -179.72500610351562,\n        -179.6750030517578,            -179.625, -179.57501220703125,\n       -179.52500915527344,\n       ...\n        179.52499389648438,  179.57501220703125,             179.625,\n        179.67498779296875,  179.72500610351562,  179.77499389648438,\n        179.82501220703125,             179.875,  179.92498779296875,\n        179.97500610351562],\n      dtype='float32', name='longitude', length=7200))Attributes: (66)_NCProperties :version=2,netcdf=4.8.1,hdf5=1.12.2acknowledgement :NOAA Coral Reef Watch programcdm_data_type :Gridcomment :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite Version 3.1, derived from CoralTemp v1.0.contributor_name :NOAA Coral Reef Watch programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archive.Conventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch programcreator_name :NOAA Coral Reef Watch programcreator_type :groupcreator_url :https://coralreefwatch.noaa.govdate_created :2018-03-01T12:00:00Zdate_issued :2019-01-19T20:32:23Zdate_metadata_modified :2018-09-01T12:00:00Zdate_modified :2018-03-01T12:00:00ZEasternmost_Easting :179.975geospatial_bounds :POLYGON((-90.0 180.0, 90.0 180.0, 90.0 -180.0, -90.0 -180.0, -90.0 180.0))geospatial_bounds_crs :EPSG:4326geospatial_lat_max :89.975geospatial_lat_min :-89.975geospatial_lat_units :degrees_northgeospatial_lon_max :179.975geospatial_lon_min :-179.975geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:32663grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Tue Jul 27 10:37:54 2021: ncrename -d lon,longitude -d lat,latitude -v lon,longitude -v lat,latitude -v sea surface temperature anomaly,sea_surface_temperature_anomaly /cwdata/coralreef/work/temp.nc\nMonthly data files for mean sea surface temperature (SST) and sea surface temperature anomaly (SST anomaly) were downloaded from ftp.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1/nc/v1.0/monthly. Monthly files were created that contain both SST and SST anomaly data, and a mask of earth surface classifications.\n2023-09-06T18:39:14Z (local files)\n2023-09-06T18:39:14Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.dasid :Satellite_Global_5km_CoralTemp_SST_SSTA_Monthly_Mean_CompositeinfoUrl :https://coralreefwatch.noaa.gov/product/5km/index.phpinstitution :NOAA/NESDIS/STAR Coral Reef Watch programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, anomaly, array, characteristics, coral, crw, data, earth, Earth Science &gt; Land Surface &gt; Land Temperature &gt; Land Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature Anomaly, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, flag, global, information, infrared, land, latitude, longitude, mask, mean, month, monthly, national, nesdis, noaa, ocean, oceans, pixel, program, quality, reef, satellite, science, sea, sea_surface_temperature, sea_surface_temperature_anomaly, seawater, service, spectral, spectral/engineering, sst, star, surface, surface_temperature_anomaly, temperature, thermal, time, v.3.1, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of the Coral Reef Watch website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/product/5km/index.phpnaming_authority :gov.noaa.coralreefwatchNCO :\"4.6.3\"Northernmost_Northing :89.975platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :Derived from L4 satellite sea surface temperature analysisproduct_version :3.1program :NOAA Coral Reef Watch programproject :NOAA Coral Reef Watch programpublisher_email :erd.data at noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch programpublisher_name :NOAA NMFS SWFSC ERD, CoastWatch West Coast Nodepublisher_type :institutionpublisher_url :https://coralreefwatch.noaa.gov, https://coastwatch.pfeg.noaa.gov/references :https://coralreefwatch.noaa.gov/product/5km/index.php and https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :Coral Reef Watch CoralTemp v1.0sourceUrl :(local files)Southernmost_Northing :-89.975spatial_resolution :0.05 degreestandard_name_vocabulary :CF Standard Name Table v27summary :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite, derived from CoralTemp v1.0.time_coverage_duration :P1Mtime_coverage_end :2023-08-16T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :1985-01-16T00:00:00Ztitle :SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring, 5km, V.3.1, Monthly, 1985-PresentWesternmost_Easting :-179.975"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#subset-the-satellite-data",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#subset-the-satellite-data",
    "title": "Extract data within a boundary",
    "section": "Subset the satellite data",
    "text": "Subset the satellite data\n\nUse the bounding box coordinates for the latitude and longitude slices\nSelect the entire year of 2020\n\n\n# This dataset has latitude in descending order. \n# Therefore use maxy first and miny last to slice latitude\nds_subset = ds['sea_surface_temperature'].sel(time=slice(\"2020-01-16\", \"2020-12-16\"),\n                                              latitude=slice(gs_bnds.maxy.item(), \n                                                             gs_bnds.miny.item()),\n                                              longitude=slice(gs_bnds.minx.item(), \n                                                              gs_bnds.maxx.item())\n                                            )\nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'sea_surface_temperature' (time: 12, latitude: 200,\n                                             longitude: 600)&gt;\n[1440000 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 2020-01-16 2020-02-16 ... 2020-12-16\n  * latitude   (latitude) float32 43.47 43.43 43.38 43.33 ... 33.62 33.58 33.53\n  * longitude  (longitude) float32 -73.47 -73.42 -73.38 ... -43.62 -43.57 -43.53\nAttributes:\n    colorBarMaximum:        32.0\n    colorBarMinimum:        0.0\n    coverage_content_type:  physicalMeasurement\n    ioos_category:          Temperature\n    long_name:              analysed sea surface temperature\n    standard_name:          sea_surface_temperature\n    units:                  degree_C\n    valid_max:              50.0\n    valid_min:              -2.0xarray.DataArray'sea_surface_temperature'time: 12latitude: 200longitude: 600...[1440000 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]2020-01-16 ... 2020-12-16_CoordinateAxisType :Timeactual_range :[4.746816e+08 1.692144e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2020-01-16T00:00:00.000000000', '2020-02-16T00:00:00.000000000',\n       '2020-03-15T23:00:00.000000000', '2020-04-15T23:00:00.000000000',\n       '2020-05-15T23:00:00.000000000', '2020-06-15T23:00:00.000000000',\n       '2020-07-15T23:00:00.000000000', '2020-08-15T23:00:00.000000000',\n       '2020-09-15T23:00:00.000000000', '2020-10-15T23:00:00.000000000',\n       '2020-11-16T00:00:00.000000000', '2020-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3243.47 43.43 43.38 ... 33.58 33.53_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([43.475   , 43.42501 , 43.375008, 43.325005, 43.275   , 43.225   ,\n       43.17501 , 43.125008, 43.075005, 43.025   , 42.975   , 42.92501 ,\n       42.875008, 42.825005, 42.775   , 42.725   , 42.67501 , 42.625008,\n       42.575005, 42.525   , 42.475   , 42.42501 , 42.375008, 42.325005,\n       42.275   , 42.225   , 42.17501 , 42.125008, 42.075005, 42.025   ,\n       41.975   , 41.92501 , 41.875008, 41.825005, 41.775   , 41.725   ,\n       41.67501 , 41.625008, 41.575005, 41.525   , 41.475   , 41.42501 ,\n       41.375008, 41.325005, 41.275   , 41.225   , 41.17501 , 41.125008,\n       41.075005, 41.025   , 40.975   , 40.92501 , 40.875008, 40.825005,\n       40.775   , 40.725   , 40.67501 , 40.625008, 40.575005, 40.525   ,\n       40.475   , 40.42501 , 40.375008, 40.325005, 40.275   , 40.225   ,\n       40.17501 , 40.125008, 40.075005, 40.025   , 39.975   , 39.92501 ,\n       39.875008, 39.825005, 39.775   , 39.725   , 39.67501 , 39.625008,\n       39.575005, 39.525   , 39.475   , 39.42501 , 39.375008, 39.325005,\n       39.275   , 39.225   , 39.17501 , 39.125008, 39.075005, 39.025   ,\n       38.975   , 38.92501 , 38.875008, 38.825005, 38.775   , 38.725   ,\n       38.67501 , 38.625008, 38.575005, 38.525   , 38.475   , 38.42501 ,\n       38.375008, 38.325005, 38.275   , 38.225   , 38.17501 , 38.125008,\n       38.075005, 38.025   , 37.975006, 37.925003, 37.875   , 37.825005,\n       37.775   , 37.725006, 37.675003, 37.625   , 37.575005, 37.525   ,\n       37.475006, 37.425003, 37.375   , 37.325005, 37.275   , 37.225006,\n       37.175003, 37.125   , 37.075005, 37.025   , 36.975006, 36.925003,\n       36.875   , 36.825005, 36.775   , 36.725006, 36.675003, 36.625   ,\n       36.575005, 36.525   , 36.475006, 36.425003, 36.375   , 36.325005,\n       36.275   , 36.225006, 36.175003, 36.125   , 36.075005, 36.025   ,\n       35.975006, 35.925003, 35.875   , 35.825005, 35.775   , 35.725006,\n       35.675003, 35.625   , 35.575005, 35.525   , 35.475006, 35.425003,\n       35.375   , 35.325005, 35.275   , 35.225006, 35.175003, 35.125   ,\n       35.075005, 35.025   , 34.975006, 34.925003, 34.875   , 34.825005,\n       34.775   , 34.725006, 34.675003, 34.625   , 34.575005, 34.525   ,\n       34.475006, 34.425003, 34.375   , 34.325005, 34.275   , 34.225006,\n       34.175003, 34.125   , 34.075005, 34.025   , 33.975006, 33.925003,\n       33.875   , 33.825005, 33.775   , 33.725006, 33.675003, 33.625   ,\n       33.575005, 33.525   ], dtype=float32)longitude(longitude)float32-73.47 -73.42 ... -43.57 -43.53_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-73.475   , -73.424995, -73.375   , ..., -43.624992, -43.57499 ,\n       -43.525   ], dtype=float32)Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2020-01-16 00:00:00', '2020-02-16 00:00:00',\n               '2020-03-15 23:00:00', '2020-04-15 23:00:00',\n               '2020-05-15 23:00:00', '2020-06-15 23:00:00',\n               '2020-07-15 23:00:00', '2020-08-15 23:00:00',\n               '2020-09-15 23:00:00', '2020-10-15 23:00:00',\n               '2020-11-16 00:00:00', '2020-12-16 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))latitudePandasIndexPandasIndex(Index([43.474998474121094, 43.425010681152344,  43.37500762939453,\n        43.32500457763672, 43.275001525878906, 43.224998474121094,\n       43.175010681152344,  43.12500762939453,  43.07500457763672,\n       43.025001525878906,\n       ...\n       33.975006103515625,  33.92500305175781,             33.875,\n        33.82500457763672, 33.775001525878906, 33.725006103515625,\n        33.67500305175781,             33.625,  33.57500457763672,\n       33.525001525878906],\n      dtype='float32', name='latitude', length=200))longitudePandasIndexPandasIndex(Index([  -73.4749984741211,  -73.42499542236328,             -73.375,\n        -73.32499694824219,  -73.27499389648438,   -73.2249984741211,\n        -73.17499542236328,             -73.125,  -73.07499694824219,\n        -73.02499389648438,\n       ...\n       -43.974998474121094,  -43.92499542236328,  -43.87499237060547,\n       -43.824989318847656, -43.775001525878906, -43.724998474121094,\n        -43.67499542236328,  -43.62499237060547, -43.574989318847656,\n       -43.525001525878906],\n      dtype='float32', name='longitude', length=600))Attributes: (9)colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#visualize-the-unmasked-data-on-a-map",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#visualize-the-unmasked-data-on-a-map",
    "title": "Extract data within a boundary",
    "section": "Visualize the unmasked data on a map",
    "text": "Visualize the unmasked data on a map\nThe map shows the full extent of the bounding box\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([260, 350, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nds_subset[0].plot.pcolormesh(ax=ax1, transform=ccrs.PlateCarree(), cmap='jet')\n\nplt.title('Satellite Data Before Masking')\n\nText(0.5, 1.0, 'Satellite Data Before Masking')"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#create-the-region-from-the-shape-file",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#create-the-region-from-the-shape-file",
    "title": "Extract data within a boundary",
    "section": "Create the region from the shape file",
    "text": "Create the region from the shape file\nThe plot shows the shape of the region and its placement along the US East Coast.\n\nregion = regionmask.from_geopandas(gulf_stream)\nregion.plot()"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#mask-the-satellite-data",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#mask-the-satellite-data",
    "title": "Extract data within a boundary",
    "section": "Mask the satellite data",
    "text": "Mask the satellite data\n\n# Create the mask\nmask = region.mask(ds_subset.longitude, ds_subset.latitude)\n\n# Apply mask the the satellite data\nmasked_ds = ds_subset.where(mask == region.numbers[0])"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#visualize-the-masked-data-on-a-map",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#visualize-the-masked-data-on-a-map",
    "title": "Extract data within a boundary",
    "section": "Visualize the masked data on a map",
    "text": "Visualize the masked data on a map\nThese data have been trimmed to contain only values within the Gulf Stream Province\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([260, 350, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nmasked_ds[0].plot.pcolormesh(ax=ax1,\n                             transform=ccrs.PlateCarree(),\n                             cmap='jet')\n\nplt.title('Satellite Data After Masking for Longhurst GFST')\n\n\nText(0.5, 1.0, 'Satellite Data After Masking for Longhurst GFST')"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#plot-the-mean-seasonal-temperature-for-the-province",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#plot-the-mean-seasonal-temperature-for-the-province",
    "title": "Extract data within a boundary",
    "section": "Plot the mean seasonal temperature for the province",
    "text": "Plot the mean seasonal temperature for the province\n\ngulf_stream_mean = masked_ds.mean(dim=['latitude', 'longitude'])\n\n\ngulf_stream_mean\n\nplt.figure(figsize=(10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(gulf_stream_mean.time,\n              gulf_stream_mean, \n              'o', markersize=8, \n              label='gulf stream', c='black', \n              linestyle='-', linewidth=2) \n\nplt.title('Gulf Stream Province Monthly Mean Temperature 2020')\nplt.ylabel('SST(degrees C)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#references",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#references",
    "title": "Extract data within a boundary",
    "section": "References",
    "text": "References\nThe several CoastWatch Node websites have data catalog containing documentation and links to all the datasets available:\n* https://oceanwatch.pifsc.noaa.gov/doc.html\n* https://coastwatch.pfeg.noaa.gov/data.html\n* https://polarwatch.noaa.gov/catalog/\nSources for marine shape files * https://www.marineregions.org/downloads.php"
  },
  {
    "objectID": "tutorials/python/gl-ice-plot-timeseries-ice-conc.html",
    "href": "tutorials/python/gl-ice-plot-timeseries-ice-conc.html",
    "title": "Summary",
    "section": "",
    "text": "This example is based on the OceanWatch tutorial meterial edited with Great Lakes satellite data.In this example you will see how to extract Great Lakes ice concentration data from the ERDDAP server and make a ice concentration map, and caculate the monthly\n\nThe example demonstrates the following techniques:\n\nLoading Great Lakes ice concentration data from Great Lakes ERDDAP data server.\nCreate a map of ice concentration.\nCompute the daily mean over the selected region.\n\n\n\nDatesets used:\n\nGreat Lakes ice concentration: Great Lakes ice concentration product.\n\n\n\nImport the required Python modules\n\nimport xarray as xr\nimport pandas as pd\nimport numpy as np\nimport urllib.request\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport warnings\n#warnings.filterwarnings('ignore')\n\n\n\nDownlading data from ERDDAP server\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure. For example, the following link allows you to subset daily ice concentration data from the dataset GL_Ice_Concentration_GCS\nIn this specific example, we will get the SST data from 2023-06-01 to 2023-06-30. the URL we generated is :\nhttps://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5D\nwe extract the data in csv format due to the nc library not available.\n\nurl=\"https://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5D\"\nurllib.request.urlretrieve(url, \"w_e_ice_concentration.nc\")\n\n('w_e_ice_concentration.nc', &lt;http.client.HTTPMessage at 0x1b687bf22d0&gt;)\n\n\n\n\nImporting NetCDF4 data in Python\nNow that we’ve downloaded the data locally, we can import it and extract our variables of interest.\nThe xarray package makes it very convenient to work with NetCDF files. Documentation is available here: http://xarray.pydata.org/en/stable/why-xarray.html\n\nimport xarray as xr\nimport netCDF4 as nc\n\n\n\nOpen the file and load it as an xarray dataset:\n\nds = xr.open_dataset('w_e_ice_concentration.nc',decode_cf=False)\n#ds = xr.open_dataset('e_sst.nc')\n\n\n\nExamine the data structure:\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:            (time: 7146, latitude: 52, longitude: 79)\nCoordinates:\n  * time               (time) float64 7.89e+08 7.89e+08 ... 1.714e+09 1.715e+09\n  * latitude           (latitude) float64 41.38 41.4 41.41 ... 42.07 42.08 42.1\n  * longitude          (longitude) float64 -83.59 -83.58 -83.56 ... -82.51 -82.5\nData variables:\n    ice_concentration  (time, latitude, longitude) float32 ...\nAttributes: (12/28)\n    cdm_data_type:              Grid\n    Conventions:                CF-1.6, COARDS, ACDD-1.3\n    Easternmost_Easting:        -82.496964466524\n    GDAL:                       GDAL 3.4.3, released 2022/04/22\n    geospatial_lat_max:         42.0985561800016\n    geospatial_lat_min:         41.3837647963109\n    ...                         ...\n    standard_name_vocabulary:   CF Standard Name Table v29\n    summary:                    Ice Concentration from Great Lakes Surface En...\n    time_coverage_end:          2024-05-01T12:00:00Z\n    time_coverage_start:        1995-01-01T12:00:00Z\n    title:                      Ice Concentration from Great Lakes Surface En...\n    Westernmost_Easting:        -83.590174818051xarray.DatasetDimensions:time: 7146latitude: 52longitude: 79Coordinates: (3)time(time)float647.89e+08 7.89e+08 ... 1.715e+09_CoordinateAxisType :Timeactual_range :[7.8896160e+08 1.7145648e+09]axis :Tcalendar :Gregorianioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00units :seconds since 1970-01-01T00:00:00Zarray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])latitude(latitude)float6441.38 41.4 41.41 ... 42.08 42.1_CoordinateAxisType :Latactual_range :[41.3837648  42.09855618]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northarray([41.383765, 41.39778 , 41.411796, 41.425811, 41.439827, 41.453842,\n       41.467858, 41.481873, 41.495889, 41.509904, 41.52392 , 41.537935,\n       41.551951, 41.565967, 41.579982, 41.593998, 41.608013, 41.622029,\n       41.636044, 41.65006 , 41.664075, 41.678091, 41.692106, 41.706122,\n       41.720137, 41.734153, 41.748168, 41.762184, 41.776199, 41.790215,\n       41.80423 , 41.818246, 41.832261, 41.846277, 41.860292, 41.874308,\n       41.888323, 41.902339, 41.916354, 41.93037 , 41.944385, 41.958401,\n       41.972417, 41.986432, 42.000448, 42.014463, 42.028479, 42.042494,\n       42.05651 , 42.070525, 42.084541, 42.098556])longitude(longitude)float64-83.59 -83.58 ... -82.51 -82.5_CoordinateAxisType :Lonactual_range :[-83.59017482 -82.49696447]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastarray([-83.590175, -83.576159, -83.562144, -83.548128, -83.534113, -83.520097,\n       -83.506082, -83.492066, -83.478051, -83.464035, -83.45002 , -83.436004,\n       -83.421989, -83.407973, -83.393958, -83.379942, -83.365927, -83.351911,\n       -83.337896, -83.32388 , -83.309864, -83.295849, -83.281833, -83.267818,\n       -83.253802, -83.239787, -83.225771, -83.211756, -83.19774 , -83.183725,\n       -83.169709, -83.155694, -83.141678, -83.127663, -83.113647, -83.099632,\n       -83.085616, -83.071601, -83.057585, -83.04357 , -83.029554, -83.015539,\n       -83.001523, -82.987508, -82.973492, -82.959477, -82.945461, -82.931446,\n       -82.91743 , -82.903414, -82.889399, -82.875383, -82.861368, -82.847352,\n       -82.833337, -82.819321, -82.805306, -82.79129 , -82.777275, -82.763259,\n       -82.749244, -82.735228, -82.721213, -82.707197, -82.693182, -82.679166,\n       -82.665151, -82.651135, -82.63712 , -82.623104, -82.609089, -82.595073,\n       -82.581058, -82.567042, -82.553027, -82.539011, -82.524996, -82.51098 ,\n       -82.496964])Data variables: (1)ice_concentration(time, latitude, longitude)float32..._FillValue :-99999.0colorBarMaximum :100.0colorBarMinimum :0.0colorBarPalette :WhiteBlackgrid_mapping :crsioos_category :Ocean Colorlong_name :Ice Concentrationstandard_name :ice_concentrationunits :percent[29355768 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(Index([ 788961600.0,  789048000.0,  789134400.0,  789220800.0,  789307200.0,\n        789393600.0,  789480000.0,  789566400.0,  789652800.0,  789739200.0,\n       ...\n       1713787200.0, 1713873600.0, 1713960000.0, 1714046400.0, 1714132800.0,\n       1714219200.0, 1714305600.0, 1714392000.0, 1714478400.0, 1714564800.0],\n      dtype='float64', name='time', length=7146))latitudePandasIndexPandasIndex(Index([41.3837647963109, 41.3977803136382, 41.4117958309654, 41.4258113482927,\n         41.43982686562, 41.4538423829472, 41.4678579002745, 41.4818734176018,\n        41.495888934929, 41.5099044522563, 41.5239199695836, 41.5379354869108,\n       41.5519510042381, 41.5659665215654, 41.5799820388927, 41.5939975562199,\n       41.6080130735472, 41.6220285908745, 41.6360441082017,  41.650059625529,\n       41.6640751428563, 41.6780906601835, 41.6921061775108, 41.7061216948381,\n       41.7201372121653, 41.7341527294926, 41.7481682468199, 41.7621837641471,\n       41.7761992814744, 41.7902147988017,  41.804230316129, 41.8182458334562,\n       41.8322613507835, 41.8462768681108,  41.860292385438, 41.8743079027653,\n       41.8883234200926, 41.9023389374198, 41.9163544547471, 41.9303699720744,\n       41.9443854894016, 41.9584010067289, 41.9724165240562, 41.9864320413835,\n       42.0004475587107,  42.014463076038, 42.0284785933653, 42.0424941106925,\n       42.0565096280198, 42.0705251453471, 42.0845406626743, 42.0985561800016],\n      dtype='float64', name='latitude'))longitudePandasIndexPandasIndex(Index([ -83.590174818051, -83.5761593007237, -83.5621437833965,\n       -83.5481282660692, -83.5341127487419, -83.5200972314146,\n       -83.5060817140874, -83.4920661967601, -83.4780506794328,\n       -83.4640351621056, -83.4500196447783,  -83.436004127451,\n       -83.4219886101238, -83.4079730927965, -83.3939575754692,\n       -83.3799420581419, -83.3659265408147, -83.3519110234874,\n       -83.3378955061601, -83.3238799888329, -83.3098644715056,\n       -83.2958489541783, -83.2818334368511, -83.2678179195238,\n       -83.2538024021965, -83.2397868848693,  -83.225771367542,\n       -83.2117558502147, -83.1977403328874, -83.1837248155602,\n       -83.1697092982329, -83.1556937809057, -83.1416782635784,\n       -83.1276627462511, -83.1136472289238, -83.0996317115966,\n       -83.0856161942693,  -83.071600676942, -83.0575851596148,\n       -83.0435696422875, -83.0295541249602,  -83.015538607633,\n       -83.0015230903057, -82.9875075729784, -82.9734920556511,\n       -82.9594765383239, -82.9454610209966, -82.9314455036693,\n       -82.9174299863421, -82.9034144690148, -82.8893989516875,\n       -82.8753834343603,  -82.861367917033, -82.8473523997057,\n       -82.8333368823785, -82.8193213650512, -82.8053058477239,\n       -82.7912903303966, -82.7772748130694, -82.7632592957421,\n       -82.7492437784149, -82.7352282610876, -82.7212127437603,\n        -82.707197226433, -82.6931817091058, -82.6791661917785,\n       -82.6651506744512,  -82.651135157124, -82.6371196397967,\n       -82.6231041224694, -82.6090886051422, -82.5950730878149,\n       -82.5810575704876, -82.5670420531603, -82.5530265358331,\n       -82.5390110185058, -82.5249955011785, -82.5109799838513,\n        -82.496964466524],\n      dtype='float64', name='longitude'))Attributes: (28)cdm_data_type :GridConventions :CF-1.6, COARDS, ACDD-1.3Easternmost_Easting :-82.496964466524GDAL :GDAL 3.4.3, released 2022/04/22geospatial_lat_max :42.0985561800016geospatial_lat_min :41.3837647963109geospatial_lat_resolution :0.014015517327269056geospatial_lat_units :degrees_northgeospatial_lon_max :-82.496964466524geospatial_lon_min :-83.590174818051geospatial_lon_resolution :0.01401551732726889geospatial_lon_units :degrees_easthistory :Ice concentration from Great Lakes Surface Environmental Analysis (GLSEA) asc format to nc fromat\n2024-09-18T16:53:43Z (local files)\n2024-09-18T16:53:43Z https://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5DinfoUrl :https://coastwatch.glerl.noaa.gov/glsea/glsea.htmlinstitution :CoastWatch Great Lakes Nodekeywords :analysis, concentration, data, distribution, environmental, glsea, great, great lakes, ice, ice distribution, ice_concentration, lakes, nic, surface, timelicense :The data may be used and redistributed for free but is not intended\nfor legal use, since it may contain inaccuracies. Neither the data\nContributor, ERD, NOAA, nor the United States Government, nor any\nof their employees or contractors, makes any warranty, express or\nimplied, including warranties of merchantability and fitness for a\nparticular purpose, or assumes any legal liability for the accuracy,\ncompleteness, or usefulness, of this information.NCO :netCDF Operators version 5.0.7 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)Northernmost_Northing :42.0985561800016source :Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-presentsourceUrl :(local files)Southernmost_Northing :41.3837647963109standard_name_vocabulary :CF Standard Name Table v29summary :Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NICtime_coverage_end :2024-05-01T12:00:00Ztime_coverage_start :1995-01-01T12:00:00Ztitle :Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-presentWesternmost_Easting :-83.590174818051\n\n\n\n\nExamine which coordinates and variables are included in the dataset:\n\n ds.dims\n\nFrozen({'time': 7146, 'latitude': 52, 'longitude': 79})\n\n\n\nds.coords\n\nCoordinates:\n  * time       (time) float64 7.89e+08 7.89e+08 ... 1.714e+09 1.715e+09\n  * latitude   (latitude) float64 41.38 41.4 41.41 41.43 ... 42.07 42.08 42.1\n  * longitude  (longitude) float64 -83.59 -83.58 -83.56 ... -82.52 -82.51 -82.5\n\n\n\nds.data_vars\n\nData variables:\n    ice_concentration  (time, latitude, longitude) float32 ...\n\n\n\nds.attrs\n\n{'cdm_data_type': 'Grid',\n 'Conventions': 'CF-1.6, COARDS, ACDD-1.3',\n 'Easternmost_Easting': -82.496964466524,\n 'GDAL': 'GDAL 3.4.3, released 2022/04/22',\n 'geospatial_lat_max': 42.0985561800016,\n 'geospatial_lat_min': 41.3837647963109,\n 'geospatial_lat_resolution': 0.014015517327269056,\n 'geospatial_lat_units': 'degrees_north',\n 'geospatial_lon_max': -82.496964466524,\n 'geospatial_lon_min': -83.590174818051,\n 'geospatial_lon_resolution': 0.01401551732726889,\n 'geospatial_lon_units': 'degrees_east',\n 'history': 'Ice concentration from Great Lakes Surface Environmental Analysis (GLSEA) asc format to nc fromat\\n2024-09-18T16:53:43Z (local files)\\n2024-09-18T16:53:43Z https://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5D',\n 'infoUrl': 'https://coastwatch.glerl.noaa.gov/glsea/glsea.html',\n 'institution': 'CoastWatch Great Lakes Node',\n 'keywords': 'analysis, concentration, data, distribution, environmental, glsea, great, great lakes, ice, ice distribution, ice_concentration, lakes, nic, surface, time',\n 'license': 'The data may be used and redistributed for free but is not intended\\nfor legal use, since it may contain inaccuracies. Neither the data\\nContributor, ERD, NOAA, nor the United States Government, nor any\\nof their employees or contractors, makes any warranty, express or\\nimplied, including warranties of merchantability and fitness for a\\nparticular purpose, or assumes any legal liability for the accuracy,\\ncompleteness, or usefulness, of this information.',\n 'NCO': 'netCDF Operators version 5.0.7 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)',\n 'Northernmost_Northing': 42.0985561800016,\n 'source': 'Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-present',\n 'sourceUrl': '(local files)',\n 'Southernmost_Northing': 41.3837647963109,\n 'standard_name_vocabulary': 'CF Standard Name Table v29',\n 'summary': 'Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC',\n 'time_coverage_end': '2024-05-01T12:00:00Z',\n 'time_coverage_start': '1995-01-01T12:00:00Z',\n 'title': 'Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-present',\n 'Westernmost_Easting': -83.590174818051}\n\n\n\n\nExamine the structure of ice concentration:\n\nds.ice_concentration.shape\n\n(7146, 52, 79)\n\n\nOur dataset is a 3-D array with 52 rows corresponding to latitudes and 79 columns corresponding to longitudes, for each of the 7146 time steps. #### Get the dates for each time step:\n\nds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 7146)&gt;\narray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])\nCoordinates:\n  * time     (time) float64 7.89e+08 7.89e+08 7.891e+08 ... 1.714e+09 1.715e+09\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [7.8896160e+08 1.7145648e+09]\n    axis:                 T\n    calendar:             Gregorian\n    ioos_category:        Time\n    long_name:            Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00\n    units:                seconds since 1970-01-01T00:00:00Zxarray.DataArray'time'time: 71467.89e+08 7.89e+08 7.891e+08 ... 1.714e+09 1.714e+09 1.715e+09array([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])Coordinates: (1)time(time)float647.89e+08 7.89e+08 ... 1.715e+09_CoordinateAxisType :Timeactual_range :[7.8896160e+08 1.7145648e+09]axis :Tcalendar :Gregorianioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00units :seconds since 1970-01-01T00:00:00Zarray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])Indexes: (1)timePandasIndexPandasIndex(Index([ 788961600.0,  789048000.0,  789134400.0,  789220800.0,  789307200.0,\n        789393600.0,  789480000.0,  789566400.0,  789652800.0,  789739200.0,\n       ...\n       1713787200.0, 1713873600.0, 1713960000.0, 1714046400.0, 1714132800.0,\n       1714219200.0, 1714305600.0, 1714392000.0, 1714478400.0, 1714564800.0],\n      dtype='float64', name='time', length=7146))Attributes: (9)_CoordinateAxisType :Timeactual_range :[7.8896160e+08 1.7145648e+09]axis :Tcalendar :Gregorianioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00units :seconds since 1970-01-01T00:00:00Z\n\n\n\nds.time.attrs\n\n{'_CoordinateAxisType': 'Time',\n 'actual_range': array([7.8896160e+08, 1.7145648e+09]),\n 'axis': 'T',\n 'calendar': 'Gregorian',\n 'ioos_category': 'Time',\n 'long_name': 'Time',\n 'standard_name': 'time',\n 'time_origin': '01-JAN-1970 00:00:00',\n 'units': 'seconds since 1970-01-01T00:00:00Z'}\n\n\n\nprint(ds.time)\n\n&lt;xarray.DataArray 'time' (time: 7146)&gt;\narray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])\nCoordinates:\n  * time     (time) float64 7.89e+08 7.89e+08 7.891e+08 ... 1.714e+09 1.715e+09\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [7.8896160e+08 1.7145648e+09]\n    axis:                 T\n    calendar:             Gregorian\n    ioos_category:        Time\n    long_name:            Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00\n    units:                seconds since 1970-01-01T00:00:00Z\n\n\n\n\nThe time units is seconds, we need to convert the seconds to dates.\n\ndates=nc.num2date(ds.time,ds.time.units,only_use_cftime_datetimes=False, \n                        only_use_python_datetimes=True )\ndates\n\narray([real_datetime(1995, 1, 1, 12, 0), real_datetime(1995, 1, 2, 12, 0),\n       real_datetime(1995, 1, 3, 12, 0), ...,\n       real_datetime(2024, 4, 29, 12, 0),\n       real_datetime(2024, 4, 30, 12, 0),\n       real_datetime(2024, 5, 1, 12, 0)], dtype=object)\n\n\n\n\nFind the index of dates for 2019-03-01\n\nfor i, date in enumerate(dates):\n    if date.strftime(\"%Y-%m-%d\") == \"2019-03-01\":\n        print(i, date)\n\n5872 2019-03-01 12:00:00\n\n\n5872 is the index on the array dates for 2019-03-01.\n\n\nCreate a map of ice concentration for March 1, 2019 (our 5872th time step).\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n#np.warnings.filterwarnings('ignore')\n\n#### Examine the values of ice concentration:\n\nprint(ds.ice_concentration.values)\nprint(ds.ice_concentration.shape)\n\n[[[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n ...\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]]\n(7146, 52, 79)\n\n\n\nds.ice_concentration.attrs\n\n{'_FillValue': -99999.0,\n 'colorBarMaximum': 100.0,\n 'colorBarMinimum': 0.0,\n 'colorBarPalette': 'WhiteBlack',\n 'grid_mapping': 'crs',\n 'ioos_category': 'Ocean Color',\n 'long_name': 'Ice Concentration',\n 'standard_name': 'ice_concentration',\n 'units': 'percent'}\n\n\n\nds.ice_concentration.attrs['_FillValue']\n\n-99999.0\n\n\n\n\nMake a new ice concentration DataArray and replace _fillValue with NaN\n\nnan_ice_concentration = ds.ice_concentration.where(ds.ice_concentration.values != ds.ice_concentration.attrs['_FillValue'])\n\nprint(nan_ice_concentration)\n\n&lt;xarray.DataArray 'ice_concentration' (time: 7146, latitude: 52, longitude: 79)&gt;\narray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n...\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)\nCoordinates:\n  * time       (time) float64 7.89e+08 7.89e+08 ... 1.714e+09 1.715e+09\n  * latitude   (latitude) float64 41.38 41.4 41.41 41.43 ... 42.07 42.08 42.1\n  * longitude  (longitude) float64 -83.59 -83.58 -83.56 ... -82.52 -82.51 -82.5\nAttributes:\n    _FillValue:       -99999.0\n    colorBarMaximum:  100.0\n    colorBarMinimum:  0.0\n    colorBarPalette:  WhiteBlack\n    grid_mapping:     crs\n    ioos_category:    Ocean Color\n    long_name:        Ice Concentration\n    standard_name:    ice_concentration\n    units:            percent\n\n\n\n\nSet some color breaks\n\n# find min value in man_sst\nnp.nanmin(nan_ice_concentration)\n\n0.0\n\n\n\nnp.nanmax(nan_ice_concentration)\n\n99.99847\n\n\n\nlevs = np.arange(0, 101, 10)\nlen(levs)\n\n11\n\n\n\n\nDefine a color palette\n\n# init a color list\njet=[\"blue\", \"#007FFF\", \"cyan\",\"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"]\n\n\n\nSet color scale using the jet palette\n\ncm = LinearSegmentedColormap.from_list('my_jet', jet, N=len(levs))\n\n\n\nplot the ice_concentration map\n\nplt.subplots(figsize=(10, 5))\n\n#plot 5872th ice concentration image: nan_ice_concentration[5872 ,:,:]\nplt.contourf(nan_ice_concentration.longitude, nan_ice_concentration.latitude, nan_ice_concentration[5872,:,:], levs,cmap=cm)\n\n#plot the color scale\nplt.colorbar()\n\n#example of how to add points to the map\n#plt.scatter(np.linspace(-82,-80.5,num=4),np.repeat(42,4),c='black')\n\n#example of how to add a contour line\n#step = np.arange(9,26, 1)\n\n#plt.contour(ds.longitude, ds.latitude, ds.sst[0,:,:],levels=step,linewidths=1)\n\n#plot title\nplt.title(\"West Lake Erie Ice Concentration - \" + dates[5872].strftime('%b %d, %Y'))\nplt.show()\n\n\n\n\n\n\n\n\n\n\nLet’s compute the daily mean over the west Lake Erie region:\n\nres=np.nanmean(nan_ice_concentration,axis=(1,2))\nres\n\narray([0., 0., 0., ..., 0., 0., 0.], dtype=float32)\n\n\n\n\nLet’s plot the time-series (from 2019-03-01 to 2019-03-31):\n\nfor i, date in enumerate(dates):\n    if date.strftime(\"%Y-%m-%d\") == \"2019-03-01\":\n        print(i, date)\n    \n    if date.strftime(\"%Y-%m-%d\") == \"2019-03-31\":\n        print(i, date)\n\n5872 2019-03-01 12:00:00\n5902 2019-03-31 12:00:00\n\n\n\nprint(res.shape)\n\n(7146,)\n\n\n\nplt.figure(figsize=(8,4))\n\nplt.scatter(dates[5872:5902+1],res[5872:5902+1])\n\n#degree_sign = u\"\\N{DEGREE SIGN}\"\nplt.ylabel('Ice Concentration (%)')\n\nplt.xlim(dates[5872], dates[5902+1])\n\nplt.xticks(dates[5872:5902+1],rotation=70, fontsize=10 )\nplt.show()\n\n\n\n\n\n\n\n\n\n!jupyter nbconvert --to html GL_python_tutorial4.ipynb\n\n[NbConvertApp] Converting notebook GL_python_tutorial4.ipynb to html\n[NbConvertApp] Writing 313369 bytes to GL_python_tutorial4.html"
  },
  {
    "objectID": "tutorials/python/gl-timeseries-surface-temp.html",
    "href": "tutorials/python/gl-timeseries-surface-temp.html",
    "title": "Great Lakes longterm water surface temperature plot",
    "section": "",
    "text": "Summary\nIn this example you will see how to extract Great Lakes average water surface temperature data from the ERDDAP server and make a plot of the longterm average water surface temperatue.\n\n\nThe example demonstrates the following techniques:\n\nLoading Great Lakes average water surface temperature data from Great Lakes ERDDAP data server.\nPloting the chart to show the highest and lowest temperature for the specific day.\nPloting the chart using the datetime class as the X axis.\nPloting the chart to show temperature in both degree C and F.\n\n\n\nDatesets used:\n\nGreat Lakes Surface Environmental Analysis (GLSEA): a lakewide average water surface temperauture product.\nWe are using the new developed: ACSPO GLSEA or GLSEA3. ACSPO means Advanced Clear-sky Processor for Oceans.\nThe data files cover from 2007 to current year.\n\n\n\nImport the required Python modules\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n#from PIL import Image\nimport math as m\nfrom datetime import datetime\nimport matplotlib.dates as mdates\n\n\n\n\n\nDefine some function that we need :\nfunction get_366_arry(): Checks to make sure the input array size is 366\n\ndef get_366_arry(t_arry):\n\n    if (t_arry.size &lt; 366):\n        t_arry = np.append(t_arry, np.NAN)\n\n    return t_arry\n\nfunction get_days_arr() takes a year (integer) and reture a list of datetime stamp.\n\ndef get_days_arr(c_yr):\n\n    d = range(1,367)  # range from 1 to 366\n\n    d_list = []\n\n    for i in d:\n\n        d_str = str(c_yr) + ' ' + str(i)\n     \n        d2 = datetime.strptime(d_str, '%Y %j')\n        d_list.append(d2)\n    \n    d_arr = np.array(d_list)\n    #print(d_arr)\n    return d_arr    \n\nfunction draw_plot() takes data array, lake, year Jilian day and years list as input to draw the plat\n\ndef draw_plot(t_all_arry, lake, c_yr, jd,  year_list):\n    \n    begin_day_str = str(c_yr) + '-01-01'  # '2021-01-01'\n    end_day_str = str(c_yr) + '-12-31'    # '2021-12-31'\n    \n    date_marker = [pd.to_datetime(date, format='%Y-%m-%d').date() for date in pd.date_range( begin_day_str, end_day_str, freq=\"ME\")]\n    print(date_marker)\n    \n    days_arr = get_days_arr(c_yr) \n    \n    fig= plt.figure(figsize=(11, 8))\n\n    ax = fig.add_subplot(111)\n\n    number_of_plots = len(year_list) + 1  \n\n    for i, yr4 in enumerate(year_list):\n        ax.plot(days_arr, t_all_arry[i], color='blue', alpha=.1)\n\n    min_v_index_tp = np.where( t_all_arry[:-1,jd] == np.amin(t_all_arry[:-1,jd]))\n    min_v_index = min_v_index_tp[0][0]\n    print(min_v_index)\n    ax.plot(days_arr, t_all_arry[min_v_index], color='green', label=str(year_list[min_v_index]) )\n\n \n    max_v_index_tp = np.where( t_all_arry[:-1,jd] == np.amax(t_all_arry[:-1,jd]))\n\n    max_v_index = max_v_index_tp[0][0]\n    \n    ax.plot(days_arr, t_all_arry[max_v_index], color='red', label=str(year_list[max_v_index]) )\n\n    ax.plot(days_arr, t_all_arry[-1], color='#eb7434', label=str(c_yr) )\n\n    nan_arr = np.empty(366)\n    nan_arr.fill(np.NAN)\n    ax.plot(days_arr, nan_arr, color='blue', alpha=.3, label='Other years' )\n\n    avg_arry = np.nanmean(t_all_arry[:-1], axis=0)\n    \n    ax.plot(days_arr, avg_arry, color='#525150',  label='Average (' + str(year_list[0]) + '-' + str(year_list[-1]) +')' )\n\n    ax.set_ybound(lower=0, upper=30)\n    ax.set_xbound(lower=0, upper=366)\n\n    ax.set_xlim(days_arr[0], days_arr[-1])\n\n    ax.set_xticks(date_marker )\n    dtFmt = mdates.DateFormatter('%b-%d') # define the formatting\n\n    ax.xaxis.set_major_formatter(dtFmt) # apply the format to the desired axis\n\n    ax.set_yticks(range(0,30,2))\n \n    ax.yaxis.set_major_formatter(plt.FuncFormatter('{:.0f}\\u00b0C'.format))  # show degree C char\n\n    ax.set_ylabel('Water Surface Temperature', weight='semibold', fontsize=12)\n    ax.set_xlabel('Months of Year',  weight='semibold', fontsize=12)\n    ax2 = ax.twinx()\n    ax2.set_yticks(range(32,86,4))\n\n    ax2.set_ylim(32, 86)\n\n    ax2.yaxis.set_major_formatter(plt.FuncFormatter('{:.0f}\\u00b0F'.format))  # show degree F char\n \n    ax.grid(True, 'major', 'y', ls='--', lw=.5, c='k', alpha=.3)\n    ax.grid(True, 'major', 'x', ls='--', lw=.5, c='k', alpha=.3)\n\n    fig.suptitle('Lake '  + lake + ' Average GLSEA Surface Water Temperature (' + str(year_list[0]) + ' - ' + str(c_yr) +')', weight='semibold', fontsize=12, ha='center')\n\n    ax.legend(title='YEARS', loc='upper left', ncol=2, fancybox=True)\n\n    plt.figtext(0.1, 0.02, 'NOAA CoastWatch Great Lakes Node', family='sans-serif', style='italic', weight='semibold', size='medium' )\n\n    plt.figtext(0.7, 0.02, datetime.now().strftime(\"%B %d, %Y %H:%M:%S\"), family='sans-serif', style='italic', weight='semibold', size='medium' )\n\n    day = datetime.strptime('{} {}'.format(jd, c_year),'%j %Y')\n    print(day.strftime('%Y %B %d'))\n\n    year_str = '(' + str(year_list[0]) + '-' + str(year_list[-1]) +')'\n\n    plt.figtext(0.20, 0.92, 'The warmest year on ' + day.strftime('%B %d') + ' for the period of record ' + year_str + ' was in ' + str(year_list[max_v_index]) + ' (shown in red)', color='black', fontsize=10 )\n\n    plt.figtext(0.20, 0.90, 'The coldest year on ' + day.strftime('%B %d') + ' for the period of record ' +  year_str + ' was in ' + str(year_list[min_v_index]) + ' (shown in green)', color='black', fontsize=10 )\n \n    plt.show()\n\n\n\nDefine current year and past years range\nGet the current year as an integer number and define a longterm time ranage. In this example, the current year is 2024 and longterm range is 2007 - 2023.\n\nc_year = int(datetime.now().strftime(\"%Y\"))\n \nprint(c_year)\n\nb_year = 2007\n\nyear_list = []\nfor i in range(b_year, c_year):\n    year_list.append(i)\n\nprint(year_list)\n\ntoday = datetime.now()\njd = (today - datetime(today.year, 1, 1)).days \n\n2024\n[2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n\n\n\n\nGet current year’s temperature data from ERDDAP\nThe dataset ID is glsea_avgtemps_3 in the ERDDAP server. The file name of the current year is glsea-temps_1024_3.dat. The file contains 9 lines header information, so we need to skip the first 9 lines when reading the data file. The data in the file are organized in 8 columns, such as Year, Julian day, Lake Superior, Lake Michigan, Lake Huron, Lake Erie, Lake Ontario, and Lake st clr. The file include the average temperature from current day back to 365 days.\neg.\nDaily Lake Average Surface Water Temperature From Great Lakes Surface Environmental Analysis maps\n\n\n\n\n\n\nSurf. Water Temp. (degrees C)\n\n\nYear Day Sup. Mich. Huron Erie Ont. St.Clr\n\n\n\n2023 127 2.24 4.64 4.14 8.87 7.02 9.59 2023 128 2.26 4.81 4.23 9.51 7.33 10.13 …… 2024 125 3.42 6.75 5.10 10.01 6.69 10.38 2024 126 3.47 6.94 5.27 9.99 6.62 10.16\nGet data from ERDDAP server:\n\nc_fn = 'https://apps.glerl.noaa.gov/erddap/files/glsea_avgtemps_3/glsea-temps_1024_3.dat'\nc_df = pd.read_csv(c_fn, skiprows=9,delimiter=r'\\s+', header=None, names=['YEAR', 'JD', 'S', 'M', 'H', 'E', 'O','St'], dtype=np.float64)\n\nprint(c_df.head())\nprint(c_df.info())\n    \nc_yr_list = c_df['YEAR']\n \nbegin_c_yr_index = list(c_yr_list).index(float(c_year))  # find the index of the current year (2024)\nprint('index of begin current year : ', begin_c_yr_index)\n\n\n     YEAR     JD     S     M     H      E     O     St\n0  2023.0  127.0  2.24  4.64  4.14   8.87  7.02   9.59\n1  2023.0  128.0  2.26  4.81  4.23   9.51  7.33  10.13\n2  2023.0  129.0  2.30  4.98  4.37   9.97  7.58  10.81\n3  2023.0  130.0  2.27  5.17  4.50  10.29  7.68  10.95\n4  2023.0  131.0  2.38  5.39  4.64  10.71  7.80  11.01\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 365 entries, 0 to 364\nData columns (total 8 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   YEAR    365 non-null    float64\n 1   JD      365 non-null    float64\n 2   S       365 non-null    float64\n 3   M       365 non-null    float64\n 4   H       365 non-null    float64\n 5   E       365 non-null    float64\n 6   O       365 non-null    float64\n 7   St      365 non-null    float64\ndtypes: float64(8)\nmemory usage: 22.9 KB\nNone\nindex of begin current year :  239\n\n\nGet a sub datafreme of Lake Michigan for current year:\n\nc_df_sub = c_df[begin_c_yr_index:]  # get a sub dataframe that only contains data for 2024\n \n\ncur_m_arry = c_df_sub['M'].values   # get a sub dataframe that only contains data for Lake Michigan\n\nfor i in range(begin_c_yr_index+1):\n    cur_m_arry = np.append(cur_m_arry, np.NAN)\n\nprint(cur_m_arry)\n\n\n[5.63 5.51 5.47 5.43 5.4  5.35 5.32 5.27 5.16 4.71 4.37 4.26 4.1  3.97\n 3.82 3.69 3.62 3.55 3.29 3.24 3.26 3.25 3.37 3.39 3.4  3.47 3.49 3.56\n 3.56 3.61 3.62 3.63 3.65 3.62 3.62 3.6  3.54 3.49 3.48 3.49 3.51 3.47\n 3.47 3.44 3.38 3.33 3.28 3.23 3.24 3.22 3.34 3.38 3.32 3.31 3.18 3.17\n 3.22 3.31 3.31 3.29 3.41 3.5  3.51 3.54 3.63 3.69 3.66 3.7  3.64 3.64\n 3.65 3.67 3.73 3.77 3.8  3.79 3.74 3.64 3.53 3.47 3.42 3.42 3.46 3.42\n 3.53 3.57 3.54 3.51 3.5  3.55 3.6  3.65 3.74 3.9  3.99 4.04 4.1  4.16\n 4.23 4.31 4.38 4.51 4.68 4.82 4.99 5.09 5.1  5.07 5.05 5.1  5.08 5.1\n 5.14 5.25 5.37 5.49 5.56 5.64 5.67 5.76 5.89 6.   6.14 6.48 6.75 6.94\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan]\n\n\n\n\nGet data from 2007 to 2023\nEach year have one data file. The file naming convention is glsea-tempsYYYY_1024_3.dat.\neg. glsea-temps2023_1024.dat.\nThe file format is samilar as the current year’s data file.\nfirst, define an array of (18,366) to hold all data\n\nm_all_arry = np.zeros( (len(year_list)+1,366), dtype=float)   \nprint(m_all_arry.shape)\n\n(18, 366)\n\n\nSecond, get the data from the 2007 to 2023 and put all the data in variable m_all_arry\n\n\nfor i, yr4 in enumerate(year_list):\n    fn = 'https://apps.glerl.noaa.gov/erddap/files/glsea_avgtemps_3/' + str(yr4) + '/glsea-temps' + str(yr4) + '_1024_3.dat'\n    #print(fn)\n    df = pd.read_csv(fn, skiprows=9,delimiter=r'\\s+', header=None, names=['YEAR', 'JD', 'S', 'M', 'H', 'E', 'O','St'], dtype=np.float64)\n\n    m_arry = df['M'].values            # get data for Lake Michigan\n\n    #print(s_arry.size)\n    print(yr4)\n    m_all_arry[i] = get_366_arry(m_arry)   \n\n#print(s_all_arry)\n\nm_all_arry[-1] = cur_m_arry   # last row is current year sst               \n \n\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n\n\nThird, call the function (defined before) to draw the plot.\n\ndraw_plot(m_all_arry, 'Michigan',  c_year, jd, year_list)\n\n[datetime.date(2024, 1, 31), datetime.date(2024, 2, 29), datetime.date(2024, 3, 31), datetime.date(2024, 4, 30), datetime.date(2024, 5, 31), datetime.date(2024, 6, 30), datetime.date(2024, 7, 31), datetime.date(2024, 8, 31), datetime.date(2024, 9, 30), datetime.date(2024, 10, 31), datetime.date(2024, 11, 30), datetime.date(2024, 12, 31)]\n7\n2024 May 05"
  },
  {
    "objectID": "tutorials/python/sport-jpss-seaice.html#notes",
    "href": "tutorials/python/sport-jpss-seaice.html#notes",
    "title": "Visualizing JPSS Sea Ice Concentration products using Google Colab",
    "section": "Notes",
    "text": "Notes\nJupyter Notebooks are made up of code cells and text cells. Code cells contain executable code and its output, while text cells contain explanatory text - like this cell.\nEach code cell has a play icon at the left gutter of the cell. Press play to execute the cell’s tasks, or hit Cmd/Ctrl+Enter. Note - sometimes the play icon is not shown (showing only empty brackets) unless your cursor hovers over it.\nAny text or image output resulting from execution of a code cell is displayed right below the code cell - or you’ll see an ‘elapsed processing time beside a checkmark’ near the play icon - or both.\nSome text cells are ‘section headers’, denoted by a “&gt;” (greater than) sign. The “&gt;” can be pressed to expand (show) the cells under it (down to the next section header). That turns the “&gt;” into a “\\/” (chevron), which can then be pressed to collapse (hide) its cells."
  },
  {
    "objectID": "tutorials/python/sport-jpss-seaice.html#loadinstall-required-packages-mount-google-drive",
    "href": "tutorials/python/sport-jpss-seaice.html#loadinstall-required-packages-mount-google-drive",
    "title": "Visualizing JPSS Sea Ice Concentration products using Google Colab",
    "section": "Load/install required packages & Mount Google Drive",
    "text": "Load/install required packages & Mount Google Drive\n\n\n# Load/install the required non-standard Python packages\n!pip install cartopy\n!pip install netCDF4\n!pip install pyresample\n!pip install ecmwflibs\n!pip install xarray\n!pip install rioxarray\n!pip install rasterio\n!pip install --upgrade rasterio rioxarray\n# Ensure the Google Drive is mounted"
  },
  {
    "objectID": "tutorials/python/sport-jpss-seaice.html#modify-the-python-script-and-run-it",
    "href": "tutorials/python/sport-jpss-seaice.html#modify-the-python-script-and-run-it",
    "title": "Visualizing JPSS Sea Ice Concentration products using Google Colab",
    "section": "Modify the Python script and Run it",
    "text": "Modify the Python script and Run it\nWithin Google Colab, you can access your Google Drive directories. At the far left of the Google Colab screen, press the simple folder icon. This will expand the left-most panel, showing your available Google drives. Navigate the directories to find your file, select it, and Right-Click to select “Copy path”. Then paste that result into the Filename variable in the next cell (below), like so:\n\nFilename = ‘MyDrive/ColabNotebooks/JPSS_Soil_Data/AMSR2-SOIL_v2r2_GW1_s20240210122904_e20240210123456_.nc’\n\nor\n\nFilename = ‘MyDrive/ColabNotebooks/JPSS_Soil_Data/NPR_SMOPS_CMAP_D20240131.nc’\n\nNext, choose one of the recognized domains, placing it into the Domain variable below.\nFinally, specify the location where you want the output PNG files to be created; in the Out_dir_L2 and Out_dir_L3 variables for level-2, and level-3 output, respectively. Execute this cell with the ‘play’ icon.\n\n# Specify Filename\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/JRR-IceConcentration_v3r3_j01_s202403070044010_e202403070045255_c202403070121021.nc'\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Blended_SIC_N20_2020_350_12_15_0000_2400_north.tiff'  # SSEC\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Blended_AMSR2_VIIRS_SIC_2023_135_05_15_2346_2357.tiff'  # GINA (swath)\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20240804_c20240805.nc'  # PolarWatch\nFilename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20241005_c20241007.nc'  # PolarWatch\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/nesdis_blendedsic_nhem_daily_79da_d8e9_7b6a_U1723144597211.nc'  # PolarWatch\n\n# Specify 1 of the recognized domains:\n#   arctic, antarctic\nDomain = 'arctic'\n\n# Specify the output directory\nOut_dir_L2 = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Output_L2'\nOut_dir_L3 = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Output_L3'\n\nThis portion of code imports required Python packages, as well as defining the domains to be recognized by the script. You can add your own domain, or change on of the existing ones, in the ‘domains’ dictionary.\n\nimport os\nimport re\nimport sys\n\nfrom time import gmtime, strftime\nimport cartopy.feature as cfeature\nimport cartopy.crs as ccrs\nimport netCDF4\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pyresample as pr\nimport rioxarray as rio\nfrom pyresample.geometry import SwathDefinition\nfrom pathlib import Path\nimport ecmwflibs # This little bugger is required to find the eccodes library!!!!\necmwflibs.find(\"eccodes\") # This line is simply to *use* the imported ecmwflibs module\n\n# geographic regions\ndomains = {\n   'world':{                             # region\n      'states':False,                    # state outlines?\n      'shape':(1000, 500),               # size (x,y)\n      'area_extent':(-180, -90, 180, 90) # lat/lon extent (degrees) (W,S,E,N)\n      },\n   'arctic':{\n      'states':False,\n      'shape':(700, 700),\n      'area_extent':(-180, 50, 180, 90)\n      },\n   'antarctic':{\n      'states':False,\n      'shape':(700, 700),\n      'area_extent':(-180, -90, 180, -55)\n      },\n    }\n\nThese classes, or functions (SIC_L2 and SIC_L3), handle the Level-2 (swath) VIIRS SIC files and the Level-3 (gridded) Blended files.\n\nclass SIC_L2:\n   \"\"\"Level2 SIC files\"\"\"\n\n   def __init__(self, domain: str, fil: str):\n      self.domain = domain\n      self.fil = fil\n      self.lats = []\n      self.lons = []\n      self.data = []\n      self.plot_data()\n\n   def plot_data(self):\n      \"\"\"Plot the data, overlay with a map, colormap, and label\"\"\"\n\n      print(f'Reading file {self.fil}')\n      f = rio.open_rasterio(self.fil, band_as_variable=True)\n\n      # Get data\n      data_tmp = f.IceConc.values\n      x_tmp = f.Longitude.values\n      y_tmp = f.Latitude.values\n\n      subsam = 20\n\n      # Subsample if needed and Mask out out-of-bounds values\n      self.lats = y_tmp[::subsam, ::subsam].squeeze()\n      self.lons = x_tmp[::subsam, ::subsam].squeeze()\n      self.data = data_tmp[::subsam, ::subsam].squeeze()\n\n      # Get date and time from filename\n      ymd, hm = re.search(r's(?P&lt;ymd&gt;\\d{8})(?P&lt;hm&gt;\\d{4})',\n                          os.path.basename(self.fil)).groups()\n      print('ymd=', ymd, 'hm=', hm)\n\n      # Min and Max for SIC percentage\n      vmin, vmax = 0.0, 100.0\n\n      # Get center lat/lon\n      ctr_lon = (domains[self.domain]['area_extent'][2]+domains[self.domain]['area_extent'][0]) / 2\n      print('ctr_lon=', ctr_lon)\n\n      # Define PROJ4 target projection (stere = stereographic)\n      proj4 = {'proj': 'stere', 'lat_0': 90.0, 'lon_0': ctr_lon,\n                    'ellps': 'WGS84', 'units': 'm'}\n\n      # Create pyresample AreaDefinition\n      area_def = pr.create_area_def(\n                                    self.domain,\n                                    proj4,\n                                    description = 'stereographic',\n                                    units = 'deg',\n                                    shape = domains[self.domain]['shape'],\n                                    area_extent = domains[self.domain]['area_extent']\n                                   )\n\n      # Create a cartopy CRS object (from pyresample)\n      crs = area_def.to_cartopy_crs()\n\n      # Define the swath projection\n      swath_def = SwathDefinition(self.lons, self.lats)\n\n      # resample swath data (self.data) to the target grid using nearest neighbour method\n      result = pr.kd_tree.resample_nearest(swath_def, self.data, area_def,\n                                           radius_of_influence=30000,\n                                           fill_value=None)\n\n      # Prepare picture\n      fig = plt.figure(figsize=(12, 8))\n      ax = plt.axes(projection=crs)\n      ax.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=0.25, edgecolor='black')\n      ax.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=0.25)\n      if domains[self.domain]['states']:\n         ax.add_feature(cfeature.STATES.with_scale('50m'), linewidth=0.1)\n\n      # Title\n      title = f'NOAA JPSS NOAA-20 VIIRS (Sea Ice Conc.) - {ymd} {hm} UTC'\n      units = '%'\n\n      # Display picture\n      result = np.float64(result) # only to remove a runtime \"overflow\" warning\n      ax.imshow(result, transform=crs, extent=crs.bounds,\n                cmap='jet_r', origin='upper', vmin=vmin, vmax=vmax)\n      ax.set_title(title, fontsize=11)\n\n      # Add color legend\n      sic = plt.cm.ScalarMappable(cmap='jet_r', norm=plt.Normalize(vmin, vmax))\n      cbar = plt.colorbar(sic, ax=ax, shrink=0.45, pad=0.03)\n\n      # ...with tick marks and labels\n      cbar.ax.tick_params(labelsize=9)\n      cbar.set_label(units, size=9)\n\n      # Display image in Google Colab\n      plt.show()\n\n      # Save as PNG\n      pngname = (f'{Out_dir_L2}/{ymd}_{hm}_VIIRS_SIC_{self.domain}.png')\n\n      print(f'{strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())} - Saving PNG  {pngname}')\n      fig.savefig(f'{pngname}', bbox_inches='tight', dpi=200)\n\n      # Verify/notify write success\n      if not os.path.isfile(f'{pngname}'):\n         print(f'Error: {pngname} NOT saved')\n\n      # Close plot\n      plt.close()\n\n################################################################################\n################################################################################\nclass SIC_L3:\n   \"\"\"Level3 Blended SIC NetCDf & GeoTIFF files\"\"\"\n\n   def __init__(self, domain: str, fil: str):\n      self.domain = domain\n      self.fil = fil\n      # Prep projection (EASE-Grid 2.0 - - - EPSG:6931, NPole)\n      self.ease_proj = ccrs.LambertAzimuthalEqualArea(central_latitude=90.)\n      self.cart_proj = ccrs.PlateCarree(central_longitude=0.0)\n      self.plot_data()\n\n   def convert_cart_laea(self, lats:list, lons:list) -&gt; tuple[int, int, int, int]:\n      \"\"\"Convert each point of the region's lat/lon polygon to LAEA coords (meters)\n      Args:\n         lons:list of longitude values\n         lats:list of latitude values\n      Returns: min_x, max_x, min_y, max_y (meters) (integer)\n      \"\"\"\n      min_x = min_y = float('inf')\n      max_x = max_y = float('-inf')\n\n      # Perform transforms on all points of polygon\n      for lat in lats:\n         for lon in lons:\n            x, y = self.ease_proj.transform_point(lon, lat, src_crs=self.cart_proj)\n            min_x = min(min_x, x)\n            max_x = max(max_x, x)\n            min_y = min(min_y, y)\n            max_y = max(max_y, y)\n      return(int(min_x), int(max_x), int(min_y), int(max_y))\n\n   def find_value_address_in(self, list:list, value:int) -&gt; tuple[int, int]:\n      \"\"\"Find address of value in monotonically increasing or decreasing list\n      Args:\n         list: list of values\n         value: value to find\n      Returns: address, direction (0 or 1)\n      \"\"\"\n      if list[0] &lt; list[1]:\n         # increasing/normal\n         dir = 1\n         for j, i in enumerate(list):\n            if i &gt;= value:\n               break\n      else:\n         # decreasing/abnormal\n         dir = 0\n         for j, i in enumerate(list):\n            if i &lt;= value:\n               break\n      return j, dir\n\n   def plot_data(self):\n      \"\"\"Read data, create sample Plot of Blended SIC data\n      \"\"\"\n      # Check consistency of request\n      print(self.domain)\n      if self.domain not in ['arctic', 'antarctic']:\n         raise ValueError(f'Only arctic and antarctic currently supported')\n      self.ctr_lat = 90. if self.domain == 'arctic' else -90.\n\n      # Read NetCDF/GeoTIFF\n      print(f'Reading file {self.fil}')\n      f = rio.open_rasterio(self.fil, band_as_variable=True)\n      print('type(f)=', type(f))\n\n      # Set full and half size variables\n      full = f.rio.width\n      half = int(full/2)\n\n      # quadrant x,y starting values (meters) (in the full array)\n      #       Dateline-90W     90W-Prime        Prime-90E       90E-Dateline    hemisphere\n      start = {'nw':[0, 0], 'sw':[0, half], 'se':[half, half], 'ne':[half, 0], 'full':[0, 0]}\n\n      # Define regions dict with series of lat,lon pairs (3 or more pairs)\n      regions = {\n                 'alaska':[59,-141,\n                           55,-163,\n                           60,-168,\n                           68,-167,\n                           70,-140],\n                 'greenland':[59,-70,\n                              84,-70,\n                              84,-10,\n                              59,-10],\n                 'hudsonbay':[52,-95,\n                              52,-72,\n                              69,-72,\n                              69,-95],\n                 'uk':[50,-10,\n                       50,2,\n                       60,2,\n                       60,-10]}\n      # Each region's list does not need to be a closed polygon\n\n      # Parameters\n      vmin, vmax = 0.0, 100.0\n      domain = 'full'\n      subsam = 20\n      print('domain=', domain)\n\n      # Subset & Subsample\n      if domain == 'full':  # full polar EASE\n         data = f.band_1.values[start[domain][0]:start[domain][0]+full:subsam, start[domain][1]:start[domain][1]+full:subsam]\n         x = f.x.values[start[domain][0]:start[domain][0]+full:subsam]\n         y = f.y.values[start[domain][1]:start[domain][1]+full:subsam]\n      elif domain in ['nw', 'ne', 'sw', 'se']:  # EASE quadrants\n         data = f.band_1.values[start[domain][1]:start[domain][1]+half:subsam, start[domain][0]:start[domain][0]+half:subsam]\n         x = f.x.values[start[domain][0]:start[domain][0]+half:subsam]\n         y = f.y.values[start[domain][1]:start[domain][1]+half:subsam]\n      else:  # polygon\n         data_tmp = f.band_1.values\n         x_tmp = f.x.values\n         y_tmp = f.y.values\n\n         # Fill lats/lons arrays with coords\n         lats = [regions[domain][i] for i in range(0, len(regions[domain]), 2)]  # even\n         lons = [regions[domain][i] for i in range(1, len(regions[domain]), 2)]  # odd\n\n         # Find min and max of x and y values (meters in LAEA proj space)\n         x1, x2, y1, y2 = self.convert_cart_laea(lats, lons)\n         print('polygon coords in LAEA meters:', x1, x2, y1, y2)\n\n         # Locate min/max x/y values in the x and y lists\n         col1, xdir = self.find_value_address_in(x_tmp, x1)\n         col2, xdir = self.find_value_address_in(x_tmp, x2)\n         row1, ydir = self.find_value_address_in(y_tmp, y1)\n         row2, ydir = self.find_value_address_in(y_tmp, y2)\n         print('col1=', col1, 'col2=', col2, 'row1=', row1, 'row2=', row2)\n         if xdir:\n            x = x_tmp[col1:col2:subsam]\n            if ydir:\n               data = data_tmp[row1:row2:subsam, col1:col2:subsam]\n            else:\n               data = data_tmp[row2:row1:subsam, col1:col2:subsam]\n         else:\n            x = x_tmp[col2:col1:subsam]\n            if ydir:\n               data = data_tmp[row1:row2:subsam, col2:col1:subsam]\n            else:\n               data = data_tmp[row2:row1:subsam, col2:col1:subsam]\n\n         if ydir:\n            y = y_tmp[row1:row2:subsam]\n         else:\n            y = y_tmp[row2:row1:subsam]\n         print(col1, col2, row1, row2)\n\n      print('data shape=', data.shape)\n      #plt.hist(data, density=True, bins=10)\n      #plt.show()\n\n      # Get date from filename  Polar-AMSR2VIIRSBLEND_\n      if '_AMSR2_VIIRS_SIC_' in self.fil:\n         data[data&gt;100] = np.nan\n         ymd_txt = re.search(r'Blended_AMSR2_VIIRS_SIC_(\\d{4})_\\d{3}_(\\d{2})_(\\d{2})', os.path.basename(self.fil))\n         ymd = (ymd_txt.group(1) + ymd_txt.group(2) + ymd_txt.group(3))\n      elif 'Blended_SIC_' in self.fil:\n         data[data&gt;100] = np.nan\n         #                     Blended_SIC_N20_2020_350_12_15_0000_2400_north.tiff\n         ymd_txt = re.search(r'Blended_SIC_N20_(\\d{4})_\\d{3}_(\\d{2})_(\\d{2})', os.path.basename(self.fil))\n         ymd = (ymd_txt.group(1) + ymd_txt.group(2) + ymd_txt.group(3))\n      elif 'Polar-AMSR2VIIRSBLEND_' in self.fil:\n         data[data&gt;100] = np.nan\n         ymd_txt = re.search(r'Polar-AMSR2VIIRSBLEND_..._v..r.._Nhem_0000_2400_d(\\d{4})(\\d{2})(\\d{2})', os.path.basename(self.fil))\n         ymd = (ymd_txt.group(1) + ymd_txt.group(2) + ymd_txt.group(3))\n      elif 'nesdis_blendedsic_nhem_daily_' in self.fil:\n         data[data&gt;100] = np.nan\n         ymd = 'YYYYMMDD'\n      else:\n         sys.exit('Not a valid file type')\n\n      # Prepare figure\n      fig = plt.figure(figsize=(12, 12))\n      axm = plt.subplot(projection = self.ease_proj)\n      axm.set_title(f'Blended Sea Ice Concentration - {ymd}', fontsize=11)\n\n      # Add map features\n      axm.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=0.25, edgecolor='black')\n      axm.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=0.25)\n      if domains[self.domain]['states']:\n         axm.add_feature(cfeature.STATES.with_scale('50m'), linewidth=0.1)\n      axm.gridlines(draw_labels=True)\n\n      # Add color bar with 'jet' cmap\n      sic = plt.cm.ScalarMappable(cmap='jet')\n      cbar = plt.colorbar(sic, ax=axm, shrink=0.45, pad=0.03)\n\n      # ...with tick marks and labels\n      cbar.ax.tick_params(labelsize=9)\n      cbar.set_label('percent', size=9)\n\n      # Display image in Google Colab\n      axm.imshow(data, cmap='jet', transform=self.ease_proj, vmin=vmin, vmax=vmax,\n                 extent=(x.min(), x.max(), y.min(), y.max()))\n      plt.show()\n\n      # Save as PNG\n      pngname = (f'{Out_dir_L3}/{ymd}_Blended_AMSR2VIIRS_SIC_{self.domain}.png')\n      print(f'{strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())} - Saving PNG  {pngname}')\n      fig.savefig(pngname, bbox_inches='tight', dpi=200)\n\n      # Verify/notify write success\n      if not os.path.isfile(pngname):\n         print(f'Error: {pngname} NOT saved')\n\n      # Close figure\n      plt.close()\n\nFinally, execute the code below. Either SIC_L2 or SIC_L3 will be executed, depending on which type of file you’ve specified. You may have to scroll down a bit to see the resulting image here in Colab, but a PNG file will be generated, as well.\nNote: During the first execution of this script, the Python module ‘Cartopy’ will need to download map-related files from “Natural Earth”. You will see Python-generated warning messages for this.\n\n# Verify data file exists\nif not os.path.exists(f'{Filename}'):\n   sys.exit(f'{Filename} does not exist')\n\n# Determine data type and call its procedure\nif Filename.find('JRR-IceConcentration', 0) != -1:  # CLASS\n   # Verify L2 output directory exists\n   if not os.path.isdir(f'{Out_dir_L2}'):\n      sys.exit(f'Output directory {Out_dir_L2} does not exist')\n   SIC_L2(Domain, f'{Filename}')\n\nelif Filename.find('Blended_', 0) != -1:  # SSEC/GINA\n   # Verify L3 output directory exists\n   if not os.path.isdir(f'{Out_dir_L3}'):\n      sys.exit(f'Output directory {Out_dir_L3} does not exist')\n   print('calling SIC_L3', Domain, Filename)\n   SIC_L3(Domain, f'{Filename}')\n\nelif Filename.find('nesdis_blendedsic_nhem_daily_', 0) != -1:  # PolarWatch\n   # Verify L3 output directory exists\n   if not os.path.isdir(f'{Out_dir_L3}'):\n      sys.exit(f'Output directory {Out_dir_L3} does not exist')\n   print('calling SIC_L3', Domain, Filename)\n   SIC_L3(Domain, f'{Filename}')\n\nelif Filename.find('Polar-AMSR2VIIRSBLEND_', 0) != -1:  # PolarWatch\n   # Verify L3 output directory exists\n   if not os.path.isdir(f'{Out_dir_L3}'):\n      sys.exit(f'Output directory {Out_dir_L3} does not exist')\n   print('calling SIC_L3', Domain, Filename)\n   SIC_L3(Domain, f'{Filename}')\n\nelse:\n   sys.exit('File must be: Blend or ????')\n###############################################################################\n\ncalling SIC_L3 arctic /content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20241005_c20241007.nc\narctic\nReading file /content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20241005_c20241007.nc\n\n\nWARNING:rasterio._env:CPLE_AppDefined in Unhandled X/Y axis unit meters. SRS will ignore axis unit and be likely wrong.\nWARNING:rasterio._env:CPLE_AppDefined in Unhandled X/Y axis unit meters. SRS will ignore axis unit and be likely wrong.\n\n\ntype(f)= &lt;class 'xarray.core.dataset.Dataset'&gt;\ndomain= full\ndata shape= (452, 452)\n\n\n/usr/local/lib/python3.10/dist-packages/cartopy/io/__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/50m_physical/ne_50m_coastline.zip\n  warnings.warn(f'Downloading: {url}', DownloadWarning)\n/usr/local/lib/python3.10/dist-packages/cartopy/io/__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/50m_cultural/ne_50m_admin_0_boundary_lines_land.zip\n  warnings.warn(f'Downloading: {url}', DownloadWarning)\n\n\n\n\n\n\n\n\n\n2024-10-08 16:52:13 - Saving PNG  /content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Output_L3/20241005_Blended_AMSR2VIIRS_SIC_arctic.png"
  }
]