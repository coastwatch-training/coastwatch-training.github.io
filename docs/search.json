[
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html",
    "href": "tutorials/python/timeseries_compare_sensors.html",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "",
    "text": "CoastWatch Python Exercises"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#background",
    "href": "tutorials/python/timeseries_compare_sensors.html#background",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Background",
    "text": "Background\nSeveral ocean color sensors have been launched since 1997 to provide continuous global coverage for ocean color data. The sensors have differences in design and calibration, and different algorithms may be applied to generate chlorophyll values. Consequently, chlorophyll-a values can vary among the sensors during periods where measurements overlap.\nTo examine this phenomenon, we will download and plot a time series of chlorophyll-a concentrations from various sensors that collected data between 1997 and the present to see how the measurements compare during periods of overlap."
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#objective",
    "href": "tutorials/python/timeseries_compare_sensors.html#objective",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show how to extract a time series from four different monthly satellite chlorophyll datasets for the period that each was in operation between 1997-present."
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/timeseries_compare_sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nUsing xarray to extract data from a rectangular area of the ocean over time\nRetrieving information about a dataset from ERDDAP\nComparing results from different sensors\nAveraging data spatially\nProducing time-series plots\nDrawing maps with satellite data"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#datasets-used",
    "href": "tutorials/python/timeseries_compare_sensors.html#datasets-used",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Datasets used",
    "text": "Datasets used\nSeaWiFS Chlorophyll-a, V.2018, Monthly, Global, 4km, 1997-2012\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nMODIS Aqua, Chlorophyll-a, V.2022, Monthly, Global, 4km, 2002-present\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022SQ\nNOAA VIIRS S-NPP, Chlorophyll-a, Monthly, Global, 4km, 2012-present\nhttps://coastwatch.noaa.gov/erddap/griddap/noaacwNPPVIIRSSQchlaMonthly\nESA CCI Ocean Colour Dataset, v6.0, Monthly, Global, 4km, 1997-Present\nThis dataset was developed by the European Space Agency’s Climate Change Initiative. The dataset merges data from multiple sensors (MERIS, MODIS, VIIRS and SeaWiFS) to create a long time series (1997 to present) with better spatial coverage than any single sensor. Parameters include chlorophyll a, remote sensing reflectance, diffuse attenuation coefficients, absorption coefficients, backscatter coefficients, and water classification.\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorMonthly"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#import-required-packages",
    "href": "tutorials/python/timeseries_compare_sensors.html#import-required-packages",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Import required packages",
    "text": "Import required packages\n\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#define-the-area-to-extract",
    "href": "tutorials/python/timeseries_compare_sensors.html#define-the-area-to-extract",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nFor each dataset we will extract data for an area in the Gulf of Mexico between -95 to -90°W longitude and 25-30°N latitude.\nSet up variables with the minimum and maximum values from the longitude and latitude ranges.\n\nlon_min = -95.\nlon_max = -90.\nlat_min = 25.\nlat_max = 30."
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#get-the-seawifs-data",
    "href": "tutorials/python/timeseries_compare_sensors.html#get-the-seawifs-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get the SeaWiFS data",
    "text": "Get the SeaWiFS data\n\nOpen a dataset object in xarray\n\nurl_sw = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday'\nsw_ds = xr.open_dataset(url_sw)\nsw_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:      (time: 157, latitude: 2160, longitude: 4320)\nCoordinates:\n  * time         (time) datetime64[ns] 1997-09-16 1997-10-16 ... 2010-12-16\n  * latitude     (latitude) float32 89.96 89.88 89.79 ... -89.79 -89.88 -89.96\n  * longitude    (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nData variables:\n    chlorophyll  (time, latitude, longitude) float32 ...\nAttributes: (12/50)\n    _lastModified:                     2018-01-31T04:58:26.000Z\n    _NCProperties:                     version=1|netcdflibversion=4.4.1.1|hdf...\n    cdm_data_type:                     Grid\n    Conventions:                       CF-1.6, COARDS, ACDD-1.3\n    creator_email:                     data@oceancolor.gsfc.nasa.gov\n    creator_name:                      NASA/GSFC/OBPG\n    ...                                ...\n    summary:                           NASA GSFC Ocean Color Web distributes ...\n    temporal_range:                    10-day\n    time_coverage_end:                 2010-12-16T00:00:00Z\n    time_coverage_start:               1997-09-16T00:00:00Z\n    title:                             Chlorophyll-a, Orbview-2 SeaWiFS, R201...\n    Westernmost_Easting:               -179.9583xarray.DatasetDimensions:time: 157latitude: 2160longitude: 4320Coordinates: (3)time(time)datetime64[ns]1997-09-16 ... 2010-12-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000', '1998-02-16T00:00:00.000000000',\n       '1998-03-16T00:00:00.000000000', '1998-04-16T00:00:00.000000000',\n       '1998-05-16T00:00:00.000000000', '1998-06-16T00:00:00.000000000',\n       '1998-07-16T00:00:00.000000000', '1998-08-16T00:00:00.000000000',\n       '1998-09-16T00:00:00.000000000', '1998-10-16T00:00:00.000000000',\n       '1998-11-16T00:00:00.000000000', '1998-12-16T00:00:00.000000000',\n       '1999-01-16T00:00:00.000000000', '1999-02-16T00:00:00.000000000',\n       '1999-03-16T00:00:00.000000000', '1999-04-16T00:00:00.000000000',\n       '1999-05-16T00:00:00.000000000', '1999-06-16T00:00:00.000000000',\n       '1999-07-16T00:00:00.000000000', '1999-08-16T00:00:00.000000000',\n       '1999-09-16T00:00:00.000000000', '1999-10-16T00:00:00.000000000',\n       '1999-11-16T00:00:00.000000000', '1999-12-16T00:00:00.000000000',\n       '2000-01-16T00:00:00.000000000', '2000-02-16T00:00:00.000000000',\n       '2000-03-16T00:00:00.000000000', '2000-04-16T00:00:00.000000000',\n       '2000-05-16T00:00:00.000000000', '2000-06-16T00:00:00.000000000',\n       '2000-07-16T00:00:00.000000000', '2000-08-16T00:00:00.000000000',\n       '2000-09-16T00:00:00.000000000', '2000-10-16T00:00:00.000000000',\n       '2000-11-16T00:00:00.000000000', '2000-12-16T00:00:00.000000000',\n       '2001-01-16T00:00:00.000000000', '2001-02-16T00:00:00.000000000',\n       '2001-03-16T00:00:00.000000000', '2001-04-16T00:00:00.000000000',\n       '2001-05-16T00:00:00.000000000', '2001-06-16T00:00:00.000000000',\n       '2001-07-16T00:00:00.000000000', '2001-08-16T00:00:00.000000000',\n       '2001-09-16T00:00:00.000000000', '2001-10-16T00:00:00.000000000',\n       '2001-11-16T00:00:00.000000000', '2001-12-16T00:00:00.000000000',\n       '2002-01-16T00:00:00.000000000', '2002-02-16T00:00:00.000000000',\n       '2002-03-16T00:00:00.000000000', '2002-04-16T00:00:00.000000000',\n       '2002-05-16T00:00:00.000000000', '2002-06-16T00:00:00.000000000',\n       '2002-07-16T00:00:00.000000000', '2002-08-16T00:00:00.000000000',\n       '2002-09-16T00:00:00.000000000', '2002-10-16T00:00:00.000000000',\n       '2002-11-16T00:00:00.000000000', '2002-12-16T00:00:00.000000000',\n       '2003-01-16T00:00:00.000000000', '2003-02-16T00:00:00.000000000',\n       '2003-03-16T00:00:00.000000000', '2003-04-16T00:00:00.000000000',\n       '2003-05-16T00:00:00.000000000', '2003-06-16T00:00:00.000000000',\n       '2003-07-16T00:00:00.000000000', '2003-08-16T00:00:00.000000000',\n       '2003-09-16T00:00:00.000000000', '2003-10-16T00:00:00.000000000',\n       '2003-11-16T00:00:00.000000000', '2003-12-16T00:00:00.000000000',\n       '2004-01-16T00:00:00.000000000', '2004-02-16T00:00:00.000000000',\n       '2004-03-16T00:00:00.000000000', '2004-04-16T00:00:00.000000000',\n       '2004-05-16T00:00:00.000000000', '2004-06-16T00:00:00.000000000',\n       '2004-07-16T00:00:00.000000000', '2004-08-16T00:00:00.000000000',\n       '2004-09-16T00:00:00.000000000', '2004-10-16T00:00:00.000000000',\n       '2004-11-16T00:00:00.000000000', '2004-12-16T00:00:00.000000000',\n       '2005-01-16T00:00:00.000000000', '2005-02-16T00:00:00.000000000',\n       '2005-03-16T00:00:00.000000000', '2005-04-16T00:00:00.000000000',\n       '2005-05-16T00:00:00.000000000', '2005-06-16T00:00:00.000000000',\n       '2005-07-16T00:00:00.000000000', '2005-08-16T00:00:00.000000000',\n       '2005-09-16T00:00:00.000000000', '2005-10-16T00:00:00.000000000',\n       '2005-11-16T00:00:00.000000000', '2005-12-16T00:00:00.000000000',\n       '2006-01-16T00:00:00.000000000', '2006-02-16T00:00:00.000000000',\n       '2006-03-16T00:00:00.000000000', '2006-04-16T00:00:00.000000000',\n       '2006-05-16T00:00:00.000000000', '2006-06-16T00:00:00.000000000',\n       '2006-07-16T00:00:00.000000000', '2006-08-16T00:00:00.000000000',\n       '2006-09-16T00:00:00.000000000', '2006-10-16T00:00:00.000000000',\n       '2006-11-16T00:00:00.000000000', '2006-12-16T00:00:00.000000000',\n       '2007-01-16T00:00:00.000000000', '2007-02-16T00:00:00.000000000',\n       '2007-03-16T00:00:00.000000000', '2007-04-16T00:00:00.000000000',\n       '2007-05-16T00:00:00.000000000', '2007-06-16T00:00:00.000000000',\n       '2007-07-16T00:00:00.000000000', '2007-08-16T00:00:00.000000000',\n       '2007-09-16T00:00:00.000000000', '2007-10-16T00:00:00.000000000',\n       '2007-11-16T00:00:00.000000000', '2007-12-16T00:00:00.000000000',\n       '2008-01-16T00:00:00.000000000', '2008-04-16T00:00:00.000000000',\n       '2008-05-16T00:00:00.000000000', '2008-06-16T00:00:00.000000000',\n       '2008-07-16T00:00:00.000000000', '2008-08-16T00:00:00.000000000',\n       '2008-09-16T00:00:00.000000000', '2008-10-16T00:00:00.000000000',\n       '2008-11-16T00:00:00.000000000', '2008-12-16T00:00:00.000000000',\n       '2009-01-16T00:00:00.000000000', '2009-02-16T00:00:00.000000000',\n       '2009-03-16T00:00:00.000000000', '2009-04-16T00:00:00.000000000',\n       '2009-06-16T00:00:00.000000000', '2009-07-16T00:00:00.000000000',\n       '2009-08-16T00:00:00.000000000', '2009-09-16T00:00:00.000000000',\n       '2009-10-16T00:00:00.000000000', '2009-11-16T00:00:00.000000000',\n       '2009-12-16T00:00:00.000000000', '2010-01-16T00:00:00.000000000',\n       '2010-02-16T00:00:00.000000000', '2010-03-16T00:00:00.000000000',\n       '2010-04-16T00:00:00.000000000', '2010-05-16T00:00:00.000000000',\n       '2010-06-16T00:00:00.000000000', '2010-07-16T00:00:00.000000000',\n       '2010-08-16T00:00:00.000000000', '2010-09-16T00:00:00.000000000',\n       '2010-10-16T00:00:00.000000000', '2010-11-16T00:00:00.000000000',\n       '2010-12-16T00:00:00.000000000'], dtype='datetime64[ns]')latitude(latitude)float3289.96 89.88 89.79 ... -89.88 -89.96_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([ 89.958336,  89.875   ,  89.79167 , ..., -89.791664, -89.87501 ,\n       -89.958336], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_CoordinateAxisType :Lonactual_range :[-179.9583  179.9584]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79166, ...,  179.79167,  179.87502,\n        179.95836], dtype=float32)Data variables: (1)chlorophyll(time, latitude, longitude)float32...colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll Concentration, OCI Algorithmreferences :Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.standard_name :concentration_of_chlorophyll_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001[1464998400 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16', '1998-02-16', '1998-03-16', '1998-04-16',\n               '1998-05-16', '1998-06-16',\n               ...\n               '2010-03-16', '2010-04-16', '2010-05-16', '2010-06-16',\n               '2010-07-16', '2010-08-16', '2010-09-16', '2010-10-16',\n               '2010-11-16', '2010-12-16'],\n              dtype='datetime64[ns]', name='time', length=157, freq=None))latitudePandasIndexPandasIndex(Index([ 89.95833587646484,             89.875,  89.79167175292969,\n        89.70833587646484,             89.625,  89.54167175292969,\n        89.45833587646484,             89.375,  89.29167175292969,\n        89.20833587646484,\n       ...\n       -89.20833587646484, -89.29166412353516, -89.37500762939453,\n       -89.45833587646484, -89.54166412353516, -89.62500762939453,\n       -89.70833587646484, -89.79166412353516, -89.87500762939453,\n       -89.95833587646484],\n      dtype='float32', name='latitude', length=2160))longitudePandasIndexPandasIndex(Index([ -179.9583282470703,            -179.875, -179.79165649414062,\n        -179.7083282470703,            -179.625, -179.54165649414062,\n        -179.4583282470703,            -179.375, -179.29165649414062,\n        -179.2083282470703,\n       ...\n        179.20835876464844,   179.2916717529297,  179.37501525878906,\n        179.45835876464844,   179.5416717529297,  179.62501525878906,\n        179.70835876464844,   179.7916717529297,  179.87501525878906,\n        179.95835876464844],\n      dtype='float32', name='longitude', length=4320))Attributes: (50)_lastModified :2018-01-31T04:58:26.000Z_NCProperties :version=1|netcdflibversion=4.4.1.1|hdf5libversion=1.8.18cdm_data_type :GridConventions :CF-1.6, COARDS, ACDD-1.3creator_email :data@oceancolor.gsfc.nasa.govcreator_name :NASA/GSFC/OBPGcreator_type :groupcreator_url :https://oceandata.sci.gsfc.nasa.govdate_created :2018-01-31T04:58:26.000ZEasternmost_Easting :179.9584geospatial_lat_max :89.95834geospatial_lat_min :-89.95834geospatial_lat_units :degrees_northgeospatial_lon_max :179.9584geospatial_lon_min :-179.9583geospatial_lon_units :degrees_eastgrid_mapping_name :latitude_longitudehistory :These R2018.0 data files were downloaded from https://oceandata.sci.gsfc.nasa.gov/SeaWiFS/Mapped/Monthly/9km/chlor_a to NOAA NMFS SWFSC by erd.data@noaa.gov ERD on 2018-03-05.\n2023-09-06T13:45:15Z (local files)\n2023-09-06T13:45:15Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday.dasidentifier_product_doi :10.5067/ORBVIEW-2/SEAWIFS/L3M/CHL/2018identifier_product_doi_authority :https://dx.doi.orginfoUrl :https://oceandata.sci.gsfc.nasa.govinstitution :NASA/GSFC OBPGinstrument :SeaWiFSkeywords :algorithm, biology, center, chemistry, chlor_a, chlorophyll, color, concentration, concentration_of_chlorophyll_in_sea_water, data, Earth Science &gt; Oceans &gt; Ocean Chemistry &gt; Chlorophyll, Earth Science &gt; Oceans &gt; Ocean Optics &gt; Ocean Color, field, field-of-view, flight, goddard, group, gsfc, image, L3, level, level-3, mapped, nasa, noaa, obpg, ocean, ocean color, oceans, oci, optics, orbview, orbview-2, palette, processing, sea, sea-wide, seawater, seawifs, sensor, smi, space, standard, view, water, widekeywords_vocabulary :GCMD Science Keywordsl2_flag_names :ATMFAIL,LAND,HILT,HISATZEN,STRAYLIGHT,CLDICE,COCCOLITH,LOWLW,CHLWARN,CHLFAIL,NAVWARN,MAXAERITER,ATMWARN,HISOLZEN,NAVFAIL,FILTER,HIGLINTlicense :https://science.nasa.gov/earth-science/earth-science-data/data-information-policy/\n\nPlease cite: NASA Goddard Space Flight Center, Ocean Ecology Laboratory, Ocean Biology Processing Group. Sea-viewing Wide Field-of-view Sensor (SeaWiFS) R2018.0 Chlorophyll Data; NASA OB.DAAC, Greenbelt, MD, USA. doi: https://dx.doi.org/10.5067/ORBVIEW-2/SEAWIFS/L3M/CHL/2018 .\n\nThe data may be used and redistributed for free but is not intended\nfor legal use, since it may contain inaccuracies. Neither the data\nContributor, ERD, NOAA, nor the United States Government, nor any\nof their employees or contractors, makes any warranty, express or\nimplied, including warranties of merchantability and fitness for a\nparticular purpose, or assumes any legal liability for the accuracy,\ncompleteness, or usefulness, of this information.map_projection :Equidistant Cylindricalmeasure :Meannaming_authority :gov.noaa.pfeg.coastwatchNorthernmost_Northing :89.95834platform :Orbview-2processing_level :L3 Mappedprocessing_version :2018.0project :Ocean Biology Processing Group (NASA/GSFC/OBPG)publisher_email :data@oceancolor.gsfc.nasa.govpublisher_name :NASA/GSFC/OBPGpublisher_type :grouppublisher_url :https://oceandata.sci.gsfc.nasa.govreferences :SeaWiFS information: https://oceancolor.gsfc.nasa.gov/SeaWiFS/ . NASA Ocean\nColor information: https://oceancolor.gsfc.nasa.gov/\nProcessing reference: O'Reilly, J.E., Maritorena, S., Mitchell, B.G., Siegel, D.A., Carder, K.L., Garver, S.A., Kahru, M. and McClain, C. (1998). Ocean color chlorophyll algorithms for SeaWiFS. J. Geophys. Res., 103: 24, 937-24, 953.\nProcessing reference: O'Reilly, J. E., and 21 others. 2000. Ocean color chlorophyll a algorithms for SeaWiFS, OC2 and OC4: Version 4. SeaWiFS Postlaunch Calibration and Validation Analyses, part 3. NASA SeaWiFS technical report series. pp. 8 226 22.\nProcessing reference: Fu, G., Baith, K. S., and McClain, C. R. (1998). SeaDAS: The SeaWiFS Data Analysis System. Proceedings of \"The 4th Pacific Ocean Remote Sensing Conference\", Qingdao, China, July 28-31, 1998, 73-79.\nValidation reference: Hooker, S.B., and C.R. McClain (2000). The Calibration and Validation of SeaWiFS Data. Prog. Oceanogr., 45, 427-465.\nR2014.0 processing reference: Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.\nR2018.0 reprocessing information: https://oceancolor.gsfc.nasa.gov/reprocessing/r2018/seawifs/sourceUrl :(local files)Southernmost_Northing :-89.95834spatialResolution :9.28 kmstandard_name_vocabulary :CF Standard Name Table v70summary :NASA GSFC Ocean Color Web distributes science-quality chlorophyll-a\nconcentration data from the Sea-viewing Wide Field-of-view Sensor (SeaWiFS)\non the Orbview-2 satellite. This version is the 2018.0 Reprocessing (R2018.0). https://oceancolor.gsfc.nasa.gov/reprocessing/r2018/seawifs/\n\nThe SeaWiFS instrument was launched by Orbital Sciences Corporation on the\nOrbView-2 (a.k.a. SeaStar) satellite in August 1997, and collected data from\nSeptember 1997 until the end of mission in December 2010. SeaWiFS had 8\nspectral bands from 412 to 865 nm. It collected global data at 4 km\nresolution, and local data (limited onboard storage and direct broadcast)\nat 1 km. The mission and sensor were optimized for ocean color measurements,\nwith a local noon (descending) equator crossing time orbit, fore-and-aft\ntilt capability, full dynamic range, and low polarization sensitivity.temporal_range :10-daytime_coverage_end :2010-12-16T00:00:00Ztime_coverage_start :1997-09-16T00:00:00Ztitle :Chlorophyll-a, Orbview-2 SeaWiFS, R2018.0, 0.1�, Global, 1997-2010 (Monthly Composite)Westernmost_Easting :-179.9583\n\n\n\n\nPrint out some useful metadata\nYou can view all of the metadata above in the dataset object. Let’s print out some metadata items to point a few things out: * The SeaWiFS dataset spans 13 years, from 1997 to 2010\n* The chlorophyll variable is called “chlorophyll”. Knowing this is important because variable names are not standardized, and we will need to know the exact variable name to extract the data. * Checking the first and last value of latitude can tell us if the latitude values are in ascending or descending order.\n\nprint('earliest date =', sw_ds.time.values[0])\nprint('most recent date =', sw_ds.time.values[-1], '\\n')\nprint('variable:', list(sw_ds.data_vars.keys()), '\\n')\n\nprint(\"Is latitude's first value --&gt;\", round(sw_ds.latitude[0].item(), 6))\nprint('greater than') \nprint(\"latitude's last value --&gt;\", round(sw_ds.latitude[-1].item(), 6))\n\nprint(sw_ds.latitude[0].item() &gt; sw_ds.latitude[-1].item())\n\n\nearliest date = 1997-09-16T00:00:00.000000000\nmost recent date = 2010-12-16T00:00:00.000000000 \n\nvariable: ['chlorophyll'] \n\nIs latitude's first value --&gt; 89.958336\ngreater than\nlatitude's last value --&gt; -89.958336\nTrue\n\n\n\n\nPay attention to the first and last values of latitude in the dataset\nIn a netCDF file that completely follows accepted standards, the latitude values are ascending; the values go from lowest to highest (south to north). Therefore, when we use the slice function (below) to subset the dataset we would list the lowest value in our subset followed by the highest.\n* slice(lat_min, lat_max)\nHowever, for some datasets the latitude values are in descending order, meaning the files were built with latitudes indexed from highest to lowest (north to south). It is a common occurrence and it impacts how we subset that dataset, so you need to be aware of it.\n* With latitude values in descending order, if you use “slice(lat_min, lat_max)” you will get no data, because there are no latitude values between lat_min and lat_max. * However, by reversing the order within slice by using “slice(lat_max, lat_min)” you will get data.\nFor the SeaWiFS dataset, the metadata above show that the first latitude value (89.958336) is greater than the last (-89.958336). The latitude values are in descending order.\n* There are methods in xarray to flip the latitude dimension. A simpler solution is to use a logic step that determines if latitude values are descending, then set slice values to use the higher value first (see below).\n\n# The lat1 and lat2 values are used in the slice function\n# At first we set them as if the dataset is compliant with standards\nlat1 = lat_min\nlat2 = lat_max\n\n# Then switch them if latitude values are descending\nif sw_ds.latitude[0].item() &gt; sw_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\n\n\nSubset the data from the dataset object.\nNote that so far we have not downloaded data. We have only set up how we want to download the data. * The download will happen when we request to use data, like when creating the map below.\n\n\nsw_subset = sw_ds['chlorophyll'].sel(time=slice(sw_ds.time[0], sw_ds.time[-1]),\n                                     latitude=slice(lat1, lat2),\n                                     longitude=slice(lon_min, lon_max)\n                                     )\nsw_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlorophyll' (time: 157, latitude: 60, longitude: 60)&gt;\n[565200 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 1997-09-16 1997-10-16 ... 2010-12-16\n  * latitude   (latitude) float32 29.96 29.87 29.79 29.71 ... 25.21 25.12 25.04\n  * longitude  (longitude) float32 -94.96 -94.88 -94.79 ... -90.21 -90.12 -90.04\nAttributes:\n    colorBarMaximum:  30.0\n    colorBarMinimum:  0.03\n    colorBarScale:    Log\n    ioos_category:    Ocean Color\n    long_name:        Chlorophyll Concentration, OCI Algorithm\n    references:       Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a a...\n    standard_name:    concentration_of_chlorophyll_in_sea_water\n    units:            mg m^-3\n    valid_max:        100.0\n    valid_min:        0.001xarray.DataArray'chlorophyll'time: 157latitude: 60longitude: 60...[565200 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]1997-09-16 ... 2010-12-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000', '1998-02-16T00:00:00.000000000',\n       '1998-03-16T00:00:00.000000000', '1998-04-16T00:00:00.000000000',\n       '1998-05-16T00:00:00.000000000', '1998-06-16T00:00:00.000000000',\n       '1998-07-16T00:00:00.000000000', '1998-08-16T00:00:00.000000000',\n       '1998-09-16T00:00:00.000000000', '1998-10-16T00:00:00.000000000',\n       '1998-11-16T00:00:00.000000000', '1998-12-16T00:00:00.000000000',\n       '1999-01-16T00:00:00.000000000', '1999-02-16T00:00:00.000000000',\n       '1999-03-16T00:00:00.000000000', '1999-04-16T00:00:00.000000000',\n       '1999-05-16T00:00:00.000000000', '1999-06-16T00:00:00.000000000',\n       '1999-07-16T00:00:00.000000000', '1999-08-16T00:00:00.000000000',\n       '1999-09-16T00:00:00.000000000', '1999-10-16T00:00:00.000000000',\n       '1999-11-16T00:00:00.000000000', '1999-12-16T00:00:00.000000000',\n       '2000-01-16T00:00:00.000000000', '2000-02-16T00:00:00.000000000',\n       '2000-03-16T00:00:00.000000000', '2000-04-16T00:00:00.000000000',\n       '2000-05-16T00:00:00.000000000', '2000-06-16T00:00:00.000000000',\n       '2000-07-16T00:00:00.000000000', '2000-08-16T00:00:00.000000000',\n       '2000-09-16T00:00:00.000000000', '2000-10-16T00:00:00.000000000',\n       '2000-11-16T00:00:00.000000000', '2000-12-16T00:00:00.000000000',\n       '2001-01-16T00:00:00.000000000', '2001-02-16T00:00:00.000000000',\n       '2001-03-16T00:00:00.000000000', '2001-04-16T00:00:00.000000000',\n       '2001-05-16T00:00:00.000000000', '2001-06-16T00:00:00.000000000',\n       '2001-07-16T00:00:00.000000000', '2001-08-16T00:00:00.000000000',\n       '2001-09-16T00:00:00.000000000', '2001-10-16T00:00:00.000000000',\n       '2001-11-16T00:00:00.000000000', '2001-12-16T00:00:00.000000000',\n       '2002-01-16T00:00:00.000000000', '2002-02-16T00:00:00.000000000',\n       '2002-03-16T00:00:00.000000000', '2002-04-16T00:00:00.000000000',\n       '2002-05-16T00:00:00.000000000', '2002-06-16T00:00:00.000000000',\n       '2002-07-16T00:00:00.000000000', '2002-08-16T00:00:00.000000000',\n       '2002-09-16T00:00:00.000000000', '2002-10-16T00:00:00.000000000',\n       '2002-11-16T00:00:00.000000000', '2002-12-16T00:00:00.000000000',\n       '2003-01-16T00:00:00.000000000', '2003-02-16T00:00:00.000000000',\n       '2003-03-16T00:00:00.000000000', '2003-04-16T00:00:00.000000000',\n       '2003-05-16T00:00:00.000000000', '2003-06-16T00:00:00.000000000',\n       '2003-07-16T00:00:00.000000000', '2003-08-16T00:00:00.000000000',\n       '2003-09-16T00:00:00.000000000', '2003-10-16T00:00:00.000000000',\n       '2003-11-16T00:00:00.000000000', '2003-12-16T00:00:00.000000000',\n       '2004-01-16T00:00:00.000000000', '2004-02-16T00:00:00.000000000',\n       '2004-03-16T00:00:00.000000000', '2004-04-16T00:00:00.000000000',\n       '2004-05-16T00:00:00.000000000', '2004-06-16T00:00:00.000000000',\n       '2004-07-16T00:00:00.000000000', '2004-08-16T00:00:00.000000000',\n       '2004-09-16T00:00:00.000000000', '2004-10-16T00:00:00.000000000',\n       '2004-11-16T00:00:00.000000000', '2004-12-16T00:00:00.000000000',\n       '2005-01-16T00:00:00.000000000', '2005-02-16T00:00:00.000000000',\n       '2005-03-16T00:00:00.000000000', '2005-04-16T00:00:00.000000000',\n       '2005-05-16T00:00:00.000000000', '2005-06-16T00:00:00.000000000',\n       '2005-07-16T00:00:00.000000000', '2005-08-16T00:00:00.000000000',\n       '2005-09-16T00:00:00.000000000', '2005-10-16T00:00:00.000000000',\n       '2005-11-16T00:00:00.000000000', '2005-12-16T00:00:00.000000000',\n       '2006-01-16T00:00:00.000000000', '2006-02-16T00:00:00.000000000',\n       '2006-03-16T00:00:00.000000000', '2006-04-16T00:00:00.000000000',\n       '2006-05-16T00:00:00.000000000', '2006-06-16T00:00:00.000000000',\n       '2006-07-16T00:00:00.000000000', '2006-08-16T00:00:00.000000000',\n       '2006-09-16T00:00:00.000000000', '2006-10-16T00:00:00.000000000',\n       '2006-11-16T00:00:00.000000000', '2006-12-16T00:00:00.000000000',\n       '2007-01-16T00:00:00.000000000', '2007-02-16T00:00:00.000000000',\n       '2007-03-16T00:00:00.000000000', '2007-04-16T00:00:00.000000000',\n       '2007-05-16T00:00:00.000000000', '2007-06-16T00:00:00.000000000',\n       '2007-07-16T00:00:00.000000000', '2007-08-16T00:00:00.000000000',\n       '2007-09-16T00:00:00.000000000', '2007-10-16T00:00:00.000000000',\n       '2007-11-16T00:00:00.000000000', '2007-12-16T00:00:00.000000000',\n       '2008-01-16T00:00:00.000000000', '2008-04-16T00:00:00.000000000',\n       '2008-05-16T00:00:00.000000000', '2008-06-16T00:00:00.000000000',\n       '2008-07-16T00:00:00.000000000', '2008-08-16T00:00:00.000000000',\n       '2008-09-16T00:00:00.000000000', '2008-10-16T00:00:00.000000000',\n       '2008-11-16T00:00:00.000000000', '2008-12-16T00:00:00.000000000',\n       '2009-01-16T00:00:00.000000000', '2009-02-16T00:00:00.000000000',\n       '2009-03-16T00:00:00.000000000', '2009-04-16T00:00:00.000000000',\n       '2009-06-16T00:00:00.000000000', '2009-07-16T00:00:00.000000000',\n       '2009-08-16T00:00:00.000000000', '2009-09-16T00:00:00.000000000',\n       '2009-10-16T00:00:00.000000000', '2009-11-16T00:00:00.000000000',\n       '2009-12-16T00:00:00.000000000', '2010-01-16T00:00:00.000000000',\n       '2010-02-16T00:00:00.000000000', '2010-03-16T00:00:00.000000000',\n       '2010-04-16T00:00:00.000000000', '2010-05-16T00:00:00.000000000',\n       '2010-06-16T00:00:00.000000000', '2010-07-16T00:00:00.000000000',\n       '2010-08-16T00:00:00.000000000', '2010-09-16T00:00:00.000000000',\n       '2010-10-16T00:00:00.000000000', '2010-11-16T00:00:00.000000000',\n       '2010-12-16T00:00:00.000000000'], dtype='datetime64[ns]')latitude(latitude)float3229.96 29.87 29.79 ... 25.12 25.04_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([29.958334, 29.874998, 29.791666, 29.708334, 29.624998, 29.541666,\n       29.458334, 29.374998, 29.291666, 29.208334, 29.124998, 29.041666,\n       28.958334, 28.874998, 28.791666, 28.708334, 28.624998, 28.541666,\n       28.458334, 28.374998, 28.291666, 28.208334, 28.124998, 28.041666,\n       27.958334, 27.874998, 27.791666, 27.708334, 27.624998, 27.541666,\n       27.458334, 27.374998, 27.291666, 27.208334, 27.124998, 27.041666,\n       26.958334, 26.874998, 26.791666, 26.708334, 26.624998, 26.541666,\n       26.458334, 26.374998, 26.291666, 26.208334, 26.124998, 26.041666,\n       25.958334, 25.874998, 25.791662, 25.708334, 25.624998, 25.541662,\n       25.458334, 25.374998, 25.291662, 25.208334, 25.124998, 25.041662],\n      dtype=float32)longitude(longitude)float32-94.96 -94.88 ... -90.12 -90.04_CoordinateAxisType :Lonactual_range :[-179.9583  179.9584]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-94.958336, -94.875   , -94.791664, -94.708336, -94.625   , -94.541664,\n       -94.458336, -94.375   , -94.291664, -94.208336, -94.125   , -94.041664,\n       -93.958336, -93.875   , -93.791664, -93.708336, -93.625   , -93.541664,\n       -93.458336, -93.375   , -93.291664, -93.208336, -93.125   , -93.041664,\n       -92.958336, -92.875   , -92.791664, -92.708336, -92.625   , -92.541664,\n       -92.458336, -92.375   , -92.291664, -92.208336, -92.125   , -92.041664,\n       -91.958336, -91.875   , -91.791664, -91.708336, -91.625   , -91.541664,\n       -91.458336, -91.375   , -91.291664, -91.208336, -91.125   , -91.041664,\n       -90.958336, -90.875   , -90.791664, -90.708336, -90.625   , -90.541664,\n       -90.458336, -90.375   , -90.291664, -90.208336, -90.125   , -90.041664],\n      dtype=float32)Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16', '1998-02-16', '1998-03-16', '1998-04-16',\n               '1998-05-16', '1998-06-16',\n               ...\n               '2010-03-16', '2010-04-16', '2010-05-16', '2010-06-16',\n               '2010-07-16', '2010-08-16', '2010-09-16', '2010-10-16',\n               '2010-11-16', '2010-12-16'],\n              dtype='datetime64[ns]', name='time', length=157, freq=None))latitudePandasIndexPandasIndex(Index([ 29.95833396911621, 29.874998092651367,  29.79166603088379,\n        29.70833396911621, 29.624998092651367,  29.54166603088379,\n        29.45833396911621, 29.374998092651367,  29.29166603088379,\n        29.20833396911621, 29.124998092651367,  29.04166603088379,\n        28.95833396911621, 28.874998092651367,  28.79166603088379,\n        28.70833396911621, 28.624998092651367,  28.54166603088379,\n        28.45833396911621, 28.374998092651367,  28.29166603088379,\n        28.20833396911621, 28.124998092651367,  28.04166603088379,\n        27.95833396911621, 27.874998092651367,  27.79166603088379,\n        27.70833396911621, 27.624998092651367,  27.54166603088379,\n        27.45833396911621, 27.374998092651367,  27.29166603088379,\n        27.20833396911621, 27.124998092651367,  27.04166603088379,\n        26.95833396911621, 26.874998092651367,  26.79166603088379,\n        26.70833396911621, 26.624998092651367,  26.54166603088379,\n        26.45833396911621, 26.374998092651367,  26.29166603088379,\n        26.20833396911621, 26.124998092651367,  26.04166603088379,\n        25.95833396911621, 25.874998092651367, 25.791662216186523,\n        25.70833396911621, 25.624998092651367, 25.541662216186523,\n        25.45833396911621, 25.374998092651367, 25.291662216186523,\n        25.20833396911621, 25.124998092651367, 25.041662216186523],\n      dtype='float32', name='latitude'))longitudePandasIndexPandasIndex(Index([-94.95833587646484,            -94.875, -94.79166412353516,\n       -94.70833587646484,            -94.625, -94.54166412353516,\n       -94.45833587646484,            -94.375, -94.29166412353516,\n       -94.20833587646484,            -94.125, -94.04166412353516,\n       -93.95833587646484,            -93.875, -93.79166412353516,\n       -93.70833587646484,            -93.625, -93.54166412353516,\n       -93.45833587646484,            -93.375, -93.29166412353516,\n       -93.20833587646484,            -93.125, -93.04166412353516,\n       -92.95833587646484,            -92.875, -92.79166412353516,\n       -92.70833587646484,            -92.625, -92.54166412353516,\n       -92.45833587646484,            -92.375, -92.29166412353516,\n       -92.20833587646484,            -92.125, -92.04166412353516,\n       -91.95833587646484,            -91.875, -91.79166412353516,\n       -91.70833587646484,            -91.625, -91.54166412353516,\n       -91.45833587646484,            -91.375, -91.29166412353516,\n       -91.20833587646484,            -91.125, -91.04166412353516,\n       -90.95833587646484,            -90.875, -90.79166412353516,\n       -90.70833587646484,            -90.625, -90.54166412353516,\n       -90.45833587646484,            -90.375, -90.29166412353516,\n       -90.20833587646484,            -90.125, -90.04166412353516],\n      dtype='float32', name='longitude'))Attributes: (10)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll Concentration, OCI Algorithmreferences :Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.standard_name :concentration_of_chlorophyll_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001\n\n\n\n\nPlot data to show where it is in the world.\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\nax1.set_extent([240, 300, 5, 45], ccrs.PlateCarree())\n\n# Set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(235, 305, 20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(0, 50, 10), crs=ccrs.PlateCarree())\n\n# Add features to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# Format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nnp.log10(sw_subset[-1]).plot.pcolormesh(ax=ax1, \n                                        transform=ccrs.PlateCarree(), \n                                        cmap='jet', \n                                        cbar_kwargs={'label': \"log chlorophyll (mg m-3)\"})\n\nplt.title('Time series data location - Gulf of Mexico')\n\nText(0.5, 1.0, 'Time series data location - Gulf of Mexico')\n\n\n\n\n\n\n\n\n\n\n\nCompute the monthly mean over the region\n\nswAVG = sw_subset.mean(dim=['latitude','longitude'])\nswAVG.head()\n\n# If you are running low on memory, uncomment the next line\n# del sw_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlorophyll' (time: 5)&gt;\narray([0.59386134, 0.59238297, 0.68359953, 0.81557316, 0.85900825],\n      dtype=float32)\nCoordinates:\n  * time     (time) datetime64[ns] 1997-09-16 1997-10-16 ... 1998-01-16xarray.DataArray'chlorophyll'time: 50.5939 0.5924 0.6836 0.8156 0.859array([0.59386134, 0.59238297, 0.68359953, 0.81557316, 0.85900825],\n      dtype=float32)Coordinates: (1)time(time)datetime64[ns]1997-09-16 ... 1998-01-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000'], dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#get-monthly-modis-data",
    "href": "tutorials/python/timeseries_compare_sensors.html#get-monthly-modis-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get monthly MODIS data",
    "text": "Get monthly MODIS data\n\nRepeat the steps above to get data for the MODIS Aqua chlorophyll dataset\n\nurl_modis = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                      'erddap',\n                      'griddap',\n                      'erdMH1chlamday_R2022SQ'\n                      ])\nmodis_ds = xr.open_dataset(url_modis)\nmodis_ds\n\nprint('earliest date =', modis_ds.time.values[0])\nprint('latest date =', modis_ds.time.values[-1], '\\n')\nprint('variables:', modis_ds.data_vars.keys(), '\\n')\nprint('Is the first latitude value --&gt;', modis_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', modis_ds.latitude[-1].item())\n\nprint(modis_ds.latitude[0].item() &gt; modis_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif modis_ds.latitude[0].item() &gt; modis_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\nmodis_subset = modis_ds['chlor_a'].sel(time=slice(modis_ds.time[0], modis_ds.time[-1]),\n                                       latitude=slice(lat1, lat2),\n                                       longitude=slice(lon_min, lon_max)\n                                       )\n\nmodisAVG = modis_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del modis_subset \n\nearliest date = 2002-07-16T00:00:00.000000000\nlatest date = 2023-07-16T00:00:00.000000000 \n\nvariables: KeysView(Data variables:\n    chlor_a  (time, latitude, longitude) float32 ...) \n\nIs the first latitude value --&gt; 89.97916412353516\ngreater than the last latitude value --&gt; -89.97917175292969\nTrue"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#get-monthly-viirs-data",
    "href": "tutorials/python/timeseries_compare_sensors.html#get-monthly-viirs-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get monthly VIIRS data",
    "text": "Get monthly VIIRS data\n\nRepeat the steps above to get data for the VIIRS SNPP chlorophyll dataset\n\nurl_viirs = '/'.join(['https://coastwatch.noaa.gov',\n                        'erddap',\n                        'griddap',\n                        'noaacwNPPVIIRSSQchlaMonthly'\n                        ])\nviirs_ds = xr.open_dataset(url_viirs)\nviirs_ds\n\nprint('earliest date =', viirs_ds.time.values[0])\nprint('latest date =', viirs_ds.time.values[-1], '\\n')\nprint('variables:', viirs_ds.data_vars.keys(), '\\n')\n\nprint('Is the first latitude value --&gt;', viirs_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', viirs_ds.latitude[-1].item())\n\nprint(viirs_ds.latitude[0].item() &gt; viirs_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif viirs_ds.latitude[0].item() &gt; viirs_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\nviirs_subset = modis_ds['chlor_a'].sel(time=slice(viirs_ds.time[0], viirs_ds.time[-1]),\n                                       latitude=slice(lat1, lat2),\n                                       longitude=slice(lon_min, lon_max)\n                                       )\nviirsAVG = viirs_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del viirs_subset \n\nearliest date = 2012-01-02T12:00:00.000000000\nlatest date = 2023-08-01T12:00:00.000000000 \n\nvariables: KeysView(Data variables:\n    chlor_a  (time, altitude, latitude, longitude) float32 ...) \n\nIs the first latitude value --&gt; 89.75625\ngreater than the last latitude value --&gt; -89.75625\nTrue"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#plot-the-time-series",
    "href": "tutorials/python/timeseries_compare_sensors.html#plot-the-time-series",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Plot the time series",
    "text": "Plot the time series\n\nPlot the result for three datasets\n\nplt.figure(figsize=(10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(swAVG.time, swAVG, \n              'o', markersize=3, \n              label='SeaWiFS', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(modisAVG.time, modisAVG, \n              'o', markersize=3, \n              label='MODIS', c='blue', \n              linestyle='-', linewidth=1) \n\n# Add VIIRS data\nplt.plot_date(viirsAVG.time, viirsAVG, \n              'o', markersize=3, \n              label='VIIRS', c='green', \n              linestyle='-', linewidth=1) \n\nplt.ylim([0, 3])\nplt.ylabel('Chl-a (mg m-3)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#get-oc-cci-data",
    "href": "tutorials/python/timeseries_compare_sensors.html#get-oc-cci-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get OC-CCI data",
    "text": "Get OC-CCI data\nIf you needed a single time series from 1997 to present, you would have to use the plot above to devise some method to reconcile the difference in values where two datasets overlap. Alternatively, you could use the ESA OC-CCI (Ocean Color Climate Change Initiative) dataset, which blends data from many satellite missions into a single dataset, including data from SeaWiFS, MODIS, and VIIRS.\nAdd the ESA OC-CCI dataset to the plot above to see how it compares with data from the individual satellite missions.\n### Repeat the steps above to get data from the ESA OC-CCI chlorophyll dataset\n\nurl_cci = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                    'erddap',\n                    'griddap',\n                    'pmlEsaCCI60OceanColorMonthly'\n                    ])\ncci_ds = xr.open_dataset(url_cci)\ncci_ds\n\nprint('earliest date =', cci_ds.time.values[0])\nprint('latest date =', cci_ds.time.values[-1])\n\n# From the 93 variables in the dataset, \n# display only those with chl in the name\nsubset_variables = [ln for ln in list(cci_ds.data_vars.keys()) if 'chl' in ln]\n\nprint('variables with chl in name:', subset_variables, '\\n')\n\n\nprint('Is the first latitude value --&gt;', cci_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', cci_ds.latitude[-1].item())\n\nprint(cci_ds.latitude[0].item() &gt; cci_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif cci_ds.latitude[0].item() &gt; cci_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\ncci_subset = cci_ds['chlor_a'].sel(time=slice(cci_ds.time[0], cci_ds.time[-1]),\n                                   latitude=slice(lat1, lat2),\n                                   longitude=slice(lon_min, lon_max)\n                                   )\ncciAVG = cci_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del cci_subset \n\nearliest date = 1997-09-04T00:00:00.000000000\nlatest date = 2023-03-01T00:00:00.000000000\nvariables with chl in name: ['chlor_a', 'chlor_a_log10_bias', 'chlor_a_log10_rmsd'] \n\nIs the first latitude value --&gt; 89.97916666666667\ngreater than the last latitude value --&gt; -89.97916666666666\nTrue"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#replot-the-results-using-data-from-all-four-datasets",
    "href": "tutorials/python/timeseries_compare_sensors.html#replot-the-results-using-data-from-all-four-datasets",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Replot the results using data from all four datasets",
    "text": "Replot the results using data from all four datasets\n\nplt.figure(figsize=(10, 5)) \n\n# Add SeaWiFS data\nplt.plot_date(swAVG.time, swAVG, \n              'o', markersize=0, \n              label='SeaWiFS', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(modisAVG.time, modisAVG, \n              's', markersize=0, \n              label='MODIS', c='blue', \n              linestyle='-', linewidth=1) \n\n# Add VIIRS data\nplt.plot_date(viirsAVG.time, viirsAVG, \n              '^', markersize=0, \n              label='VIIRS', c='green', \n              linestyle='-', linewidth=1) \n\n# Add CCI data\nplt.plot_date(cciAVG.time, cciAVG, \n              'o', markersize=3,\n              label='OC-CCI', c='black', \n              linestyle='-', linewidth=1) \n\nplt.ylim([0, 3])\nplt.ylabel('Chl-a (mg m-3)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/python/timeseries_compare_sensors.html#references",
    "href": "tutorials/python/timeseries_compare_sensors.html#references",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "References",
    "text": "References\n\nCoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html\nhttps://polarwatch.noaa.gov/catalog/"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html",
    "title": "Working with data that crosses the antimeridian",
    "section": "",
    "text": "History | Updated Sep 2023"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#background",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#background",
    "title": "Working with data that crosses the antimeridian",
    "section": "Background",
    "text": "Background\nMany datasets use a system where longitude is numbered from -180 to +180 degrees east (see example below). This numbering system presents a problem for researchers working in a region that spans the antimeridian, because the parts of the data end up on the opposite ends of the map.\n\n\n\nmap_-180to180_500px.png\n\n\n\nFigure. Global map on -180/+180 longitude showing data region crossing the antimeridian."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#objectives",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#objectives",
    "title": "Working with data that crosses the antimeridian",
    "section": "Objectives",
    "text": "Objectives\nThis tutorial will demonstrate how to use datasets with -180 to +180 longitude values to work within regions that cross the antimeridian."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Working with data that crosses the antimeridian",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data that crosses the antimeridian from a dataset with -180 to +180 longitude values\n\nConvert the data to a 0-360 longitude values\nReordering the longitude axis so that the longitude values are in ascending order\nVisualizing data on a map"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#datasets-used",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#datasets-used",
    "title": "Working with data that crosses the antimeridian",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Chlorophyll Gap-filled, Blended NOAA-20 and S-NPP VIIRS, Science Quality, Global, 9km, 2018- recent, Daily\nThis NOAA dataset blends chlorophyll data from the Visible and Infrared Imager/Radiometer Suite (VIIRS) sensors aboard the Suomi-NPP and NOAA-20 spacecraft. The gaps in the data are then filled using an empirical orthogonal function (DINEOF). The dataset is available from the CoastWatch Central ERDDAP: https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily\n\nImport packages\n\nimport xarray as xr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#define-the-area-to-extract",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#define-the-area-to-extract",
    "title": "Working with data that crosses the antimeridian",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nWe will extract data for an area in the Bering Sea between Russia and the United States at 176°E to -152°E longitude and 50°N to 70°N latitude.\n\n\n\ninterest_area_500px.png\n\n\n\nSet up variables\n\nDate to extract\nMinimum and maximum values for the longitude and latitude ranges.\n\n\nmy_date = '2023-08-18'\nlon_min = -152.\nlon_max = 176.\nlat_min = 50.\nlat_max = 70."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#get-the-seawifs-data",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#get-the-seawifs-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Get the SeaWiFS data",
    "text": "Get the SeaWiFS data\n\nOpen an xarray dataset object\n\n#url = 'https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily'\n\nurl = '/'.join(['https://coastwatch.noaa.gov',\n                'erddap',\n                'griddap',\n                'noaacwNPPN20VIIRSSCIDINEOFDaily'\n                ])\n\nds = xr.open_dataset(url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:    (time: 1874, altitude: 1, latitude: 2160, longitude: 4320)\nCoordinates:\n  * time       (time) datetime64[ns] 2018-05-30T12:00:00 ... 2023-08-24T12:00:00\n  * altitude   (altitude) float64 0.0\n  * latitude   (latitude) float32 89.96 89.88 89.79 ... -89.79 -89.88 -89.96\n  * longitude  (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nData variables:\n    chlor_a    (time, altitude, latitude, longitude) float32 ...\nAttributes: (12/77)\n    _lastModified:                    2023-09-04T21:15:13.000Z\n    _NCProperties:                    version=2,netcdf=4.7.3,hdf5=1.12.0,\n    cdm_data_type:                    Grid\n    Conventions:                      CF-1.6, COARDS, ACDD-1.3\n    creator_email:                    coastwatch.info@noaa.gov\n    creator_name:                     NOAA CoastWatch\n    ...                               ...\n    testOutOfDate:                    now-4days\n    time_coverage_end:                2023-08-24T12:00:00Z\n    time_coverage_start:              2018-05-30T12:00:00Z\n    title:                            Chlorophyll (Gap-filled DINEOF), NOAA S...\n    Westernmost_Easting:              -179.9583\n    westernmost_longitude:            -180.0xarray.DatasetDimensions:time: 1874altitude: 1latitude: 2160longitude: 4320Coordinates: (4)time(time)datetime64[ns]2018-05-30T12:00:00 ... 2023-08-..._CoordinateAxisType :Timeactual_range :[1.5276816e+09 1.6928784e+09]axis :Tioos_category :Timelong_name :Timesource_name :timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2018-05-30T12:00:00.000000000', '2018-05-31T12:00:00.000000000',\n       '2018-06-01T12:00:00.000000000', ..., '2023-08-22T12:00:00.000000000',\n       '2023-08-23T12:00:00.000000000', '2023-08-24T12:00:00.000000000'],\n      dtype='datetime64[ns]')altitude(altitude)float640.0_CoordinateAxisType :Height_CoordinateZisPositive :upactual_range :[0. 0.]axis :Zioos_category :Locationlong_name :Altitudepositive :upstandard_name :altitudeunits :marray([0.])latitude(latitude)float3289.96 89.88 89.79 ... -89.88 -89.96_ChunkSizes :2160_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudesource_name :latstandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([ 89.958336,  89.875   ,  89.791664, ..., -89.79167 , -89.87501 ,\n       -89.958336], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_ChunkSizes :4320_CoordinateAxisType :Lonactual_range :[-179.9583  179.9583]axis :Xioos_category :Locationlong_name :Longitudesource_name :lonstandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79167, ...,  179.79167,  179.87502,\n        179.95834], dtype=float32)Data variables: (1)chlor_a(time, altitude, latitude, longitude)float32...C_format :%.4gcell_methods :time:mean(interval:1 day)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logcoverage_content_type :physicalMeasurementgrid_mapping :coord_refioos_category :Ocean Colorlong_name :Chlorophyll Concentration, DINEOF Gap-Filledstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001[17486668800 values with dtype=float32]Indexes: (4)timePandasIndexPandasIndex(DatetimeIndex(['2018-05-30 12:00:00', '2018-05-31 12:00:00',\n               '2018-06-01 12:00:00', '2018-06-02 12:00:00',\n               '2018-06-03 12:00:00', '2018-06-04 12:00:00',\n               '2018-06-05 12:00:00', '2018-06-06 12:00:00',\n               '2018-06-07 12:00:00', '2018-06-08 12:00:00',\n               ...\n               '2023-08-15 12:00:00', '2023-08-16 12:00:00',\n               '2023-08-17 12:00:00', '2023-08-18 12:00:00',\n               '2023-08-19 12:00:00', '2023-08-20 12:00:00',\n               '2023-08-21 12:00:00', '2023-08-22 12:00:00',\n               '2023-08-23 12:00:00', '2023-08-24 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=1874, freq=None))altitudePandasIndexPandasIndex(Index([0.0], dtype='float64', name='altitude'))latitudePandasIndexPandasIndex(Index([ 89.95833587646484,             89.875,  89.79166412353516,\n        89.70833587646484,             89.625,  89.54166412353516,\n        89.45833587646484,             89.375,  89.29166412353516,\n        89.20833587646484,\n       ...\n       -89.20833587646484, -89.29167175292969, -89.37500762939453,\n       -89.45833587646484, -89.54167175292969, -89.62500762939453,\n       -89.70833587646484, -89.79167175292969, -89.87500762939453,\n       -89.95833587646484],\n      dtype='float32', name='latitude', length=2160))longitudePandasIndexPandasIndex(Index([-179.9583282470703,           -179.875, -179.7916717529297,\n       -179.7083282470703,           -179.625, -179.5416717529297,\n       -179.4583282470703,           -179.375, -179.2916717529297,\n       -179.2083282470703,\n       ...\n       179.20834350585938,  179.2916717529297, 179.37501525878906,\n       179.45834350585938,  179.5416717529297, 179.62501525878906,\n       179.70834350585938,  179.7916717529297, 179.87501525878906,\n       179.95834350585938],\n      dtype='float32', name='longitude', length=4320))Attributes: (77)_lastModified :2023-09-04T21:15:13.000Z_NCProperties :version=2,netcdf=4.7.3,hdf5=1.12.0,cdm_data_type :GridConventions :CF-1.6, COARDS, ACDD-1.3creator_email :coastwatch.info@noaa.govcreator_name :NOAA CoastWatchcreator_type :groupcreator_url :https://coastwatch.noaa.gov/data_bins :4466138.0data_maximum :301.4826data_minimum :0.0022108806date_created :2023-09-04T21:15:13.000ZEasternmost_Easting :179.9583easternmost_longitude :180.0end_orbit_number :0geospatial_lat_max :89.95834geospatial_lat_min :-89.95834geospatial_lat_resolution :0.08333333950903196geospatial_lat_units :degrees_northgeospatial_lon_max :179.9583geospatial_lon_min :-179.9583geospatial_lon_resolution :0.0833333178976615geospatial_lon_units :degrees_eastgeospatial_vertical_max :0.0geospatial_vertical_min :0.0geospatial_vertical_positive :upgeospatial_vertical_units :mhistory :/data/data369/hgu/ocssw/bin/l3mapgen par=/data/data652/coastwatch/oc/L3/scripts/bin/../config/l3mapgen_par_dineof_chlor_a ifile=/data/data652/coastwatch/oc/L3/scripts/bin/../temp/Config_dineof/V2023236_oci_L3.nc ofile=/data/data369/viirs/L3_dineof/236/V2023236_A1_WW00_chlor_a.nc   Mon Sep  4 21:15:16 2023\n: /data/data652/coastwatch/oc/L3/scripts/bin/l3cnvtr -b -s Suomi-NPP,NOAA-20 /data/data369/viirs/L3_dineof/236/V2023236_A1_WW00_chlor_a.nc /data/aftp/socd1/mecb/coastwatch/viirs/science/L3/global/chlora/dineof/2023/V2023236_A1_WW00_chlora.nc\n2023-09-05T23:55:50Z (local files)\n2023-09-05T23:55:50Z https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily.dasid :L3//data/data540/DINEOF/EOF-global-daily4/reconstructed_mix_nsw/V2023236_oci_L3.ncinfoUrl :https://coastwatch.noaa.gov/institution :NOAA NESDIS CoastWatchinstrument :VIIRSkeywords :altitude, applications, baseline, center, chlorophyll, data, environmental, graphics, imager, imager/radiometer, imaging, information, infrared, latitude, leaving, longitude, mean, merged, n20, national, nesdis, noaa, NOAA-20, normalized, npp, optical, optical properties, orbiting, overlay, partnership, planes, polar, polar-orbiting, properties, radiance, radiometer, research, satellite, service, suite, time, viirs, visible, water, water-leaving, ww00l2_flag_names :ATMFAIL,LAND,HIGLINT,HILT,HISATZEN,CLOUD,HISOLZEN,LOWLW,CHLFAIL,NAVWARN,CLDSHDSTL,MAXAERITER,CHLWARN,ALGICE,SEAICE,NAVFAIL,FILTERlatitude_step :0.083333336latitude_units :degrees_northlicense :These data were produced by NOAA and are not subject to copyright protection in the United States. \nNOAA waives any potential copyright and related rights in these data worldwide through the Creative \nCommons Zero 1.0 Universal Public Domain Dedication (CC0-1.0). \nThe data may be used and redistributed for free but is not intended\n for legal use, since it may contain inaccuracies. Neither the data\n Contributor, ERD, NOAA, nor the United States Government, nor any\n of their employees or contractors, makes any warranty, express or\n implied, including warranties of merchantability and fitness for a\n particular purpose, or assumes any legal liability for the accuracy,\n completeness, or usefulness, of this information.longitude_step :0.083333336longitude_units :degrees_eastmap_projection :geographicmeasure :Meannaming_authority :gov.noaa.coastwatchnorthernmost_latitude :90.0Northernmost_Northing :89.95834number_of_columns :4320number_of_lines :2160platform :Suomi-NPP, NOAA-20processing_level :L3 Mappedprocessing_version :Unspecifiedproduct_name :V2023236_A1_WW00_chlora.ncproj4_string :+proj=eqc +lat_ts=0 +lat_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +lon_0=0.000000project :Ocean Color Science Team (NOAA/NESDIS/STAR/OCST)publisher_email :coastwatch.info@noaa.gov;ncei.info@noaa.govpublisher_name :NOAA CoastWatch;National Centers for Environmental Information (NCEI)publisher_url :https://coastwatch.noaa.gov;https://www.ncei.noaa.gov/Satellite :Suomi-NPP\n NOAA-20Sensor :VIIRSsourceUrl :(local files)southernmost_latitude :-90.0Southernmost_Northing :-89.95834spatialResolution :9.28 kmstandard_name_vocabulary :CF Standard Name Table v29start_orbit_number :0suggested_image_scaling_applied :Nosuggested_image_scaling_maximum :20.0suggested_image_scaling_minimum :0.01suggested_image_scaling_type :LOGsummary :Visible and Infrared Imager/Radiometer Suite/Suomi-NPP NOAA-20 (VIIRS) Level-3 (WW00), Chlorophyll, DINEOF, Gap filled, MSL12,  Science Quality,Global, Daily, processed by NOAA.  EXPERIMENTAL.sw_point_latitude :-89.958336sw_point_longitude :-179.95833temporal_range :dailytestOutOfDate :now-4daystime_coverage_end :2023-08-24T12:00:00Ztime_coverage_start :2018-05-30T12:00:00Ztitle :Chlorophyll (Gap-filled DINEOF), NOAA S-NPP NOAA-20, VIIRS, Science Quality, Global 9km, 2018-recent,  DailyWesternmost_Easting :-179.9583westernmost_longitude :-180.0\n\n\n\n\nSubset the data\nWe will do this in two steps to make the process easier to follow. 1. Subset the data for date and latitude range 2. Subset the area around the antimeridian * Request data &lt; the limit (-152) on the US side of the antimeridian, i.e. -180 to -152 * Request data &gt; the limit (176) on the Russian side of the antimeridian, i.e. 176 to 180\n\n# The lat1 and lat2 values are used in the slice function\n# At first we set them as if the dataset is compliant with standards\nlat1 = lat_min\nlat2 = lat_max\n\n# Then switch them if latitude values are descending\nif ds.latitude[0].item() &gt; ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\n# Subset the data in two steps to make it easier to understand\n# 1. Subset the date and latitude range\nds_subset = ds['chlor_a'].sel(time=my_date, \n                              method='nearest').sel(latitude=slice(lat1, lat2))\n\n# 2. Subset the around the antimeridian\nds_subset = ds_subset.sel(longitude=(ds.longitude &lt; lon_min) \n                          | (ds.longitude &gt; lon_max)\n                          )\n\nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlor_a' (altitude: 1, latitude: 240, longitude: 384)&gt;\n[92160 values with dtype=float32]\nCoordinates:\n    time       datetime64[ns] 2023-08-18T12:00:00\n  * altitude   (altitude) float64 0.0\n  * latitude   (latitude) float32 69.96 69.88 69.79 69.71 ... 50.21 50.12 50.04\n  * longitude  (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nAttributes: (12/13)\n    C_format:               %.4g\n    cell_methods:           time:mean(interval:1 day)\n    colorBarMaximum:        30.0\n    colorBarMinimum:        0.03\n    colorBarScale:          Log\n    coverage_content_type:  physicalMeasurement\n    ...                     ...\n    ioos_category:          Ocean Color\n    long_name:              Chlorophyll Concentration, DINEOF Gap-Filled\n    standard_name:          mass_concentration_of_chlorophyll_a_in_sea_water\n    units:                  mg m^-3\n    valid_max:              100.0\n    valid_min:              0.001xarray.DataArray'chlor_a'altitude: 1latitude: 240longitude: 384...[92160 values with dtype=float32]Coordinates: (4)time()datetime64[ns]2023-08-18T12:00:00_CoordinateAxisType :Timeactual_range :[1.5276816e+09 1.6928784e+09]axis :Tioos_category :Timelong_name :Timesource_name :timestandard_name :timetime_origin :01-JAN-1970 00:00:00array('2023-08-18T12:00:00.000000000', dtype='datetime64[ns]')altitude(altitude)float640.0_CoordinateAxisType :Height_CoordinateZisPositive :upactual_range :[0. 0.]axis :Zioos_category :Locationlong_name :Altitudepositive :upstandard_name :altitudeunits :marray([0.])latitude(latitude)float3269.96 69.88 69.79 ... 50.12 50.04_ChunkSizes :2160_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudesource_name :latstandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([69.958336, 69.875   , 69.791664, ..., 50.208332, 50.125   , 50.041664],\n      dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_ChunkSizes :4320_CoordinateAxisType :Lonactual_range :[-179.9583  179.9583]axis :Xioos_category :Locationlong_name :Longitudesource_name :lonstandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79167, ...,  179.79167,  179.87502,\n        179.95834], dtype=float32)Indexes: (3)altitudePandasIndexPandasIndex(Index([0.0], dtype='float64', name='altitude'))latitudePandasIndexPandasIndex(Index([ 69.95833587646484,             69.875,  69.79166412353516,\n        69.70833587646484,             69.625,  69.54166412353516,\n        69.45833587646484,             69.375,  69.29166412353516,\n        69.20833587646484,\n       ...\n       50.791664123535156,  50.70833206176758,             50.625,\n       50.541664123535156,  50.45833206176758,             50.375,\n       50.291664123535156,  50.20833206176758,             50.125,\n       50.041664123535156],\n      dtype='float32', name='latitude', length=240))longitudePandasIndexPandasIndex(Index([-179.9583282470703,           -179.875, -179.7916717529297,\n       -179.7083282470703,           -179.625, -179.5416717529297,\n       -179.4583282470703,           -179.375, -179.2916717529297,\n       -179.2083282470703,\n       ...\n       179.20834350585938,  179.2916717529297, 179.37501525878906,\n       179.45834350585938,  179.5416717529297, 179.62501525878906,\n       179.70834350585938,  179.7916717529297, 179.87501525878906,\n       179.95834350585938],\n      dtype='float32', name='longitude', length=384))Attributes: (13)C_format :%.4gcell_methods :time:mean(interval:1 day)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logcoverage_content_type :physicalMeasurementgrid_mapping :coord_refioos_category :Ocean Colorlong_name :Chlorophyll Concentration, DINEOF Gap-Filledstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-downloaded-data",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-downloaded-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Plot the downloaded data",
    "text": "Plot the downloaded data\n\n# Make plot area\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Set the color palette\ncmap = mpl.cm.get_cmap(\"jet\").copy()\ncmap.set_bad(color='gray')\n\n# Show image\nshw = ax.imshow(np.log10(ds_subset.squeeze()), cmap=cmap, vmin=-1, vmax=2)\n\nbar = plt.colorbar(shw, shrink=0.65)\n  \n# Show plot with labels\nbar.set_label('Chlorophyll (log mg m-3)')\nplt.show()\n\n\n\n\n\n\n\n\n\nThe plot of the data shows a discontinuity\nThe plot of subsetted data (above) shows that we downloaded the data we requested, but there is a discontinuity on the right side of the map. The data from the Russian side (west of the antimeridian) is mapped to the east of the data on the US side.\nTo fix the discontinuity, we need to:\n* Change the longitude values on the US side of the antimeridian (-180 to -152) to values on the 0-360 longitude indexing system (180-208). * Rearrange the longitude values so that the data on the Russian side is moved to the west of the data on the US side."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#change-to-0-360-longitude-numbering",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#change-to-0-360-longitude-numbering",
    "title": "Working with data that crosses the antimeridian",
    "section": "Change to 0-360 longitude numbering",
    "text": "Change to 0-360 longitude numbering\n\nds_360 = ds_subset.assign_coords(longitude=(ds_subset.longitude % 360))\n\nprint('minimum lon value =', ds_360.longitude.min().item())\nprint('minimum lon value =', ds_360.longitude.max().item(), end='\\n\\n')\n\nprint('first value in lon array =', ds_360.longitude[0].item())\nprint('last value in lon array =', ds_360.longitude[-1].item())\n\nminimum lat value = 176.0416717529297\nminimum lat value = 207.9583282470703\n\nfirst value in lat array = 180.0416717529297\nlast value in lat array = 179.95834350585938"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#reorder-the-longitude-axis",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#reorder-the-longitude-axis",
    "title": "Working with data that crosses the antimeridian",
    "section": "Reorder the longitude axis",
    "text": "Reorder the longitude axis\nThe output from the cell above shows that the longitude values have been converted to 0-360. However, the lowest longitude value is not at the beginning of the array and the highest longitude value is not at the end of the array.\nTo rearrange the longitude values, use the roll function of xarray. The roll function will push values along an axis by the number of steps you enter. The values that are “pushed off” of the end of the array will be put at the beginning of the array.\n\nFirst we need to find the position where the longitude discontinuity happens, i.e. where the most easterly longitude (208.0) abruptly meets the most easterly longitude value (176.0)\nNext, use the discontinuity position to determine how many positions to roll the longitude array to the right. Apply the number to the roll function.\n\n\n# This code finds the index where the absolute value between each longitude value \n# and the largest longitude value is maximal\ndiscont_index = max(range(len(ds_360.longitude)), \n                    key=lambda i: abs(ds_360.longitude[i] -\n                                      ds_360.longitude.max())\n                    )\nprint('the index marking the discontinuity is:', discont_index, end='\\n\\n')\n\n# Substract the discontinuity position from the length of the array \n# to obtain the number of positions to roll the longitude axis\npostions_to_roll = len(ds_360.longitude) - discont_index\n\n# Roll the dataset\nds_rolled = ds_360.roll(longitude=postions_to_roll, roll_coords=True)\n\nprint('minimum lon value =', ds_rolled.longitude.min().item())\nprint('minimum lon value =', ds_rolled.longitude.max().item(), end='\\n\\n')\n\nprint('first value in lon array =', ds_rolled.longitude[0].item())\nprint('last value in lon array =', ds_rolled.longitude[-1].item())\n\nthe index marking the discontinuity is: 336\n\nminimum lon value = 176.0416717529297\nminimum lon value = 207.9583282470703\n\nfirst value in lon array = 176.0416717529297\nlast value in lon array = 207.9583282470703\n\n\nThe output from the cell above shows that the longitude values have been converted to 0-360, and that the lowest longitude value is at the beginning of the array and the highest longitude value is at the end of the array."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-data",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Plot the data",
    "text": "Plot the data\n\nThe discontinuity has been corrected!\n\n# Make plot area\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Set the color palette\ncmap = mpl.cm.get_cmap(\"jet\").copy()\ncmap.set_bad(color='gray')\n\n# show image\nshw = ax.imshow(np.log10(ds_rolled.squeeze()), \n                cmap=cmap,\n                vmin=-1, \n                vmax=2)\n\nbar = plt.colorbar(shw, shrink=0.65)\n  \n# show plot with labels\nbar.set_label('Chlorophyll (log mg m-3)')\nplt.show()"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#save-the-corrected-dataset-as-a-netcdf-file",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#save-the-corrected-dataset-as-a-netcdf-file",
    "title": "Working with data that crosses the antimeridian",
    "section": "Save the corrected dataset as a netCDF file",
    "text": "Save the corrected dataset as a netCDF file\n\nds_rolled.to_netcdf('data_corrected_0_to_360.nc')"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html",
    "href": "tutorials/r/virtual_buoy_example.html",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Updated August 2023 \n\nThere are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov), ARGO floats program (http://www.argo.ucsd.edu) or CoastWatch ERDDAP data servers (https://coastwatch.pfeg.noaa.gov/erddap/). In situ buoy data are widely used to monitor environmental conditions. In the absence of in situ buoy data - whether the buoy operation is discontinued, interrupted, or limited - satellite data within temporal and spatial coverage of the desired locationcan be used to create a time series of a parameter of interest.\n\n\nThis tutorial will demonstrate how to create a time series from satellite data to gap-fill or replace buoy data.\n\n\n\n\nDownloading the satellite and buoy data from ERDDAP data server\nVisualizing the datasets\nReshaping the satellite data into a buoy data format\nResampling buoy data (aggregation) to match satellite data temporal resolution\nValidating the satellite data with the actual buoy data\nPerforming a linear regression of satellite vs. buoy data\nCreating a scatter plot of satellite vs. buoy data with the regression line\n\n\n\n\nSea-Surface Temperature, NOAA Geo-polar Blended Analysis Day+Night, GHRSST,Near Real-Time, Global 5km, 2019-Present, Daily\n.\nNDBC Standard Meteorological Buoy Data, 1970-present  NDBC Standard Meteorological Buoy Data  from the buoy station no. 46259 are from off the California coast at 34.737N latitude and 121.664E longitude.\n\n\n\n\nNOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center\n\n\n\n\n# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"utils\", \"ggplot2\", \"dplyr\", \"lubridate\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\nWe will download NDBC buoy data between January 16, 2022 and August 16, 2022 from the CoastWatch ERDDAP server.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\n# Set the ERDDAP data request URL\n \nbuoy_url &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?time%2Clongitude%2Clatitude%2Cwtmp&station%3E=%2246259%22&station%3C=%2246259%22&time%3E=2022-01-16T00%3A00%3A00Z&time%3C=2022-08-16T17%3A52%3A00Z\"\n\n# Set file name\nfname = 'buoy.csv'\n\n# Download file\ndownload.file(buoy_url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\n \nbuoy_df &lt;- read.csv(fname, skip=2, header=TRUE)\n\n# Name the columns\nnames(buoy_df) &lt;- c(\"utc\", \"lon\", \"lat\", \"sst\" )\n\n# Add additional date column\nbuoy_df$date &lt;- as.Date(buoy_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(buoy_df, 3)\n\n##                    utc      lon    lat  sst       date\n## 1 2022-01-16T00:56:00Z -121.664 34.732 13.4 2022-01-16\n## 2 2022-01-16T01:26:00Z -121.664 34.732 13.4 2022-01-16\n## 3 2022-01-16T01:56:00Z -121.664 34.732 13.3 2022-01-16\n\n\n\noptions(repr.plot.width = 10)\n\nggplot(buoy_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n # geom_point(size=.2, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celsius)\", title=\"SST from NDBC Buoy Station: 46259 (Aug 2022- Aug 2023) \")\n\n\n\n\nThe satellite Sea Surface Temperature (SST) product we will use is the NOAA GeoPolar Blended SST dataset (in Celsius), which blends data from many satellite sensors to obtain good daily coverage of the globe at 5km resolution, and then an interpolation method is applied to fill in data gaps.\nThe data request can be sent to a CoastWatch ERDDAP server via URL with a query string to specify the temporal and spatial coverage of interest. In this case, we want to subset the satellite data to match the buoy station location and time range.\n\n\n# Set ERDDAP URL for the satellite data\nurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisBLENDEDsstDNDaily.csv?analysed_sst%5B(2022-01-16T12:00:00Z):1:(2022-08-16T12:00:00Z)%5D%5B(34.737):1:(34.737)%5D%5B(-121.664):1:(-121.664)%5D\"\n\n# Set file name\nfname = 'sst.csv'\n\n# Download file\ndownload.file(url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\nsst_df &lt;- read.csv(fname, skip=2, header=TRUE)\nnames(sst_df) &lt;- c(\"utc\", \"lat\", \"lon\", \"sst\")\n\n# Add formatted data column\nsst_df$date &lt;- as.Date(sst_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(sst_df, 3)\n\n##                    utc    lat      lon      sst       date\n## 1 2022-01-18T12:00:00Z 34.725 -121.675 13.49999 2022-01-18\n## 2 2022-01-19T12:00:00Z 34.725 -121.675 13.44999 2022-01-19\n## 3 2022-01-20T12:00:00Z 34.725 -121.675 13.53999 2022-01-20\n\n\n\n\nApply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, a value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Filter data that are within the valid range (-2 and 45)\nsst_df_clean = sst_df %&gt;%\n  filter(sst &gt;=-2 & sst &lt;= 45)\n\n\n\n# Plot sea surface temperature values from satellite\np &lt;- ggplot(sst_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"Sea surface temperature from satellite\")\np\n\n\n\n\nThe sampling resolution for the buoy data is a sample every 30 minutes. However, the temporal resolution for the satellite dataset is daily. We will downsample the buoy data by computing daily mean to match the temporal resolution of the satellite data.\n# Aggregating (taking a mean value) grouped by day\nbuoy_ds &lt;- buoy_df %&gt;%\n  group_by(date = floor_date(date, unit=\"days\")) %&gt;%\n  summarise(mean_sst = mean(sst))\n\n# Show first 3 rows\nhead(buoy_ds, 3)\n\n## # A tibble: 3 × 2\n##   date       mean_sst\n##   &lt;date&gt;        &lt;dbl&gt;\n## 1 2022-01-16     13.4\n## 2 2022-01-17     13.5\n## 3 2022-01-18     13.6\n\n\n\nApply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Remove outliers sst values outside of -2 and 45 deg C\nbuoy_ds_clean = buoy_ds %&gt;%\n  filter(mean_sst &gt;=-2 & mean_sst &lt;= 45)\n\n\n\n# Plot daily mean sst\nggplot(buoy_ds_clean, aes(x = date, y = mean_sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"2022 Aug- 2023 Aug Downsampled Buoy SST\")\n\n\n\n\nWe will use dplyr::inner_join() function to merge the two data frames (satellite and buoy data) based on the dates that appear in both data frames.\n# Combine two data frames with date column where dates exist in both data frames\nmerged_df &lt;- inner_join(sst_df_clean[c(\"date\", \"sst\")],  buoy_ds_clean, by = \"date\")\n\n\n\n# Plot satellite sst and buoy daily mean sst \np &lt;- ggplot(merged_df, aes(x = date)) +  \n    geom_line(aes(y = sst, color = \"Satellite\")) +   \n    geom_line(aes(y = mean_sst, color = \"NDBC Buoy\")) +   \n    scale_color_manual(name = \"Data source\", \n                       values = c(\"Satellite\" = \"blue\", \"NDBC Buoy\" = \"orange\"))+\n    labs( x = \"Date\", y = \"Temperature (in Celsius)\", title=\"SST from Satellite and NDBC Buoy\" )+\n    theme(axis.text.x = element_text(angle = 0),plot.title=element_text(hjust=0.5))\np\n ## Perform a simple linear regression\n# Run linear regression \nmodel &lt;- lm(mean_sst ~ sst, data = merged_df)   \nsummary(model)\n\n## \n## Call:\n## lm(formula = mean_sst ~ sst, data = merged_df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.48812 -0.21354 -0.02782  0.14581  1.67408 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.54793    0.30272    1.81   0.0718 .  \n## sst          0.96142    0.02221   43.29   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4462 on 203 degrees of freedom\n## Multiple R-squared:  0.9023, Adjusted R-squared:  0.9018 \n## F-statistic:  1874 on 1 and 203 DF,  p-value: &lt; 2.2e-16\n\n\n\nggplot(merged_df, aes(x=sst, y=mean_sst)) +\n  geom_point(color=\"black\", size=1) +                      # Plot the data points\n  geom_smooth(method=\"lm\", se=FALSE) +\n  labs(x = \"SST from Buoy\", y = \"SST from Satellite\", title = \"Satellite vs Buoy data with regression line\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n## `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#objective",
    "href": "tutorials/r/virtual_buoy_example.html#objective",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "This tutorial will demonstrate how to create a time series from satellite data to gap-fill or replace buoy data."
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/virtual_buoy_example.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Downloading the satellite and buoy data from ERDDAP data server\nVisualizing the datasets\nReshaping the satellite data into a buoy data format\nResampling buoy data (aggregation) to match satellite data temporal resolution\nValidating the satellite data with the actual buoy data\nPerforming a linear regression of satellite vs. buoy data\nCreating a scatter plot of satellite vs. buoy data with the regression line"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#datasets-used",
    "href": "tutorials/r/virtual_buoy_example.html#datasets-used",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Sea-Surface Temperature, NOAA Geo-polar Blended Analysis Day+Night, GHRSST,Near Real-Time, Global 5km, 2019-Present, Daily\n.\nNDBC Standard Meteorological Buoy Data, 1970-present  NDBC Standard Meteorological Buoy Data  from the buoy station no. 46259 are from off the California coast at 34.737N latitude and 121.664E longitude."
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#references",
    "href": "tutorials/r/virtual_buoy_example.html#references",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "NOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#install-required-packages-and-load-libraries",
    "href": "tutorials/r/virtual_buoy_example.html#install-required-packages-and-load-libraries",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"utils\", \"ggplot2\", \"dplyr\", \"lubridate\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#download-ndbc-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#download-ndbc-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "We will download NDBC buoy data between January 16, 2022 and August 16, 2022 from the CoastWatch ERDDAP server.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\n# Set the ERDDAP data request URL\n \nbuoy_url &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?time%2Clongitude%2Clatitude%2Cwtmp&station%3E=%2246259%22&station%3C=%2246259%22&time%3E=2022-01-16T00%3A00%3A00Z&time%3C=2022-08-16T17%3A52%3A00Z\"\n\n# Set file name\nfname = 'buoy.csv'\n\n# Download file\ndownload.file(buoy_url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\n \nbuoy_df &lt;- read.csv(fname, skip=2, header=TRUE)\n\n# Name the columns\nnames(buoy_df) &lt;- c(\"utc\", \"lon\", \"lat\", \"sst\" )\n\n# Add additional date column\nbuoy_df$date &lt;- as.Date(buoy_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(buoy_df, 3)\n\n##                    utc      lon    lat  sst       date\n## 1 2022-01-16T00:56:00Z -121.664 34.732 13.4 2022-01-16\n## 2 2022-01-16T01:26:00Z -121.664 34.732 13.4 2022-01-16\n## 3 2022-01-16T01:56:00Z -121.664 34.732 13.3 2022-01-16"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#visualize-sst-from-the-buoy",
    "href": "tutorials/r/virtual_buoy_example.html#visualize-sst-from-the-buoy",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "options(repr.plot.width = 10)\n\nggplot(buoy_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n # geom_point(size=.2, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celsius)\", title=\"SST from NDBC Buoy Station: 46259 (Aug 2022- Aug 2023) \")"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#download-the-satellite-sea-surface-temperature-sst-data",
    "href": "tutorials/r/virtual_buoy_example.html#download-the-satellite-sea-surface-temperature-sst-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "The satellite Sea Surface Temperature (SST) product we will use is the NOAA GeoPolar Blended SST dataset (in Celsius), which blends data from many satellite sensors to obtain good daily coverage of the globe at 5km resolution, and then an interpolation method is applied to fill in data gaps.\nThe data request can be sent to a CoastWatch ERDDAP server via URL with a query string to specify the temporal and spatial coverage of interest. In this case, we want to subset the satellite data to match the buoy station location and time range.\n\n\n# Set ERDDAP URL for the satellite data\nurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisBLENDEDsstDNDaily.csv?analysed_sst%5B(2022-01-16T12:00:00Z):1:(2022-08-16T12:00:00Z)%5D%5B(34.737):1:(34.737)%5D%5B(-121.664):1:(-121.664)%5D\"\n\n# Set file name\nfname = 'sst.csv'\n\n# Download file\ndownload.file(url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\nsst_df &lt;- read.csv(fname, skip=2, header=TRUE)\nnames(sst_df) &lt;- c(\"utc\", \"lat\", \"lon\", \"sst\")\n\n# Add formatted data column\nsst_df$date &lt;- as.Date(sst_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(sst_df, 3)\n\n##                    utc    lat      lon      sst       date\n## 1 2022-01-18T12:00:00Z 34.725 -121.675 13.49999 2022-01-18\n## 2 2022-01-19T12:00:00Z 34.725 -121.675 13.44999 2022-01-19\n## 3 2022-01-20T12:00:00Z 34.725 -121.675 13.53999 2022-01-20"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#clean-up-the-data",
    "href": "tutorials/r/virtual_buoy_example.html#clean-up-the-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Apply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, a value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Filter data that are within the valid range (-2 and 45)\nsst_df_clean = sst_df %&gt;%\n  filter(sst &gt;=-2 & sst &lt;= 45)"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#visualize-the-satellite-sst-data",
    "href": "tutorials/r/virtual_buoy_example.html#visualize-the-satellite-sst-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot sea surface temperature values from satellite\np &lt;- ggplot(sst_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"Sea surface temperature from satellite\")\np"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#resample-the-buoy-data-to-match-the-satellite-data",
    "href": "tutorials/r/virtual_buoy_example.html#resample-the-buoy-data-to-match-the-satellite-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "The sampling resolution for the buoy data is a sample every 30 minutes. However, the temporal resolution for the satellite dataset is daily. We will downsample the buoy data by computing daily mean to match the temporal resolution of the satellite data.\n# Aggregating (taking a mean value) grouped by day\nbuoy_ds &lt;- buoy_df %&gt;%\n  group_by(date = floor_date(date, unit=\"days\")) %&gt;%\n  summarise(mean_sst = mean(sst))\n\n# Show first 3 rows\nhead(buoy_ds, 3)\n\n## # A tibble: 3 × 2\n##   date       mean_sst\n##   &lt;date&gt;        &lt;dbl&gt;\n## 1 2022-01-16     13.4\n## 2 2022-01-17     13.5\n## 3 2022-01-18     13.6"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#clean-up-the-downsampled-data",
    "href": "tutorials/r/virtual_buoy_example.html#clean-up-the-downsampled-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Apply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Remove outliers sst values outside of -2 and 45 deg C\nbuoy_ds_clean = buoy_ds %&gt;%\n  filter(mean_sst &gt;=-2 & mean_sst &lt;= 45)"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#visualize-the-downsampled-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#visualize-the-downsampled-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot daily mean sst\nggplot(buoy_ds_clean, aes(x = date, y = mean_sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"2022 Aug- 2023 Aug Downsampled Buoy SST\")"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#merge-satellite-and-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#merge-satellite-and-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "We will use dplyr::inner_join() function to merge the two data frames (satellite and buoy data) based on the dates that appear in both data frames.\n# Combine two data frames with date column where dates exist in both data frames\nmerged_df &lt;- inner_join(sst_df_clean[c(\"date\", \"sst\")],  buoy_ds_clean, by = \"date\")"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#plot-both-satellite-and-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#plot-both-satellite-and-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot satellite sst and buoy daily mean sst \np &lt;- ggplot(merged_df, aes(x = date)) +  \n    geom_line(aes(y = sst, color = \"Satellite\")) +   \n    geom_line(aes(y = mean_sst, color = \"NDBC Buoy\")) +   \n    scale_color_manual(name = \"Data source\", \n                       values = c(\"Satellite\" = \"blue\", \"NDBC Buoy\" = \"orange\"))+\n    labs( x = \"Date\", y = \"Temperature (in Celsius)\", title=\"SST from Satellite and NDBC Buoy\" )+\n    theme(axis.text.x = element_text(angle = 0),plot.title=element_text(hjust=0.5))\np\n ## Perform a simple linear regression\n# Run linear regression \nmodel &lt;- lm(mean_sst ~ sst, data = merged_df)   \nsummary(model)\n\n## \n## Call:\n## lm(formula = mean_sst ~ sst, data = merged_df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.48812 -0.21354 -0.02782  0.14581  1.67408 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.54793    0.30272    1.81   0.0718 .  \n## sst          0.96142    0.02221   43.29   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4462 on 203 degrees of freedom\n## Multiple R-squared:  0.9023, Adjusted R-squared:  0.9018 \n## F-statistic:  1874 on 1 and 203 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#plot-satellite-vs.-buoy-data-and-overlay-the-regression-line",
    "href": "tutorials/r/virtual_buoy_example.html#plot-satellite-vs.-buoy-data-and-overlay-the-regression-line",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "ggplot(merged_df, aes(x=sst, y=mean_sst)) +\n  geom_point(color=\"black\", size=1) +                      # Plot the data points\n  geom_smooth(method=\"lm\", se=FALSE) +\n  labs(x = \"SST from Buoy\", y = \"SST from Satellite\", title = \"Satellite vs Buoy data with regression line\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n## `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html",
    "href": "tutorials/r/Tutorial1-basics.html",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "A tidyverse/ggplot version is also available here: https://github.com/jebyrnes/noaa_coastwatch_tutorial_1/blob/main/tutorial1-1.md\ncourtesy of Jarrett Byrnes from UMass Boston - http://byrneslab.net (Thank you Jarrett!!)"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#objective",
    "href": "tutorials/r/Tutorial1-basics.html#objective",
    "title": "CoastWatch Training Materials",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab data hosted on an ERDDAP server from R, how to work with NetCDF files in R and how to make some maps and time-series of sea surface temperature."
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "CoastWatch Training Materials",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nLocating a satellite product in ERDDAP, manually changing the constraints and copying the URL defining the data request\nDownloading the resulting NetCDF file\nOpening and examining the NetCDF file\nMaking basic maps and time series plots"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#datasets-used",
    "href": "tutorials/r/Tutorial1-basics.html#datasets-used",
    "title": "CoastWatch Training Materials",
    "section": "Datasets used",
    "text": "Datasets used\nCoralTemp Sea Surface Temperature product from the NOAA Coral Reef Watch program. The NOAA Coral Reef Watch (CRW) daily global 5km Sea Surface Temperature (SST) product, also known as CoralTemp, shows the nighttime ocean temperature measured at the surface. The SST scale ranges from -2 to 35 °C. The CoralTemp SST data product was developed from two, related reanalysis (reprocessed) SST products and a near real-time SST product. Spanning January 1, 1985 to the present, the CoralTemp SST is one of the best and most internally consistent daily global 5km SST products available. More information about the product: https://coralreefwatch.noaa.gov/product/5km/index_5km_sst.php\nWe will use the monthly composite of this product and download it from the NOAA CoastWatch ERDDAP server: https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.graph\n# Package names\npackages &lt;- c( \"ncdf4\",\"httr\")\n\n# Install packages not yet installed\ninstalled_packages &lt;- packages %in% rownames(installed.packages())\n\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages])\n}\n\n# Load packages \ninvisible(lapply(packages, library, character.only = TRUE))"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#downloading-data-from-r",
    "href": "tutorials/r/Tutorial1-basics.html#downloading-data-from-r",
    "title": "CoastWatch Training Materials",
    "section": "1. Downloading data from R",
    "text": "1. Downloading data from R\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from R using the URL structure.\nFor example, the following page allows you to subset monthly sea surface temperature (SST) https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n NOTE: Notice that the latitudes are indexed from North to South (negative spacing)\nIn this specific example, the URL we generated is : https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D\nYou can also edit this URL manually.\nIn R, run the following to download the data using the generated URL (you need to copy it from your browser):\njunk &lt;- GET('https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D', write_disk(\"sst.nc\", overwrite=TRUE))"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#importing-the-downloaded-file-in-r",
    "href": "tutorials/r/Tutorial1-basics.html#importing-the-downloaded-file-in-r",
    "title": "CoastWatch Training Materials",
    "section": "2. Importing the downloaded file in R",
    "text": "2. Importing the downloaded file in R\nNow that we’ve downloaded the data locally, we can import it and extract our variables of interest:\n\nopen the file\n\n\nnc &lt;- nc_open('sst.nc')\n\nexamine which variables are included in the dataset:\n\n\nnames(nc$var)\n\n## [1] \"sea_surface_temperature\"\n\nExtract sea_surface_temperature:\n\n\nv1 &lt;- nc$var[[1]]\nsst &lt;- ncvar_get(nc,v1)\n\nexamine the structure of sst:\n\n\ndim(sst)\n\n## [1] 201 202  12\nOur dataset is a 3-D array with 201 rows corresponding to longitudes, 202 columns corresponding to latitudes for each of the 12 time steps.\n\nget the dates for each time step:\n\n\ndates &lt;- as.POSIXlt(v1$dim[[3]]$vals,origin='1970-01-01',tz='GMT')\ndates\n\n##  [1] \"2022-01-16 GMT\" \"2022-02-16 GMT\" \"2022-03-16 GMT\" \"2022-04-16 GMT\"\n##  [5] \"2022-05-16 GMT\" \"2022-06-16 GMT\" \"2022-07-16 GMT\" \"2022-08-16 GMT\"\n##  [9] \"2022-09-16 GMT\" \"2022-10-16 GMT\" \"2022-11-16 GMT\" \"2022-12-16 GMT\"\n\nget the longitude and latitude values\n\n\nlon &lt;- v1$dim[[1]]$vals\nlat &lt;- v1$dim[[2]]$vals\n\nClose the netcdf file and remove the data and files that are not needed anymore.\n\n\nnc_close(nc)\nrm(junk,v1)\nfile.remove('sst.nc')\n\n## [1] TRUE"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#working-with-the-extracted-data",
    "href": "tutorials/r/Tutorial1-basics.html#working-with-the-extracted-data",
    "title": "CoastWatch Training Materials",
    "section": "3. Working with the extracted data",
    "text": "3. Working with the extracted data\n\nCreating a map for one time step\nLet’s create a map of SST for January 2022 (our first time step).\nYou will need to download the scale.R file and copy it to your working directory to plot the color scale properly.\n\nset some color breaks\n\n\nh &lt;- hist(sst[,,1], 100, plot=FALSE)\nbreaks &lt;- h$breaks\nn &lt;- length(breaks)-1\n\ndefine a color palette\n\n\njet.colors &lt;- colorRampPalette(c(\"blue\", \"#007FFF\", \"cyan\",\"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"))\n\nset color scale using the jet.colors palette\n\n\nc &lt;- jet.colors(n)\n\nprepare graphic window : left side for map, right side for color scale\n\n\nlayout(matrix(c(1,2), nrow=1, ncol=2), widths=c(7,2), heights=4)\npar(mar=c(3,3,3,1))\n\n#plot the SST map. Because this product was built with latitudes going from North to South, we need to reverse the lat vector because the 'image' function needs increasing values for the coordinates. We also need to flip the sst matrix along the 2d dimension so it plots correctly\nimage(lon,rev(lat),sst[,dim(sst)[2]:1,1],col=c,breaks=breaks,xlab='',ylab='',axes=TRUE,xaxs='i',yaxs='i',asp=1, main=paste(\"Monthly SST\", dates[1]))\n\n#example of how to add points to the map\npoints(-74:-71,rep(34,4), pch=20, cex=2)\n\n#example of how to add a contour (this is considered a new plot, not a feature, so you need to use par(new=TRUE)) to overlay it on top of the SST map\npar(new=TRUE)\ncontour(lon,rev(lat),sst[,dim(sst)[2]:1,1],levels=14,xaxs='i',yaxs='i',labcex=0.8,vfont = c(\"sans serif\", \"bold\"),axes=FALSE,asp=1)\n\n#plot color scale using 'image.scale' function from 'scale.R' script)\npar(mar=c(3,1,3,3))\nsource('scale.R')\nimage.scale(sst[,,1], col=c, breaks=breaks, horiz=FALSE, yaxt=\"n\",xlab='',ylab='',main='SST')\naxis(4, las=1)\nbox()\n\n\n\nPlotting a time series\nLet’s pick the following box : 36-38N, -77 to -75W.. We are going to generate a time series of mean SST within that box.\nI=which(lon&gt;=-77 & lon&lt;=-75)\nJ=which(lat&gt;=36 & lat&lt;=38)\nsst2=sst[I,J,]\nn=dim(sst2)[3]\nres=rep(NA,n)\nfor (i in 1:n)\nres[i]=mean(sst2[,,i],na.rm=TRUE)\nplot(1:n,res,axes=FALSE,type='o',pch=20,xlab='',ylab='SST (ºC)')\naxis(2)\naxis(1,1:n,format(dates,'%m'))\nbox()\n\n\n\nCreating a map of average SST over a year\nsst.yr=apply(sst[,,1:12],c(1,2),mean,na.rm=TRUE)\nh=hist(sst.yr, 100, plot=FALSE)\nbreaks=h$breaks\nn=length(breaks)-1\nc=jet.colors(n)\nlayout(matrix(c(1,2), nrow=1, ncol=2), widths=c(7,2), heights=4)\npar(mar=c(3,3,3,1))\nimage(lon,rev(lat),sst.yr[,dim(sst.yr)[2]:1],col=c,breaks=breaks,xlab='',ylab='',axes=TRUE,xaxs='i',yaxs='i',asp=1,main=paste(\"Mean SST\", format(dates[1],'%Y/%m/%d'),' - ',format(dates[12],'%Y/%m/%d')))\npar(mar=c(3,1,3,3))\nimage.scale(sst.yr, col=c, breaks=breaks, horiz=FALSE, yaxt=\"n\",xlab='',ylab='',main='SST')\naxis(4)\nbox()"
  },
  {
    "objectID": "tutorials/matlab/Tutorial1-basics.html",
    "href": "tutorials/matlab/Tutorial1-basics.html",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands. Note: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset monthly SST data: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.html Select your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nerddap interface\n\n\nIn this specific example, the URL we generated is: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.nc?sea_surface_temperature%5B(2018-1-31T12:00:00Z):1:(2018-12-31T12:00:00Z)%5D%5B(17):1:(30)%5D%5B(195):1:(210)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly'); \nNotice that the full data set has four variables: time, latitude, longitude, and sea_surface_temperature. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\nTime Notice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'time');\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the year we’re interested in: 2018.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2018);\nLatitude and Longitude Before we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'longitude');\nNotice in the output above that sea_surface_temperature has the dimensions of longitude x latitude x time which means it has a size of 7200 x 3600 x 444. In the code below, we’ll create indices for our particular area of interest in the central North Pacific.\n% Find longitudes from 195 - 210 E\nlon_aoi = find(lon_full &gt;= 195 & lon_full &lt;= 210);\n\n% Find latitudes from 17 - 30 N\nlat_aoi = find(lat_full &gt;= 17 & lat_full &lt;= 30);\nSea Surface Temperature Now, we’ll access just the small amount of sea_surface_temperature data we’re interested in. We’ll do this by telling the computer to access the variable ‘sea_surface_temperature’, beginning at a specific location and time, and spanning our area and time of interest.\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', ...\n    'sea_surface_temperature', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 300 x 260 x 12. Before we see what these data look like, let’s create indices for the area and timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* % Delete every variable with 'aoi' or with 'full' in its name\n\n\n\nLet’s create a map for a single month, January 2018, the first month in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 100, 'fill', 'on');\ntitle(sprintf('Monthly SST %s', datestr(time_ymdhms(1,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(26,4), 202:1:205, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 20\ncontourm(lat, lon, sst(:,:,1)', [20 20], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\nJanuary SST\n\n\n\n\n\nLet’s pick the following box: 24-26N, 200-206E. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above to identify a subsetted area of interest.\n% Find longitudes from 200 - 206 E\nlon_aoi = find(lon &gt;= 200 & lon &lt;= 206);\n\n% Find latitudes from 24 - 26 N\nlat_aoi = find(lat &gt;= 24 & lat &lt;= 26);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 12 months\nsst_ts(1:12,1) = NaN;\nfor m = 1:1:12 \n    sst_ts(m,1) = mean(sst_subset(:,:,m), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,2), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\n\n\n\nSST time series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n\n% Average over time, which is the third dimention of our data\nsst_yr = mean(sst, 3, \"omitnan\");\n\n% Plot\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_yr', 100, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(12,:),'mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nJan mean sst"
  },
  {
    "objectID": "tutorials/matlab/Tutorial1-basics.html#tutorial-1.-how-to-work-with-satellite-data-in-matlab",
    "href": "tutorials/matlab/Tutorial1-basics.html#tutorial-1.-how-to-work-with-satellite-data-in-matlab",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands. Note: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset monthly SST data: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.html Select your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nerddap interface\n\n\nIn this specific example, the URL we generated is: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.nc?sea_surface_temperature%5B(2018-1-31T12:00:00Z):1:(2018-12-31T12:00:00Z)%5D%5B(17):1:(30)%5D%5B(195):1:(210)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly'); \nNotice that the full data set has four variables: time, latitude, longitude, and sea_surface_temperature. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\nTime Notice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'time');\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the year we’re interested in: 2018.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2018);\nLatitude and Longitude Before we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'longitude');\nNotice in the output above that sea_surface_temperature has the dimensions of longitude x latitude x time which means it has a size of 7200 x 3600 x 444. In the code below, we’ll create indices for our particular area of interest in the central North Pacific.\n% Find longitudes from 195 - 210 E\nlon_aoi = find(lon_full &gt;= 195 & lon_full &lt;= 210);\n\n% Find latitudes from 17 - 30 N\nlat_aoi = find(lat_full &gt;= 17 & lat_full &lt;= 30);\nSea Surface Temperature Now, we’ll access just the small amount of sea_surface_temperature data we’re interested in. We’ll do this by telling the computer to access the variable ‘sea_surface_temperature’, beginning at a specific location and time, and spanning our area and time of interest.\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', ...\n    'sea_surface_temperature', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 300 x 260 x 12. Before we see what these data look like, let’s create indices for the area and timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* % Delete every variable with 'aoi' or with 'full' in its name\n\n\n\nLet’s create a map for a single month, January 2018, the first month in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 100, 'fill', 'on');\ntitle(sprintf('Monthly SST %s', datestr(time_ymdhms(1,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(26,4), 202:1:205, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 20\ncontourm(lat, lon, sst(:,:,1)', [20 20], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\nJanuary SST\n\n\n\n\n\nLet’s pick the following box: 24-26N, 200-206E. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above to identify a subsetted area of interest.\n% Find longitudes from 200 - 206 E\nlon_aoi = find(lon &gt;= 200 & lon &lt;= 206);\n\n% Find latitudes from 24 - 26 N\nlat_aoi = find(lat &gt;= 24 & lat &lt;= 26);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 12 months\nsst_ts(1:12,1) = NaN;\nfor m = 1:1:12 \n    sst_ts(m,1) = mean(sst_subset(:,:,m), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,2), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\n\n\n\nSST time series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n\n% Average over time, which is the third dimention of our data\nsst_yr = mean(sst, 3, \"omitnan\");\n\n% Plot\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_yr', 100, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(12,:),'mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nJan mean sst"
  },
  {
    "objectID": "tutorials/codegallery.html",
    "href": "tutorials/codegallery.html",
    "title": "Code Gallery",
    "section": "",
    "text": "This page lists CoastWatch code gallery tutorials.\nClick the eye icon to view the tutorial or download to get the source file.\n\n\n\n\n\n\n\n\n\n  \n    Category\n    \n      All\n      ERDDAP BasicsTime Series & Trend Analysis\n    \n  \n\n  \n    Software\n\n    \n      Python ×\n    \n\n    \n      R ×\n    \n\n    \n      Matlab ×\n    \n\n    \n      Clear\n    \n  \n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nCategory\nPreview\nPython ↓\nR ↓\nMatlab ↓\n\n\n\n\nBasics of working with satellite data\nERDDAP Basics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompare time series from different sensors\nTime Series & Trend Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMake a virtual buoy with satellite data\nTime Series & Trend Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n    \n      Basics of working with satellite data\n      Access and analyze satellite-derived sea surface temperature using ERDDAP and NetCDF-based workflows. This tutorial demonstrates how to locate and subset a satellite SST product in ERDDAP, download gridded NetCDF data, examine its structure, and create basic spatial maps and regional time series. Users work with the NOAA Coral Reef Watch CoralTemp monthly sea surface temperature product to explore coordinate conventions, generate SST maps, compute regional averages, and visualize temporal variability.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature in the western North Atlantic Ocean along the US East Coast in 2022.\n          \n          \n          \n            \n              \n            \n            Map of the 2022 average sea surface temperature in the western North Atlantic Ocean along the US East Coast.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature in the western North Atlantic Ocean along the US East Coast in 2022.\n          \n          \n          \n            \n              \n            \n            Map of the 2022 average sea surface temperature in the western North Atlantic Ocean along the US East Coast.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature around the Hawaiian Islands in 2018.\n          \n          \n          \n            \n              \n            \n            Map of the 2018 average sea surface temperature in the Hawaiian Islands.\n          \n            ◀  1 / 2  ▶\n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      Compare time series from different sensors\n      Compare satellite chlorophyll-a time series from multiple ocean color sensors to understand differences during overlapping observation periods. This tutorial demonstrates how to use ERDDAP to extract spatially averaged chlorophyll-a time series from a defined region, examine dataset metadata, handle differences in coordinate conventions, and compare measurements across sensors through visualization. Monthly chlorophyll-a data from SeaWiFS, MODIS Aqua, NOAA VIIRS S-NPP, and the ESA Ocean Colour Climate Change Initiative (OC-CCI) are used to evaluate consistency and variability among sensors from 1997 to the present.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          \n            \n              \n            \n            Mean log-transformed chlorophyll-a concentration for the Gulf of Mexico region derived from SeaWiFS, MODIS Aqua, NOAA VIIRS S-NPP, and the ESA OC-CCI blended dataset.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      Make a virtual buoy with satellite data\n      Create a virtual ocean buoy using satellite data to extend or replace discontinued in situ observations. This tutorial demonstrates how to use ERDDAP to extract satellite sea surface temperature at a fixed location, build and clean a virtual buoy time series, resample the data to a lower temporal resolution, and analyze trends through visualization and linear regression. Data from NDBC Buoy 46259 are used alongside the NOAA GeoPolar Blended SST satellite dataset.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            National Data Buoy Center buoy 46259 matched up with sea surface temperature data.\n          \n          \n          \n            \n              \n            \n             Trend analysis of buoy and satellite data.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            National Data Buoy Center buoy 46259 matched up with sea surface temperature data.\n          \n          \n          \n            \n              \n            \n             Trend analysis of buoy and satellite data.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n\n\n\n\n\n\n✕",
    "crumbs": [
      "Training Tutorials",
      "Code Gallery"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CoastWatch Training Tutorials",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Tutorials will live here.",
    "crumbs": [
      "Training Tutorials",
      "Software Tutorials"
    ]
  },
  {
    "objectID": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html",
    "href": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "As an example, we are going to plot time-series of mean chlorophyll-a concentration from various sensors from 1997 to 2018 to look at the periods of overlap.\nWe are going to download data from SeaWiFS (1997-2010), MODIS (2002-present) and VIIRS (2012-present) and compare it to the ESA-CCI data which combines all 3 sensors into a homogeneous time-series.\nIn this tutorial, the URLs to the data are provided so you don’t have to search for them. But, if you weren’t sure what the URLs were, you could find them by searing the list of datasets hosted on the OceanWatch ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/index.html) and following the steps at the beginning of Tutoral 1.\nFor this tutoral, we’re interested in all time steps in the area bounded by 15 - 25N, 198 - 208E.\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nsw_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'time');\n\n% Convert this to [Y M D H M S]\nsw_time_ymdhms = datevec(sw_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(sw_time)];\n% Download the data of interest\nsw = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nswAVG(1:length(sw_time),1) = NaN;\nfor m = 1:1:length(sw_time)\n    swAVG(m,1) = mean(sw(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* sw m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nmodis_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'time'); \n\n% Convert this to [Y M D H M S]\nmodis_time_ymdhms = datevec(modis_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(modis_time)];\n\n% Download the data of interest\nmodis = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nmodisAVG(1:length(modis_time),1) = NaN;\nfor m = 1:1:length(modis_time)\n    modisAVG(m,1) = mean(modis(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* modis m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nviirs_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'time');\n\n% Convert this to [Y M D H M S]\nviirs_time_ymdhms = datevec(viirs_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(viirs_time)];\n% Download the data of interest\nviirs = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nviirsAVG(1:length(viirs_time),1) = NaN;\nfor m = 1:1:length(viirs_time)\n    viirsAVG(m,1) = mean(viirs(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* viirs m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nesa_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'time');\n\n% Convert this to [Y M D H M S]\nesa_time_ymdhms = datevec(esa_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(esa_time)];\n\n% Download the data of interest\nesa = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nesaAVG(1:length(esa_time),1) = NaN;\nfor m = 1:1:length(esa_time)\n    esaAVG(m,1) = mean(esa(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* esa m \n\n\n\nNow we can compare the spatial averages across the three sensors: SeaWiFS, MODIS, and VIIRS. We’ll do this by generating a plot the includes all three time series, which overlap to varying degrees.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'Color', [0 70 127]/255);\nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'Color', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'Color', [127 127 255]/255);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChloraophyll-a from MODIS and VIIRS\n\n\nYou can see that the values of chlorophyll-a concentration don’t match across sensors.\n\n\n\nThe OC-CCI data are from a blended product, that merges the three sensors.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'o', 'MarkerFaceColor', [0 70 127]/255, 'MarkerEdgeColor', ...\n    [0 70 127]/255); \nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'o', 'MarkerFaceColor', [147 213 0]/255, ...\n    'MarkerEdgeColor', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'o', 'MarkerFaceColor', [127 127 255]/255, ...\n    'MarkerEdgeColor', [127 127 255]/255);\nplot(datenum(esa_time_ymdhms), esaAVG, 'k', 'LineWidth', 2);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'OC-CCI', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChlorphyll from ESA OC-CCI"
  },
  {
    "objectID": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html#tutorial-2.-comparison-of-chlorophyll-data-from-different-sensors",
    "href": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html#tutorial-2.-comparison-of-chlorophyll-data-from-different-sensors",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "As an example, we are going to plot time-series of mean chlorophyll-a concentration from various sensors from 1997 to 2018 to look at the periods of overlap.\nWe are going to download data from SeaWiFS (1997-2010), MODIS (2002-present) and VIIRS (2012-present) and compare it to the ESA-CCI data which combines all 3 sensors into a homogeneous time-series.\nIn this tutorial, the URLs to the data are provided so you don’t have to search for them. But, if you weren’t sure what the URLs were, you could find them by searing the list of datasets hosted on the OceanWatch ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/index.html) and following the steps at the beginning of Tutoral 1.\nFor this tutoral, we’re interested in all time steps in the area bounded by 15 - 25N, 198 - 208E.\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nsw_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'time');\n\n% Convert this to [Y M D H M S]\nsw_time_ymdhms = datevec(sw_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(sw_time)];\n% Download the data of interest\nsw = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nswAVG(1:length(sw_time),1) = NaN;\nfor m = 1:1:length(sw_time)\n    swAVG(m,1) = mean(sw(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* sw m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nmodis_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'time'); \n\n% Convert this to [Y M D H M S]\nmodis_time_ymdhms = datevec(modis_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(modis_time)];\n\n% Download the data of interest\nmodis = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nmodisAVG(1:length(modis_time),1) = NaN;\nfor m = 1:1:length(modis_time)\n    modisAVG(m,1) = mean(modis(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* modis m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nviirs_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'time');\n\n% Convert this to [Y M D H M S]\nviirs_time_ymdhms = datevec(viirs_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(viirs_time)];\n% Download the data of interest\nviirs = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nviirsAVG(1:length(viirs_time),1) = NaN;\nfor m = 1:1:length(viirs_time)\n    viirsAVG(m,1) = mean(viirs(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* viirs m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nesa_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'time');\n\n% Convert this to [Y M D H M S]\nesa_time_ymdhms = datevec(esa_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(esa_time)];\n\n% Download the data of interest\nesa = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nesaAVG(1:length(esa_time),1) = NaN;\nfor m = 1:1:length(esa_time)\n    esaAVG(m,1) = mean(esa(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* esa m \n\n\n\nNow we can compare the spatial averages across the three sensors: SeaWiFS, MODIS, and VIIRS. We’ll do this by generating a plot the includes all three time series, which overlap to varying degrees.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'Color', [0 70 127]/255);\nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'Color', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'Color', [127 127 255]/255);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChloraophyll-a from MODIS and VIIRS\n\n\nYou can see that the values of chlorophyll-a concentration don’t match across sensors.\n\n\n\nThe OC-CCI data are from a blended product, that merges the three sensors.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'o', 'MarkerFaceColor', [0 70 127]/255, 'MarkerEdgeColor', ...\n    [0 70 127]/255); \nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'o', 'MarkerFaceColor', [147 213 0]/255, ...\n    'MarkerEdgeColor', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'o', 'MarkerFaceColor', [127 127 255]/255, ...\n    'MarkerEdgeColor', [127 127 255]/255);\nplot(datenum(esa_time_ymdhms), esaAVG, 'k', 'LineWidth', 2);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'OC-CCI', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChlorphyll from ESA OC-CCI"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html",
    "title": "CoastWatch Training Materials",
    "section": "",
    "text": "A tidyverse/ggplot version is also available here: https://github.com/jebyrnes/noaa_coastwatch_tutorial_1/blob/main/tutorial2-1.md Links to an external site.\ncourtesy of Jarrett Byrnes from UMass Boston - http://byrneslab.net (Thank you Jarrett!!)"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#background",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#background",
    "title": "CoastWatch Training Materials",
    "section": "Background",
    "text": "Background\nSeveral ocean color sensors have been launched since 1997 to provide continuous global coverage for ocean color data. The sensors have differences in design and calibration, and different algorithms may be applied to generate chlorophyll values. Consequently, chlorophyll-a values can vary among the sensors during periods where measurements overlap.\nTo examine this phenomenon, we will download and plot time-series of chlorophyll-a concentrations from various sensors from 1997 to the present and see how the measurements compare during periods of overlap."
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#objective",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#objective",
    "title": "CoastWatch Training Materials",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show how to extract a time-series from four different monthly satellite chlorophyll datasets for the period that each was in operation between 1997-present. It will showcase the use of the rerddap and rerddapXtracto packages, which have been developed to make it easier to interact with ERDDAP servers from R.\nMore information about the rerddap package can be found here: https://cran.r-project.org/web/packages/rerddap/index.html\nand here: https://cran.r-project.org/web/packages/rerddap/vignettes/Using_rerddap.html\nMore information about the rerddapXtracto package can be found here: https://cran.r-project.org/web/packages/rerddapXtracto/index.html\nand here: https://cran.r-project.org/web/packages/rerddapXtracto/vignettes/UsingrerddapXtracto.html"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "CoastWatch Training Materials",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nUsing rerddapXtracto package to extract data from a rectangular area of the ocean over time\nUsing rerddap to retrieving information about a dataset from ERDDAP\nComparing results from different sensors\nAveraging data spatially\nProducing timeseries plots\nDrawing maps with satellite data"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "title": "CoastWatch Training Materials",
    "section": "Datasets used",
    "text": "Datasets used\nSeaWiFS Chlorophyll-a, V.2018, Monthly, Global, 4km, 1997-2012 https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nMODIS Aqua, Chlorophyll-a, V.2022, Monthly, Global, 4km, 2002-present https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022SQ\nNOAA VIIRS S-NPP, Chlorophyll-a, Monthly, Global, 4km, 2012-present https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisVHNSQchlaMonthly\nESA CCI Ocean Colour Dataset, v6.0, Monthly, Global, 4km, 1997-Present This dataset was developed by the European Space Agency’s Climate Change Initiative. The dataset merges data from multiple sensors (MERIS, MODIS, VIIRS and SeaWiFS) to create a long timeseries (1997 to present) with better spatial coverage than any single sensor. Parameters include chlorophyll-a, remote sensing reflectance, diffuse attenuation coefficients, absorption coefficients, backscatter coefficients, and water classification. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorMonthly"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#load-packages",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#load-packages",
    "title": "CoastWatch Training Materials",
    "section": "Load packages",
    "text": "Load packages\npackages &lt;- c( \"ncdf4\",\"plyr\",\"lubridate\",\"rerddap\",\"ggplot2\",\"plotdap\",\n               \"rerddapXtracto\",\"maps\", \"mapdata\",\"grid\", \"reshape2\", \"gridExtra\")\n\n# Install packages not yet installed\ninstalled_packages &lt;- packages %in% rownames(installed.packages())\n\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages])\n}\n\n# Load packages \ninvisible(lapply(packages, library, character.only = TRUE))"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "title": "CoastWatch Training Materials",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nFirst we define the longitude-latitude boundaries of the region. The coordinates used here, between -95 to -90°W longitude and 25-30°N latitude, define an area in teh Gulf of Mexico.\nxcoord &lt;- c(-95,-90)\nycoord &lt;- c(25,30)"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#get-information-about-the-dataset-we-will-be-downloading",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#get-information-about-the-dataset-we-will-be-downloading",
    "title": "CoastWatch Training Materials",
    "section": "Get information about the dataset we will be downloading",
    "text": "Get information about the dataset we will be downloading\nDefine the URL of the ERDDAP we will be using:\nERDDAP_Node &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/\"\n\nGet monthly SeaWiFS data, which starts in 1997.\nGo to ERDDAP to find the name of the dataset for monthly SeaWIFS data: erdSW2018chlamday\nYou should always examine the dataset in ERDDAP to check the date range, names of the variables and dataset ID, to make sure your griddap calls are correct: https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nFirst we need to know what our variable is called. Let’s retrieve some metadata using the info function of the rerddap package:\ndataInfo &lt;- rerddap::info('erdSW2018chlamday', url=ERDDAP_Node)\nvar &lt;- dataInfo$variable$variable_name\n\n# Display the dataset metadata\ndataInfo\n\n## &lt;ERDDAP info&gt; erdSW2018chlamday \n##  Base URL: https://coastwatch.pfeg.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-16T00:00:00Z, 2010-12-16T00:00:00Z) \n##      latitude: (-89.95834, 89.95834) \n##      longitude: (-179.9583, 179.9584) \n##  Variables:  \n##      chlorophyll: \n##          Units: mg m^-3\n\n\nExtract satellite data with rxtracto_3D\nFor each dataset, we will extract satellite data for the entire length of the available timeseries.\n\nDates must be defined separately for each dataset. rxtracto_3D will crash if dates are entered that are not part of the timeseries.\n\nThe beginning (earliest) date to use in timeseries is obtained from the information returned in dataInfo.\n\nTo get the end (most recent) date to use in the timeseries, use the last option for time.\nThe variable name can change between datasets. For this dataset, the chloropyll variable is called chlorophyll, as seen in the metadata returned by dataInfo\n\n\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n# Set the altitude coordinate to zero\nzcoord &lt;- 0.\n\n# Extract the beginning and ending dates of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntcoord &lt;- c(tt[2],\"last\")\n** Run the SeaWiFS data extraction with rxtracto_3D:\n# Extract the timeseries data using rxtracto_3D\nchlSeaWiFS&lt;-rxtracto_3D(dataInfo,\n                        parameter=parameter,\n                        tcoord=tcoord,\n                        xcoord=xcoord,\n                        ycoord=ycoord)\n\n\nPlot data to show where it is in the world\nWe will use the plotBBox function of the rerddapXtracto package to make a quick map of the data\nmyFunc &lt;- function(x) log(x)\nplotBBox(chlSeaWiFS, plotColor = 'algae', myFunc = myFunc)\n\n\n\nGet monthly MODIS data, which starts in 2002.\ndataInfo &lt;- rerddap::info('erdMH1chlamday_R2022SQ', url=ERDDAP_Node)\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n#Extract the start and end times of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\n#Run rxtracto_3D\nchlMODIS&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord)\n\n\nGet monthly VIIRS data, which starts in 2012.\ndataInfo &lt;- rerddap::info('nesdisVHNSQchlaMonthly', url=ERDDAP_Node)\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n#Extract the start and end times of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\n\n# This dataset has an altitude dimensionm, so must include zcoord as an argument in the rxtracto_3D function Set the altitude coordinate to zero\nzcoord &lt;- 0.\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\n#Run rxtracto_3D\nchlVIIRS &lt;- rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord,\n                      zcoord=zcoord)\n\n# Remove extraneous zcoord dimension for chlorophyll \nchlVIIRS$chlor_a &lt;- drop(chlVIIRS$chlor_a)\n\n\nAverage data spatially and temporally\n\nspatially averages data for each time step within the area boundaries for each dataset.\n\ntemporally averages data for data in each timeseries onto a map, for each dataset.\n\n\n## Spatially average all the data within the box for each dataset.\n## The c(3) indicates the dimension to keep - in this case time \nchlSeaWiFS$avg &lt;- apply(chlSeaWiFS$chlorophyll, c(3),function(x) mean(x,na.rm=TRUE))\nchlMODIS$avg &lt;- apply(chlMODIS$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\nchlVIIRS$avg &lt;- apply(chlVIIRS$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\n\n## Temporally average all of the data into one map \n## The c(1,2) indicates the dimensions to keep - in this case latitude and longitude  \nchlSeaWiFS$avgmap &lt;- apply(chlSeaWiFS$chlorophyll,c(1,2),function(x) mean(x,na.rm=TRUE))\nchlMODIS$avgmap &lt;- apply(chlMODIS$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\nchlVIIRS$avgmap &lt;- apply(chlVIIRS$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\n\n\nPlot time series for the three datasets\nplot(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg, type='l', col=2,lwd=2, \n     xlab=\"\", xlim=as.Date(c(\"1997-12-01\",\"2024-06-01\")), \n     ylim=c(0.5,3.5), ylab=\"CHL\")\naxis(2)\npoints(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg,pch=20,col=2)\n\nlines(as.Date(chlMODIS$time), chlMODIS$avg, col=4, lwd=2)\npoints(as.Date(chlMODIS$time), chlMODIS$avg,pch=20,col=4)\n\nlines(as.Date(chlVIIRS$time), chlVIIRS$avg, col=3, lwd=2)\npoints(as.Date(chlVIIRS$time), chlVIIRS$avg,pch=20,col=3)\n\nlegend('topleft',legend=c('SeaWiFS','MODIS','VIIRS'),cex=0.6,col=c(2,4,3),lwd=2)\n\nYou can see that the values of chl-a concentration doesn’t always match between sensors.\n\n\nGet OC-CCI data (September 1997 to Dec 2022)\nIf you needed a single time series from 1997 to present, you would have to use the plot above to devise some method to reconcile the difference in values where two datasets overlap. Alternatively, you could use the ESA OC-CCI (ocean color climate change initiative) dataset, which blends data from many satellite missions into a single dataset, including data from SeaWiFS, MODIS, and VIIRS.\nAdd the ESA OC-CCI dataset to the plot above to see how it compares with data from the individual satellite missions.\ndataInfo &lt;- rerddap::info('pmlEsaCCI60OceanColorMonthly', url=ERDDAP_Node)\n\n# This identifies the parameter to choose - there are &gt; 60 in this dataset!\nparameter &lt;- 'chlor_a'\n\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\nchlOCCCI&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord)\n\n# Now spatially average the data into a timeseries\nchlOCCCI$avg &lt;- apply(chlOCCCI$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\n\n# Now temporally average the data into one map \nchlOCCCI$avgmap &lt;- apply(chlOCCCI$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\n\n\nMake another plot with CCI as well to compare\nplot(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg, type='l', col=2,lwd=2, \n     xlab=\"\", xlim=as.Date(c(\"1997-12-01\",\"2024-06-01\")), \n     ylim=c(0.5,3.5), ylab=\"CHL\")\naxis(2)\npoints(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg,pch=20,col=2)\npoints(as.Date(chlMODIS$time), chlMODIS$avg,pch=20,col=4)\npoints(as.Date(chlVIIRS$time), chlVIIRS$avg,pch=20,col=3)\nlines(as.Date(chlOCCCI$time),chlOCCCI$avg,lwd=2)\n\nlegend('topleft',legend=c('SeaWiFS','MODIS','VIIRS','OC-CCI'),cex=0.6,col=c(2,4,3,1),\n       pch=c(20,20,20,NA),lty=c(NA,NA,NA,1),lwd=2)\n\ncoast &lt;- map_data(\"worldHires\", ylim = ycoord, xlim = xcoord)\n\n# Put arrays into format for ggplot\nmelt_map &lt;- function(lon,lat,var) {\n  dimnames(var) &lt;- list(Longitude=lon, Latitude=lat)\n  ret &lt;- melt(var,value.name=\"Chl\")\n}\n\n# Loop for making 4 maps\ndatasetnames &lt;- c(\"SeaWiFS\",\"MODIS\",\"VIIRS\",\"OC-CCI\")\n\nplot_list = list()\n\nfor(i in 1:4) {\n  \n  if(i == 1) chl &lt;- chlSeaWiFS\n  if(i == 2) chl &lt;- chlMODIS\n  if(i == 3) chl &lt;- chlVIIRS\n  if(i == 4) chl &lt;- chlOCCCI\n  \n   chlmap &lt;- melt_map(chl$longitude, chl$latitude, chl$avgmap)\n\n   p = ggplot(\n     data = chlmap, \n     aes(x = Longitude, y = Latitude, fill = log(Chl))) +\n         geom_tile(na.rm=T) +\n         geom_polygon(data = coast, aes(x=long, y = lat, group = group), fill = \"grey80\") +\n         theme_bw(base_size = 12) + ylab(\"Latitude\") + xlab(\"Longitude\") +\n         coord_fixed(1.3, xlim = c(-95,-90), ylim = ycoord) +\n         scale_fill_viridis_c(limits=c(-2.5,3)) +\n         ggtitle(paste(\"Average\", datasetnames[i])\n      ) \n\n  plot_list[[i]] = p\n}\n\n# Now print out maps into a png file.  Can't use par function with **ggplpot** to get \n# multiple plots per page.  Here using a function in the **grid** package\n\ngrid.arrange(plot_list[[1]],plot_list[[2]],plot_list[[3]],plot_list[[4]], nrow = 2)"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html",
    "href": "tutorials/python/Tutorial1-basics.html",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "",
    "text": "History | Updated August 2023"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#objective",
    "href": "tutorials/python/Tutorial1-basics.html#objective",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab data hosted on an ERDDAP server from Python, how to work with NetCDF files in Python and how to make some maps and time-series of sea surface temperature."
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nLocating a satellite product in ERDDAP, manually changing the constraints and copying the URL defining the data request\nDownloading the resulting netCDF file\nOpening and examining the netCDF file\nMaking basic maps and time series plots"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#datasets-used",
    "href": "tutorials/python/Tutorial1-basics.html#datasets-used",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Datasets used",
    "text": "Datasets used\nCoralTemp Sea Surface Temperature product from the NOAA Coral Reef Watch program. The NOAA Coral Reef Watch (CRW) daily global 5km Sea Surface Temperature (SST) product, also known as CoralTemp, shows the nighttime ocean temperature measured at the surface. The SST scale ranges from -2 to 35 °C. The CoralTemp SST data product was developed from two, related reanalysis (reprocessed) SST products and a near real-time SST product. Spanning January 1, 1985 to the present, the CoralTemp SST is one of the best and most internally consistent daily global 5km SST products available. More information about the product: https://coralreefwatch.noaa.gov/product/5km/index_5km_sst.php\nWe will use the monthly composite of this product and download it from the NOAA CoastWatch ERDDAP server: https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.graph"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#import-python-modules",
    "href": "tutorials/python/Tutorial1-basics.html#import-python-modules",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Import Python modules",
    "text": "Import Python modules\n\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#download-data-from-erddap-using-python",
    "href": "tutorials/python/Tutorial1-basics.html#download-data-from-erddap-using-python",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "1. Download data from ERDDAP using Python",
    "text": "1. Download data from ERDDAP using Python\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure.\nFor example, the following page allows you to subset monthly sea surface temperature (SST) https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html\n\n\n\nerddap.png\n\n\n\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\nIn this specific example, the URL we generated is :\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D\n\n\nWith Python, run the following to download the data using the generated URL .\n\n# Below we have broken the url into parts and rejoin the them\n# to allow you to better see the url in the notebook.\nurl = ''.join(['https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?',\n               'sea_surface_temperature',\n               '%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D',\n               '%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D'\n               ])\n\nurllib.request.urlretrieve(url, \"sst.nc\")\n\n('sst.nc', &lt;http.client.HTTPMessage at 0x1ac0e35b0&gt;)"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#loading-netcdf4-data-into-python",
    "href": "tutorials/python/Tutorial1-basics.html#loading-netcdf4-data-into-python",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "2. Loading netCDF4 data into Python",
    "text": "2. Loading netCDF4 data into Python\nNow that we’ve downloaded the data locally, we can load it into Python and extract the variables of interest.\nThe xarray package makes it very convenient to work with NetCDF files. Documentation is available here: http://xarray.pydata.org/en/stable/why-xarray.html\n\nOpen the netCDF file as an xarray dataset object and examine the data structure.\n\nds = xr.open_dataset('sst.nc', decode_cf=True)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 12, latitude: 202, longitude: 201)\nCoordinates:\n  * time                     (time) datetime64[ns] 2022-01-16 ... 2022-12-16\n  * latitude                 (latitude) float32 40.03 39.97 ... 30.02 29.98\n  * longitude                (longitude) float32 -80.02 -79.97 ... -70.07 -70.02\nData variables:\n    sea_surface_temperature  (time, latitude, longitude) float32 ...\nAttributes: (12/65)\n    acknowledgement:                  NOAA Coral Reef Watch program\n    cdm_data_type:                    Grid\n    comment:                          This is a product of NOAA Coral Reef Wa...\n    contributor_name:                 NOAA Coral Reef Watch program\n    contributor_role:                 Collecting source data and deriving pro...\n    Conventions:                      CF-1.6, ACDD-1.3, COARDS\n    ...                               ...\n    time_coverage_duration:           P1M\n    time_coverage_end:                2022-12-16T00:00:00Z\n    time_coverage_resolution:         P1M\n    time_coverage_start:              2022-01-16T00:00:00Z\n    title:                            SST and SST Anomaly, NOAA Global Coral ...\n    Westernmost_Easting:              -80.024994xarray.DatasetDimensions:time: 12latitude: 202longitude: 201Coordinates: (3)time(time)datetime64[ns]2022-01-16 ... 2022-12-16_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3240.03 39.97 39.93 ... 30.02 29.98_CoordinateAxisType :Latactual_range :[29.975004 40.025   ]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([40.025   , 39.975   , 39.92501 , ..., 30.075003, 30.025   , 29.975004],\n      dtype=float32)longitude(longitude)float32-80.02 -79.97 ... -70.07 -70.02_CoordinateAxisType :Lonactual_range :[-80.024994 -70.024994]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-80.024994, -79.975   , -79.924995, ..., -70.125   , -70.075   ,\n       -70.024994], dtype=float32)Data variables: (1)sea_surface_temperature(time, latitude, longitude)float32...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[487224 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-16', '2022-02-16', '2022-03-16', '2022-04-16',\n               '2022-05-16', '2022-06-16', '2022-07-16', '2022-08-16',\n               '2022-09-16', '2022-10-16', '2022-11-16', '2022-12-16'],\n              dtype='datetime64[ns]', name='time', freq=None))latitudePandasIndexPandasIndex(Index([40.025001525878906, 39.974998474121094, 39.925010681152344,\n        39.87500762939453,  39.82500457763672, 39.775001525878906,\n       39.724998474121094, 39.675010681152344,  39.62500762939453,\n        39.57500457763672,\n       ...\n        30.42500114440918, 30.374998092651367, 30.325002670288086,\n       30.274999618530273, 30.225004196166992,  30.17500114440918,\n       30.124998092651367, 30.075002670288086, 30.024999618530273,\n       29.975004196166992],\n      dtype='float32', name='latitude', length=202))longitudePandasIndexPandasIndex(Index([-80.02499389648438,  -79.9749984741211, -79.92499542236328,\n                  -79.875, -79.82499694824219, -79.77499389648438,\n        -79.7249984741211, -79.67499542236328,            -79.625,\n       -79.57499694824219,\n       ...\n        -70.4749984741211, -70.42499542236328,            -70.375,\n       -70.32499694824219, -70.27499389648438,  -70.2249984741211,\n       -70.17499542236328,            -70.125, -70.07499694824219,\n       -70.02499389648438],\n      dtype='float32', name='longitude', length=201))Attributes: (65)acknowledgement :NOAA Coral Reef Watch programcdm_data_type :Gridcomment :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite Version 3.1, derived from CoralTemp v1.0.contributor_name :NOAA Coral Reef Watch programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archive.Conventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch programcreator_name :NOAA Coral Reef Watch programcreator_type :groupcreator_url :https://coralreefwatch.noaa.govdate_created :2018-03-01T12:00:00Zdate_issued :2019-01-19T20:32:23Zdate_metadata_modified :2018-09-01T12:00:00Zdate_modified :2018-03-01T12:00:00ZEasternmost_Easting :-70.024994geospatial_bounds :POLYGON((-90.0 180.0, 90.0 180.0, 90.0 -180.0, -90.0 -180.0, -90.0 180.0))geospatial_bounds_crs :EPSG:4326geospatial_lat_max :40.025geospatial_lat_min :29.975004geospatial_lat_units :degrees_northgeospatial_lon_max :-70.024994geospatial_lon_min :-80.024994geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:32663grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Tue Jul 27 10:37:54 2021: ncrename -d lon,longitude -d lat,latitude -v lon,longitude -v lat,latitude -v sea surface temperature anomaly,sea_surface_temperature_anomaly /cwdata/coralreef/work/temp.nc\nMonthly data files for mean sea surface temperature (SST) and sea surface temperature anomaly (SST anomaly) were downloaded from ftp.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1/nc/v1.0/monthly. Monthly files were created that contain both SST and SST anomaly data, and a mask of earth surface classifications.\n2023-09-06T14:23:22Z (local files)\n2023-09-06T14:23:22Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5Did :Satellite_Global_5km_CoralTemp_SST_SSTA_Monthly_Mean_CompositeinfoUrl :https://coralreefwatch.noaa.gov/product/5km/index.phpinstitution :NOAA/NESDIS/STAR Coral Reef Watch programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, anomaly, array, characteristics, coral, crw, data, earth, Earth Science &gt; Land Surface &gt; Land Temperature &gt; Land Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature Anomaly, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, flag, global, information, infrared, land, latitude, longitude, mask, mean, month, monthly, national, nesdis, noaa, ocean, oceans, pixel, program, quality, reef, satellite, science, sea, sea_surface_temperature, sea_surface_temperature_anomaly, seawater, service, spectral, spectral/engineering, sst, star, surface, surface_temperature_anomaly, temperature, thermal, time, v.3.1, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of the Coral Reef Watch website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/product/5km/index.phpnaming_authority :gov.noaa.coralreefwatchNCO :\"4.6.3\"Northernmost_Northing :40.025platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :Derived from L4 satellite sea surface temperature analysisproduct_version :3.1program :NOAA Coral Reef Watch programproject :NOAA Coral Reef Watch programpublisher_email :erd.data at noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch programpublisher_name :NOAA NMFS SWFSC ERD, CoastWatch West Coast Nodepublisher_type :institutionpublisher_url :https://coralreefwatch.noaa.gov, https://coastwatch.pfeg.noaa.gov/references :https://coralreefwatch.noaa.gov/product/5km/index.php and https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :Coral Reef Watch CoralTemp v1.0sourceUrl :(local files)Southernmost_Northing :29.975004spatial_resolution :0.05 degreestandard_name_vocabulary :CF Standard Name Table v27summary :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite, derived from CoralTemp v1.0.time_coverage_duration :P1Mtime_coverage_end :2022-12-16T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2022-01-16T00:00:00Ztitle :SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring, 5km, V.3.1, Monthly, 1985-PresentWesternmost_Easting :-80.024994\n\n\n\n\nExamine which coordinates and variables are included in the dataset.\n\n# List the coordinates\nprint('The coordinates variables:', list(ds.coords), '\\n')\n\n# List the data variables\nprint('The data variables:', list(ds.data_vars))\n\nThe coordinates variables: ['time', 'latitude', 'longitude'] \n\nThe data variables: ['sea_surface_temperature']\n\n\n\n\nExamine the structure of sea_surface_temperature.\n\nds.sea_surface_temperature.shape\n\n(12, 202, 201)\n\n\nThe dataset is a 3-D array with 12 time steps, each with 202 rows corresponding to latitudes and 201 columns corresponding to longitudes.\n\n\nList the dates for each time step.\nThe dataset has 12 time steps, one for each month between January 2022 and December 2022.\n\nds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 12)&gt;\narray(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 2022-01-16 2022-02-16 ... 2022-12-16\nAttributes:\n    _CoordinateAxisType:    Time\n    actual_range:           [1.6422912e+09 1.6711488e+09]\n    axis:                   T\n    coverage_content_type:  coordinate\n    ioos_category:          Time\n    long_name:              reference time of the last day of the composite t...\n    standard_name:          time\n    time_origin:            01-JAN-1970 00:00:00xarray.DataArray'time'time: 122022-01-16 2022-02-16 2022-03-16 ... 2022-10-16 2022-11-16 2022-12-16array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2022-01-16 ... 2022-12-16_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-16', '2022-02-16', '2022-03-16', '2022-04-16',\n               '2022-05-16', '2022-06-16', '2022-07-16', '2022-08-16',\n               '2022-09-16', '2022-10-16', '2022-11-16', '2022-12-16'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (8)_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00\n\n\n\n\nExamine the latitude coordinate variable\nTypically, the latitude coordinate variable will be in ascending order. However, in some datasets the order is reversed, i.e the order is descending.\nBy examining the first and last values on our latitude array (below), we can see that the values are descending.\n* In practice what this means is that when you slice (subset) using latitude later in this tutorial, you will put the largest latitude value first.\n\nprint('First latitude value', ds.latitude[0].item())\nprint('Last latitude value', ds.latitude[-1].item())\n\nFirst latitude value 40.025001525878906\nLast latitude value 29.975004196166992"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#working-with-the-data",
    "href": "tutorials/python/Tutorial1-basics.html#working-with-the-data",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "3. Working with the data",
    "text": "3. Working with the data\n\nCreating a map for for January 2022 (our first time step)\n\nFind the minimum and maximum SST values.\n\nprint('Minimum SST', np.nanmin(ds.sea_surface_temperature))\nprint('Maximum SST', np.nanmax(ds.sea_surface_temperature))\n\nMinimum SST 2.34\nMaximum SST 29.87\n\n\n\n\nUse the minimum and maximum SST to set some color breaks.\n\n# Sets color breaks from 2 to 30 with 0.05 steps\nlevs = np.arange(2, 30, 0.05)\n\n\n\nDefine a color palette.\n\njet = [\"blue\", \"#007FFF\", \"cyan\", \"#7FFF7F\",\n       \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"]\n\n\n\nSet color scale using the jet palette.\n\ncm = LinearSegmentedColormap.from_list('my_jet', jet, N=len(levs))\n\n\n\nPlot the SST map\nThe code also shows how to annotate the map by: - Adding points to the map (e.g. station locations) - Adding contour lines\n\nplt.contourf(ds.longitude, \n             ds.latitude, \n             ds.sea_surface_temperature[0, :, :], \n             levs,\n             cmap=cm)\n\n# Plot the colorbar\nplt.colorbar()\n\n# Annotation: Example of how to add points to the map\nplt.scatter(range(-74, -71), np.repeat(34, 3), c='black')\n\n# Annotation: Example of how to add a contour line\nplt.contour(ds.longitude, \n            ds.latitude, \n            ds.sea_surface_temperature[0, :, :], \n            levels=[14],\n            linewidths=1)\n\n# Add a title\nplt.title(\"Monthly Sea Surface Temperature - \" \n          + ds.time[0].dt.strftime('%b %Y').item())\nplt.show()"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#plotting-a-time-series",
    "href": "tutorials/python/Tutorial1-basics.html#plotting-a-time-series",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Plotting a time series",
    "text": "Plotting a time series\n\nSubset the following box from the data:\n\n36o to 38oN latitude\n-77o to -75oE longitude\n\nWe are going to generate a time series of mean SST within that box.\n\nFirst, subset the data:\n\nRemember!\nFor this product, latitudes are indexed in descending order (high to low). Therefore when you slice latitude, put the largest value first.\n\nda = ds.sel(latitude=slice(38, 36), longitude=slice(-77, -75))\n\n\n\nExamine the structure of the subsetted data.\nThe subset is a 3-D array with 12 time steps, each with 40 rows corresponding to latitudes and 40 columns corresponding to longitudes.\n\nda.sea_surface_temperature.shape\n\n(12, 40, 40)\n\n\n\n\nPlot the subsetted data\n\nplt.contourf(da.longitude, \n             da.latitude, \n             da.sea_surface_temperature[0, :, :], \n             levs,\n             cmap=cm)\nplt.colorbar()\nplt.title(\"Monthly Sea Surface Temperature \" \n          + ds.time[0].dt.strftime('%b %Y').item())\nplt.show()"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#compute-the-monthly-mean-for-each-month",
    "href": "tutorials/python/Tutorial1-basics.html#compute-the-monthly-mean-for-each-month",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Compute the monthly mean for each month",
    "text": "Compute the monthly mean for each month\n\nres = np.mean(da.sea_surface_temperature, axis=(1, 2))\n\n\nPlot the time-series\n\nplt.figure(figsize=(8, 4))\nplt.scatter(ds.time, res)\nplt.ylabel('SST (ºC)')\n\nText(0, 0.5, 'SST (ºC)')"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#creating-a-map-of-average-sst-over-a-year",
    "href": "tutorials/python/Tutorial1-basics.html#creating-a-map-of-average-sst-over-a-year",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Creating a map of average SST over a year",
    "text": "Creating a map of average SST over a year\n\nCompute the yearly mean for the region\n\nmean_sst = np.mean(ds.sea_surface_temperature, axis=0)\n\n\n\nPlot the map of the 2022 average SST in the region\n\nplt.contourf(ds.longitude, ds.latitude, mean_sst, levs, cmap=cm)\nplt.colorbar()\nplt.title(\"Mean SST \" \n          + ds.time[0].dt.strftime('%b %Y').item() \n          + ' - '\n          + ds.time[11].dt.strftime('%b %Y').item())\n\nplt.show()"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html",
    "title": "Make a virtual buoy with satellite data",
    "section": "",
    "text": "History | Updated August 2023 ## Background There are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov) and ARGO floats program (http://www.argo.ucsd.edu). Despite these impressive efforts to monitor environmental conditions, in situ buoy data may not be available for your area of interest. Some locations are hard to access, making deploying and maintaining a buoy impractical. In addition, buoys are expensive to purchase, deploy and maintain. Therefore, limited funding may prevent installation of a buoy or the continued operation of a buoy already in place.\nUsing satellite data to create virtual buoys can provide a solution to monitoring surface environmental conditions at locations where it is not feasible to install a buoy. For example, the University of South Florida has developed a virtual buoy system for locations off the Florida coast (https://optics.marine.usf.edu/projects/vbs.html)."
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#objectives",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#objectives",
    "title": "Make a virtual buoy with satellite data",
    "section": "Objectives",
    "text": "Objectives\nThe following exercise will demonstrate the use of the ERDDAP data server to create a virtual buoy. For the scenario, we will envision that a virtual buoy is needed to continue the datastream for an in situ buoy that was discontinued at the end of 2019. For this exercise we will use the National Data Buoy Center (NDBC) buoy # 46259, which is located off the California coast at 34.767N latitude and -121.497E longitude, and pretend that it was discontinued at the end of 2019. The buoy measures several oceanic variables, but we will continue the sea surface temperature (SST) datastream using NOAA GeoPolar Blended SST satellite dataset."
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#the-tutorial-demonstrates-the-following-skills",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#the-tutorial-demonstrates-the-following-skills",
    "title": "Make a virtual buoy with satellite data",
    "section": "The tutorial demonstrates the following skills:",
    "text": "The tutorial demonstrates the following skills:\n\nThe use of ERDDAP to create a virtual buoy\n\nThe use of the pandas and xarray modules to import and manipulate data\n\nResampling data to bin them into a lower resolution time steps\nGenerating a linear regression and statistics\nPlotting time-series data\n\nCleaning data to remove outlying data points"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#datasets-used",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#datasets-used",
    "title": "Make a virtual buoy with satellite data",
    "section": "Datasets used",
    "text": "Datasets used\nNDBC Buoy Data\nThe National Data Buoy Center (NDBC) distributes meteorological data from moored buoys maintained by NDBC and others. They are deployed in the coastal and offshore waters from the western Atlantic to the Pacific Ocean around Hawaii, and from the Bering Sea to the South Pacific. For this tutorial we will use buoy number 46259. NDBC data are available from the CoastWatch West Coast Node ERDDAP. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#import-required-modules",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#import-required-modules",
    "title": "Make a virtual buoy with satellite data",
    "section": "Import required modules",
    "text": "Import required modules\n\nimport numpy as np\nimport xarray as xr\nfrom datetime import datetime\nimport os\nimport pandas as pd\nimport io\nimport requests\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\nfrom sklearn.metrics import r2_score\n\n# the %matplotlib is a magic function allow displaying results in notebooks\n%matplotlib inline\n\n# some tools for Pandas to work will with matplotlib\nfrom pandas.plotting import register_matplotlib_converters"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#a-note-about-tabledap",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#a-note-about-tabledap",
    "title": "Make a virtual buoy with satellite data",
    "section": "A note about tabledap",
    "text": "A note about tabledap\nMost of our examples in this course use gridded datasets. The NDBC data for this tutorial is a tabular dataset, served via the tabledap part of ERDDAP. The API for tabledap is a little different than for gridded datasets. You can go to the following URL and play around with subsetting. Then push the “Just generate the URL” button, copy the link, put it in a browser. See if you get what you expected. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet\nA quick primer is below\nThe data request URL has three parts: 1. Base URL: https://url/erddap/tabledap/datasetID.fileType? * e.g. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?\n\nA list of variables you want to download that are separated by commas\n\n\n\ne.g. station,longitude,latitude,time,wtmp\n\n\nA list of constraints, each starting with an ampersand (&).\n\n\nThe constraints use =, &gt;, &gt;=, &lt;, and &lt;= to subset the data\ne.g. &station=“46259”, mean station # 46259\ne.g. &time&gt;=2017-01-01T&time&lt;=2020-12-31’, means time between and including Jan. 1, 2017 and Dec. 31, 2020.\n\nThe data request URL we will use for the NDBC data:\nndbc_url = 'https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?station,longitude,latitude,time,wtmp&station=\"46259\"&time&gt;=2017-01-01T&time&lt;=2020-12-31"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#download-the-data-into-a-pandas-dataframe",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#download-the-data-into-a-pandas-dataframe",
    "title": "Make a virtual buoy with satellite data",
    "section": "Download the data into a Pandas dataframe",
    "text": "Download the data into a Pandas dataframe\n\n# Break the url into part and rejoin it so that it is easier to see.\nndbc_url = ''.join(['https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?',\n                    'station,longitude,latitude,time,wtmp',\n                    '&station=\"46259\"&time&gt;=2018-01-01&time&lt;=2019-12-31'\n                    ])\n\nreq = requests.get(ndbc_url).content\nbuoy_df = pd.read_csv(io.StringIO(req.decode('utf-8')), skiprows=[1], parse_dates=['time'])\nbuoy_df.head(2)\n\n\n\n\n\n\n\n\nstation\nlongitude\nlatitude\ntime\nwtmp\n\n\n\n\n0\n46259\n-121.664\n34.732\n2018-01-01 00:22:00+00:00\n14.6\n\n\n1\n46259\n-121.664\n34.732\n2018-01-01 00:52:00+00:00\n14.6\n\n\n\n\n\n\n\n\nExtract the longitude and latitude coordinates for the station\nAfter, clean up the dataframe by deleting unneeded columns.\n\nbuoy_lat = buoy_df.latitude[0]\nbuoy_lon = buoy_df.longitude[0]\n\n# Clean up the dataset by removing unneeded columns\ndel buoy_df['station']\ndel buoy_df['latitude']\ndel buoy_df['longitude'] \n\nprint('latitude', buoy_lat)\nprint('longitude', buoy_lon)\n\nlatitude 34.732\nlongitude -121.664"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-buoy-data",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-buoy-data",
    "title": "Make a virtual buoy with satellite data",
    "section": "Process the buoy data",
    "text": "Process the buoy data\nThe measurement rate of the buoy is on the order of minutes. We need to downsample the dataset to the daily resolution of the satellite dataset.\nThere are a few cleanup steps that are needed:\n* The time data are associated with the UTC time zone. Panda operations often don’t like time zones so let’s get rid of it. * Rename the SST variable to something more intuitive\n\nprint('# of timesteps before =', buoy_df.shape[0] )\n\n# The resampling will put time as the df index\nbuoy_df_resampled = buoy_df.resample('D', on='time').mean()\nprint('# of timesteps after =', buoy_df_resampled.shape[0] )\n\n# Remove the timezone (UTC, GMT).\nbuoy_df_resampled = buoy_df_resampled.tz_localize(None)\n\n# Rename the SST variable\nbuoy_df_resampled.rename(columns={\"wtmp\": \"sst_buoy\"}, errors=\"raise\", inplace=True)\nbuoy_df_resampled\n\nbuoy_df_resampled.head(2)\n\n# of timesteps before = 34455\n# of timesteps after = 730\n\n\n\n\n\n\n\n\n\nsst_buoy\n\n\ntime\n\n\n\n\n\n2018-01-01\n14.679167\n\n\n2018-01-02\n14.891489"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#load-the-satellite-data-into-xarray-and-subset",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#load-the-satellite-data-into-xarray-and-subset",
    "title": "Make a virtual buoy with satellite data",
    "section": "Load the satellite data into xarray and subset",
    "text": "Load the satellite data into xarray and subset\n\n# Put satellite data xarray dataset object\nsst_url = 'https://coastwatch.noaa.gov/erddap/griddap/noaacwBLENDEDCsstDaily'\nsst_ds = xr.open_dataset(sst_url)\n\n# Subset the dataset\nsst_ds_subset = sst_ds['analysed_sst'].sel(latitude=buoy_lat,\n                            longitude = buoy_lon, method='nearest'\n                            ).sel(time=slice('2018-01-01', \n                                             '2019-12-31'\n                                             ))\n\nsst_ds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'analysed_sst' (time: 692)&gt;\n[692 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 2018-01-01T12:00:00 ... 2019-12-31T12:00:00\n    latitude   float32 34.72\n    longitude  float32 -121.7\nAttributes:\n    colorBarMaximum:  35.0\n    colorBarMinimum:  0.0\n    comment:          nighttime analysed SST for each ocean grid point\n    ioos_category:    Temperature\n    long_name:        analysed sea surface temperature\n    references:       Fieguth,P.W. et al. \"Mapping Mediterranean altimeter da...\n    standard_name:    sea_surface_foundation_temperature\n    units:            degree_Cxarray.DataArray'analysed_sst'time: 692...[692 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]2018-01-01T12:00:00 ... 2019-12-..._CoordinateAxisType :Timeactual_range :[1.0308816e+09 1.6938288e+09]axis :Tcomment :Nominal time of Level 4 analysisioos_category :Timelong_name :reference time of sst fieldstandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2018-01-01T12:00:00.000000000', '2018-01-02T12:00:00.000000000',\n       '2018-01-03T12:00:00.000000000', ..., '2019-12-29T12:00:00.000000000',\n       '2019-12-30T12:00:00.000000000', '2019-12-31T12:00:00.000000000'],\n      dtype='datetime64[ns]')latitude()float3234.72_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projectionioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array(34.725, dtype=float32)longitude()float32-121.7_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projectionioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array(-121.675, dtype=float32)Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2018-01-01 12:00:00', '2018-01-02 12:00:00',\n               '2018-01-03 12:00:00', '2018-01-04 12:00:00',\n               '2018-01-05 12:00:00', '2018-01-06 12:00:00',\n               '2018-01-07 12:00:00', '2018-01-08 12:00:00',\n               '2018-01-09 12:00:00', '2018-02-09 12:00:00',\n               ...\n               '2019-12-22 12:00:00', '2019-12-23 12:00:00',\n               '2019-12-24 12:00:00', '2019-12-25 12:00:00',\n               '2019-12-26 12:00:00', '2019-12-27 12:00:00',\n               '2019-12-28 12:00:00', '2019-12-29 12:00:00',\n               '2019-12-30 12:00:00', '2019-12-31 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=692, freq=None))Attributes: (8)colorBarMaximum :35.0colorBarMinimum :0.0comment :nighttime analysed SST for each ocean grid pointioos_category :Temperaturelong_name :analysed sea surface temperaturereferences :Fieguth,P.W. et al. \"Mapping Mediterranean altimeter data with a multiresolution optimal interpolation algorithm\", J. Atmos. Ocean Tech, 15\n (2): 535-546, 1998.     Fieguth, P. Multiply-Rooted Multiscale Models for Large-Scale Estimation, IEEE Image Processing, 10(11), 1676-1686, 2001.     Khellah, F., P.W. Fieguth, M.J. M\nurray and M.R. Allen, \"Statistical Processing of Large Image Sequences\", IEEE Transactions on Geoscience and Remote Sensing, 12 (1), 80-93, 2005.standard_name :sea_surface_foundation_temperatureunits :degree_C"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-satellite-data-to-make-them-compatible-with-the-buoy-data",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-satellite-data-to-make-them-compatible-with-the-buoy-data",
    "title": "Make a virtual buoy with satellite data",
    "section": "Process the satellite data to make them compatible with the buoy data",
    "text": "Process the satellite data to make them compatible with the buoy data\n\nPut the satellite data into a Pandas dataframe\nResample the data to daily bins: The data are already daily, but resampling them makes the timestamp format the same as for the buoy data, and puts time into the index column of the dataframe.\nRemove the timezone localization from time\n\n\n# Initialize data\nsat_data = {'time': sst_ds_subset.time.values,\n            'sst_sat': sst_ds_subset.to_numpy()\n            }\n\n# Creates pandas DataFrame.\nsat_df = pd.DataFrame(sat_data)\n\n# Resample\nsat_df = sat_df.resample('D', on='time').mean()\n\n# Remove timezone\nsat_df = sat_df.tz_localize(None)\n\n\nsat_df.head(2)\n\n\n\n\n\n\n\n\nsst_sat\n\n\ntime\n\n\n\n\n\n2018-01-01\n14.18\n\n\n2018-01-02\n14.76"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#merge-the-datasets",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#merge-the-datasets",
    "title": "Make a virtual buoy with satellite data",
    "section": "Merge the datasets",
    "text": "Merge the datasets\n\nmerged_df = pd.merge(buoy_df_resampled, \n                     sat_df, \n                     left_index=True, \n                     right_index=True).reset_index()\nmerged_df.head(2)\n\n\n\n\n\n\n\n\ntime\nsst_buoy\nsst_sat\n\n\n\n\n0\n2018-01-01\n14.679167\n14.18\n\n\n1\n2018-01-02\n14.891489\n14.76"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#plot-the-data-along-the-same-time-x-axis",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#plot-the-data-along-the-same-time-x-axis",
    "title": "Make a virtual buoy with satellite data",
    "section": "Plot the data along the same time (x) axis",
    "text": "Plot the data along the same time (x) axis\nThe data from the buoy and satellite seem to track each other very well (below). * You will want to at least run a linear regression to determine how well satellite data reflects the in situ buoy measurements.\n\nplt.figure(figsize = (10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(merged_df.index, merged_df.sst_buoy, \n              'o', markersize=3, \n              label='Buoy', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(merged_df.index, merged_df.sst_sat,  \n              's', markersize=3, \n              label='Satellite', c='blue', \n              linestyle='-', linewidth=1) \n\n#plt.ylim([0, 3])\nplt.ylabel('SST (degrees C)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#clean-up-the-merged-dataset",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#clean-up-the-merged-dataset",
    "title": "Make a virtual buoy with satellite data",
    "section": "Clean up the merged dataset",
    "text": "Clean up the merged dataset\nRegression packages typically do not like nan’s. * Delete rows with nan\nThe data could contain data points that are outliers. Let’s remove those points from the data frame. * Apply a conservative allowable data range. - For the lower end of the range, the freezing point of seawater (ca. -2).\n- For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n\n# Drop nan\nclean_merged_df = merged_df.dropna()\n\n# Drop &lt; -2 and &gt; 45\nclean_merged_df = clean_merged_df.drop(clean_merged_df[(clean_merged_df['sst_sat'] &lt; -2) \n                                       | (clean_merged_df['sst_sat'] &gt; 45)].index)"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#run-the-regression",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#run-the-regression",
    "title": "Make a virtual buoy with satellite data",
    "section": "Run the regression",
    "text": "Run the regression\n\n# Regression packages typically do not like nan's. Delete rows with nan\nclean_merged_df = merged_df.dropna()\n\n# Generate the regression plot\nsns.regplot(x='sst_buoy', y='sst_sat', data=clean_merged_df)\n\n# Calculate the slope and intercept\nslope, intercept = np.polyfit(clean_merged_df[\"sst_buoy\"], clean_merged_df[\"sst_sat\"], 1)\n\n# Calculate R2\nr2 = r2_score(clean_merged_df[\"sst_sat\"], clean_merged_df[\"sst_buoy\"])\n\n# Annotate the plot\nplt.annotate(f\"y = {slope:.2f}x + {intercept:.2f},  R2 = {r2:.2f}\", \n             xy=(12, 18), \n             #xytext=(30, 5), \n             fontsize=12, \n             color=\"black\", \n             ha=\"left\")\n\nprint(slope, intercept)\n\n# To save your data, uncomment the next line\n# clean_merged_df.to_csv(\"virtual_buoy_example.csv\", index=False)\n\n0.9338037509902803 0.9930764222028932"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#it-looks-like-your-virtual-buoy-is-ready-for-operations",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#it-looks-like-your-virtual-buoy-is-ready-for-operations",
    "title": "Make a virtual buoy with satellite data",
    "section": "It looks like your virtual buoy is ready for operations",
    "text": "It looks like your virtual buoy is ready for operations\n\nThere is essentially a one-to-one relationship between buoy and satellite SST. The slope (0.93) is very close to 1\nThe R2 indicates that 90% of the variability of satellite SST is explained by the regression."
  }
]