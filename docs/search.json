[
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "History | Create July 2023 | Updated August 2023"
  },
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html#background",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html#background",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Background",
    "text": "Background\nMap projections try to portray the earth’s spherical surface on a flat surface. A coordinate reference system (CRS) defines how the two-dimensional, projected map relates to real places on the earth. Which map projection and CRS to use depends on the region in which you are working and the analysis you will do.\nNOAA PolarWatch distributes gridded and tabular oceanographic data for polar regions.\nMost of the satellite data in the PolarWatch data catalog use a projection based on a Geographic Coordinate Reference System, where the X and Y coordinates are longitude and latitude, respectively. Geographical coordinates work well in many parts of the globe, but within polar regions, features tend to be very distorted. A Polar Stereographic projection often is a better choice for polar regions. For example, the NSIDC’s Polar Stereographic Projections, which were developed to optimize mapping of sea ice, have only a 6% distortion of the grid at the poles and no distortion at 70º, a latitude close to where the marginal ice zones occur. The NOAA NSIDC Sea Ice Concentration Climate Data Record dataset, for example, is in a polar stereographic projection.\nWhen working with satellite datasets with a mix of map projections, it is often necessary to transform all the data to a common projection."
  },
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html#objective",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html#objective",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Objective",
    "text": "Objective\nIn this tutorial, we will learn to transform dataset coordinates from one projection to another."
  },
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html#this-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html#this-tutorial-demonstrates-the-following-techniques",
    "title": "Transforming satellite data from one map projection to another",
    "section": "This tutorial demonstrates the following techniques",
    "text": "This tutorial demonstrates the following techniques\n\nDownloading and saving a netCDF file from PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nTransforming coordinates using EPSG codes\nMapping data using the transformed coordinates"
  },
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html#datasets-used",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html#datasets-used",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Datasets used",
    "text": "Datasets used\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, Science Quality, 1978-2022, Monthly\nThe sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Southern Polar Stereographic projection (EPSG:3031). The resolution is 25km, meaning each pixel in this data set represents a value that covers a 25km by 25km area. The dataset can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday"
  },
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html#import-packages",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html#import-packages",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Import packages",
    "text": "Import packages\n\nimport cartopy.crs as ccrs\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nfrom pyproj import CRS\nfrom pyproj import Transformer\nfrom matplotlib import pyplot as plt \nimport cmocean\n\n## Get data from ERDDAP\n\n# request data from polarwatch.noaa.gov erddap and save it to sic.nc file\n\nurl = ''.join([\"https://polarwatch.noaa.gov/erddap/griddap/\",\n               \"nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly\",\n               \"[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)]\", \n               \"[(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]\"\n               ])\n\nurllib.request.urlretrieve(url, \"sic.nc\")\n\n('sic.nc', &lt;http.client.HTTPMessage at 0x1a7e0cca0&gt;)\n\n\n\n# open and assign data from the file to a variable ds using xarray\nds = xr.open_dataset(\"sic.nc\")\n\n# view metadata \nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 1, ygrid: 332, xgrid: 316)\nCoordinates:\n  * time                     (time) datetime64[ns] 2022-12-01\n  * ygrid                    (ygrid) float32 4.338e+06 4.312e+06 ... -3.938e+06\n  * xgrid                    (xgrid) float32 -3.938e+06 -3.912e+06 ... 3.938e+06\nData variables:\n    cdr_seaice_conc_monthly  (time, ygrid, xgrid) float32 ...\nAttributes: (12/65)\n    acknowledgement:                                     This project was sup...\n    cdm_data_type:                                       Grid\n    cdr_variable:                                        cdr_seaice_conc_monthly\n    contributor_name:                                    Walter N. Meier, Flo...\n    contributor_role:                                    principal investigat...\n    Conventions:                                         CF-1.6, ACDD-1.3, CO...\n    ...                                                  ...\n    summary:                                             This data set provid...\n    time_coverage_duration:                              P1M\n    time_coverage_end:                                   2022-12-01T00:00:00Z\n    time_coverage_resolution:                            P1M\n    time_coverage_start:                                 2022-12-01T00:00:00Z\n    title:                                               Sea Ice Concentratio...xarray.DatasetDimensions:time: 1ygrid: 332xgrid: 316Coordinates: (3)time(time)datetime64[ns]2022-12-01_ChunkSizes :1024_CoordinateAxisType :Timeactual_range :[1.6698528e+09 1.6698528e+09]axis :Tioos_category :Timelong_name :ANSI datestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-12-01T00:00:00.000000000'], dtype='datetime64[ns]')ygrid(ygrid)float324.338e+06 4.312e+06 ... -3.938e+06_ChunkSizes :332actual_range :[-3937500.  4337500.]axis :Yioos_category :Locationlong_name :projection_grid_y_centersstandard_name :projection_y_coordinateunits :metersvalid_range :[-3950000.  4350000.]array([ 4337500.,  4312500.,  4287500., ..., -3887500., -3912500., -3937500.],\n      dtype=float32)xgrid(xgrid)float32-3.938e+06 -3.912e+06 ... 3.938e+06_ChunkSizes :316actual_range :[-3937500.  3937500.]axis :Xioos_category :Locationlong_name :projection_grid_x_centersstandard_name :projection_x_coordinateunits :metersvalid_range :[-3950000.  3950000.]array([-3937500., -3912500., -3887500., ...,  3887500.,  3912500.,  3937500.],\n      dtype=float32)Data variables: (1)cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...ancillary_variables :stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthlycolorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole lakes coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Southern Hemisphere Sea Ice Concentrationreferences :https://nsidc.org/data/g02202/versions/4/standard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][104912 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2022-12-01'], dtype='datetime64[ns]', name='time', freq=None))ygridPandasIndexPandasIndex(Index([ 4337500.0,  4312500.0,  4287500.0,  4262500.0,  4237500.0,  4212500.0,\n        4187500.0,  4162500.0,  4137500.0,  4112500.0,\n       ...\n       -3712500.0, -3737500.0, -3762500.0, -3787500.0, -3812500.0, -3837500.0,\n       -3862500.0, -3887500.0, -3912500.0, -3937500.0],\n      dtype='float32', name='ygrid', length=332))xgridPandasIndexPandasIndex(Index([-3937500.0, -3912500.0, -3887500.0, -3862500.0, -3837500.0, -3812500.0,\n       -3787500.0, -3762500.0, -3737500.0, -3712500.0,\n       ...\n        3712500.0,  3737500.0,  3762500.0,  3787500.0,  3812500.0,  3837500.0,\n        3862500.0,  3887500.0,  3912500.0,  3937500.0],\n      dtype='float32', name='xgrid', length=316))Attributes: (65)acknowledgement :This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.cdm_data_type :Gridcdr_variable :cdr_seaice_conc_monthlycontributor_name :Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fishercontributor_role :principal investigator, author, author, software developer, software developer, software developerConventions :CF-1.6, ACDD-1.3, COARDScreator_email :nsidc@nsidc.orgcreator_name :NSIDCcreator_type :institutioncreator_url :https://nsidc.org/date_created :2023-02-22T23:17:53ZdefaultGraphQuery :cdr_seaice_conc_monthly%5Blast%5D%5B(4337500.0):(-3937500.0)%5D%5B(-3937500.0):(3937500.0)%5D&.draw=surfacegrid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3950000.0 25000.0 0 4350000.0 0 -25000.0grid_mapping_grid_boundary_bottom_projected_y :-3950000.0grid_mapping_grid_boundary_left_projected_x :-3950000.0grid_mapping_grid_boundary_right_projected_x :3950000.0grid_mapping_grid_boundary_top_projected_y :4350000.0grid_mapping_latitude_of_projection_origin :-90.0grid_mapping_longitude_of_projection_origin :0.0grid_mapping_name :polar_stereographicgrid_mapping_parent_grid_cell_column_subset_end :316.0grid_mapping_parent_grid_cell_column_subset_start :0.0grid_mapping_parent_grid_cell_row_subset_end :332.0grid_mapping_parent_grid_cell_row_subset_start :0.0grid_mapping_proj4text :+proj=stere +lat_0=-90 +lat_ts=-70 +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_scaling_factor :1.0grid_mapping_semimajor_radius :6378273.0grid_mapping_semiminor_radius :6356889.449grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic South\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",-70],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3412\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3412grid_mapping_standard_parallel :-70.0grid_mapping_straight_vertical_longitude_from_pole :180.0grid_mapping_units :metershistory :Tue Jan  5 13:40:25 2021: ncks -x -v goddard_merged_seaice_conc_monthly ./previous_blank_ncs/S_monthly_blank.nc ./S_monthly_blank.nc\n2023-09-06T03:13:27Z (local files)\n2023-09-06T03:13:27Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]id :https://doi.org/10.7265/sr8p-kc62infoUrl :https://nsidc.org/data/g02202/versions/4/institution :NSIDC &gt; National Snow and Ice Data Centerkeywords :algorithm, area, bellingshausen, bootstrap, cdr_seaice_conc_monthly, center, climate, common, concentration, cryosphere, data, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Polar, Geographic Region &gt; Southern Hemisphere, goddard, gsfc, hemisphere, ice, ice distribution, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Southern Ocean, Ocean &gt; Southern Ocean &gt; Bellingshausen Sea, Ocean &gt; Southern Ocean &gt; Ross Sea, Ocean &gt; Southern Ocean &gt; Weddell Sea, oceans, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, ross, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, southern, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, tdim, team, version, weddellkeywords_vocabulary :GCMD Science Keywordslicense :No constraints on data access or usemetadata_link :https://nsidc.org/data/g02202/versions/4/naming_authority :org.doi.dxNCO :\"4.5.4\"platform :DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17processing_level :NOAA Level 3product_version :v04r00program :NOAA Climate Data Record Programproj_crs_code :EPSG:3412proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.project :NOAA/NSIDC passive microwave sea ice concentration climate data recordreferences :Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7):  15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1sensor :SSMI/S &gt; Special Sensor Microwave Imager/Soundersoftware_version_id :git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897source :ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220701_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220702_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220703_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220704_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220705_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220706_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220707_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220708_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220709_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220710_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220711_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220712_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220713_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220714_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220715_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220716_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220717_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220718_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220719_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220720_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220721_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220722_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220723_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220724_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220725_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220726_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220727_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220728_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220729_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220730_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220731_f17_v04r00.ncsourceUrl :(local files)spatial_resolution :25kmstandard_name_vocabulary :CF Standard Name Table v70summary :This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).time_coverage_duration :P1Mtime_coverage_end :2022-12-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2022-12-01T00:00:00Ztitle :Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-Present, Monthly"
  },
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html#inspect-crs-definitions-and-the-transformation-function",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html#inspect-crs-definitions-and-the-transformation-function",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Inspect CRS definitions and the transformation function",
    "text": "Inspect CRS definitions and the transformation function\nWhen transforming from one CRS to another, it is important to inspect CRS definitions and the transformation function for proper transformation. We will transform from CRS EPSG: 3031 (NSIDC Polar Stereographic South) to EPSG: 4326 (geographic coordinate system) .\nThere are several ways to specify CRS as shown below. For this exercise, we will use EPSG code.\n1. crs = CRS.from_epsg(4326)\n2. crs = CRS.from_string(\"EPSG:4326\")\n3. crs = CRS.from_proj4(\"+proj=latlon\")\nFor this exercise, we will use method 1, the EPSG code.\n\nGet the projection information from the EPSG code\nGeographic\n\ncrs_4326 = CRS.from_epsg(4326)\ncrs_4326\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\nNSIDC Polar Stereographic South\n\ncrs_3031 = CRS.from_epsg(3031)\ncrs_3031\n\n&lt;Projected CRS: EPSG:3031&gt;\nName: WGS 84 / Antarctic Polar Stereographic\nAxis Info [cartesian]:\n- E[north]: Easting (metre)\n- N[north]: Northing (metre)\nArea of Use:\n- name: Antarctica.\n- bounds: (-180.0, -90.0, 180.0, -60.0)\nCoordinate Operation:\n- name: Antarctic Polar Stereographic\n- method: Polar Stereographic (variant B)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n\nInspect CRS definitions\ncrs_4326 * order of axis: latitude first, and longitude in degree * bounds (-180, -90, 180, 90) global coverage\ncrs_3031 * order of axis: X then Y in meter * bounds (-180, -90, 180, -60)\nbased on the crs definitions * transformation input should be in the order of latitude and longitude * transformation input/output should be within the bounds\nNOTE: if you prefer to use lon and lat (or x, y) axis order, you can set transformer parameter always_xy to True\nTransformer.from_crs(crs_3031, crs_4326, always_xy=True)"
  },
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html#transform-the-data",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html#transform-the-data",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Transform the data",
    "text": "Transform the data\n\n# transformer converts lon and lat values to x, y \ntransformer = Transformer.from_crs(crs_3031, crs_4326)\n\n# create a rectangular grid \nx, y = np.meshgrid(ds.xgrid, ds.ygrid)\n\n# pass x and y grid values to transform\nlat, lon = transformer.transform(x,y)"
  },
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html#add-latitude-and-longitude-values-to-the-dataset",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html#add-latitude-and-longitude-values-to-the-dataset",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Add latitude and longitude values to the dataset",
    "text": "Add latitude and longitude values to the dataset\nFor adding the new coordinates to the dataset, create a tuple with its dimension and values then add to the dataset.\n\ncreate a tuple (dimension, value)\nadd to the dataset (ds) ds.coord['name']=(dimension, value)\n\n\nds.coords['lat'] = (ds.cdr_seaice_conc_monthly[0][:].dims, lat)\nds.coords['lon'] = (ds.cdr_seaice_conc_monthly[0][:].dims, lon)\n\nds['cdr_seaice_conc_monthly'] = (ds['cdr_seaice_conc_monthly']\n                                 .where(ds['cdr_seaice_conc_monthly'] &lt;= 1, \n                                        np.nan)\n                                 )"
  },
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html#plot-data-with-new-coordinates-on-a-global-map",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html#plot-data-with-new-coordinates-on-a-global-map",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Plot data with new coordinates on a global map",
    "text": "Plot data with new coordinates on a global map\nBecause the data were in the polar stereographic projection, mapping the data onto a different projection (global map projection) below, doesn’t make the data fit well on the map.\n\n# set the map size\nplt.figure(figsize=(13,5))\n\n# set map projection (PlateCarree(): global map projection)\nax = plt.axes(projection=ccrs.PlateCarree())\n\n# plot data with new coordinates\nds.cdr_seaice_conc_monthly[0][:].plot.pcolormesh('lon', \n                                                 'lat', \n                                                 ax=ax, \n                                                 transform=ccrs.PlateCarree(), \n                                                 cmap=cmocean.cm.ice, \n                                                 add_colorbar=False)\n# add coastlines to the map\nax.coastlines()"
  },
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html#plot-data-with-new-coordinates-on-a-polar-stereographic-projection-map",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html#plot-data-with-new-coordinates-on-a-polar-stereographic-projection-map",
    "title": "Transforming satellite data from one map projection to another",
    "section": "Plot data with new coordinates on a polar stereographic projection map",
    "text": "Plot data with new coordinates on a polar stereographic projection map\n\n# Set map projection \n# SouthPolarStereo(): southern polar stereographic projection)\nax = plt.axes(projection=ccrs.SouthPolarStereo())\n\nds.cdr_seaice_conc_monthly[0][:].plot.pcolormesh('lon', \n                                                 'lat', \n                                                 ax=ax, \n                                                 cmap=cmocean.cm.ice, \n                                                 transform=ccrs.PlateCarree())\n\nax.coastlines()"
  },
  {
    "objectID": "tutorials/python/transforming-coords-from-crs-to-crs.html#references",
    "href": "tutorials/python/transforming-coords-from-crs-to-crs.html#references",
    "title": "Transforming satellite data from one map projection to another",
    "section": "References",
    "text": "References\nUseful links\n\nNOAA PolarWatch Data Product Page (download, preview)\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)"
  },
  {
    "objectID": "tutorials/python/sport-jpss-seaice.html#notes",
    "href": "tutorials/python/sport-jpss-seaice.html#notes",
    "title": "Visualizing JPSS Sea Ice Concentration products using Google Colab",
    "section": "Notes",
    "text": "Notes\nJupyter Notebooks are made up of code cells and text cells. Code cells contain executable code and its output, while text cells contain explanatory text - like this cell.\nEach code cell has a play icon at the left gutter of the cell. Press play to execute the cell’s tasks, or hit Cmd/Ctrl+Enter. Note - sometimes the play icon is not shown (showing only empty brackets) unless your cursor hovers over it.\nAny text or image output resulting from execution of a code cell is displayed right below the code cell - or you’ll see an ‘elapsed processing time beside a checkmark’ near the play icon - or both.\nSome text cells are ‘section headers’, denoted by a “&gt;” (greater than) sign. The “&gt;” can be pressed to expand (show) the cells under it (down to the next section header). That turns the “&gt;” into a “\\/” (chevron), which can then be pressed to collapse (hide) its cells."
  },
  {
    "objectID": "tutorials/python/sport-jpss-seaice.html#loadinstall-required-packages-mount-google-drive",
    "href": "tutorials/python/sport-jpss-seaice.html#loadinstall-required-packages-mount-google-drive",
    "title": "Visualizing JPSS Sea Ice Concentration products using Google Colab",
    "section": "Load/install required packages & Mount Google Drive",
    "text": "Load/install required packages & Mount Google Drive\n\n\n# Load/install the required non-standard Python packages\n!pip install cartopy\n!pip install netCDF4\n!pip install pyresample\n!pip install ecmwflibs\n!pip install xarray\n!pip install rioxarray\n!pip install rasterio\n!pip install --upgrade rasterio rioxarray\n# Ensure the Google Drive is mounted"
  },
  {
    "objectID": "tutorials/python/sport-jpss-seaice.html#modify-the-python-script-and-run-it",
    "href": "tutorials/python/sport-jpss-seaice.html#modify-the-python-script-and-run-it",
    "title": "Visualizing JPSS Sea Ice Concentration products using Google Colab",
    "section": "Modify the Python script and Run it",
    "text": "Modify the Python script and Run it\nWithin Google Colab, you can access your Google Drive directories. At the far left of the Google Colab screen, press the simple folder icon. This will expand the left-most panel, showing your available Google drives. Navigate the directories to find your file, select it, and Right-Click to select “Copy path”. Then paste that result into the Filename variable in the next cell (below), like so:\n\nFilename = ‘MyDrive/ColabNotebooks/JPSS_Soil_Data/AMSR2-SOIL_v2r2_GW1_s20240210122904_e20240210123456_.nc’\n\nor\n\nFilename = ‘MyDrive/ColabNotebooks/JPSS_Soil_Data/NPR_SMOPS_CMAP_D20240131.nc’\n\nNext, choose one of the recognized domains, placing it into the Domain variable below.\nFinally, specify the location where you want the output PNG files to be created; in the Out_dir_L2 and Out_dir_L3 variables for level-2, and level-3 output, respectively. Execute this cell with the ‘play’ icon.\n\n# Specify Filename\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/JRR-IceConcentration_v3r3_j01_s202403070044010_e202403070045255_c202403070121021.nc'\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Blended_SIC_N20_2020_350_12_15_0000_2400_north.tiff'  # SSEC\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Blended_AMSR2_VIIRS_SIC_2023_135_05_15_2346_2357.tiff'  # GINA (swath)\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20240804_c20240805.nc'  # PolarWatch\nFilename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20241005_c20241007.nc'  # PolarWatch\n#Filename = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/nesdis_blendedsic_nhem_daily_79da_d8e9_7b6a_U1723144597211.nc'  # PolarWatch\n\n# Specify 1 of the recognized domains:\n#   arctic, antarctic\nDomain = 'arctic'\n\n# Specify the output directory\nOut_dir_L2 = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Output_L2'\nOut_dir_L3 = '/content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Output_L3'\n\nThis portion of code imports required Python packages, as well as defining the domains to be recognized by the script. You can add your own domain, or change on of the existing ones, in the ‘domains’ dictionary.\n\nimport os\nimport re\nimport sys\n\nfrom time import gmtime, strftime\nimport cartopy.feature as cfeature\nimport cartopy.crs as ccrs\nimport netCDF4\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pyresample as pr\nimport rioxarray as rio\nfrom pyresample.geometry import SwathDefinition\nfrom pathlib import Path\nimport ecmwflibs # This little bugger is required to find the eccodes library!!!!\necmwflibs.find(\"eccodes\") # This line is simply to *use* the imported ecmwflibs module\n\n# geographic regions\ndomains = {\n   'world':{                             # region\n      'states':False,                    # state outlines?\n      'shape':(1000, 500),               # size (x,y)\n      'area_extent':(-180, -90, 180, 90) # lat/lon extent (degrees) (W,S,E,N)\n      },\n   'arctic':{\n      'states':False,\n      'shape':(700, 700),\n      'area_extent':(-180, 50, 180, 90)\n      },\n   'antarctic':{\n      'states':False,\n      'shape':(700, 700),\n      'area_extent':(-180, -90, 180, -55)\n      },\n    }\n\nThese classes, or functions (SIC_L2 and SIC_L3), handle the Level-2 (swath) VIIRS SIC files and the Level-3 (gridded) Blended files.\n\nclass SIC_L2:\n   \"\"\"Level2 SIC files\"\"\"\n\n   def __init__(self, domain: str, fil: str):\n      self.domain = domain\n      self.fil = fil\n      self.lats = []\n      self.lons = []\n      self.data = []\n      self.plot_data()\n\n   def plot_data(self):\n      \"\"\"Plot the data, overlay with a map, colormap, and label\"\"\"\n\n      print(f'Reading file {self.fil}')\n      f = rio.open_rasterio(self.fil, band_as_variable=True)\n\n      # Get data\n      data_tmp = f.IceConc.values\n      x_tmp = f.Longitude.values\n      y_tmp = f.Latitude.values\n\n      subsam = 20\n\n      # Subsample if needed and Mask out out-of-bounds values\n      self.lats = y_tmp[::subsam, ::subsam].squeeze()\n      self.lons = x_tmp[::subsam, ::subsam].squeeze()\n      self.data = data_tmp[::subsam, ::subsam].squeeze()\n\n      # Get date and time from filename\n      ymd, hm = re.search(r's(?P&lt;ymd&gt;\\d{8})(?P&lt;hm&gt;\\d{4})',\n                          os.path.basename(self.fil)).groups()\n      print('ymd=', ymd, 'hm=', hm)\n\n      # Min and Max for SIC percentage\n      vmin, vmax = 0.0, 100.0\n\n      # Get center lat/lon\n      ctr_lon = (domains[self.domain]['area_extent'][2]+domains[self.domain]['area_extent'][0]) / 2\n      print('ctr_lon=', ctr_lon)\n\n      # Define PROJ4 target projection (stere = stereographic)\n      proj4 = {'proj': 'stere', 'lat_0': 90.0, 'lon_0': ctr_lon,\n                    'ellps': 'WGS84', 'units': 'm'}\n\n      # Create pyresample AreaDefinition\n      area_def = pr.create_area_def(\n                                    self.domain,\n                                    proj4,\n                                    description = 'stereographic',\n                                    units = 'deg',\n                                    shape = domains[self.domain]['shape'],\n                                    area_extent = domains[self.domain]['area_extent']\n                                   )\n\n      # Create a cartopy CRS object (from pyresample)\n      crs = area_def.to_cartopy_crs()\n\n      # Define the swath projection\n      swath_def = SwathDefinition(self.lons, self.lats)\n\n      # resample swath data (self.data) to the target grid using nearest neighbour method\n      result = pr.kd_tree.resample_nearest(swath_def, self.data, area_def,\n                                           radius_of_influence=30000,\n                                           fill_value=None)\n\n      # Prepare picture\n      fig = plt.figure(figsize=(12, 8))\n      ax = plt.axes(projection=crs)\n      ax.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=0.25, edgecolor='black')\n      ax.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=0.25)\n      if domains[self.domain]['states']:\n         ax.add_feature(cfeature.STATES.with_scale('50m'), linewidth=0.1)\n\n      # Title\n      title = f'NOAA JPSS NOAA-20 VIIRS (Sea Ice Conc.) - {ymd} {hm} UTC'\n      units = '%'\n\n      # Display picture\n      result = np.float64(result) # only to remove a runtime \"overflow\" warning\n      ax.imshow(result, transform=crs, extent=crs.bounds,\n                cmap='jet_r', origin='upper', vmin=vmin, vmax=vmax)\n      ax.set_title(title, fontsize=11)\n\n      # Add color legend\n      sic = plt.cm.ScalarMappable(cmap='jet_r', norm=plt.Normalize(vmin, vmax))\n      cbar = plt.colorbar(sic, ax=ax, shrink=0.45, pad=0.03)\n\n      # ...with tick marks and labels\n      cbar.ax.tick_params(labelsize=9)\n      cbar.set_label(units, size=9)\n\n      # Display image in Google Colab\n      plt.show()\n\n      # Save as PNG\n      pngname = (f'{Out_dir_L2}/{ymd}_{hm}_VIIRS_SIC_{self.domain}.png')\n\n      print(f'{strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())} - Saving PNG  {pngname}')\n      fig.savefig(f'{pngname}', bbox_inches='tight', dpi=200)\n\n      # Verify/notify write success\n      if not os.path.isfile(f'{pngname}'):\n         print(f'Error: {pngname} NOT saved')\n\n      # Close plot\n      plt.close()\n\n################################################################################\n################################################################################\nclass SIC_L3:\n   \"\"\"Level3 Blended SIC NetCDf & GeoTIFF files\"\"\"\n\n   def __init__(self, domain: str, fil: str):\n      self.domain = domain\n      self.fil = fil\n      # Prep projection (EASE-Grid 2.0 - - - EPSG:6931, NPole)\n      self.ease_proj = ccrs.LambertAzimuthalEqualArea(central_latitude=90.)\n      self.cart_proj = ccrs.PlateCarree(central_longitude=0.0)\n      self.plot_data()\n\n   def convert_cart_laea(self, lats:list, lons:list) -&gt; tuple[int, int, int, int]:\n      \"\"\"Convert each point of the region's lat/lon polygon to LAEA coords (meters)\n      Args:\n         lons:list of longitude values\n         lats:list of latitude values\n      Returns: min_x, max_x, min_y, max_y (meters) (integer)\n      \"\"\"\n      min_x = min_y = float('inf')\n      max_x = max_y = float('-inf')\n\n      # Perform transforms on all points of polygon\n      for lat in lats:\n         for lon in lons:\n            x, y = self.ease_proj.transform_point(lon, lat, src_crs=self.cart_proj)\n            min_x = min(min_x, x)\n            max_x = max(max_x, x)\n            min_y = min(min_y, y)\n            max_y = max(max_y, y)\n      return(int(min_x), int(max_x), int(min_y), int(max_y))\n\n   def find_value_address_in(self, list:list, value:int) -&gt; tuple[int, int]:\n      \"\"\"Find address of value in monotonically increasing or decreasing list\n      Args:\n         list: list of values\n         value: value to find\n      Returns: address, direction (0 or 1)\n      \"\"\"\n      if list[0] &lt; list[1]:\n         # increasing/normal\n         dir = 1\n         for j, i in enumerate(list):\n            if i &gt;= value:\n               break\n      else:\n         # decreasing/abnormal\n         dir = 0\n         for j, i in enumerate(list):\n            if i &lt;= value:\n               break\n      return j, dir\n\n   def plot_data(self):\n      \"\"\"Read data, create sample Plot of Blended SIC data\n      \"\"\"\n      # Check consistency of request\n      print(self.domain)\n      if self.domain not in ['arctic', 'antarctic']:\n         raise ValueError(f'Only arctic and antarctic currently supported')\n      self.ctr_lat = 90. if self.domain == 'arctic' else -90.\n\n      # Read NetCDF/GeoTIFF\n      print(f'Reading file {self.fil}')\n      f = rio.open_rasterio(self.fil, band_as_variable=True)\n      print('type(f)=', type(f))\n\n      # Set full and half size variables\n      full = f.rio.width\n      half = int(full/2)\n\n      # quadrant x,y starting values (meters) (in the full array)\n      #       Dateline-90W     90W-Prime        Prime-90E       90E-Dateline    hemisphere\n      start = {'nw':[0, 0], 'sw':[0, half], 'se':[half, half], 'ne':[half, 0], 'full':[0, 0]}\n\n      # Define regions dict with series of lat,lon pairs (3 or more pairs)\n      regions = {\n                 'alaska':[59,-141,\n                           55,-163,\n                           60,-168,\n                           68,-167,\n                           70,-140],\n                 'greenland':[59,-70,\n                              84,-70,\n                              84,-10,\n                              59,-10],\n                 'hudsonbay':[52,-95,\n                              52,-72,\n                              69,-72,\n                              69,-95],\n                 'uk':[50,-10,\n                       50,2,\n                       60,2,\n                       60,-10]}\n      # Each region's list does not need to be a closed polygon\n\n      # Parameters\n      vmin, vmax = 0.0, 100.0\n      domain = 'full'\n      subsam = 20\n      print('domain=', domain)\n\n      # Subset & Subsample\n      if domain == 'full':  # full polar EASE\n         data = f.band_1.values[start[domain][0]:start[domain][0]+full:subsam, start[domain][1]:start[domain][1]+full:subsam]\n         x = f.x.values[start[domain][0]:start[domain][0]+full:subsam]\n         y = f.y.values[start[domain][1]:start[domain][1]+full:subsam]\n      elif domain in ['nw', 'ne', 'sw', 'se']:  # EASE quadrants\n         data = f.band_1.values[start[domain][1]:start[domain][1]+half:subsam, start[domain][0]:start[domain][0]+half:subsam]\n         x = f.x.values[start[domain][0]:start[domain][0]+half:subsam]\n         y = f.y.values[start[domain][1]:start[domain][1]+half:subsam]\n      else:  # polygon\n         data_tmp = f.band_1.values\n         x_tmp = f.x.values\n         y_tmp = f.y.values\n\n         # Fill lats/lons arrays with coords\n         lats = [regions[domain][i] for i in range(0, len(regions[domain]), 2)]  # even\n         lons = [regions[domain][i] for i in range(1, len(regions[domain]), 2)]  # odd\n\n         # Find min and max of x and y values (meters in LAEA proj space)\n         x1, x2, y1, y2 = self.convert_cart_laea(lats, lons)\n         print('polygon coords in LAEA meters:', x1, x2, y1, y2)\n\n         # Locate min/max x/y values in the x and y lists\n         col1, xdir = self.find_value_address_in(x_tmp, x1)\n         col2, xdir = self.find_value_address_in(x_tmp, x2)\n         row1, ydir = self.find_value_address_in(y_tmp, y1)\n         row2, ydir = self.find_value_address_in(y_tmp, y2)\n         print('col1=', col1, 'col2=', col2, 'row1=', row1, 'row2=', row2)\n         if xdir:\n            x = x_tmp[col1:col2:subsam]\n            if ydir:\n               data = data_tmp[row1:row2:subsam, col1:col2:subsam]\n            else:\n               data = data_tmp[row2:row1:subsam, col1:col2:subsam]\n         else:\n            x = x_tmp[col2:col1:subsam]\n            if ydir:\n               data = data_tmp[row1:row2:subsam, col2:col1:subsam]\n            else:\n               data = data_tmp[row2:row1:subsam, col2:col1:subsam]\n\n         if ydir:\n            y = y_tmp[row1:row2:subsam]\n         else:\n            y = y_tmp[row2:row1:subsam]\n         print(col1, col2, row1, row2)\n\n      print('data shape=', data.shape)\n      #plt.hist(data, density=True, bins=10)\n      #plt.show()\n\n      # Get date from filename  Polar-AMSR2VIIRSBLEND_\n      if '_AMSR2_VIIRS_SIC_' in self.fil:\n         data[data&gt;100] = np.nan\n         ymd_txt = re.search(r'Blended_AMSR2_VIIRS_SIC_(\\d{4})_\\d{3}_(\\d{2})_(\\d{2})', os.path.basename(self.fil))\n         ymd = (ymd_txt.group(1) + ymd_txt.group(2) + ymd_txt.group(3))\n      elif 'Blended_SIC_' in self.fil:\n         data[data&gt;100] = np.nan\n         #                     Blended_SIC_N20_2020_350_12_15_0000_2400_north.tiff\n         ymd_txt = re.search(r'Blended_SIC_N20_(\\d{4})_\\d{3}_(\\d{2})_(\\d{2})', os.path.basename(self.fil))\n         ymd = (ymd_txt.group(1) + ymd_txt.group(2) + ymd_txt.group(3))\n      elif 'Polar-AMSR2VIIRSBLEND_' in self.fil:\n         data[data&gt;100] = np.nan\n         ymd_txt = re.search(r'Polar-AMSR2VIIRSBLEND_..._v..r.._Nhem_0000_2400_d(\\d{4})(\\d{2})(\\d{2})', os.path.basename(self.fil))\n         ymd = (ymd_txt.group(1) + ymd_txt.group(2) + ymd_txt.group(3))\n      elif 'nesdis_blendedsic_nhem_daily_' in self.fil:\n         data[data&gt;100] = np.nan\n         ymd = 'YYYYMMDD'\n      else:\n         sys.exit('Not a valid file type')\n\n      # Prepare figure\n      fig = plt.figure(figsize=(12, 12))\n      axm = plt.subplot(projection = self.ease_proj)\n      axm.set_title(f'Blended Sea Ice Concentration - {ymd}', fontsize=11)\n\n      # Add map features\n      axm.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=0.25, edgecolor='black')\n      axm.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=0.25)\n      if domains[self.domain]['states']:\n         axm.add_feature(cfeature.STATES.with_scale('50m'), linewidth=0.1)\n      axm.gridlines(draw_labels=True)\n\n      # Add color bar with 'jet' cmap\n      sic = plt.cm.ScalarMappable(cmap='jet')\n      cbar = plt.colorbar(sic, ax=axm, shrink=0.45, pad=0.03)\n\n      # ...with tick marks and labels\n      cbar.ax.tick_params(labelsize=9)\n      cbar.set_label('percent', size=9)\n\n      # Display image in Google Colab\n      axm.imshow(data, cmap='jet', transform=self.ease_proj, vmin=vmin, vmax=vmax,\n                 extent=(x.min(), x.max(), y.min(), y.max()))\n      plt.show()\n\n      # Save as PNG\n      pngname = (f'{Out_dir_L3}/{ymd}_Blended_AMSR2VIIRS_SIC_{self.domain}.png')\n      print(f'{strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())} - Saving PNG  {pngname}')\n      fig.savefig(pngname, bbox_inches='tight', dpi=200)\n\n      # Verify/notify write success\n      if not os.path.isfile(pngname):\n         print(f'Error: {pngname} NOT saved')\n\n      # Close figure\n      plt.close()\n\nFinally, execute the code below. Either SIC_L2 or SIC_L3 will be executed, depending on which type of file you’ve specified. You may have to scroll down a bit to see the resulting image here in Colab, but a PNG file will be generated, as well.\nNote: During the first execution of this script, the Python module ‘Cartopy’ will need to download map-related files from “Natural Earth”. You will see Python-generated warning messages for this.\n\n# Verify data file exists\nif not os.path.exists(f'{Filename}'):\n   sys.exit(f'{Filename} does not exist')\n\n# Determine data type and call its procedure\nif Filename.find('JRR-IceConcentration', 0) != -1:  # CLASS\n   # Verify L2 output directory exists\n   if not os.path.isdir(f'{Out_dir_L2}'):\n      sys.exit(f'Output directory {Out_dir_L2} does not exist')\n   SIC_L2(Domain, f'{Filename}')\n\nelif Filename.find('Blended_', 0) != -1:  # SSEC/GINA\n   # Verify L3 output directory exists\n   if not os.path.isdir(f'{Out_dir_L3}'):\n      sys.exit(f'Output directory {Out_dir_L3} does not exist')\n   print('calling SIC_L3', Domain, Filename)\n   SIC_L3(Domain, f'{Filename}')\n\nelif Filename.find('nesdis_blendedsic_nhem_daily_', 0) != -1:  # PolarWatch\n   # Verify L3 output directory exists\n   if not os.path.isdir(f'{Out_dir_L3}'):\n      sys.exit(f'Output directory {Out_dir_L3} does not exist')\n   print('calling SIC_L3', Domain, Filename)\n   SIC_L3(Domain, f'{Filename}')\n\nelif Filename.find('Polar-AMSR2VIIRSBLEND_', 0) != -1:  # PolarWatch\n   # Verify L3 output directory exists\n   if not os.path.isdir(f'{Out_dir_L3}'):\n      sys.exit(f'Output directory {Out_dir_L3} does not exist')\n   print('calling SIC_L3', Domain, Filename)\n   SIC_L3(Domain, f'{Filename}')\n\nelse:\n   sys.exit('File must be: Blend or ????')\n###############################################################################\n\ncalling SIC_L3 arctic /content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20241005_c20241007.nc\narctic\nReading file /content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Polar-AMSR2VIIRSBLEND_j01_v01r00_Nhem_0000_2400_d20241005_c20241007.nc\n\n\nWARNING:rasterio._env:CPLE_AppDefined in Unhandled X/Y axis unit meters. SRS will ignore axis unit and be likely wrong.\nWARNING:rasterio._env:CPLE_AppDefined in Unhandled X/Y axis unit meters. SRS will ignore axis unit and be likely wrong.\n\n\ntype(f)= &lt;class 'xarray.core.dataset.Dataset'&gt;\ndomain= full\ndata shape= (452, 452)\n\n\n/usr/local/lib/python3.10/dist-packages/cartopy/io/__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/50m_physical/ne_50m_coastline.zip\n  warnings.warn(f'Downloading: {url}', DownloadWarning)\n/usr/local/lib/python3.10/dist-packages/cartopy/io/__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/50m_cultural/ne_50m_admin_0_boundary_lines_land.zip\n  warnings.warn(f'Downloading: {url}', DownloadWarning)\n\n\n\n\n\n\n\n\n\n2024-10-08 16:52:13 - Saving PNG  /content/drive/MyDrive/ColabNotebooks/JPSS_SIC/Output_L3/20241005_Blended_AMSR2VIIRS_SIC_arctic.png"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "",
    "text": "History | Updated July 2024\n\nIn this exercise you will extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like that produced by an animal telemetry tag, and ship track, or a glider tract.\nPlease note that there may be more efficient ways, more Pythonic ways, to accomplish the tasks in this tutorial. The tutorial was developed to be easier to follow for less experienced users of Python.\n\n\n\nLoading data from a tab- or comma-separated file\nPlotting the latitude/longitude points onto a map\nExtracting satellite data along a track\nSaving results as a CSV file\nPlotting the satellite data onto a map\n\n\n\n\n\nChlorophyll a concentration from the European Space Agency’s Ocean Colour Climate Change Initiative Monthly dataset v6.0\nYellowfin tuna telemetry track data that was developed as part of the Palmyra Bluewater Research (PBR) project (https://portal.atn.ioos.us/?ls=861Wqpd2#metadata/1f877c4c-7b50-49f5-be86-3354664e0cff/project). This example track used in the tutorial is from May 2022 to November 2022 and accessed via the Animal Telemetry Network (ATN) data portal.\n\n\n\n\n\npandas (reading and analyzing data)\n\nnumpy (data analysis, manipulation)\nxarray (multi-dimensional data analysis, manipulation)\nmatplotlib (mapping)\ncartopy (mapping)\ndatetime (date manipulation)"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#overview",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#overview",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "",
    "text": "History | Updated July 2024\n\nIn this exercise you will extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like that produced by an animal telemetry tag, and ship track, or a glider tract.\nPlease note that there may be more efficient ways, more Pythonic ways, to accomplish the tasks in this tutorial. The tutorial was developed to be easier to follow for less experienced users of Python.\n\n\n\nLoading data from a tab- or comma-separated file\nPlotting the latitude/longitude points onto a map\nExtracting satellite data along a track\nSaving results as a CSV file\nPlotting the satellite data onto a map\n\n\n\n\n\nChlorophyll a concentration from the European Space Agency’s Ocean Colour Climate Change Initiative Monthly dataset v6.0\nYellowfin tuna telemetry track data that was developed as part of the Palmyra Bluewater Research (PBR) project (https://portal.atn.ioos.us/?ls=861Wqpd2#metadata/1f877c4c-7b50-49f5-be86-3354664e0cff/project). This example track used in the tutorial is from May 2022 to November 2022 and accessed via the Animal Telemetry Network (ATN) data portal.\n\n\n\n\n\npandas (reading and analyzing data)\n\nnumpy (data analysis, manipulation)\nxarray (multi-dimensional data analysis, manipulation)\nmatplotlib (mapping)\ncartopy (mapping)\ndatetime (date manipulation)"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#import-the-required-python-modules",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#import-the-required-python-modules",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Import the required Python modules",
    "text": "Import the required Python modules\n\nfrom IPython.display import clear_output\nimport pandas as pd\nimport numpy as np\nimport os\nimport warnings\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport matplotlib.pyplot as plt\nimport xarray as xr\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#download-animal-track-data-from-the-atn-website",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#download-animal-track-data-from-the-atn-website",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Download animal track data from the ATN website",
    "text": "Download animal track data from the ATN website\n\nThe data you need for this exercise are already in the GitHub repository\nThe following step are show you how to download the data yourself"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#atn-portal",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#atn-portal",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "ATN Portal",
    "text": "ATN Portal\n\nFollow the link to the ATN website: https://portal.atn.ioos.us/?ls=O6vlufm7#map\nOn the right navigational panel, look for the “Palmyra Bluewater Research (PBR) Megafauna Movement Ecology Project, 2022-2023” tab.\nWithin the tab, scroll to find the telemetry tag labeled “Yellowfin tuna (233568)”.\nClick the search icon (maginifying glass) label next to the label to zoom into the area the area of the animal track.\n\n\n\n\natn_map.png\n\n\nImage of the ATN portal webpage"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#detail-page-for-the-yellowfin-tuna-233568",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#detail-page-for-the-yellowfin-tuna-233568",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Detail page for the Yellowfin tuna (233568)",
    "text": "Detail page for the Yellowfin tuna (233568)\n\nNext click the tag icon to the right of the search icon.\nThis page shows you details about the animal and the track.\n\n\n\n\natn_detail.png\n\n\nImage of the detail page for the Yellowfin Tuna #233568"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#data-download-page",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#data-download-page",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Data Download Page",
    "text": "Data Download Page\n\nPress the “Project Data” tab near the top of the webpage to bring up the data file list.\nSearch for the animal id number (233568).\nClick on the link “THUALB_2022_04-PTT_233568.zip (8.6 MB)” to download the data.\n\n\n\n\natn_data.png\n\n\nData download page"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#the-downloaded-data-file",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#the-downloaded-data-file",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "The Downloaded Data File",
    "text": "The Downloaded Data File\n\nThe download will be a zip file. You will need to unzip it.\nThe unzipped file folder contains many ancillary data files, but the one you are looking for is the CSV file (THUALB_2022_04-233568-4-GPE3.csv).\nYou don’t have to move this file into the data folder for this exercise. It is already there.\nBut if you download the file for a different animal track you would need to put the CSV file into the folder."
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#load-the-track-data-into-a-pandas-data-frame",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#load-the-track-data-into-a-pandas-data-frame",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Load the track data into a Pandas data frame",
    "text": "Load the track data into a Pandas data frame\nBelow, the track data will load using the Pandas “read_csv” method. * Then use the “.head()” method to view the column names and the first few rows of data.\n\ntrack_path = os.path.join('..',\n                          'data',\n                          'THUALB_2022_04-233568-5-GPE3.csv')\n\ntrack_df = pd.read_csv(track_path, skiprows=4)\ntrack_df.head(2)\n\n\n\n\n\n\n\n\nDeployID\nPtt\nDate\nMost Likely Latitude\nMost Likely Longitude\nObservation Type\nObserved SST\nSatellite SST\nObserved Depth\nBathymetry Depth\nObservation LL (MSS)\nObservation Score\nSunrise\nSunset\n\n\n\n\n0\nTHUALB_2022_04\n233568\n31-May-2022 19:00:00\n5.875\n-162.125\nUser\nNaN\nNaN\nNaN\nNaN\nNaN\n68.605853\nNaN\nNaN\n\n\n1\nTHUALB_2022_04\n233568\n01-Jun-2022 00:00:00\n5.875\n-162.100\nNone\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n01-Jun-2022 16:33:04\n02-Jun-2022 04:59:36\n\n\n\n\n\n\n\n## Convert the date strings into the Python datetime date objects * The dates are loaded from the CSV file as strings. * Converting the dates to Python datetime date object gives us flexibility to manipulate the dataframe.\n\ntrack_df['Date'] = pd.to_datetime(track_df['Date'], format='%d-%b-%Y %H:%M:%S')\ntrack_df.head(2)\n\n\n\n\n\n\n\n\nDeployID\nPtt\nDate\nMost Likely Latitude\nMost Likely Longitude\nObservation Type\nObserved SST\nSatellite SST\nObserved Depth\nBathymetry Depth\nObservation LL (MSS)\nObservation Score\nSunrise\nSunset\n\n\n\n\n0\nTHUALB_2022_04\n233568\n2022-05-31 19:00:00\n5.875\n-162.125\nUser\nNaN\nNaN\nNaN\nNaN\nNaN\n68.605853\nNaN\nNaN\n\n\n1\nTHUALB_2022_04\n233568\n2022-06-01 00:00:00\n5.875\n-162.100\nNone\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n01-Jun-2022 16:33:04\n02-Jun-2022 04:59:36"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#clean-up-the-dataframe",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#clean-up-the-dataframe",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Clean up the dataframe",
    "text": "Clean up the dataframe\n\nRemove the columns with non-numerical data.\nRename the “Most Likely Latitude” and “Most Likely Longitude” columns to make the easier to work with.\n\nThe track data has longitude values into -180/+180 format. However, the satellite dataset we are using has longitude values into 0/360 format. So, convert the track data to 0/360 format so that the longitude formats are consistent.\n\n\ndel track_df['DeployID']\ndel track_df['Ptt']\ndel track_df['Sunrise']\ndel track_df['Sunset']\ndel track_df['Observation Type']\n\ntrack_df.rename(columns={\"Most Likely Latitude\": \"Latitude\",\n                         \"Most Likely Longitude\": \"Longitude\"}, inplace=True)\n\n# Convert lontitudes to 0~360 (Re-center map to the dateline)\ntrack_df.Longitude = track_df.Longitude + 360\n\ntrack_df.head(2)\n\n\n\n\n\n\n\n\nDate\nLatitude\nLongitude\nObserved SST\nSatellite SST\nObserved Depth\nBathymetry Depth\nObservation LL (MSS)\nObservation Score\n\n\n\n\n0\n2022-05-31 19:00:00\n5.875\n197.875\nNaN\nNaN\nNaN\nNaN\nNaN\n68.605853\n\n\n1\n2022-06-01 00:00:00\n5.875\n197.900\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#bin-multiple-observations-from-each-day-into-daily-mean-values",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#bin-multiple-observations-from-each-day-into-daily-mean-values",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Bin multiple observations from each day into daily mean values",
    "text": "Bin multiple observations from each day into daily mean values\nThe track data has multiple longitude/latitude/time points for each date. That temporal resolution is much higher than the daily and month satellite datasets that are available. So, let’s reduce the multiple daily values for the animal track data to a single value for each day. The code below creates a new dataframe that bins data for each date and calculates the mean for selected columns. * This process will move the “Date” column to the index column (most left column)\n\ndf = track_df.resample('D', on='Date').mean()\ndf.head()\n\n\n\n\n\n\n\n\nLatitude\nLongitude\nObserved SST\nSatellite SST\nObserved Depth\nBathymetry Depth\nObservation LL (MSS)\nObservation Score\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n2022-05-31\n5.87500\n197.8750\nNaN\nNaN\nNaN\nNaN\nNaN\n68.605853\n\n\n2022-06-01\n5.88500\n198.0000\n28.2\n28.324583\n85.666667\n2908.0\nNaN\n58.239984\n\n\n2022-06-02\n5.92500\n197.9500\n28.3\n28.305416\n64.666667\n3778.0\nNaN\n93.446222\n\n\n2022-06-03\n5.92500\n197.8550\n28.1\n28.310833\n53.666667\n3778.0\nNaN\n71.484871\n\n\n2022-06-04\n5.98125\n197.8125\n28.2\n28.320000\n43.000000\n3778.0\nNaN\n82.962634"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#plot-the-track-on-a-map",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#plot-the-track-on-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot the track on a map",
    "text": "Plot the track on a map\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([180, 221, 0, 26], ccrs.PlateCarree())\n\n# Set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(180, 221, 10), crs=ccrs.PlateCarree())\nax1.set_yticks(range(0, 26, 10), crs=ccrs.PlateCarree())\n\n# Add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# Format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# Bring the lon and lat data into a numpy array \nx, y = df.Longitude.to_numpy(), df.Latitude.to_numpy()\nax1 = plt.plot(x, y, transform=ccrs.PlateCarree(), color='blue')\n# start point in green star\nax1 = plt.plot(x[0], y[0],\n               marker='*',\n               color='g',\n               label='start',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\n# end point in red X\nax1 = plt.plot(x[-1], y[-1],\n               marker='X',\n               color='r',\n               label='end',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\nplt.legend()\nplt.title('Yellowfin Tuna Track (PTT 233568)', fontsize=20)\n\nplt.show()"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Extract data from a satellite dataset corresponding to points on the track",
    "text": "Extract data from a satellite dataset corresponding to points on the track\nWe are going to download data from an ERDDAP server using the following steps: * Select a dataset on an ERDDAP server * Open the dataset using the Xarray module * Loop though the track data and pull out the date, latitude and longitude coordinates from each row * Insert these coordinates into the Xarray open-dataset object to subset and download the satellite data that corresponds to the coordinates. * Add the satellite data to the track dataset.\n\nSelect a dataset\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product that blends data from many ocean color sensors to create a long time series (1997-present) with better spatial coverage than any single sensor.\nIdeally we would use a daily dataset, selecting the day that corresponds to the track data date. However, chlorophyll measurements can have a lot of missing data, primarily due to cloud cover. To reduce data gaps and improve the likelihood of data for our matchups, we can use a dataset that combines all of the data from each month into the monthly average.\nThe ERDDAP URL to the monthly version of the OC-CCI product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\n\n\nOpen the satellite data in Xarray\n\nUse the ERDDAP URL with no extension (e.g. without .html or .graph…). This is the OPeNDAP URL, which allows viewing the dataset metadata and, when you select the data you want, downloading the data.\nUse the Xarray “open_dataset” function then view the metadata\n\n\nerddap_url = '/'.join(['https://oceanwatch.pifsc.noaa.gov',\n                       'erddap',\n                       'griddap',\n                       'esa-cci-chla-monthly-v6-0'])\n\nds = xr.open_dataset(erddap_url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:             (time: 316, latitude: 4320, longitude: 8640)\nCoordinates:\n  * time                (time) datetime64[ns] 1997-09-04 ... 2023-12-01\n  * latitude            (latitude) float64 89.98 89.94 89.9 ... -89.94 -89.98\n  * longitude           (longitude) float64 0.02083 0.0625 ... 359.9 360.0\nData variables:\n    chlor_a             (time, latitude, longitude) float32 ...\n    MERIS_nobs_sum      (time, latitude, longitude) float32 ...\n    MODISA_nobs_sum     (time, latitude, longitude) float32 ...\n    OLCI_A_nobs_sum     (time, latitude, longitude) float32 ...\n    OLCI_B_nobs_sum     (time, latitude, longitude) float32 ...\n    SeaWiFS_nobs_sum    (time, latitude, longitude) float32 ...\n    VIIRS_nobs_sum      (time, latitude, longitude) float32 ...\n    chlor_a_log10_bias  (time, latitude, longitude) float32 ...\n    chlor_a_log10_rmsd  (time, latitude, longitude) float32 ...\n    total_nobs_sum      (time, latitude, longitude) float32 ...\nAttributes: (12/53)\n    cdm_data_type:                     Grid\n    comment:                           See summary attribute\n    Conventions:                       CF-1.7, COARDS, ACDD-1.3\n    creation_date:                     Thu Jan 18 09:04:18 2024\n    creator_email:                     help@esa-oceancolour-cci.org\n    creator_name:                      Plymouth Marine Laboratory\n    ...                                ...\n    time_coverage_end:                 2023-12-01T00:00:00Z\n    time_coverage_resolution:          P1M\n    time_coverage_start:               1997-09-04T00:00:00Z\n    title:                             Chlorophyll a concentration, ESA OC CC...\n    tracking_id:                       abd52a4c-7009-464f-b1eb-958f7d333a1d\n    Westernmost_Easting:               0.020833333333314386xarray.DatasetDimensions:time: 316latitude: 4320longitude: 8640Coordinates: (3)time(time)datetime64[ns]1997-09-04 ... 2023-12-01_CoordinateAxisType :Timeactual_range :[8.7333120e+08 1.7013888e+09]axis :Tioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-04T00:00:00.000000000', '1997-10-01T00:00:00.000000000',\n       '1997-11-01T00:00:00.000000000', ..., '2023-10-01T00:00:00.000000000',\n       '2023-11-01T00:00:00.000000000', '2023-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float6489.98 89.94 89.9 ... -89.94 -89.98_CoordinateAxisType :Latactual_range :[-89.97916667  89.97916667]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.97916666666667valid_min :-89.97916666666666array([ 89.979167,  89.9375  ,  89.895833, ..., -89.895833, -89.9375  ,\n       -89.979167])longitude(longitude)float640.02083 0.0625 ... 359.9 360.0_CoordinateAxisType :Lonactual_range :[2.08333333e-02 3.59979167e+02]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :359.97918701171875valid_min :0.020829999819397926array([2.083333e-02, 6.250000e-02, 1.041667e-01, ..., 3.598958e+02,\n       3.599375e+02, 3.599792e+02])Data variables: (10)chlor_a(time, latitude, longitude)float32...ancillary_variables :chlor_a_log10_rmsd chlor_a_log10_biascolorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll-a concentration in seawater (not log-transformed), generated by as a blended combination of OCI, OCI2, OC2 and OCx algorithms, depending on water class membershipsparameter_vocab_uri :http://vocab.ndg.nerc.ac.uk/term/P011/current/CHLTVOLUstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m-3units_nonstandard :mg m^-3[11794636800 values with dtype=float32]MERIS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the MERIS sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]MODISA_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the MODIS (Aqua) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]OLCI_A_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the OLCI (Sentinel-3a) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]OLCI_B_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the OLCI (Sentinel-3b) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]SeaWiFS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the SeaWiFS (GAC and LAC) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]VIIRS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the VIIRS sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]chlor_a_log10_bias(time, latitude, longitude)float32...colorBarMaximum :0.1colorBarMinimum :-0.1comment :Uncertainty lookups derived from file: /data/datasets/CCI/v6.0-production/stage09b-uncertainty_tables/chlor_a/cci_chla_bias.datioos_category :Statisticslong_name :Bias of log10-transformed chlorophyll-a concentration in seawater.references :https://esa-oceancolour-cci.org/?q=webfm_send/581rel :uncertainty[11794636800 values with dtype=float32]chlor_a_log10_rmsd(time, latitude, longitude)float32...colorBarMaximum :0.002colorBarMinimum :0.0comment :Uncertainty lookups derived from file: /data/datasets/CCI/v6.0-production/stage09b-uncertainty_tables/chlor_a/cci_chla_rmsd.datioos_category :Statisticslong_name :Root-mean-square-difference of log10-transformed chlorophyll-a concentration in seawater.references :https://esa-oceancolour-cci.org/?q=webfm_send/581rel :uncertainty[11794636800 values with dtype=float32]total_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the total number of observations contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-04', '1997-10-01', '1997-11-01', '1997-12-01',\n               '1998-01-01', '1998-02-01', '1998-03-01', '1998-04-01',\n               '1998-05-01', '1998-06-01',\n               ...\n               '2023-03-01', '2023-04-01', '2023-05-01', '2023-06-01',\n               '2023-07-01', '2023-08-01', '2023-09-01', '2023-10-01',\n               '2023-11-01', '2023-12-01'],\n              dtype='datetime64[ns]', name='time', length=316, freq=None))latitudePandasIndexPandasIndex(Float64Index([ 89.97916666666667,            89.9375,  89.89583333333333,\n               89.85416666666667,            89.8125,  89.77083333333333,\n               89.72916666666667,            89.6875,  89.64583333333333,\n               89.60416666666667,\n              ...\n              -89.60416666666666, -89.64583333333331,           -89.6875,\n              -89.72916666666666, -89.77083333333331,           -89.8125,\n              -89.85416666666666, -89.89583333333331,           -89.9375,\n              -89.97916666666666],\n             dtype='float64', name='latitude', length=4320))longitudePandasIndexPandasIndex(Float64Index([0.020833333333314386,               0.0625,  0.10416666666665719,\n               0.14583333333331439,               0.1875,   0.2291666666666572,\n                0.2708333333333144,               0.3125,   0.3541666666666572,\n                0.3958333333333144,\n              ...\n                359.60416666666663,    359.6458333333333,             359.6875,\n                359.72916666666663,    359.7708333333333,             359.8125,\n                359.85416666666663,    359.8958333333333,             359.9375,\n                359.97916666666663],\n             dtype='float64', name='longitude', length=8640))Attributes: (53)cdm_data_type :Gridcomment :See summary attributeConventions :CF-1.7, COARDS, ACDD-1.3creation_date :Thu Jan 18 09:04:18 2024creator_email :help@esa-oceancolour-cci.orgcreator_name :Plymouth Marine Laboratorycreator_url :https://esa-oceancolour-cci.orgdate_created :2022-08-15T22:03:48ZEasternmost_Easting :359.97916666666663geospatial_lat_max :89.97916666666667geospatial_lat_min :-89.97916666666666geospatial_lat_resolution :0.041666666666666664geospatial_lat_units :degrees_northgeospatial_lon_max :359.97916666666663geospatial_lon_min :0.020833333333314386geospatial_lon_resolution :0.041666666666666664geospatial_lon_units :degrees_eastgit_commit_hash :27964270df6ae0b9bdd0af5672529dbebb4e7bd9history :Thu Jan 18 08:21:00 2024: ncatted -O -a geospatial_lon_max,global,o,f,360.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a geospatial_lon_min,global,o,f,0.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a valid_max,lon,o,f,359.9792 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a valid_min,lon,o,f,0.02083 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:20:41 2024: ncap2 -O -s where(lon&lt;0) lon=lon+360 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:20:20 2024: ncks -O --msa_usr_rdr -d lon,0.0,180.0 -d lon,-180.0,0.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0.nc ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nSource data were: ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231201-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231202-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231203-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231204-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231205-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231206-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231207-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231208-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231209-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231210-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231211-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231212-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231213-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231214-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231215-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231216-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231217-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231218-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231219-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231220-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231221-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231222-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231223-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231224-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231225-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231226-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231227-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231228-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231229-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231230-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231231-fv6.0.nc; netcdf_compositor_cci composites  Rrs_412, Rrs_412_bias, Rrs_443, Rrs_443_bias, Rrs_490, Rrs_490_bias, Rrs_510, Rrs_510_bias, Rrs_560, Rrs_560_bias, Rrs_665, Rrs_665_bias, adg_412, adg_412_bias, adg_443, adg_443_bias, adg_490, adg_490_bias, adg_510, adg_510_bias, adg_560, adg_560_bias, adg_665, adg_665_bias, aph_412, aph_412_bias, aph_443, aph_443_bias, aph_490, aph_490_bias, aph_510, aph_510_bias, aph_560, aph_560_bias, aph_665, aph_665_bias, atot_412, atot_443, atot_490, atot_510, atot_560, atot_665, bbp_412, bbp_443, bbp_490, bbp_510, bbp_560, bbp_665, chlor_a, chlor_a_log10_bias, kd_490, kd_490_bias, water_class1, water_class10, water_class11, water_class12, water_class13, water_class14, water_class2, water_class3, water_class4, water_class5, water_class6, water_class7, water_class8, water_class9 with --mean,  Rrs_412_rmsd, Rrs_443_rmsd, Rrs_490_rmsd, Rrs_510_rmsd, Rrs_560_rmsd, Rrs_665_rmsd, adg_412_rmsd, adg_443_rmsd, adg_490_rmsd, adg_510_rmsd, adg_560_rmsd, adg_665_rmsd, aph_412_rmsd, aph_443_rmsd, aph_490_rmsd, aph_510_rmsd, aph_560_rmsd, aph_665_rmsd, chlor_a_log10_rmsd, kd_490_rmsd with --root-mean-square, and  MERIS_nobs, MODISA_nobs, OLCI-A_nobs, OLCI-B_nobs, SeaWiFS_nobs, VIIRS_nobs, total_nobs - with --total\n1705571341 Subsetted from standardised_geo/ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1M_MONTHLY_4km_GEO_PML_OCx_QAA-202312-fv6.0.nc to only include variables MERIS_nobs_sum,MODISA_nobs_sum,OLCI-A_nobs_sum,OLCI-B_nobs_sum,SeaWiFS_nobs_sum,VIIRS_nobs_sum,chlor_a,chlor_a_log10_bias,chlor_a_log10_rmsd,crs,lat,lon,time,total_nobs_sum\n2024-07-31T19:58:44Z (local files)\n2024-07-31T19:58:44Z https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.dasid :ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0.ncinfoUrl :https://esa-oceancolour-cci.org/institution :Plymouth Marine Laboratorykeywords :algorithms, aqua, area, array, array-data, bias, bin, blended, cci, cell, chemistry, chlor_a, chlor_a_log10_bias, chlor_a_log10_rmsd, chlorophyll, chlorophyll-a, class, color, colour, combination, comprehensive, concentration, contributing, count, coverage, data, depending, difference, earth, Earth Science &gt; Oceans &gt; Ocean Chemistry &gt; Chlorophyll, esa, field, field-of-view, gac, generated, global, imager, imager/radiometer, imaging, infrared, laboratory, lac, large, local, log, log-transformed, log10, log10-transformed, marine, mass, mass_concentration_of_chlorophyll_a_in_sea_water, mean, memberships, meris, MERIS_nobs_sum, moderate, modis, MODISA_nobs_sum, not, number, observation, observations, oc2, ocean, ocean color, ocean colour, oceans, oci, oci2, ocx, olci, OLCI-A_nobs_sum, OLCI-B_nobs_sum, plymouth, product, radiometer, resolution, root, root-mean-square-difference, satellite, science, sea, sea-wide, seawater, seawifs, SeaWiFS_nobs_sum, sensor, sentinel, sentinel-3a, sentinel-3b, spectroradiometer, square, statistics, stewardship, suite, system, time, total, total_nobs_sum, transformed, view, viirs, VIIRS_nobs_sum, visible, water, widekeywords_vocabulary :GCMD Science Keywordslicense :ESA CCI Data Policy: free and open access.  When referencing, please use: Ocean Colour Climate Change Initiative dataset, Version &lt;Version Number&gt;, European Space Agency, available online at https://esa-oceancolour-cci.org.  We would also appreciate being notified of publications so that we can list them on the project website at https://esa-oceancolour-cci.org/?q=publicationsnaming_authority :uk.ac.pmlNCO :netCDF Operators version 4.7.5 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)nco_openmp_thread_number :1netcdf_file_type :NETCDF4_CLASSICNorthernmost_Northing :89.97916666666667number_of_bands_used_to_classify :4number_of_files_composited :31number_of_optical_water_types :14platform :Orbview-2,Aqua,Envisat,Suomi-NPP, Sentinel-3a, Sentinel-3bprocessing_level :Level-3product_version :6.0project :Climate Change Initiative - European Space Agencyreferences :https://esa-oceancolour-cci.org/sensor :SeaWiFS,MODIS,MERIS,VIIRS,OLCIsensors_present :OLCIa OLCIbsource :NASA SeaWiFS  L1A and L2 R2018.0 LAC and GAC, MODIS-Aqua L1A and L2 R2018.0, MERIS L1B 3rd reprocessing inc OCL corrections, NASA VIIRS L1A and L2 R2018.0, OLCI L1BsourceUrl :(local files)Southernmost_Northing :-89.97916666666666spatial_resolution :4km nominal at equatorstandard_name_vocabulary :CF Standard Name Table v70summary :Data products generated by the Ocean Colour component of the European Space Agency Climate Change Initiative project. These files are monthly composites of merged sensor (MERIS, Moderate Resolution Imaging Spectroradiometer (MODIS) Aqua, Sea-Wide Field-of-View Sensor (SeaWiFS) Local Area Coverage (LAC) & Global Area Coverage (GAC), Visible and Infrared Imager/Radiometer Suite (VIIRS), OLCI) products.  MODIS Aqua and SeaWiFS were band-shifted and bias-corrected to MERIS bands and values using a temporally and spatially varying scheme based on the overlap years of 2003-2007.  VIIRS was band-shifted and bias-corrected in a second stage against the MODIS Rrs that had already been corrected to MERIS levels, for the overlap period 2012-2014; at the third stage Sentinel-3A OLCI was bias corrected against already corrected MODIS, for overlap period 2016-07-01 to 2019-06-30;  at the fourth stage Sentinel-3B OLCI was bias corrected against already corrected Sentinel-3A OLCI, for overlap period 2018-07-01 to 2021-06-30.  VIIRS, MODIS, SeaWiFS and MERIS Rrs were derived from a combination of NASA's l2gen (for basic sensor geometry corrections, etc) and HYGEOS POLYMER (for atmospheric correction). OLCI Rrs were sourced at L1b (already geometrically corrected) and processed with POLYMER.  The Rrs were binned to a sinusoidal 4km level-3 grid, and later to 4km geographic projection, by Brockmann Consult's SNAP.  Derived products were generally computed with the standard algorithms through SeaDAS.  QAA IOPs were derived using the standard SeaDAS algorithm but with a modified backscattering table to match that used in the bandshifting.  The final chlorophyll is a combination of OCI, OCI2, OC2 and OCx, depending on the water class memberships.  Uncertainty estimates were added using the fuzzy water classifier and uncertainty estimation algorithm of Tim Moore as documented in Jackson et al (2017). and updated according to Jackson et al. (in prep).time_coverage_duration :P1Mtime_coverage_end :2023-12-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :1997-09-04T00:00:00Ztitle :Chlorophyll a concentration, ESA OC CCI - Monthly, 1997-present. v6.0tracking_id :abd52a4c-7009-464f-b1eb-958f7d333a1dWesternmost_Easting :0.020833333333314386\n\n\nOpening the dataset in Xarray lets you look at the dataset metadata.\n* The metadata are listed above. * No data is downloaded until you request it.\nFrom the metadata you can view: * The coordinates (time, latitude and longitude) that you will use to select the data to download. * A list of ten data variables. For this exercise, we want the “chlor_a” variable. If you want, you can find out about each variable with clicking the page icon to the right of each variable name.\nA note on dataset selection\nWe have preselected the OC-CCI monthly dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application.\nYou can find that information above by clicking the right arrow next to “Attribute”. Then look through the list to find: * ‘time_coverage_start’ and ‘time_coverage_end’: the time range * ‘geospatial_lat_min’ and ‘geospatial_lat_max’: the latitude range * ‘geospatial_lon_min’ and ‘geospatial_lon_max’: the longitude range\nThere are a lot of metadata attributes to look through. We can make it easier with a little code to print out the metadata of interest. Then compare these ranges to those found in your track data.\n\nprint('Temporal and spatial ranges of the satellite dataset')\nprint('time range', ds.attrs['time_coverage_start'], \n      ds.attrs['time_coverage_end'])\nprint('latitude range', ds.attrs['geospatial_lat_min'], \n      ds.attrs['geospatial_lat_max'])\nprint('longitude range', ds.attrs['geospatial_lon_min'], \n      ds.attrs['geospatial_lon_max'])\nprint(' ')\nprint('Temporal and spatial ranges of the track data')\nprint('time range', df.index.min(), df.index.max())\nprint('latitude range', \n      round(df.Latitude.min(), 2), round(df.Latitude.max(), 2))\nprint('longitude range', \n      round(df.Longitude.min(), 2), round(df.Longitude.max(), 2))\n\nTemporal and spatial ranges of the satellite dataset\ntime range 1997-09-04T00:00:00Z 2023-12-01T00:00:00Z\nlatitude range -89.97916666666666 89.97916666666667\nlongitude range 0.020833333333314386 359.97916666666663\n \nTemporal and spatial ranges of the track data\ntime range 2022-05-31 00:00:00 2022-11-23 00:00:00\nlatitude range 3.5 17.14\nlongitude range 194.91 201.15\n\n\n\n\nDownload the satellite data that corresponds to each track location\n\nFirst, create new columns in the df dataframe to hold the downloaded data. Fill each row with nan.\n\nDownload the chlorophyll data, time, latitude, and longitude from the ERDDAP satellite dataset.\nConsolidate data adding the downloaded satellite data to the track data (df) dataframe.\n\n\n# Add new columns to the dataframe\ndf[[\"erddap_date\", \"matched_lat\", \"matched_lon\", \"matched_chla\"]] = np.nan\n\n# Subset the satellite data \nfor i in range(0, len(df)):\n    clear_output(wait=True)\n    print(i+1, 'of', len(df))\n    \n    # Download the satellite data and put into a temperary dataframe\n    temp_ds = ds['chlor_a'].sel(time='{0:%Y-%m-%d}'.format(df.index[1]),\n                                latitude=df.loc[df.index[i], 'Latitude'],\n                                longitude=df.loc[df.index[i], 'Longitude'],\n                                method='nearest'\n                                )\n     \n    # Consolidate the data\n    df.loc[df.index[i], [\"erddap_date\", \"matched_lat\",\n               \"matched_lon\", \"matched_chla\"]\n          ] = [temp_ds.time.values,\n               np.round(temp_ds.latitude.values, 5),  # round 5 dec\n               np.round(temp_ds.longitude.values, 5), # round 5 dec\n               np.round(temp_ds.values, 2)  # round 2 decimals\n               ]\n    \n    print(df.loc[df.index[i], [\"erddap_date\", \"matched_lat\",\n               \"matched_lon\", \"matched_chla\"]])\n\n\n177 of 177\nerddap_date     2022-06-01T00:00:00.000000000\nmatched_lat                           4.52083\nmatched_lon                         198.22917\nmatched_chla                             0.22\nName: 2022-11-23 00:00:00, dtype: object\n\n\n\n\nSave your work\n\nSince we moved the Date column to the index, be sure to use index=True\n\n\ndf.to_csv('chl_matchup_tuna233568.csv', index=True, encoding='utf-8')"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#plot-chlorophyll-matchup-data-onto-a-map",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#plot-chlorophyll-matchup-data-onto-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot chlorophyll matchup data onto a map",
    "text": "Plot chlorophyll matchup data onto a map\n\nFirst plot a histogram of the chlorophyll data\n\nprint('Range:', df.matched_chla.min(), df.matched_chla.max())\n_ = df.matched_chla.hist(bins=40)\n\nRange: 0.03999999910593033 0.4699999988079071\n\n\n\n\n\n\n\n\n\nThe range of chlorophyll values can be large, with lots of very low values and a few very high values. Using a linear color bar, most of the lower values would have the same color. * To better visualize the data, we often plot the log or log10 of chlorophyll.\n\n\nPlot a histogram of the log of the chlorophyll data\n\nprint('Range:',\n      np.log(df.matched_chla.min()),\n      np.log(df.matched_chla.max()))\n\n_ = np.log(df.matched_chla).hist(bins=40)\n\nRange: -3.218875847219943 -0.7550225868144006\n\n\n\n\n\n\n\n\n\n\nThe logarithmic transformation displays the range of values across the color bar range (above).\n\n\n\nMap the chlorophyll data\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\n\n# set the projection\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([180, 221, 0, 26], ccrs.PlateCarree())\n\n# Set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(180, 221, 10), crs=ccrs.PlateCarree())\nax1.set_yticks(range(0, 26, 10), crs=ccrs.PlateCarree())\n\n# Add geographical features\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# build and plot coordinates onto map\nx,y = list(df.Longitude), list(df.Latitude)\nax1 = plt.scatter(x, y, transform=ccrs.PlateCarree(),\n                  marker='o',\n                  c=np.log(df.matched_chla),\n                  cmap=plt.get_cmap('jet')\n                  )\nax1=plt.plot(x[0],y[0],marker='*', label='start',transform=ccrs.PlateCarree(), markersize=10)\nax1=plt.plot(x[-1],y[-1],marker='X', label='end',transform=ccrs.PlateCarree(), markersize=10)\n\n\n\n# control color bar values spacing\nlevs2 = np.arange(-3, -1, 0.5)\ncbar=plt.colorbar(ticks=levs2, shrink=0.75, aspect=10)\n#cbar=plt.colorbar(shrink=0.75, aspect=10)\ncbar.set_label(\"Chl a (mg/m^3)\", size=15, labelpad=20)\n\n# set the labels to be exp(levs2) so the label reflect values of chl-a, not log(chl-a)\ncbar.ax.set_yticklabels(np.around(np.exp(levs2), 2), size=10)\n\nplt.legend()\nplt.title(\"Chlorophyll Matchup to Yellowfin Tuna Track (233568)\", size=15)\nplt.show()"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#on-your-own",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray_ATN_0731.html#on-your-own",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "On your own!",
    "text": "On your own!\n\nExercise 1:\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the NOAA Geo-polar Blended Analysis SST, GHRSST dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html\n* This dataset is a different ERDDAP; It has a different base URL and dataset ID and variable name. * Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nExercise 2:\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/\n* This dataset will likely be on a different base URL and dataset ID and variable name. * Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nOptional\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v1_0.html"
  },
  {
    "objectID": "tutorials/python/matchup-polar-satellite-data-to-buoy-data_dh.html",
    "href": "tutorials/python/matchup-polar-satellite-data-to-buoy-data_dh.html",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "In this exercise, you will combine satellite and buoy data by extracting satellite measurements around specific points defined by buoy locations and dates. The focus of this exercise is on matching two data sources from different projections.\nSimilar tutorials for mid to lower latitudes can be found at https://github.com/coastwatch-training/CoastWatch-Tutorials."
  },
  {
    "objectID": "tutorials/python/matchup-polar-satellite-data-to-buoy-data_dh.html#this-exercise-demonstrates-the-following-techniques",
    "href": "tutorials/python/matchup-polar-satellite-data-to-buoy-data_dh.html#this-exercise-demonstrates-the-following-techniques",
    "title": "Matching Satellite and Buoy Data",
    "section": "This exercise demonstrates the following techniques:",
    "text": "This exercise demonstrates the following techniques:\n\nUsing ERDDAP to retrieve buoy data in CSV format and satellite data in netCDF format\nImporting and manipulating data with the pandas and xarray libraries\nResampling data to lower-resolution time steps\nConverting latitude and longitude coordinates to the polar stereographic projection\n\n\nData used in this exercise\nIce Surface Temperature, NOAA-20 VIIRS, Near Real-Time, Polar Stereographic (North), 4-day\nThis dataset provides VIIRS sea ice surface temperature for the Arctic at a 750m resolution, collected by the NOAA-20 satellite. It includes near-real-time daily data and 4-day composites for the past three weeks. For this exercise, we will use 4-day composites data.\nInternational Arctic Buoy Programme (IABP) Buoy Data, Daily\nThis data set is from the US International Arctic Buoy Programme and includes meteorological and oceanographic data from buoys. Dataset is updated daily and includes multiple variables. For this exercise, we will extract surface temperature data.\nWhile both instruments measure surface temperatures, they do so at different locations and with different sensors.\nSatellite Ice Surface Temperature (IST) is measured by the Visible Infrared Imaging Radiometer Suite (VIIRS) and captures the temperature of the surface layer of ice.\nBuoy Surface Temperature (Ts) is measured from the bottom of the buoy hull. If the buoy is floating, the reported temperature is of the sea surface. If the buoy is frozen into the ice or sitting on top of it, the reported temperature is of the ground or ice. The freezing temperature of seawater is about -1.8°C, so temperature readings below this indicate ground or ice temperatures.\nMore details can be found in the metadata section of the data products (click on the data links above).\n\n\nLoad packages\n\nimport xarray as xr\nimport pandas as pd\nimport requests\nimport io\nimport pyproj\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\nfrom sklearn.metrics import r2_score \nimport cartopy.crs as ccrs # cartopy: geospatial data visualization\nimport cartopy.feature as cfeature\n\n\n\nLoad buoy data (IABP) from PolarWatch ERDDAP data server\n\nConstruct ERDDAP URL to query the IABP buoy for: buoy_id, longitude, latitude, time, and surface temperature that filters for data where surface_temp exists and for the date range between 2023-08-01 and 2023-09-30.\nDownload the data into a Pandas dataframe.\n\n\n# Construct ERDDAP URL\nbuoy_url = ''.join(['https://polarwatch.noaa.gov/erddap/tabledap/iabpv2_buoys.csv?',\n                    'buoy_id,longitude,latitude,time,surface_temp',\n                    '&has_surface_temp=\"yes\"&time&gt;=2023-08-01&time&lt;=2023-09-30'\n                    ])\n\n# Make a request to the ERDDAP server\nreq = requests.get(buoy_url).content\n\n# The response from the web service is read as a CSV file into a pandas DataFrame. \ndf = pd.read_csv(io.StringIO(req.decode('utf-8')), skiprows=[1], parse_dates=['time'])\n\ndf.head(3)\n\n\n\n\n\n\n\n\n\nbuoy_id\nlongitude\nlatitude\ntime\nsurface_temp\n\n\n\n\n0\n300234066034140\n-28.5226\n55.0168\n2023-08-01 00:00:00+00:00\n13.5\n\n\n1\n300234066034140\n-28.5226\n55.0168\n2023-08-01 01:00:02+00:00\n13.4\n\n\n2\n300234066034140\n-28.5226\n55.0168\n2023-08-01 01:59:57+00:00\n13.4\n\n\n\n\n\n\n\n\n\nSelect one buoy and process data\nSelect one buoy (buoy id = “300534062897730”). The buoy records measurements at intervals of minutes, resulting in a high-resolution dataset. , * Downsample the buoy data to align it with the daily resolution of the satellite dataset.\n* The time data is recorded in the UTC time zone. Pandas operations often encounter issues with time zones, so remove the time zone information for easier processing.\n\n# Select one buoy (buoy id = \"300534062897730\")\nbuoy_df = df.loc[df[\"buoy_id\"]== 300534062897730]\n\nprint('# of timesteps before =', buoy_df.shape[0] )\n\n# The resampling will put time as the df index\nbuoy_df_resampled = buoy_df.resample('D', on='time').mean()\nprint('# of timesteps after =', buoy_df_resampled.shape[0] )\n\n# Remove the timezone (UTC, GMT).\nbuoy_df_resampled = buoy_df_resampled.tz_localize(None)\n\n# Rename the variable\nbuoy_df_resampled.rename(columns={\"surface_temp\": \"temp_buoy\"},\n                         errors=\"raise\",\n                         inplace=True)\n\nbuoy_df_resampled.head(2)\n\n# of timesteps before = 8523\n# of timesteps after = 60\n\n\n\n\n\n\n\n\n\nbuoy_id\nlongitude\nlatitude\ntemp_buoy\n\n\ntime\n\n\n\n\n\n\n\n\n2023-08-01\n3.005341e+14\n-143.782008\n86.385202\n2.193916\n\n\n2023-08-02\n3.005341e+14\n-143.104535\n86.333932\n1.520208\n\n\n\n\n\n\n\n\n\nTransform buoy coordinates to polar projection\nThe buoy locations are provided in latitude and longitude coordinates. The satellite data is in polar stereographic projection, which provided location in columns and rows with units of meters. * Convert the buoy locations from latitude and longitude to the corresponding columns and rows values in the polar projection.\n\n# Define the projection using the PROJ4 string format\nproj4text = \"+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n\n# Initialize the projection object using pyproj with the given PROJ4 text\nproj = pyproj.Proj(proj4text)\n\n# Transform latitude and longitude to x, y coordinates\n# Longitude and latitude are passed as arrays, \n# pyproj returns the corresponding x (cols) and y (rows) values\nbuoy_df_resampled['cols'], buoy_df_resampled['rows'] = proj(buoy_df_resampled['longitude'].values, \n                                                            buoy_df_resampled['latitude'].values)\n\n# Verify that the 'cols' and 'rows' columns were added to dataframe\nbuoy_df_resampled.head(2)\n\n\n\n\n\n\n\n\nbuoy_id\nlongitude\nlatitude\ntemp_buoy\ncols\nrows\n\n\ntime\n\n\n\n\n\n\n\n\n\n\n2023-08-01\n3.005341e+14\n-143.782008\n86.385202\n2.193916\n-387113.857367\n59803.924517\n\n\n2023-08-02\n3.005341e+14\n-143.104535\n86.333932\n1.520208\n-393297.704017\n56006.315907\n\n\n\n\n\n\n\n\n# Select the first buoy location to pull corresponding satellite data\nbuoy_cols = buoy_df_resampled['cols'].iloc[0]\nbuoy_rows = buoy_df_resampled['rows'].iloc[0]\n\n\n\nLoad satellite data from PolarWatch\n\n# Construct ERDDAP data request\ngridded_url = \"https://polarwatch.noaa.gov/erddap/griddap/noaacwVIIRSn20icesrftempNP06Daily4Day\"\n\n# Open and load data into xarray dataset\nsrftemp_ds = xr.open_dataset(gridded_url)\n\n# The altitude dimension has a size of 1, remove it to reduce the dimensionality\nsrftemp_ds = srftemp_ds.squeeze()\n\n\n\nSelect satellite data to match buoy location and dates\nSubset the satellite data using the buoy locations and dates.\n\nbuoy_cols = buoy_df_resampled['cols'].values\nbuoy_rows = buoy_df_resampled['rows'].values\nbuoy_times = buoy_df_resampled.index.values\n\nsat_temps =[]\nfor ct, buoy_col in enumerate(buoy_cols):\n    sat_temp = srftemp_ds['IceSrfTemp'].sel(\n                     rows=buoy_rows[ct],\n                     cols=buoy_col, \n                     time=buoy_times[ct],\n                     method='nearest'\n                     )\n    \n    sat_temps.append(sat_temp.values.item())\n\n\n\nMerge satellite ice temperature data with buoy\nMerge the datasets by index (date). Not all buoy dates have corresponding satellite data. Unmatched dates will be filled with NaN values.\n\nmerged_df = buoy_df_resampled\n\nmerged_df['temp_sat'] = np.array(sat_temps) - 273.15\n\nmerged_df.head(3)\n\n\n\n\n\n\n\n\nbuoy_id\nlongitude\nlatitude\ntemp_buoy\ncols\nrows\ntemp_sat\n\n\ntime\n\n\n\n\n\n\n\n\n\n\n\n2023-08-01\n3.005341e+14\n-143.782008\n86.385202\n2.193916\n-387113.857367\n59803.924517\n-0.413336\n\n\n2023-08-02\n3.005341e+14\n-143.104535\n86.333932\n1.520208\n-393297.704017\n56006.315907\nNaN\n\n\n2023-08-03\n3.005341e+14\n-142.195432\n86.271987\n0.803264\n-400800.933610\n50600.465317\nNaN\n\n\n\n\n\n\n\n\n\nVisualize matched dataSets\nVisualize the matched buoy and satellite datasets to assess the data alignment.\n\nplt.figure(figsize = (10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(merged_df.index, merged_df.temp_buoy, \n              'o', markersize=3, \n              label='Buoy Surface Temperature', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(merged_df.index, merged_df.temp_sat,  \n              's', markersize=3, \n              label='VIIRS Sea Ice Surface Temperature', c='blue', \n              linestyle='-', linewidth=0) \n\n#plt.ylim([0, 3])\nplt.ylabel('Temperature (degrees C)') \nplt.xticks(rotation=45)\nplt.legend()"
  },
  {
    "objectID": "tutorials/python/map-data-with-different-projections.html",
    "href": "tutorials/python/map-data-with-different-projections.html",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "",
    "text": "history | Updated September 2023\nNOAA PolarWatch distributes gridded and tabular oceanographic data for polar regions. Satellite data include geospatial information and most of them are in geographical coordinates (latitude and longitude). PolarWatch satellite data are often projected using Polar Stereographic Projections in x and y coordinates."
  },
  {
    "objectID": "tutorials/python/map-data-with-different-projections.html#objective",
    "href": "tutorials/python/map-data-with-different-projections.html#objective",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "Objective",
    "text": "Objective\nThis tutorial will demonstrate how to plot a polar stereographic projected data on a projected map, and to add another dataset with geographical coordinates (latitude and longitude) onto the map."
  },
  {
    "objectID": "tutorials/python/map-data-with-different-projections.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/map-data-with-different-projections.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nAccessing satellite data from ERDDAP\nMaking a projected map\nAdding polarstereographic data to the map\nAdding geographically referenced data (lat and lon) to the map"
  },
  {
    "objectID": "tutorials/python/map-data-with-different-projections.html#datasets-used",
    "href": "tutorials/python/map-data-with-different-projections.html#datasets-used",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "Datasets used",
    "text": "Datasets used\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\nThis dataset includes sea ice concentration data from the northern hemisphere, and is produced by the NOAA/NSIDC using the Climate Data Record algorithm. The resolution is 25km, meaning each grid in this data set represents a value that covers a 25km by 25km area. The dataset is avaialble from the NOAA PolarWatch Catalog.\nPolar bear tracking data  For the demonstrative purpose of adding a dataset in geographical coords (lat, lon) to the projected map, GPS data for a polar bear track were used. More information about the data can be found at https://borealisdata.ca/file.xhtml?fileId=151017&version=1.0"
  },
  {
    "objectID": "tutorials/python/map-data-with-different-projections.html#import-packages",
    "href": "tutorials/python/map-data-with-different-projections.html#import-packages",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "Import packages",
    "text": "Import packages\n\nimport netCDF4 as nc\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n \n\n\n# There are many ways to get data.  We will create a function that points to \n# NOAA PolarWatch ERDDAP Server gridded dataset page to get data with its unique ID\n\ndef point_to_dataset(dataset_id, base_url='https://polarwatch.noaa.gov/erddap/griddap'):\n    base_url = base_url.rstrip('/')\n    full_url = '/'.join([base_url, dataset_id])\n    return nc.Dataset(full_url)\n \n\n# 'nsidcG02202v4nhmday' is the unique ID of our interested data \n# from PolarWatch ERDDAP data server\nda = point_to_dataset('nsidcG02202v4nhmday')"
  },
  {
    "objectID": "tutorials/python/map-data-with-different-projections.html#mapping-projected-data-on-a-projected-basemap",
    "href": "tutorials/python/map-data-with-different-projections.html#mapping-projected-data-on-a-projected-basemap",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "Mapping projected data on a projected basemap",
    "text": "Mapping projected data on a projected basemap\nWe first need to create a basemap with the Polar Stereographic projection. Most of the netCDF data files include metadata about mapping. This can be used to set a projection and mapping boundaries for the data.\n\n# prints metadata embedded in netCDF file\nprint(da)\n\n&lt;class 'netCDF4._netCDF4.Dataset'&gt;\nroot group (NETCDF3_CLASSIC data model, file format DAP2):\n    _NCProperties: version=2,netcdf=4.8.1,hdf5=1.10.6\n    acknowledgement: This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.\n    cdm_data_type: Grid\n    cdr_variable: cdr_seaice_conc_monthly\n    comment: The variable melt_onset_day_cdr_seaice_conc_monthly is not available for this month.\n    contributor_name: Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fisher\n    contributor_role: principal investigator, author, author, software developer, software developer, software developer\n    Conventions: CF-1.6, ACDD-1.3, COARDS\n    creator_email: nsidc@nsidc.org\n    creator_name: NSIDC\n    creator_type: institution\n    creator_url: https://nsidc.org/\n    date_created: 2023-02-22T23:18:04Z\n    defaultGraphQuery: cdr_seaice_conc_monthly[last]%5B(-5337500.0)%5D%5B(3737500.0)%5D&.draw=surface\n    grid_mapping_false_easting: 0.0\n    grid_mapping_false_northing: 0.0\n    grid_mapping_GeoTransform: -3850000.0 25000.0 0 5850000.0 0 -25000.0\n    grid_mapping_grid_boundary_bottom_projected_y: -5350000.0\n    grid_mapping_grid_boundary_left_projected_x: -3850000.0\n    grid_mapping_grid_boundary_right_projected_x: 3750000.0\n    grid_mapping_grid_boundary_top_projected_y: 5850000.0\n    grid_mapping_latitude_of_projection_origin: 90.0\n    grid_mapping_longitude_of_projection_origin: -45.0\n    grid_mapping_name: polar_stereographic\n    grid_mapping_parent_grid_cell_column_subset_end: 304.0\n    grid_mapping_parent_grid_cell_column_subset_start: 0.0\n    grid_mapping_parent_grid_cell_row_subset_end: 448.0\n    grid_mapping_parent_grid_cell_row_subset_start: 0.0\n    grid_mapping_proj4text: +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defs\n    grid_mapping_scaling_factor: 1.0\n    grid_mapping_semimajor_radius: 6378273.0\n    grid_mapping_semiminor_radius: 6356889.449\n    grid_mapping_spatial_ref: PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3411\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]\n    grid_mapping_srid: urn:ogc:def:crs:EPSG::3411\n    grid_mapping_standard_parallel: 70.0\n    grid_mapping_straight_vertical_longitude_from_pole: 135.0\n    grid_mapping_units: meters\n    history: HISTORY_ATTRIBUTE\n2023-08-04T18:45:39Z (local files)\n2023-08-04T18:45:39Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.das\n    id: https://doi.org/10.7265/sr8p-kc62\n    infoUrl: https://nsidc.org/data/g02202/versions/4/\n    institution: NSIDC &gt; National Snow and Ice Data Center\n    keywords: algorithm, america, arctic, area, atlantic, barents, bay, beaufort, bering, bootstrap, canada, cdr_seaice_conc_monthly, center, chukchi, climate, common, concentration, continent, CONTINENT &gt; NORTH AMERICA &gt; CANADA &gt; HUDSON BAY, Continent &gt; North America &gt; Canada &gt; Hudson Bay, cryosphere, data, davis, day, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Arctic, Geographic Region &gt; Northern Hemisphere, Geographic Region &gt; Polar, goddard, gsfc, gulf, hemisphere, hudson, ice, ice distribution, lawrence, mayen, melt, melt_onset_day_cdr_seaice_conc_monthly, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, north, northern, norwegian, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Arctic Ocean, Ocean &gt; Arctic Ocean &gt; Barents Sea, Ocean &gt; Arctic Ocean &gt; Beaufort Sea, Ocean &gt; Arctic Ocean &gt; Chukchi Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Davis Straight, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; GULF OF ST LAWRENCE, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; North Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Norwegian Sea, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; SVALBARD AND JAN MAYEN, Ocean &gt; Pacific Ocean, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Bering Sea, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Sea Of Okhotsk, oceans, okhotsk, onset, over, pacific, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, straight, svalbard, tdim, team, version\n    keywords_vocabulary: GCMD Science Keywords\n    license: No constraints on data access or use\n    metadata_link: https://nsidc.org/data/g02202/versions/4/\n    naming_authority: org.doi.dx\n    platform: DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17\n    processing_level: NOAA Level 3\n    product_version: v04r00\n    program: NOAA Climate Data Record Program\n    proj_crs_code: EPSG:3411\n    proj_crs_code_description: The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.\n    project: NOAA/NSIDC passive microwave sea ice concentration climate data record\n    references: Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7): 15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251?2267, https://doi.org/10.1175/JCLI-D-16-0408.1\n    sensor: SSMI/S &gt; Special Sensor Microwave Imager/Sounder\n    software_version_id: git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897\n    source: ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220901_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220902_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220903_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220904_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220905_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220906_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220907_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220908_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220909_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220910_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220911_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220912_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220913_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220914_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220915_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220916_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220917_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220918_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220919_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220920_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220921_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220922_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220923_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220924_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220925_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220926_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220927_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220928_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220929_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220930_f17_v04r00.nc\n    sourceUrl: (local files)\n    spatial_resolution: 25km\n    standard_name_vocabulary: CF Standard Name Table v70\n    summary: This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).\n    time_coverage_duration: P1M\n    time_coverage_end: 2022-12-01T00:00:00Z\n    time_coverage_resolution: P1M\n    time_coverage_start: 1978-11-01T00:00:00Z\n    title: Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\n    dimensions(sizes): time(530), xgrid(304), ygrid(448)\n    variables(dimensions): float64 time(time), float32 ygrid(ygrid), float32 xgrid(xgrid), float32 cdr_seaice_conc_monthly(time, ygrid, xgrid), int8 melt_onset_day_cdr_seaice_conc_monthly(time, ygrid, xgrid), float32 nsidc_bt_seaice_conc_monthly(time, ygrid, xgrid), float32 nsidc_nt_seaice_conc_monthly(time, ygrid, xgrid), int8 qa_of_cdr_seaice_conc_monthly(time, ygrid, xgrid), float32 stdev_of_cdr_seaice_conc_monthly(time, ygrid, xgrid)\n    groups: \n\n\n\n# prints variable names\nda.variables.keys()\n\ndict_keys(['time', 'ygrid', 'xgrid', 'cdr_seaice_conc_monthly', 'melt_onset_day_cdr_seaice_conc_monthly', 'nsidc_bt_seaice_conc_monthly', 'nsidc_nt_seaice_conc_monthly', 'qa_of_cdr_seaice_conc_monthly', 'stdev_of_cdr_seaice_conc_monthly'])\n\n\n\nda['cdr_seaice_conc_monthly'][0][:].shape\n\n(448, 304)\n\n\n\n# set mapping crs to Cartopy's North Polar Stereo graphic\ncrs_epsg = ccrs.NorthPolarStereo(central_longitude=-45)\n\n# set figure size\nfig = plt.figure(figsize=[10, 10])\n\n# set the map projection and associated boundaries\nax = plt.axes(projection = crs_epsg)\nax.set_extent([-3850000.0, 3750000.0, -5350000, 5850000.0],crs_epsg)\nax.coastlines()\nax.add_feature(cfeature.LAND)\n\n# set the data crs using 'transform' \n# set the data crs as described in the netcdf metadata\ncs = ax.pcolormesh(da['xgrid'], da['ygrid'], da['cdr_seaice_conc_monthly'][0][:] , \n                   cmap=plt.cm.Blues,  transform= ccrs.NorthPolarStereo(true_scale_latitude=70, central_longitude=-45)) #transform default is basemap specs\n\nfig.colorbar(cs, ax=ax, location='bottom', shrink =0.8)\nax.set_title('Ice Concentration using Cartopy projection NorthPolarStereo()')\n\nplt.show()"
  },
  {
    "objectID": "tutorials/python/map-data-with-different-projections.html#mapping-data-with-epsg-code",
    "href": "tutorials/python/map-data-with-different-projections.html#mapping-data-with-epsg-code",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "Mapping data with EPSG Code",
    "text": "Mapping data with EPSG Code\nYou can set the data crs using the EPSG code. In our case, the metadata provides the projection crs (EPSG: 3411) In this exercise, we will use the same basemap projection, but set the data projection with the EPSG code.\n\n# Set data projection using EPSG Code \ndata_crs = ccrs.epsg('3411')\ncrs_epsg = ccrs.NorthPolarStereo(central_longitude=-45)\n\n# set the basemap \nfig = plt.figure(figsize=[10, 10])\nax = plt.axes(projection = crs_epsg)\nax.set_extent([-3850000.0, 3750000.0, -5350000, 5850000.0],ccrs.NorthPolarStereo(central_longitude=-45))\nax.add_feature(cfeature.LAND)\nax.coastlines()\n\n# transform= which projection data (coords) were defined \ncs = ax.pcolormesh(da['xgrid'], da['ygrid'], da['cdr_seaice_conc_monthly'][0][:], \n                   cmap=plt.cm.Blues,  transform= data_crs) \n\nfig.colorbar(cs, ax=ax, location='bottom', shrink =0.8)\nax.set_title('Ice Concentration using EPSG code (3411)')\n\nplt.show()"
  },
  {
    "objectID": "tutorials/python/map-data-with-different-projections.html#references",
    "href": "tutorials/python/map-data-with-different-projections.html#references",
    "title": "Map Geographical and Polarstereographic data on a projected map",
    "section": "References",
    "text": "References\n\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nNOAA PolarWatch Data Product Page (download, preview)"
  },
  {
    "objectID": "tutorials/python/gl-timeseries-surface-temp.html",
    "href": "tutorials/python/gl-timeseries-surface-temp.html",
    "title": "Great Lakes longterm water surface temperature plot",
    "section": "",
    "text": "Summary\nIn this example you will see how to extract Great Lakes average water surface temperature data from the ERDDAP server and make a plot of the longterm average water surface temperatue.\n\n\nThe example demonstrates the following techniques:\n\nLoading Great Lakes average water surface temperature data from Great Lakes ERDDAP data server.\nPloting the chart to show the highest and lowest temperature for the specific day.\nPloting the chart using the datetime class as the X axis.\nPloting the chart to show temperature in both degree C and F.\n\n\n\nDatesets used:\n\nGreat Lakes Surface Environmental Analysis (GLSEA): a lakewide average water surface temperauture product.\nWe are using the new developed: ACSPO GLSEA or GLSEA3. ACSPO means Advanced Clear-sky Processor for Oceans.\nThe data files cover from 2007 to current year.\n\n\n\nImport the required Python modules\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n#from PIL import Image\nimport math as m\nfrom datetime import datetime\nimport matplotlib.dates as mdates\n\n\n\n\n\nDefine some function that we need :\nfunction get_366_arry(): Checks to make sure the input array size is 366\n\ndef get_366_arry(t_arry):\n\n    if (t_arry.size &lt; 366):\n        t_arry = np.append(t_arry, np.NAN)\n\n    return t_arry\n\nfunction get_days_arr() takes a year (integer) and reture a list of datetime stamp.\n\ndef get_days_arr(c_yr):\n\n    d = range(1,367)  # range from 1 to 366\n\n    d_list = []\n\n    for i in d:\n\n        d_str = str(c_yr) + ' ' + str(i)\n     \n        d2 = datetime.strptime(d_str, '%Y %j')\n        d_list.append(d2)\n    \n    d_arr = np.array(d_list)\n    #print(d_arr)\n    return d_arr    \n\nfunction draw_plot() takes data array, lake, year Jilian day and years list as input to draw the plat\n\ndef draw_plot(t_all_arry, lake, c_yr, jd,  year_list):\n    \n    begin_day_str = str(c_yr) + '-01-01'  # '2021-01-01'\n    end_day_str = str(c_yr) + '-12-31'    # '2021-12-31'\n    \n    date_marker = [pd.to_datetime(date, format='%Y-%m-%d').date() for date in pd.date_range( begin_day_str, end_day_str, freq=\"ME\")]\n    print(date_marker)\n    \n    days_arr = get_days_arr(c_yr) \n    \n    fig= plt.figure(figsize=(11, 8))\n\n    ax = fig.add_subplot(111)\n\n    number_of_plots = len(year_list) + 1  \n\n    for i, yr4 in enumerate(year_list):\n        ax.plot(days_arr, t_all_arry[i], color='blue', alpha=.1)\n\n    min_v_index_tp = np.where( t_all_arry[:-1,jd] == np.amin(t_all_arry[:-1,jd]))\n    min_v_index = min_v_index_tp[0][0]\n    print(min_v_index)\n    ax.plot(days_arr, t_all_arry[min_v_index], color='green', label=str(year_list[min_v_index]) )\n\n \n    max_v_index_tp = np.where( t_all_arry[:-1,jd] == np.amax(t_all_arry[:-1,jd]))\n\n    max_v_index = max_v_index_tp[0][0]\n    \n    ax.plot(days_arr, t_all_arry[max_v_index], color='red', label=str(year_list[max_v_index]) )\n\n    ax.plot(days_arr, t_all_arry[-1], color='#eb7434', label=str(c_yr) )\n\n    nan_arr = np.empty(366)\n    nan_arr.fill(np.NAN)\n    ax.plot(days_arr, nan_arr, color='blue', alpha=.3, label='Other years' )\n\n    avg_arry = np.nanmean(t_all_arry[:-1], axis=0)\n    \n    ax.plot(days_arr, avg_arry, color='#525150',  label='Average (' + str(year_list[0]) + '-' + str(year_list[-1]) +')' )\n\n    ax.set_ybound(lower=0, upper=30)\n    ax.set_xbound(lower=0, upper=366)\n\n    ax.set_xlim(days_arr[0], days_arr[-1])\n\n    ax.set_xticks(date_marker )\n    dtFmt = mdates.DateFormatter('%b-%d') # define the formatting\n\n    ax.xaxis.set_major_formatter(dtFmt) # apply the format to the desired axis\n\n    ax.set_yticks(range(0,30,2))\n \n    ax.yaxis.set_major_formatter(plt.FuncFormatter('{:.0f}\\u00b0C'.format))  # show degree C char\n\n    ax.set_ylabel('Water Surface Temperature', weight='semibold', fontsize=12)\n    ax.set_xlabel('Months of Year',  weight='semibold', fontsize=12)\n    ax2 = ax.twinx()\n    ax2.set_yticks(range(32,86,4))\n\n    ax2.set_ylim(32, 86)\n\n    ax2.yaxis.set_major_formatter(plt.FuncFormatter('{:.0f}\\u00b0F'.format))  # show degree F char\n \n    ax.grid(True, 'major', 'y', ls='--', lw=.5, c='k', alpha=.3)\n    ax.grid(True, 'major', 'x', ls='--', lw=.5, c='k', alpha=.3)\n\n    fig.suptitle('Lake '  + lake + ' Average GLSEA Surface Water Temperature (' + str(year_list[0]) + ' - ' + str(c_yr) +')', weight='semibold', fontsize=12, ha='center')\n\n    ax.legend(title='YEARS', loc='upper left', ncol=2, fancybox=True)\n\n    plt.figtext(0.1, 0.02, 'NOAA CoastWatch Great Lakes Node', family='sans-serif', style='italic', weight='semibold', size='medium' )\n\n    plt.figtext(0.7, 0.02, datetime.now().strftime(\"%B %d, %Y %H:%M:%S\"), family='sans-serif', style='italic', weight='semibold', size='medium' )\n\n    day = datetime.strptime('{} {}'.format(jd, c_year),'%j %Y')\n    print(day.strftime('%Y %B %d'))\n\n    year_str = '(' + str(year_list[0]) + '-' + str(year_list[-1]) +')'\n\n    plt.figtext(0.20, 0.92, 'The warmest year on ' + day.strftime('%B %d') + ' for the period of record ' + year_str + ' was in ' + str(year_list[max_v_index]) + ' (shown in red)', color='black', fontsize=10 )\n\n    plt.figtext(0.20, 0.90, 'The coldest year on ' + day.strftime('%B %d') + ' for the period of record ' +  year_str + ' was in ' + str(year_list[min_v_index]) + ' (shown in green)', color='black', fontsize=10 )\n \n    plt.show()\n\n\n\nDefine current year and past years range\nGet the current year as an integer number and define a longterm time ranage. In this example, the current year is 2024 and longterm range is 2007 - 2023.\n\nc_year = int(datetime.now().strftime(\"%Y\"))\n \nprint(c_year)\n\nb_year = 2007\n\nyear_list = []\nfor i in range(b_year, c_year):\n    year_list.append(i)\n\nprint(year_list)\n\ntoday = datetime.now()\njd = (today - datetime(today.year, 1, 1)).days \n\n2024\n[2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n\n\n\n\nGet current year’s temperature data from ERDDAP\nThe dataset ID is glsea_avgtemps_3 in the ERDDAP server. The file name of the current year is glsea-temps_1024_3.dat. The file contains 9 lines header information, so we need to skip the first 9 lines when reading the data file. The data in the file are organized in 8 columns, such as Year, Julian day, Lake Superior, Lake Michigan, Lake Huron, Lake Erie, Lake Ontario, and Lake st clr. The file include the average temperature from current day back to 365 days.\neg.\nDaily Lake Average Surface Water Temperature From Great Lakes Surface Environmental Analysis maps\n\n\n\n\n\n\nSurf. Water Temp. (degrees C)\n\n\nYear Day Sup. Mich. Huron Erie Ont. St.Clr\n\n\n\n2023 127 2.24 4.64 4.14 8.87 7.02 9.59 2023 128 2.26 4.81 4.23 9.51 7.33 10.13 …… 2024 125 3.42 6.75 5.10 10.01 6.69 10.38 2024 126 3.47 6.94 5.27 9.99 6.62 10.16\nGet data from ERDDAP server:\n\nc_fn = 'https://apps.glerl.noaa.gov/erddap/files/glsea_avgtemps_3/glsea-temps_1024_3.dat'\nc_df = pd.read_csv(c_fn, skiprows=9,delimiter=r'\\s+', header=None, names=['YEAR', 'JD', 'S', 'M', 'H', 'E', 'O','St'], dtype=np.float64)\n\nprint(c_df.head())\nprint(c_df.info())\n    \nc_yr_list = c_df['YEAR']\n \nbegin_c_yr_index = list(c_yr_list).index(float(c_year))  # find the index of the current year (2024)\nprint('index of begin current year : ', begin_c_yr_index)\n\n\n     YEAR     JD     S     M     H      E     O     St\n0  2023.0  127.0  2.24  4.64  4.14   8.87  7.02   9.59\n1  2023.0  128.0  2.26  4.81  4.23   9.51  7.33  10.13\n2  2023.0  129.0  2.30  4.98  4.37   9.97  7.58  10.81\n3  2023.0  130.0  2.27  5.17  4.50  10.29  7.68  10.95\n4  2023.0  131.0  2.38  5.39  4.64  10.71  7.80  11.01\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 365 entries, 0 to 364\nData columns (total 8 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   YEAR    365 non-null    float64\n 1   JD      365 non-null    float64\n 2   S       365 non-null    float64\n 3   M       365 non-null    float64\n 4   H       365 non-null    float64\n 5   E       365 non-null    float64\n 6   O       365 non-null    float64\n 7   St      365 non-null    float64\ndtypes: float64(8)\nmemory usage: 22.9 KB\nNone\nindex of begin current year :  239\n\n\nGet a sub datafreme of Lake Michigan for current year:\n\nc_df_sub = c_df[begin_c_yr_index:]  # get a sub dataframe that only contains data for 2024\n \n\ncur_m_arry = c_df_sub['M'].values   # get a sub dataframe that only contains data for Lake Michigan\n\nfor i in range(begin_c_yr_index+1):\n    cur_m_arry = np.append(cur_m_arry, np.NAN)\n\nprint(cur_m_arry)\n\n\n[5.63 5.51 5.47 5.43 5.4  5.35 5.32 5.27 5.16 4.71 4.37 4.26 4.1  3.97\n 3.82 3.69 3.62 3.55 3.29 3.24 3.26 3.25 3.37 3.39 3.4  3.47 3.49 3.56\n 3.56 3.61 3.62 3.63 3.65 3.62 3.62 3.6  3.54 3.49 3.48 3.49 3.51 3.47\n 3.47 3.44 3.38 3.33 3.28 3.23 3.24 3.22 3.34 3.38 3.32 3.31 3.18 3.17\n 3.22 3.31 3.31 3.29 3.41 3.5  3.51 3.54 3.63 3.69 3.66 3.7  3.64 3.64\n 3.65 3.67 3.73 3.77 3.8  3.79 3.74 3.64 3.53 3.47 3.42 3.42 3.46 3.42\n 3.53 3.57 3.54 3.51 3.5  3.55 3.6  3.65 3.74 3.9  3.99 4.04 4.1  4.16\n 4.23 4.31 4.38 4.51 4.68 4.82 4.99 5.09 5.1  5.07 5.05 5.1  5.08 5.1\n 5.14 5.25 5.37 5.49 5.56 5.64 5.67 5.76 5.89 6.   6.14 6.48 6.75 6.94\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n  nan  nan]\n\n\n\n\nGet data from 2007 to 2023\nEach year have one data file. The file naming convention is glsea-tempsYYYY_1024_3.dat.\neg. glsea-temps2023_1024.dat.\nThe file format is samilar as the current year’s data file.\nfirst, define an array of (18,366) to hold all data\n\nm_all_arry = np.zeros( (len(year_list)+1,366), dtype=float)   \nprint(m_all_arry.shape)\n\n(18, 366)\n\n\nSecond, get the data from the 2007 to 2023 and put all the data in variable m_all_arry\n\n\nfor i, yr4 in enumerate(year_list):\n    fn = 'https://apps.glerl.noaa.gov/erddap/files/glsea_avgtemps_3/' + str(yr4) + '/glsea-temps' + str(yr4) + '_1024_3.dat'\n    #print(fn)\n    df = pd.read_csv(fn, skiprows=9,delimiter=r'\\s+', header=None, names=['YEAR', 'JD', 'S', 'M', 'H', 'E', 'O','St'], dtype=np.float64)\n\n    m_arry = df['M'].values            # get data for Lake Michigan\n\n    #print(s_arry.size)\n    print(yr4)\n    m_all_arry[i] = get_366_arry(m_arry)   \n\n#print(s_all_arry)\n\nm_all_arry[-1] = cur_m_arry   # last row is current year sst               \n \n\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n\n\nThird, call the function (defined before) to draw the plot.\n\ndraw_plot(m_all_arry, 'Michigan',  c_year, jd, year_list)\n\n[datetime.date(2024, 1, 31), datetime.date(2024, 2, 29), datetime.date(2024, 3, 31), datetime.date(2024, 4, 30), datetime.date(2024, 5, 31), datetime.date(2024, 6, 30), datetime.date(2024, 7, 31), datetime.date(2024, 8, 31), datetime.date(2024, 9, 30), datetime.date(2024, 10, 31), datetime.date(2024, 11, 30), datetime.date(2024, 12, 31)]\n7\n2024 May 05"
  },
  {
    "objectID": "tutorials/python/gl-ice-plot-timeseries-ice-conc.html",
    "href": "tutorials/python/gl-ice-plot-timeseries-ice-conc.html",
    "title": "Summary",
    "section": "",
    "text": "This example is based on the OceanWatch tutorial meterial edited with Great Lakes satellite data.In this example you will see how to extract Great Lakes ice concentration data from the ERDDAP server and make a ice concentration map, and caculate the monthly\n\nThe example demonstrates the following techniques:\n\nLoading Great Lakes ice concentration data from Great Lakes ERDDAP data server.\nCreate a map of ice concentration.\nCompute the daily mean over the selected region.\n\n\n\nDatesets used:\n\nGreat Lakes ice concentration: Great Lakes ice concentration product.\n\n\n\nImport the required Python modules\n\nimport xarray as xr\nimport pandas as pd\nimport numpy as np\nimport urllib.request\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport warnings\n#warnings.filterwarnings('ignore')\n\n\n\nDownlading data from ERDDAP server\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure. For example, the following link allows you to subset daily ice concentration data from the dataset GL_Ice_Concentration_GCS\nIn this specific example, we will get the SST data from 2023-06-01 to 2023-06-30. the URL we generated is :\nhttps://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5D\nwe extract the data in csv format due to the nc library not available.\n\nurl=\"https://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5D\"\nurllib.request.urlretrieve(url, \"w_e_ice_concentration.nc\")\n\n('w_e_ice_concentration.nc', &lt;http.client.HTTPMessage at 0x1b687bf22d0&gt;)\n\n\n\n\nImporting NetCDF4 data in Python\nNow that we’ve downloaded the data locally, we can import it and extract our variables of interest.\nThe xarray package makes it very convenient to work with NetCDF files. Documentation is available here: http://xarray.pydata.org/en/stable/why-xarray.html\n\nimport xarray as xr\nimport netCDF4 as nc\n\n\n\nOpen the file and load it as an xarray dataset:\n\nds = xr.open_dataset('w_e_ice_concentration.nc',decode_cf=False)\n#ds = xr.open_dataset('e_sst.nc')\n\n\n\nExamine the data structure:\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:            (time: 7146, latitude: 52, longitude: 79)\nCoordinates:\n  * time               (time) float64 7.89e+08 7.89e+08 ... 1.714e+09 1.715e+09\n  * latitude           (latitude) float64 41.38 41.4 41.41 ... 42.07 42.08 42.1\n  * longitude          (longitude) float64 -83.59 -83.58 -83.56 ... -82.51 -82.5\nData variables:\n    ice_concentration  (time, latitude, longitude) float32 ...\nAttributes: (12/28)\n    cdm_data_type:              Grid\n    Conventions:                CF-1.6, COARDS, ACDD-1.3\n    Easternmost_Easting:        -82.496964466524\n    GDAL:                       GDAL 3.4.3, released 2022/04/22\n    geospatial_lat_max:         42.0985561800016\n    geospatial_lat_min:         41.3837647963109\n    ...                         ...\n    standard_name_vocabulary:   CF Standard Name Table v29\n    summary:                    Ice Concentration from Great Lakes Surface En...\n    time_coverage_end:          2024-05-01T12:00:00Z\n    time_coverage_start:        1995-01-01T12:00:00Z\n    title:                      Ice Concentration from Great Lakes Surface En...\n    Westernmost_Easting:        -83.590174818051xarray.DatasetDimensions:time: 7146latitude: 52longitude: 79Coordinates: (3)time(time)float647.89e+08 7.89e+08 ... 1.715e+09_CoordinateAxisType :Timeactual_range :[7.8896160e+08 1.7145648e+09]axis :Tcalendar :Gregorianioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00units :seconds since 1970-01-01T00:00:00Zarray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])latitude(latitude)float6441.38 41.4 41.41 ... 42.08 42.1_CoordinateAxisType :Latactual_range :[41.3837648  42.09855618]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northarray([41.383765, 41.39778 , 41.411796, 41.425811, 41.439827, 41.453842,\n       41.467858, 41.481873, 41.495889, 41.509904, 41.52392 , 41.537935,\n       41.551951, 41.565967, 41.579982, 41.593998, 41.608013, 41.622029,\n       41.636044, 41.65006 , 41.664075, 41.678091, 41.692106, 41.706122,\n       41.720137, 41.734153, 41.748168, 41.762184, 41.776199, 41.790215,\n       41.80423 , 41.818246, 41.832261, 41.846277, 41.860292, 41.874308,\n       41.888323, 41.902339, 41.916354, 41.93037 , 41.944385, 41.958401,\n       41.972417, 41.986432, 42.000448, 42.014463, 42.028479, 42.042494,\n       42.05651 , 42.070525, 42.084541, 42.098556])longitude(longitude)float64-83.59 -83.58 ... -82.51 -82.5_CoordinateAxisType :Lonactual_range :[-83.59017482 -82.49696447]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastarray([-83.590175, -83.576159, -83.562144, -83.548128, -83.534113, -83.520097,\n       -83.506082, -83.492066, -83.478051, -83.464035, -83.45002 , -83.436004,\n       -83.421989, -83.407973, -83.393958, -83.379942, -83.365927, -83.351911,\n       -83.337896, -83.32388 , -83.309864, -83.295849, -83.281833, -83.267818,\n       -83.253802, -83.239787, -83.225771, -83.211756, -83.19774 , -83.183725,\n       -83.169709, -83.155694, -83.141678, -83.127663, -83.113647, -83.099632,\n       -83.085616, -83.071601, -83.057585, -83.04357 , -83.029554, -83.015539,\n       -83.001523, -82.987508, -82.973492, -82.959477, -82.945461, -82.931446,\n       -82.91743 , -82.903414, -82.889399, -82.875383, -82.861368, -82.847352,\n       -82.833337, -82.819321, -82.805306, -82.79129 , -82.777275, -82.763259,\n       -82.749244, -82.735228, -82.721213, -82.707197, -82.693182, -82.679166,\n       -82.665151, -82.651135, -82.63712 , -82.623104, -82.609089, -82.595073,\n       -82.581058, -82.567042, -82.553027, -82.539011, -82.524996, -82.51098 ,\n       -82.496964])Data variables: (1)ice_concentration(time, latitude, longitude)float32..._FillValue :-99999.0colorBarMaximum :100.0colorBarMinimum :0.0colorBarPalette :WhiteBlackgrid_mapping :crsioos_category :Ocean Colorlong_name :Ice Concentrationstandard_name :ice_concentrationunits :percent[29355768 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(Index([ 788961600.0,  789048000.0,  789134400.0,  789220800.0,  789307200.0,\n        789393600.0,  789480000.0,  789566400.0,  789652800.0,  789739200.0,\n       ...\n       1713787200.0, 1713873600.0, 1713960000.0, 1714046400.0, 1714132800.0,\n       1714219200.0, 1714305600.0, 1714392000.0, 1714478400.0, 1714564800.0],\n      dtype='float64', name='time', length=7146))latitudePandasIndexPandasIndex(Index([41.3837647963109, 41.3977803136382, 41.4117958309654, 41.4258113482927,\n         41.43982686562, 41.4538423829472, 41.4678579002745, 41.4818734176018,\n        41.495888934929, 41.5099044522563, 41.5239199695836, 41.5379354869108,\n       41.5519510042381, 41.5659665215654, 41.5799820388927, 41.5939975562199,\n       41.6080130735472, 41.6220285908745, 41.6360441082017,  41.650059625529,\n       41.6640751428563, 41.6780906601835, 41.6921061775108, 41.7061216948381,\n       41.7201372121653, 41.7341527294926, 41.7481682468199, 41.7621837641471,\n       41.7761992814744, 41.7902147988017,  41.804230316129, 41.8182458334562,\n       41.8322613507835, 41.8462768681108,  41.860292385438, 41.8743079027653,\n       41.8883234200926, 41.9023389374198, 41.9163544547471, 41.9303699720744,\n       41.9443854894016, 41.9584010067289, 41.9724165240562, 41.9864320413835,\n       42.0004475587107,  42.014463076038, 42.0284785933653, 42.0424941106925,\n       42.0565096280198, 42.0705251453471, 42.0845406626743, 42.0985561800016],\n      dtype='float64', name='latitude'))longitudePandasIndexPandasIndex(Index([ -83.590174818051, -83.5761593007237, -83.5621437833965,\n       -83.5481282660692, -83.5341127487419, -83.5200972314146,\n       -83.5060817140874, -83.4920661967601, -83.4780506794328,\n       -83.4640351621056, -83.4500196447783,  -83.436004127451,\n       -83.4219886101238, -83.4079730927965, -83.3939575754692,\n       -83.3799420581419, -83.3659265408147, -83.3519110234874,\n       -83.3378955061601, -83.3238799888329, -83.3098644715056,\n       -83.2958489541783, -83.2818334368511, -83.2678179195238,\n       -83.2538024021965, -83.2397868848693,  -83.225771367542,\n       -83.2117558502147, -83.1977403328874, -83.1837248155602,\n       -83.1697092982329, -83.1556937809057, -83.1416782635784,\n       -83.1276627462511, -83.1136472289238, -83.0996317115966,\n       -83.0856161942693,  -83.071600676942, -83.0575851596148,\n       -83.0435696422875, -83.0295541249602,  -83.015538607633,\n       -83.0015230903057, -82.9875075729784, -82.9734920556511,\n       -82.9594765383239, -82.9454610209966, -82.9314455036693,\n       -82.9174299863421, -82.9034144690148, -82.8893989516875,\n       -82.8753834343603,  -82.861367917033, -82.8473523997057,\n       -82.8333368823785, -82.8193213650512, -82.8053058477239,\n       -82.7912903303966, -82.7772748130694, -82.7632592957421,\n       -82.7492437784149, -82.7352282610876, -82.7212127437603,\n        -82.707197226433, -82.6931817091058, -82.6791661917785,\n       -82.6651506744512,  -82.651135157124, -82.6371196397967,\n       -82.6231041224694, -82.6090886051422, -82.5950730878149,\n       -82.5810575704876, -82.5670420531603, -82.5530265358331,\n       -82.5390110185058, -82.5249955011785, -82.5109799838513,\n        -82.496964466524],\n      dtype='float64', name='longitude'))Attributes: (28)cdm_data_type :GridConventions :CF-1.6, COARDS, ACDD-1.3Easternmost_Easting :-82.496964466524GDAL :GDAL 3.4.3, released 2022/04/22geospatial_lat_max :42.0985561800016geospatial_lat_min :41.3837647963109geospatial_lat_resolution :0.014015517327269056geospatial_lat_units :degrees_northgeospatial_lon_max :-82.496964466524geospatial_lon_min :-83.590174818051geospatial_lon_resolution :0.01401551732726889geospatial_lon_units :degrees_easthistory :Ice concentration from Great Lakes Surface Environmental Analysis (GLSEA) asc format to nc fromat\n2024-09-18T16:53:43Z (local files)\n2024-09-18T16:53:43Z https://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5DinfoUrl :https://coastwatch.glerl.noaa.gov/glsea/glsea.htmlinstitution :CoastWatch Great Lakes Nodekeywords :analysis, concentration, data, distribution, environmental, glsea, great, great lakes, ice, ice distribution, ice_concentration, lakes, nic, surface, timelicense :The data may be used and redistributed for free but is not intended\nfor legal use, since it may contain inaccuracies. Neither the data\nContributor, ERD, NOAA, nor the United States Government, nor any\nof their employees or contractors, makes any warranty, express or\nimplied, including warranties of merchantability and fitness for a\nparticular purpose, or assumes any legal liability for the accuracy,\ncompleteness, or usefulness, of this information.NCO :netCDF Operators version 5.0.7 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)Northernmost_Northing :42.0985561800016source :Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-presentsourceUrl :(local files)Southernmost_Northing :41.3837647963109standard_name_vocabulary :CF Standard Name Table v29summary :Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NICtime_coverage_end :2024-05-01T12:00:00Ztime_coverage_start :1995-01-01T12:00:00Ztitle :Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-presentWesternmost_Easting :-83.590174818051\n\n\n\n\nExamine which coordinates and variables are included in the dataset:\n\n ds.dims\n\nFrozen({'time': 7146, 'latitude': 52, 'longitude': 79})\n\n\n\nds.coords\n\nCoordinates:\n  * time       (time) float64 7.89e+08 7.89e+08 ... 1.714e+09 1.715e+09\n  * latitude   (latitude) float64 41.38 41.4 41.41 41.43 ... 42.07 42.08 42.1\n  * longitude  (longitude) float64 -83.59 -83.58 -83.56 ... -82.52 -82.51 -82.5\n\n\n\nds.data_vars\n\nData variables:\n    ice_concentration  (time, latitude, longitude) float32 ...\n\n\n\nds.attrs\n\n{'cdm_data_type': 'Grid',\n 'Conventions': 'CF-1.6, COARDS, ACDD-1.3',\n 'Easternmost_Easting': -82.496964466524,\n 'GDAL': 'GDAL 3.4.3, released 2022/04/22',\n 'geospatial_lat_max': 42.0985561800016,\n 'geospatial_lat_min': 41.3837647963109,\n 'geospatial_lat_resolution': 0.014015517327269056,\n 'geospatial_lat_units': 'degrees_north',\n 'geospatial_lon_max': -82.496964466524,\n 'geospatial_lon_min': -83.590174818051,\n 'geospatial_lon_resolution': 0.01401551732726889,\n 'geospatial_lon_units': 'degrees_east',\n 'history': 'Ice concentration from Great Lakes Surface Environmental Analysis (GLSEA) asc format to nc fromat\\n2024-09-18T16:53:43Z (local files)\\n2024-09-18T16:53:43Z https://apps.glerl.noaa.gov/erddap/griddap/GL_Ice_Concentration_GCS.nc?ice_concentration%5B(1995-01-01T12:00:00Z):1:(2024-05-01T12:00:00Z)%5D%5B(41.38):1:(42.10)%5D%5B(-83.59):1:(-82.5)%5D',\n 'infoUrl': 'https://coastwatch.glerl.noaa.gov/glsea/glsea.html',\n 'institution': 'CoastWatch Great Lakes Node',\n 'keywords': 'analysis, concentration, data, distribution, environmental, glsea, great, great lakes, ice, ice distribution, ice_concentration, lakes, nic, surface, time',\n 'license': 'The data may be used and redistributed for free but is not intended\\nfor legal use, since it may contain inaccuracies. Neither the data\\nContributor, ERD, NOAA, nor the United States Government, nor any\\nof their employees or contractors, makes any warranty, express or\\nimplied, including warranties of merchantability and fitness for a\\nparticular purpose, or assumes any legal liability for the accuracy,\\ncompleteness, or usefulness, of this information.',\n 'NCO': 'netCDF Operators version 5.0.7 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)',\n 'Northernmost_Northing': 42.0985561800016,\n 'source': 'Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-present',\n 'sourceUrl': '(local files)',\n 'Southernmost_Northing': 41.3837647963109,\n 'standard_name_vocabulary': 'CF Standard Name Table v29',\n 'summary': 'Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC',\n 'time_coverage_end': '2024-05-01T12:00:00Z',\n 'time_coverage_start': '1995-01-01T12:00:00Z',\n 'title': 'Ice Concentration from Great Lakes Surface Environmental Analysis (GLSEA) and NIC, Geodetic coordinate system (LAT, LON), 1995-present',\n 'Westernmost_Easting': -83.590174818051}\n\n\n\n\nExamine the structure of ice concentration:\n\nds.ice_concentration.shape\n\n(7146, 52, 79)\n\n\nOur dataset is a 3-D array with 52 rows corresponding to latitudes and 79 columns corresponding to longitudes, for each of the 7146 time steps. #### Get the dates for each time step:\n\nds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 7146)&gt;\narray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])\nCoordinates:\n  * time     (time) float64 7.89e+08 7.89e+08 7.891e+08 ... 1.714e+09 1.715e+09\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [7.8896160e+08 1.7145648e+09]\n    axis:                 T\n    calendar:             Gregorian\n    ioos_category:        Time\n    long_name:            Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00\n    units:                seconds since 1970-01-01T00:00:00Zxarray.DataArray'time'time: 71467.89e+08 7.89e+08 7.891e+08 ... 1.714e+09 1.714e+09 1.715e+09array([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])Coordinates: (1)time(time)float647.89e+08 7.89e+08 ... 1.715e+09_CoordinateAxisType :Timeactual_range :[7.8896160e+08 1.7145648e+09]axis :Tcalendar :Gregorianioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00units :seconds since 1970-01-01T00:00:00Zarray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])Indexes: (1)timePandasIndexPandasIndex(Index([ 788961600.0,  789048000.0,  789134400.0,  789220800.0,  789307200.0,\n        789393600.0,  789480000.0,  789566400.0,  789652800.0,  789739200.0,\n       ...\n       1713787200.0, 1713873600.0, 1713960000.0, 1714046400.0, 1714132800.0,\n       1714219200.0, 1714305600.0, 1714392000.0, 1714478400.0, 1714564800.0],\n      dtype='float64', name='time', length=7146))Attributes: (9)_CoordinateAxisType :Timeactual_range :[7.8896160e+08 1.7145648e+09]axis :Tcalendar :Gregorianioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00units :seconds since 1970-01-01T00:00:00Z\n\n\n\nds.time.attrs\n\n{'_CoordinateAxisType': 'Time',\n 'actual_range': array([7.8896160e+08, 1.7145648e+09]),\n 'axis': 'T',\n 'calendar': 'Gregorian',\n 'ioos_category': 'Time',\n 'long_name': 'Time',\n 'standard_name': 'time',\n 'time_origin': '01-JAN-1970 00:00:00',\n 'units': 'seconds since 1970-01-01T00:00:00Z'}\n\n\n\nprint(ds.time)\n\n&lt;xarray.DataArray 'time' (time: 7146)&gt;\narray([7.889616e+08, 7.890480e+08, 7.891344e+08, ..., 1.714392e+09,\n       1.714478e+09, 1.714565e+09])\nCoordinates:\n  * time     (time) float64 7.89e+08 7.89e+08 7.891e+08 ... 1.714e+09 1.715e+09\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [7.8896160e+08 1.7145648e+09]\n    axis:                 T\n    calendar:             Gregorian\n    ioos_category:        Time\n    long_name:            Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00\n    units:                seconds since 1970-01-01T00:00:00Z\n\n\n\n\nThe time units is seconds, we need to convert the seconds to dates.\n\ndates=nc.num2date(ds.time,ds.time.units,only_use_cftime_datetimes=False, \n                        only_use_python_datetimes=True )\ndates\n\narray([real_datetime(1995, 1, 1, 12, 0), real_datetime(1995, 1, 2, 12, 0),\n       real_datetime(1995, 1, 3, 12, 0), ...,\n       real_datetime(2024, 4, 29, 12, 0),\n       real_datetime(2024, 4, 30, 12, 0),\n       real_datetime(2024, 5, 1, 12, 0)], dtype=object)\n\n\n\n\nFind the index of dates for 2019-03-01\n\nfor i, date in enumerate(dates):\n    if date.strftime(\"%Y-%m-%d\") == \"2019-03-01\":\n        print(i, date)\n\n5872 2019-03-01 12:00:00\n\n\n5872 is the index on the array dates for 2019-03-01.\n\n\nCreate a map of ice concentration for March 1, 2019 (our 5872th time step).\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n#np.warnings.filterwarnings('ignore')\n\n#### Examine the values of ice concentration:\n\nprint(ds.ice_concentration.values)\nprint(ds.ice_concentration.shape)\n\n[[[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n ...\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n [[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999.      0.]\n  [-99999. -99999. -99999. ...      0.      0.      0.]\n  ...\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n  [-99999. -99999. -99999. ... -99999. -99999. -99999.]]]\n(7146, 52, 79)\n\n\n\nds.ice_concentration.attrs\n\n{'_FillValue': -99999.0,\n 'colorBarMaximum': 100.0,\n 'colorBarMinimum': 0.0,\n 'colorBarPalette': 'WhiteBlack',\n 'grid_mapping': 'crs',\n 'ioos_category': 'Ocean Color',\n 'long_name': 'Ice Concentration',\n 'standard_name': 'ice_concentration',\n 'units': 'percent'}\n\n\n\nds.ice_concentration.attrs['_FillValue']\n\n-99999.0\n\n\n\n\nMake a new ice concentration DataArray and replace _fillValue with NaN\n\nnan_ice_concentration = ds.ice_concentration.where(ds.ice_concentration.values != ds.ice_concentration.attrs['_FillValue'])\n\nprint(nan_ice_concentration)\n\n&lt;xarray.DataArray 'ice_concentration' (time: 7146, latitude: 52, longitude: 79)&gt;\narray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n...\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan,  0.],\n        [nan, nan, nan, ...,  0.,  0.,  0.],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)\nCoordinates:\n  * time       (time) float64 7.89e+08 7.89e+08 ... 1.714e+09 1.715e+09\n  * latitude   (latitude) float64 41.38 41.4 41.41 41.43 ... 42.07 42.08 42.1\n  * longitude  (longitude) float64 -83.59 -83.58 -83.56 ... -82.52 -82.51 -82.5\nAttributes:\n    _FillValue:       -99999.0\n    colorBarMaximum:  100.0\n    colorBarMinimum:  0.0\n    colorBarPalette:  WhiteBlack\n    grid_mapping:     crs\n    ioos_category:    Ocean Color\n    long_name:        Ice Concentration\n    standard_name:    ice_concentration\n    units:            percent\n\n\n\n\nSet some color breaks\n\n# find min value in man_sst\nnp.nanmin(nan_ice_concentration)\n\n0.0\n\n\n\nnp.nanmax(nan_ice_concentration)\n\n99.99847\n\n\n\nlevs = np.arange(0, 101, 10)\nlen(levs)\n\n11\n\n\n\n\nDefine a color palette\n\n# init a color list\njet=[\"blue\", \"#007FFF\", \"cyan\",\"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"]\n\n\n\nSet color scale using the jet palette\n\ncm = LinearSegmentedColormap.from_list('my_jet', jet, N=len(levs))\n\n\n\nplot the ice_concentration map\n\nplt.subplots(figsize=(10, 5))\n\n#plot 5872th ice concentration image: nan_ice_concentration[5872 ,:,:]\nplt.contourf(nan_ice_concentration.longitude, nan_ice_concentration.latitude, nan_ice_concentration[5872,:,:], levs,cmap=cm)\n\n#plot the color scale\nplt.colorbar()\n\n#example of how to add points to the map\n#plt.scatter(np.linspace(-82,-80.5,num=4),np.repeat(42,4),c='black')\n\n#example of how to add a contour line\n#step = np.arange(9,26, 1)\n\n#plt.contour(ds.longitude, ds.latitude, ds.sst[0,:,:],levels=step,linewidths=1)\n\n#plot title\nplt.title(\"West Lake Erie Ice Concentration - \" + dates[5872].strftime('%b %d, %Y'))\nplt.show()\n\n\n\n\n\n\n\n\n\n\nLet’s compute the daily mean over the west Lake Erie region:\n\nres=np.nanmean(nan_ice_concentration,axis=(1,2))\nres\n\narray([0., 0., 0., ..., 0., 0., 0.], dtype=float32)\n\n\n\n\nLet’s plot the time-series (from 2019-03-01 to 2019-03-31):\n\nfor i, date in enumerate(dates):\n    if date.strftime(\"%Y-%m-%d\") == \"2019-03-01\":\n        print(i, date)\n    \n    if date.strftime(\"%Y-%m-%d\") == \"2019-03-31\":\n        print(i, date)\n\n5872 2019-03-01 12:00:00\n5902 2019-03-31 12:00:00\n\n\n\nprint(res.shape)\n\n(7146,)\n\n\n\nplt.figure(figsize=(8,4))\n\nplt.scatter(dates[5872:5902+1],res[5872:5902+1])\n\n#degree_sign = u\"\\N{DEGREE SIGN}\"\nplt.ylabel('Ice Concentration (%)')\n\nplt.xlim(dates[5872], dates[5902+1])\n\nplt.xticks(dates[5872:5902+1],rotation=70, fontsize=10 )\nplt.show()\n\n\n\n\n\n\n\n\n\n!jupyter nbconvert --to html GL_python_tutorial4.ipynb\n\n[NbConvertApp] Converting notebook GL_python_tutorial4.ipynb to html\n[NbConvertApp] Writing 313369 bytes to GL_python_tutorial4.html"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html",
    "title": "Extract data within a boundary",
    "section": "",
    "text": "History | Updated Sep 2023"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#background",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#background",
    "title": "Extract data within a boundary",
    "section": "Background",
    "text": "Background\nOne use for satellite observations is to supplement in situ sampling of geographical locations where the timespan or frequency measurements, or spatial dimensions or remoteness of the locations, make physical sampling impossible or impractical. One drawback is that satellite data are often rectangular, whereas geographical locations can have irregular boundaries. Examples of locations with boundaries include Marine Protected Areas or marine physical, biological, and ecological divisions like the Longhurst Marine Provinces."
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#objectives",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#objectives",
    "title": "Extract data within a boundary",
    "section": "Objectives",
    "text": "Objectives\nIn this tutorial we will learn how to download a timeseries of SST satellite data from an ERDDAP server, and then mask the data to retain only the data within an irregular geographical boundary (polygon). We will then plot a yearly seasonal cycle from within the boundary."
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Extract data within a boundary",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data from an ERDDAP data server\nVisualizing data on a map\nMasking satellite data using a shape file"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#datasets-used",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#datasets-used",
    "title": "Extract data within a boundary",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Geo-polar Blended Analysis Sea-Surface Temperature, Global, Monthly, 5km, 2019-Present\nThe NOAA geo-polar blended SST is a high resolution satellite-based sea surface temperature (SST) product that combines SST data from US, Japanese and European geostationary infrared imagers, and low-earth orbiting infrared (U.S. and European) SST data, into a single product. We will use the monthly composite. https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly\nLonghurst Marine Provinces\nThe dataset represents the division of the world oceans into provinces as defined by Longhurst (1995; 1998; 2006). This division has been based on the prevailing role of physical forcing as a regulator of phytoplankton distribution. The Longhurst Marine Provinces dataset is available online (https://www.marineregions.org/downloads.php) and within the shapes folder associated with this repository. For this tutorial we will use the Gulf Stream province (ProvCode: GFST)\n\n\n\n../images/longhurst.png"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#import-packages",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#import-packages",
    "title": "Extract data within a boundary",
    "section": "Import packages",
    "text": "Import packages\nNote: Make sure you have at least version 0.10.0 of regionmask * To install with conda use “conda install -c conda-forge regionmask=0.10.0 cartopy”\n\nimport matplotlib.pyplot as plt\nimport xarray as xr\nimport geopandas\nimport regionmask\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport warnings\nimport os\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#load-the-longhurst-provinces-shape-files-into-a-geopandas-dataframe",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#load-the-longhurst-provinces-shape-files-into-a-geopandas-dataframe",
    "title": "Extract data within a boundary",
    "section": "Load the Longhurst Provinces shape files into a geopandas dataframe",
    "text": "Load the Longhurst Provinces shape files into a geopandas dataframe\n\n#shape_path = '../resources/longhurst_v4_2010/Longhurst_world_v4_2010.shp'\nshape_path = os.path.join('..',\n                          'resources',\n                          'longhurst_v4_2010',\n                          'Longhurst_world_v4_2010.shp'\n                          )\nshapefiles = geopandas.read_file(shape_path)\nshapefiles.head(8)\n\n\n\n\n\n\n\n\nProvCode\nProvDescr\ngeometry\n\n\n\n\n0\nBPLR\nPolar - Boreal Polar Province (POLR)\nMULTIPOLYGON (((-161.18426 63.50000, -161.5000...\n\n\n1\nARCT\nPolar - Atlantic Arctic Province\nMULTIPOLYGON (((-21.51305 64.64409, -21.55945 ...\n\n\n2\nSARC\nPolar - Atlantic Subarctic Province\nMULTIPOLYGON (((11.26472 63.96082, 11.09548 63...\n\n\n3\nNADR\nWesterlies - N. Atlantic Drift Province (WWDR)\nPOLYGON ((-11.50000 57.50000, -11.50000 56.500...\n\n\n4\nGFST\nWesterlies - Gulf Stream Province\nPOLYGON ((-43.50000 43.50000, -43.50000 42.500...\n\n\n5\nNASW\nWesterlies - N. Atlantic Subtropical Gyral Pro...\nPOLYGON ((-39.50000 25.50000, -40.50000 25.500...\n\n\n6\nNATR\nTrades - N. Atlantic Tropical Gyral Province (...\nMULTIPOLYGON (((-72.34673 18.53597, -72.36877 ...\n\n\n7\nWTRA\nTrades - Western Tropical Atlantic Province\nPOLYGON ((-19.50000 -6.50000, -20.50000 -6.500..."
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#isolate-the-gulf-stream-province",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#isolate-the-gulf-stream-province",
    "title": "Extract data within a boundary",
    "section": "Isolate the Gulf Stream Province",
    "text": "Isolate the Gulf Stream Province\nThe Gulf Stream Province can be isolated using its ProvCode (GFST)\n\nProvCode = \"GFST\"\n\n# Locate the row with the ProvCode code\ngulf_stream = shapefiles.loc[shapefiles[\"ProvCode\"] == ProvCode]\ngulf_stream\n\n\n\n\n\n\n\n\nProvCode\nProvDescr\ngeometry\n\n\n\n\n4\nGFST\nWesterlies - Gulf Stream Province\nPOLYGON ((-43.50000 43.50000, -43.50000 42.500..."
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#find-the-coordinates-of-the-bounding-box",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#find-the-coordinates-of-the-bounding-box",
    "title": "Extract data within a boundary",
    "section": "Find the coordinates of the bounding box",
    "text": "Find the coordinates of the bounding box\n\nThe bounding box is the smallest rectangle that will completely enclose the province.\nWe will use the bounding box coordinates to subset the satellite data\n\n\ngs_bnds = gulf_stream.bounds\ngs_bnds\n\n\n\n\n\n\n\n\nminx\nminy\nmaxx\nmaxy\n\n\n\n\n4\n-73.5\n33.5\n-43.5\n43.5"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#open-the-satellite-dataset-into-a-xarray-dataset-object",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#open-the-satellite-dataset-into-a-xarray-dataset-object",
    "title": "Extract data within a boundary",
    "section": "Open the satellite dataset into a xarray dataset object",
    "text": "Open the satellite dataset into a xarray dataset object\n\nerddap_url = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                       'erddap',\n                       'griddap',\n                       'NOAA_DHW_monthly'\n                       ])\n\nds = xr.open_dataset(erddap_url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                          (time: 464, latitude: 3600, longitude: 7200)\nCoordinates:\n  * time                             (time) datetime64[ns] 1985-01-16 ... 202...\n  * latitude                         (latitude) float32 89.97 89.93 ... -89.97\n  * longitude                        (longitude) float32 -180.0 -179.9 ... 180.0\nData variables:\n    sea_surface_temperature          (time, latitude, longitude) float32 ...\n    mask                             (time, latitude, longitude) float32 ...\n    sea_surface_temperature_anomaly  (time, latitude, longitude) float32 ...\nAttributes: (12/66)\n    _NCProperties:                    version=2,netcdf=4.8.1,hdf5=1.12.2\n    acknowledgement:                  NOAA Coral Reef Watch program\n    cdm_data_type:                    Grid\n    comment:                          This is a product of NOAA Coral Reef Wa...\n    contributor_name:                 NOAA Coral Reef Watch program\n    contributor_role:                 Collecting source data and deriving pro...\n    ...                               ...\n    time_coverage_duration:           P1M\n    time_coverage_end:                2023-08-16T00:00:00Z\n    time_coverage_resolution:         P1M\n    time_coverage_start:              1985-01-16T00:00:00Z\n    title:                            SST and SST Anomaly, NOAA Global Coral ...\n    Westernmost_Easting:              -179.975xarray.DatasetDimensions:time: 464latitude: 3600longitude: 7200Coordinates: (3)time(time)datetime64[ns]1985-01-16 ... 2023-08-16_CoordinateAxisType :Timeactual_range :[4.746816e+08 1.692144e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1985-01-16T00:00:00.000000000', '1985-02-16T00:00:00.000000000',\n       '1985-03-16T00:00:00.000000000', ..., '2023-06-16T00:00:00.000000000',\n       '2023-07-16T00:00:00.000000000', '2023-08-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3289.97 89.93 89.88 ... -89.92 -89.97_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([ 89.975   ,  89.92501 ,  89.87501 , ..., -89.875   , -89.924995,\n       -89.975   ], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-179.975  , -179.925  , -179.875  , ...,  179.875  ,  179.92499,\n        179.975  ], dtype=float32)Data variables: (3)sea_surface_temperature(time, latitude, longitude)float32...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[12026880000 values with dtype=float32]mask(time, latitude, longitude)float32...colorBarMaximum :5.0colorBarMinimum :0.0comment :A 2D array, in the same size as the data array in the X and Y directions, the classifies land, ice pixels, and water (data) pixelscoverage_content_type :thematicClassificationflag_meanings :valid-water land missing iceflag_values :[0 1 2 4]ioos_category :Qualitylong_name :Pixel characteristics flag arrayunits :pixel_classification[12026880000 values with dtype=float32]sea_surface_temperature_anomaly(time, latitude, longitude)float32...colorBarMaximum :3.0colorBarMinimum :-3.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :sea surface temperature anomalystandard_name :surface_temperature_anomalyunits :degree_Cvalid_max :15.0valid_min :-15.0[12026880000 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1985-01-16 00:00:00', '1985-02-16 00:00:00',\n               '1985-03-16 00:00:00', '1985-04-16 00:00:00',\n               '1985-05-15 23:00:00', '1985-06-15 23:00:00',\n               '1985-07-15 23:00:00', '1985-08-15 23:00:00',\n               '1985-09-15 23:00:00', '1985-10-15 23:00:00',\n               ...\n               '2022-11-16 00:00:00', '2022-12-16 00:00:00',\n               '2023-01-16 00:00:00', '2023-02-16 00:00:00',\n               '2023-03-16 00:00:00', '2023-04-16 00:00:00',\n               '2023-05-16 00:00:00', '2023-06-16 00:00:00',\n               '2023-07-16 00:00:00', '2023-08-16 00:00:00'],\n              dtype='datetime64[ns]', name='time', length=464, freq=None))latitudePandasIndexPandasIndex(Index([  89.9749984741211,  89.92501068115234,  89.87500762939453,\n        89.82500457763672,   89.7750015258789,   89.7249984741211,\n        89.67501068115234,  89.62500762939453,  89.57500457763672,\n         89.5250015258789,\n       ...\n        -89.5250015258789, -89.57499694824219,            -89.625,\n       -89.67499542236328,  -89.7249984741211,  -89.7750015258789,\n       -89.82499694824219,            -89.875, -89.92499542236328,\n        -89.9749984741211],\n      dtype='float32', name='latitude', length=3600))longitudePandasIndexPandasIndex(Index([-179.97500610351562,  -179.9250030517578,            -179.875,\n       -179.82501220703125, -179.77500915527344, -179.72500610351562,\n        -179.6750030517578,            -179.625, -179.57501220703125,\n       -179.52500915527344,\n       ...\n        179.52499389648438,  179.57501220703125,             179.625,\n        179.67498779296875,  179.72500610351562,  179.77499389648438,\n        179.82501220703125,             179.875,  179.92498779296875,\n        179.97500610351562],\n      dtype='float32', name='longitude', length=7200))Attributes: (66)_NCProperties :version=2,netcdf=4.8.1,hdf5=1.12.2acknowledgement :NOAA Coral Reef Watch programcdm_data_type :Gridcomment :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite Version 3.1, derived from CoralTemp v1.0.contributor_name :NOAA Coral Reef Watch programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archive.Conventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch programcreator_name :NOAA Coral Reef Watch programcreator_type :groupcreator_url :https://coralreefwatch.noaa.govdate_created :2018-03-01T12:00:00Zdate_issued :2019-01-19T20:32:23Zdate_metadata_modified :2018-09-01T12:00:00Zdate_modified :2018-03-01T12:00:00ZEasternmost_Easting :179.975geospatial_bounds :POLYGON((-90.0 180.0, 90.0 180.0, 90.0 -180.0, -90.0 -180.0, -90.0 180.0))geospatial_bounds_crs :EPSG:4326geospatial_lat_max :89.975geospatial_lat_min :-89.975geospatial_lat_units :degrees_northgeospatial_lon_max :179.975geospatial_lon_min :-179.975geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:32663grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Tue Jul 27 10:37:54 2021: ncrename -d lon,longitude -d lat,latitude -v lon,longitude -v lat,latitude -v sea surface temperature anomaly,sea_surface_temperature_anomaly /cwdata/coralreef/work/temp.nc\nMonthly data files for mean sea surface temperature (SST) and sea surface temperature anomaly (SST anomaly) were downloaded from ftp.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1/nc/v1.0/monthly. Monthly files were created that contain both SST and SST anomaly data, and a mask of earth surface classifications.\n2023-09-06T18:39:14Z (local files)\n2023-09-06T18:39:14Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.dasid :Satellite_Global_5km_CoralTemp_SST_SSTA_Monthly_Mean_CompositeinfoUrl :https://coralreefwatch.noaa.gov/product/5km/index.phpinstitution :NOAA/NESDIS/STAR Coral Reef Watch programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, anomaly, array, characteristics, coral, crw, data, earth, Earth Science &gt; Land Surface &gt; Land Temperature &gt; Land Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature Anomaly, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, flag, global, information, infrared, land, latitude, longitude, mask, mean, month, monthly, national, nesdis, noaa, ocean, oceans, pixel, program, quality, reef, satellite, science, sea, sea_surface_temperature, sea_surface_temperature_anomaly, seawater, service, spectral, spectral/engineering, sst, star, surface, surface_temperature_anomaly, temperature, thermal, time, v.3.1, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of the Coral Reef Watch website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/product/5km/index.phpnaming_authority :gov.noaa.coralreefwatchNCO :\"4.6.3\"Northernmost_Northing :89.975platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :Derived from L4 satellite sea surface temperature analysisproduct_version :3.1program :NOAA Coral Reef Watch programproject :NOAA Coral Reef Watch programpublisher_email :erd.data at noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch programpublisher_name :NOAA NMFS SWFSC ERD, CoastWatch West Coast Nodepublisher_type :institutionpublisher_url :https://coralreefwatch.noaa.gov, https://coastwatch.pfeg.noaa.gov/references :https://coralreefwatch.noaa.gov/product/5km/index.php and https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :Coral Reef Watch CoralTemp v1.0sourceUrl :(local files)Southernmost_Northing :-89.975spatial_resolution :0.05 degreestandard_name_vocabulary :CF Standard Name Table v27summary :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite, derived from CoralTemp v1.0.time_coverage_duration :P1Mtime_coverage_end :2023-08-16T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :1985-01-16T00:00:00Ztitle :SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring, 5km, V.3.1, Monthly, 1985-PresentWesternmost_Easting :-179.975"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#subset-the-satellite-data",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#subset-the-satellite-data",
    "title": "Extract data within a boundary",
    "section": "Subset the satellite data",
    "text": "Subset the satellite data\n\nUse the bounding box coordinates for the latitude and longitude slices\nSelect the entire year of 2020\n\n\n# This dataset has latitude in descending order. \n# Therefore use maxy first and miny last to slice latitude\nds_subset = ds['sea_surface_temperature'].sel(time=slice(\"2020-01-16\", \"2020-12-16\"),\n                                              latitude=slice(gs_bnds.maxy.item(), \n                                                             gs_bnds.miny.item()),\n                                              longitude=slice(gs_bnds.minx.item(), \n                                                              gs_bnds.maxx.item())\n                                            )\nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'sea_surface_temperature' (time: 12, latitude: 200,\n                                             longitude: 600)&gt;\n[1440000 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 2020-01-16 2020-02-16 ... 2020-12-16\n  * latitude   (latitude) float32 43.47 43.43 43.38 43.33 ... 33.62 33.58 33.53\n  * longitude  (longitude) float32 -73.47 -73.42 -73.38 ... -43.62 -43.57 -43.53\nAttributes:\n    colorBarMaximum:        32.0\n    colorBarMinimum:        0.0\n    coverage_content_type:  physicalMeasurement\n    ioos_category:          Temperature\n    long_name:              analysed sea surface temperature\n    standard_name:          sea_surface_temperature\n    units:                  degree_C\n    valid_max:              50.0\n    valid_min:              -2.0xarray.DataArray'sea_surface_temperature'time: 12latitude: 200longitude: 600...[1440000 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]2020-01-16 ... 2020-12-16_CoordinateAxisType :Timeactual_range :[4.746816e+08 1.692144e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2020-01-16T00:00:00.000000000', '2020-02-16T00:00:00.000000000',\n       '2020-03-15T23:00:00.000000000', '2020-04-15T23:00:00.000000000',\n       '2020-05-15T23:00:00.000000000', '2020-06-15T23:00:00.000000000',\n       '2020-07-15T23:00:00.000000000', '2020-08-15T23:00:00.000000000',\n       '2020-09-15T23:00:00.000000000', '2020-10-15T23:00:00.000000000',\n       '2020-11-16T00:00:00.000000000', '2020-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3243.47 43.43 43.38 ... 33.58 33.53_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([43.475   , 43.42501 , 43.375008, 43.325005, 43.275   , 43.225   ,\n       43.17501 , 43.125008, 43.075005, 43.025   , 42.975   , 42.92501 ,\n       42.875008, 42.825005, 42.775   , 42.725   , 42.67501 , 42.625008,\n       42.575005, 42.525   , 42.475   , 42.42501 , 42.375008, 42.325005,\n       42.275   , 42.225   , 42.17501 , 42.125008, 42.075005, 42.025   ,\n       41.975   , 41.92501 , 41.875008, 41.825005, 41.775   , 41.725   ,\n       41.67501 , 41.625008, 41.575005, 41.525   , 41.475   , 41.42501 ,\n       41.375008, 41.325005, 41.275   , 41.225   , 41.17501 , 41.125008,\n       41.075005, 41.025   , 40.975   , 40.92501 , 40.875008, 40.825005,\n       40.775   , 40.725   , 40.67501 , 40.625008, 40.575005, 40.525   ,\n       40.475   , 40.42501 , 40.375008, 40.325005, 40.275   , 40.225   ,\n       40.17501 , 40.125008, 40.075005, 40.025   , 39.975   , 39.92501 ,\n       39.875008, 39.825005, 39.775   , 39.725   , 39.67501 , 39.625008,\n       39.575005, 39.525   , 39.475   , 39.42501 , 39.375008, 39.325005,\n       39.275   , 39.225   , 39.17501 , 39.125008, 39.075005, 39.025   ,\n       38.975   , 38.92501 , 38.875008, 38.825005, 38.775   , 38.725   ,\n       38.67501 , 38.625008, 38.575005, 38.525   , 38.475   , 38.42501 ,\n       38.375008, 38.325005, 38.275   , 38.225   , 38.17501 , 38.125008,\n       38.075005, 38.025   , 37.975006, 37.925003, 37.875   , 37.825005,\n       37.775   , 37.725006, 37.675003, 37.625   , 37.575005, 37.525   ,\n       37.475006, 37.425003, 37.375   , 37.325005, 37.275   , 37.225006,\n       37.175003, 37.125   , 37.075005, 37.025   , 36.975006, 36.925003,\n       36.875   , 36.825005, 36.775   , 36.725006, 36.675003, 36.625   ,\n       36.575005, 36.525   , 36.475006, 36.425003, 36.375   , 36.325005,\n       36.275   , 36.225006, 36.175003, 36.125   , 36.075005, 36.025   ,\n       35.975006, 35.925003, 35.875   , 35.825005, 35.775   , 35.725006,\n       35.675003, 35.625   , 35.575005, 35.525   , 35.475006, 35.425003,\n       35.375   , 35.325005, 35.275   , 35.225006, 35.175003, 35.125   ,\n       35.075005, 35.025   , 34.975006, 34.925003, 34.875   , 34.825005,\n       34.775   , 34.725006, 34.675003, 34.625   , 34.575005, 34.525   ,\n       34.475006, 34.425003, 34.375   , 34.325005, 34.275   , 34.225006,\n       34.175003, 34.125   , 34.075005, 34.025   , 33.975006, 33.925003,\n       33.875   , 33.825005, 33.775   , 33.725006, 33.675003, 33.625   ,\n       33.575005, 33.525   ], dtype=float32)longitude(longitude)float32-73.47 -73.42 ... -43.57 -43.53_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-73.475   , -73.424995, -73.375   , ..., -43.624992, -43.57499 ,\n       -43.525   ], dtype=float32)Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2020-01-16 00:00:00', '2020-02-16 00:00:00',\n               '2020-03-15 23:00:00', '2020-04-15 23:00:00',\n               '2020-05-15 23:00:00', '2020-06-15 23:00:00',\n               '2020-07-15 23:00:00', '2020-08-15 23:00:00',\n               '2020-09-15 23:00:00', '2020-10-15 23:00:00',\n               '2020-11-16 00:00:00', '2020-12-16 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))latitudePandasIndexPandasIndex(Index([43.474998474121094, 43.425010681152344,  43.37500762939453,\n        43.32500457763672, 43.275001525878906, 43.224998474121094,\n       43.175010681152344,  43.12500762939453,  43.07500457763672,\n       43.025001525878906,\n       ...\n       33.975006103515625,  33.92500305175781,             33.875,\n        33.82500457763672, 33.775001525878906, 33.725006103515625,\n        33.67500305175781,             33.625,  33.57500457763672,\n       33.525001525878906],\n      dtype='float32', name='latitude', length=200))longitudePandasIndexPandasIndex(Index([  -73.4749984741211,  -73.42499542236328,             -73.375,\n        -73.32499694824219,  -73.27499389648438,   -73.2249984741211,\n        -73.17499542236328,             -73.125,  -73.07499694824219,\n        -73.02499389648438,\n       ...\n       -43.974998474121094,  -43.92499542236328,  -43.87499237060547,\n       -43.824989318847656, -43.775001525878906, -43.724998474121094,\n        -43.67499542236328,  -43.62499237060547, -43.574989318847656,\n       -43.525001525878906],\n      dtype='float32', name='longitude', length=600))Attributes: (9)colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#visualize-the-unmasked-data-on-a-map",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#visualize-the-unmasked-data-on-a-map",
    "title": "Extract data within a boundary",
    "section": "Visualize the unmasked data on a map",
    "text": "Visualize the unmasked data on a map\nThe map shows the full extent of the bounding box\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([260, 350, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nds_subset[0].plot.pcolormesh(ax=ax1, transform=ccrs.PlateCarree(), cmap='jet')\n\nplt.title('Satellite Data Before Masking')\n\nText(0.5, 1.0, 'Satellite Data Before Masking')"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#create-the-region-from-the-shape-file",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#create-the-region-from-the-shape-file",
    "title": "Extract data within a boundary",
    "section": "Create the region from the shape file",
    "text": "Create the region from the shape file\nThe plot shows the shape of the region and its placement along the US East Coast.\n\nregion = regionmask.from_geopandas(gulf_stream)\nregion.plot()"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#mask-the-satellite-data",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#mask-the-satellite-data",
    "title": "Extract data within a boundary",
    "section": "Mask the satellite data",
    "text": "Mask the satellite data\n\n# Create the mask\nmask = region.mask(ds_subset.longitude, ds_subset.latitude)\n\n# Apply mask the the satellite data\nmasked_ds = ds_subset.where(mask == region.numbers[0])"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#visualize-the-masked-data-on-a-map",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#visualize-the-masked-data-on-a-map",
    "title": "Extract data within a boundary",
    "section": "Visualize the masked data on a map",
    "text": "Visualize the masked data on a map\nThese data have been trimmed to contain only values within the Gulf Stream Province\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([260, 350, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nmasked_ds[0].plot.pcolormesh(ax=ax1,\n                             transform=ccrs.PlateCarree(),\n                             cmap='jet')\n\nplt.title('Satellite Data After Masking for Longhurst GFST')\n\n\nText(0.5, 1.0, 'Satellite Data After Masking for Longhurst GFST')"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#plot-the-mean-seasonal-temperature-for-the-province",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#plot-the-mean-seasonal-temperature-for-the-province",
    "title": "Extract data within a boundary",
    "section": "Plot the mean seasonal temperature for the province",
    "text": "Plot the mean seasonal temperature for the province\n\ngulf_stream_mean = masked_ds.mean(dim=['latitude', 'longitude'])\n\n\ngulf_stream_mean\n\nplt.figure(figsize=(10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(gulf_stream_mean.time,\n              gulf_stream_mean, \n              'o', markersize=8, \n              label='gulf stream', c='black', \n              linestyle='-', linewidth=2) \n\nplt.title('Gulf Stream Province Monthly Mean Temperature 2020')\nplt.ylabel('SST(degrees C)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/python/extract-satellite-data-within-boundary.html#references",
    "href": "tutorials/python/extract-satellite-data-within-boundary.html#references",
    "title": "Extract data within a boundary",
    "section": "References",
    "text": "References\nThe several CoastWatch Node websites have data catalog containing documentation and links to all the datasets available:\n* https://oceanwatch.pifsc.noaa.gov/doc.html\n* https://coastwatch.pfeg.noaa.gov/data.html\n* https://polarwatch.noaa.gov/catalog/\nSources for marine shape files * https://www.marineregions.org/downloads.php"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html",
    "title": "Make a virtual buoy with satellite data",
    "section": "",
    "text": "History | Updated August 2023 ## Background There are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov) and ARGO floats program (http://www.argo.ucsd.edu). Despite these impressive efforts to monitor environmental conditions, in situ buoy data may not be available for your area of interest. Some locations are hard to access, making deploying and maintaining a buoy impractical. In addition, buoys are expensive to purchase, deploy and maintain. Therefore, limited funding may prevent installation of a buoy or the continued operation of a buoy already in place.\nUsing satellite data to create virtual buoys can provide a solution to monitoring surface environmental conditions at locations where it is not feasible to install a buoy. For example, the University of South Florida has developed a virtual buoy system for locations off the Florida coast (https://optics.marine.usf.edu/projects/vbs.html)."
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#objectives",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#objectives",
    "title": "Make a virtual buoy with satellite data",
    "section": "Objectives",
    "text": "Objectives\nThe following exercise will demonstrate the use of the ERDDAP data server to create a virtual buoy. For the scenario, we will envision that a virtual buoy is needed to continue the datastream for an in situ buoy that was discontinued at the end of 2019. For this exercise we will use the National Data Buoy Center (NDBC) buoy # 46259, which is located off the California coast at 34.767N latitude and -121.497E longitude, and pretend that it was discontinued at the end of 2019. The buoy measures several oceanic variables, but we will continue the sea surface temperature (SST) datastream using NOAA GeoPolar Blended SST satellite dataset."
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#the-tutorial-demonstrates-the-following-skills",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#the-tutorial-demonstrates-the-following-skills",
    "title": "Make a virtual buoy with satellite data",
    "section": "The tutorial demonstrates the following skills:",
    "text": "The tutorial demonstrates the following skills:\n\nThe use of ERDDAP to create a virtual buoy\n\nThe use of the pandas and xarray modules to import and manipulate data\n\nResampling data to bin them into a lower resolution time steps\nGenerating a linear regression and statistics\nPlotting time-series data\n\nCleaning data to remove outlying data points"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#datasets-used",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#datasets-used",
    "title": "Make a virtual buoy with satellite data",
    "section": "Datasets used",
    "text": "Datasets used\nNDBC Buoy Data\nThe National Data Buoy Center (NDBC) distributes meteorological data from moored buoys maintained by NDBC and others. They are deployed in the coastal and offshore waters from the western Atlantic to the Pacific Ocean around Hawaii, and from the Bering Sea to the South Pacific. For this tutorial we will use buoy number 46259. NDBC data are available from the CoastWatch West Coast Node ERDDAP. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#import-required-modules",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#import-required-modules",
    "title": "Make a virtual buoy with satellite data",
    "section": "Import required modules",
    "text": "Import required modules\n\nimport numpy as np\nimport xarray as xr\nfrom datetime import datetime\nimport os\nimport pandas as pd\nimport io\nimport requests\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\nfrom sklearn.metrics import r2_score\n\n# the %matplotlib is a magic function allow displaying results in notebooks\n%matplotlib inline\n\n# some tools for Pandas to work will with matplotlib\nfrom pandas.plotting import register_matplotlib_converters"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#a-note-about-tabledap",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#a-note-about-tabledap",
    "title": "Make a virtual buoy with satellite data",
    "section": "A note about tabledap",
    "text": "A note about tabledap\nMost of our examples in this course use gridded datasets. The NDBC data for this tutorial is a tabular dataset, served via the tabledap part of ERDDAP. The API for tabledap is a little different than for gridded datasets. You can go to the following URL and play around with subsetting. Then push the “Just generate the URL” button, copy the link, put it in a browser. See if you get what you expected. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet\nA quick primer is below\nThe data request URL has three parts: 1. Base URL: https://url/erddap/tabledap/datasetID.fileType? * e.g. https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?\n\nA list of variables you want to download that are separated by commas\n\n\n\ne.g. station,longitude,latitude,time,wtmp\n\n\nA list of constraints, each starting with an ampersand (&).\n\n\nThe constraints use =, &gt;, &gt;=, &lt;, and &lt;= to subset the data\ne.g. &station=“46259”, mean station # 46259\ne.g. &time&gt;=2017-01-01T&time&lt;=2020-12-31’, means time between and including Jan. 1, 2017 and Dec. 31, 2020.\n\nThe data request URL we will use for the NDBC data:\nndbc_url = 'https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?station,longitude,latitude,time,wtmp&station=\"46259\"&time&gt;=2017-01-01T&time&lt;=2020-12-31"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#download-the-data-into-a-pandas-dataframe",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#download-the-data-into-a-pandas-dataframe",
    "title": "Make a virtual buoy with satellite data",
    "section": "Download the data into a Pandas dataframe",
    "text": "Download the data into a Pandas dataframe\n\n# Break the url into part and rejoin it so that it is easier to see.\nndbc_url = ''.join(['https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?',\n                    'station,longitude,latitude,time,wtmp',\n                    '&station=\"46259\"&time&gt;=2018-01-01&time&lt;=2019-12-31'\n                    ])\n\nreq = requests.get(ndbc_url).content\nbuoy_df = pd.read_csv(io.StringIO(req.decode('utf-8')), skiprows=[1], parse_dates=['time'])\nbuoy_df.head(2)\n\n\n\n\n\n\n\n\nstation\nlongitude\nlatitude\ntime\nwtmp\n\n\n\n\n0\n46259\n-121.664\n34.732\n2018-01-01 00:22:00+00:00\n14.6\n\n\n1\n46259\n-121.664\n34.732\n2018-01-01 00:52:00+00:00\n14.6\n\n\n\n\n\n\n\n\nExtract the longitude and latitude coordinates for the station\nAfter, clean up the dataframe by deleting unneeded columns.\n\nbuoy_lat = buoy_df.latitude[0]\nbuoy_lon = buoy_df.longitude[0]\n\n# Clean up the dataset by removing unneeded columns\ndel buoy_df['station']\ndel buoy_df['latitude']\ndel buoy_df['longitude'] \n\nprint('latitude', buoy_lat)\nprint('longitude', buoy_lon)\n\nlatitude 34.732\nlongitude -121.664"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-buoy-data",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-buoy-data",
    "title": "Make a virtual buoy with satellite data",
    "section": "Process the buoy data",
    "text": "Process the buoy data\nThe measurement rate of the buoy is on the order of minutes. We need to downsample the dataset to the daily resolution of the satellite dataset.\nThere are a few cleanup steps that are needed:\n* The time data are associated with the UTC time zone. Panda operations often don’t like time zones so let’s get rid of it. * Rename the SST variable to something more intuitive\n\nprint('# of timesteps before =', buoy_df.shape[0] )\n\n# The resampling will put time as the df index\nbuoy_df_resampled = buoy_df.resample('D', on='time').mean()\nprint('# of timesteps after =', buoy_df_resampled.shape[0] )\n\n# Remove the timezone (UTC, GMT).\nbuoy_df_resampled = buoy_df_resampled.tz_localize(None)\n\n# Rename the SST variable\nbuoy_df_resampled.rename(columns={\"wtmp\": \"sst_buoy\"}, errors=\"raise\", inplace=True)\nbuoy_df_resampled\n\nbuoy_df_resampled.head(2)\n\n# of timesteps before = 34455\n# of timesteps after = 730\n\n\n\n\n\n\n\n\n\nsst_buoy\n\n\ntime\n\n\n\n\n\n2018-01-01\n14.679167\n\n\n2018-01-02\n14.891489"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#load-the-satellite-data-into-xarray-and-subset",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#load-the-satellite-data-into-xarray-and-subset",
    "title": "Make a virtual buoy with satellite data",
    "section": "Load the satellite data into xarray and subset",
    "text": "Load the satellite data into xarray and subset\n\n# Put satellite data xarray dataset object\nsst_url = 'https://coastwatch.noaa.gov/erddap/griddap/noaacwBLENDEDCsstDaily'\nsst_ds = xr.open_dataset(sst_url)\n\n# Subset the dataset\nsst_ds_subset = sst_ds['analysed_sst'].sel(latitude=buoy_lat,\n                            longitude = buoy_lon, method='nearest'\n                            ).sel(time=slice('2018-01-01', \n                                             '2019-12-31'\n                                             ))\n\nsst_ds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'analysed_sst' (time: 692)&gt;\n[692 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 2018-01-01T12:00:00 ... 2019-12-31T12:00:00\n    latitude   float32 34.72\n    longitude  float32 -121.7\nAttributes:\n    colorBarMaximum:  35.0\n    colorBarMinimum:  0.0\n    comment:          nighttime analysed SST for each ocean grid point\n    ioos_category:    Temperature\n    long_name:        analysed sea surface temperature\n    references:       Fieguth,P.W. et al. \"Mapping Mediterranean altimeter da...\n    standard_name:    sea_surface_foundation_temperature\n    units:            degree_Cxarray.DataArray'analysed_sst'time: 692...[692 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]2018-01-01T12:00:00 ... 2019-12-..._CoordinateAxisType :Timeactual_range :[1.0308816e+09 1.6938288e+09]axis :Tcomment :Nominal time of Level 4 analysisioos_category :Timelong_name :reference time of sst fieldstandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2018-01-01T12:00:00.000000000', '2018-01-02T12:00:00.000000000',\n       '2018-01-03T12:00:00.000000000', ..., '2019-12-29T12:00:00.000000000',\n       '2019-12-30T12:00:00.000000000', '2019-12-31T12:00:00.000000000'],\n      dtype='datetime64[ns]')latitude()float3234.72_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projectionioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array(34.725, dtype=float32)longitude()float32-121.7_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projectionioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array(-121.675, dtype=float32)Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2018-01-01 12:00:00', '2018-01-02 12:00:00',\n               '2018-01-03 12:00:00', '2018-01-04 12:00:00',\n               '2018-01-05 12:00:00', '2018-01-06 12:00:00',\n               '2018-01-07 12:00:00', '2018-01-08 12:00:00',\n               '2018-01-09 12:00:00', '2018-02-09 12:00:00',\n               ...\n               '2019-12-22 12:00:00', '2019-12-23 12:00:00',\n               '2019-12-24 12:00:00', '2019-12-25 12:00:00',\n               '2019-12-26 12:00:00', '2019-12-27 12:00:00',\n               '2019-12-28 12:00:00', '2019-12-29 12:00:00',\n               '2019-12-30 12:00:00', '2019-12-31 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=692, freq=None))Attributes: (8)colorBarMaximum :35.0colorBarMinimum :0.0comment :nighttime analysed SST for each ocean grid pointioos_category :Temperaturelong_name :analysed sea surface temperaturereferences :Fieguth,P.W. et al. \"Mapping Mediterranean altimeter data with a multiresolution optimal interpolation algorithm\", J. Atmos. Ocean Tech, 15\n (2): 535-546, 1998.     Fieguth, P. Multiply-Rooted Multiscale Models for Large-Scale Estimation, IEEE Image Processing, 10(11), 1676-1686, 2001.     Khellah, F., P.W. Fieguth, M.J. M\nurray and M.R. Allen, \"Statistical Processing of Large Image Sequences\", IEEE Transactions on Geoscience and Remote Sensing, 12 (1), 80-93, 2005.standard_name :sea_surface_foundation_temperatureunits :degree_C"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-satellite-data-to-make-them-compatible-with-the-buoy-data",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#process-the-satellite-data-to-make-them-compatible-with-the-buoy-data",
    "title": "Make a virtual buoy with satellite data",
    "section": "Process the satellite data to make them compatible with the buoy data",
    "text": "Process the satellite data to make them compatible with the buoy data\n\nPut the satellite data into a Pandas dataframe\nResample the data to daily bins: The data are already daily, but resampling them makes the timestamp format the same as for the buoy data, and puts time into the index column of the dataframe.\nRemove the timezone localization from time\n\n\n# Initialize data\nsat_data = {'time': sst_ds_subset.time.values,\n            'sst_sat': sst_ds_subset.to_numpy()\n            }\n\n# Creates pandas DataFrame.\nsat_df = pd.DataFrame(sat_data)\n\n# Resample\nsat_df = sat_df.resample('D', on='time').mean()\n\n# Remove timezone\nsat_df = sat_df.tz_localize(None)\n\n\nsat_df.head(2)\n\n\n\n\n\n\n\n\nsst_sat\n\n\ntime\n\n\n\n\n\n2018-01-01\n14.18\n\n\n2018-01-02\n14.76"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#merge-the-datasets",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#merge-the-datasets",
    "title": "Make a virtual buoy with satellite data",
    "section": "Merge the datasets",
    "text": "Merge the datasets\n\nmerged_df = pd.merge(buoy_df_resampled, \n                     sat_df, \n                     left_index=True, \n                     right_index=True).reset_index()\nmerged_df.head(2)\n\n\n\n\n\n\n\n\ntime\nsst_buoy\nsst_sat\n\n\n\n\n0\n2018-01-01\n14.679167\n14.18\n\n\n1\n2018-01-02\n14.891489\n14.76"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#plot-the-data-along-the-same-time-x-axis",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#plot-the-data-along-the-same-time-x-axis",
    "title": "Make a virtual buoy with satellite data",
    "section": "Plot the data along the same time (x) axis",
    "text": "Plot the data along the same time (x) axis\nThe data from the buoy and satellite seem to track each other very well (below). * You will want to at least run a linear regression to determine how well satellite data reflects the in situ buoy measurements.\n\nplt.figure(figsize = (10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(merged_df.index, merged_df.sst_buoy, \n              'o', markersize=3, \n              label='Buoy', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(merged_df.index, merged_df.sst_sat,  \n              's', markersize=3, \n              label='Satellite', c='blue', \n              linestyle='-', linewidth=1) \n\n#plt.ylim([0, 3])\nplt.ylabel('SST (degrees C)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#clean-up-the-merged-dataset",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#clean-up-the-merged-dataset",
    "title": "Make a virtual buoy with satellite data",
    "section": "Clean up the merged dataset",
    "text": "Clean up the merged dataset\nRegression packages typically do not like nan’s. * Delete rows with nan\nThe data could contain data points that are outliers. Let’s remove those points from the data frame. * Apply a conservative allowable data range. - For the lower end of the range, the freezing point of seawater (ca. -2).\n- For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n\n# Drop nan\nclean_merged_df = merged_df.dropna()\n\n# Drop &lt; -2 and &gt; 45\nclean_merged_df = clean_merged_df.drop(clean_merged_df[(clean_merged_df['sst_sat'] &lt; -2) \n                                       | (clean_merged_df['sst_sat'] &gt; 45)].index)"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#run-the-regression",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#run-the-regression",
    "title": "Make a virtual buoy with satellite data",
    "section": "Run the regression",
    "text": "Run the regression\n\n# Regression packages typically do not like nan's. Delete rows with nan\nclean_merged_df = merged_df.dropna()\n\n# Generate the regression plot\nsns.regplot(x='sst_buoy', y='sst_sat', data=clean_merged_df)\n\n# Calculate the slope and intercept\nslope, intercept = np.polyfit(clean_merged_df[\"sst_buoy\"], clean_merged_df[\"sst_sat\"], 1)\n\n# Calculate R2\nr2 = r2_score(clean_merged_df[\"sst_sat\"], clean_merged_df[\"sst_buoy\"])\n\n# Annotate the plot\nplt.annotate(f\"y = {slope:.2f}x + {intercept:.2f},  R2 = {r2:.2f}\", \n             xy=(12, 18), \n             #xytext=(30, 5), \n             fontsize=12, \n             color=\"black\", \n             ha=\"left\")\n\nprint(slope, intercept)\n\n# To save your data, uncomment the next line\n# clean_merged_df.to_csv(\"virtual_buoy_example.csv\", index=False)\n\n0.9338037509902803 0.9930764222028932"
  },
  {
    "objectID": "tutorials/python/create-virtual-buoy-with-satellite-data.html#it-looks-like-your-virtual-buoy-is-ready-for-operations",
    "href": "tutorials/python/create-virtual-buoy-with-satellite-data.html#it-looks-like-your-virtual-buoy-is-ready-for-operations",
    "title": "Make a virtual buoy with satellite data",
    "section": "It looks like your virtual buoy is ready for operations",
    "text": "It looks like your virtual buoy is ready for operations\n\nThere is essentially a one-to-one relationship between buoy and satellite SST. The slope (0.93) is very close to 1\nThe R2 indicates that 90% of the variability of satellite SST is explained by the regression."
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html",
    "href": "tutorials/python/calculating-sea-ice-extent.html",
    "title": "Calculating sea ice area and extent",
    "section": "",
    "text": "History | Created Sep 2023"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#background",
    "href": "tutorials/python/calculating-sea-ice-extent.html#background",
    "title": "Calculating sea ice area and extent",
    "section": "Background",
    "text": "Background\nSea ice cover is one of the key components of polar ecological and climatological research. This measurement has gained attention because of the recent decrease in the Arctic sea ice cover. Satellite observations are a key tool in tracking sea ice cover, providing continuous global coverage extending back to 1978. Typically for satellite data, sea ice cover is reported as sea ice concentration, which is the percent areal coverage of ice within a grid cell. Depending on the application, additional parameters of interest can be calculated from sea ice cover:\n* Sea ice area - the sum of the product of ice concentration and area of all grid cells with at least 15% ice concentration.\n* Sea ice extent - the sum of the areas of all grid cells with at least 15% ice concentration"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#objective",
    "href": "tutorials/python/calculating-sea-ice-extent.html#objective",
    "title": "Calculating sea ice area and extent",
    "section": "Objective",
    "text": "Objective\nThis tutorial will demonstrate how to calculate the sea ice area and extent using sea ice concentration and grid cell area data. Please visit the NSIDC website for more detailed descriptions of the calculations."
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#this-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/calculating-sea-ice-extent.html#this-tutorial-demonstrates-the-following-techniques",
    "title": "Calculating sea ice area and extent",
    "section": "This tutorial demonstrates the following techniques",
    "text": "This tutorial demonstrates the following techniques\n\nDownloading and saving a netCDF file from PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nDownloading and adding grid cell area using OPeNDAP web services\nVisualizing data on a map\nComputing sea ice area and extent using sea ice concentration data\nPlotting a time series of sea ice area and extent"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#datasets-used",
    "href": "tutorials/python/calculating-sea-ice-extent.html#datasets-used",
    "title": "Calculating sea ice area and extent",
    "section": "Datasets used",
    "text": "Datasets used\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere\nThe Sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Northern Polar Stereographic projection (EPSG:3413). The resolution is 25km, meaning each grid in this data set represents a value that covers a 25km by 25km area. The dataset is available on the PolarWatch data portal and can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.graph\nPolar Stereographic Ancillary Grid Information\nThis dataset includes area values (m2) of each grid cell in the 25km resolution Northern Polar Stereographic projection (EPSG:3413). The file for this exercise is available in the resources folder or can be downloaded from the NSIDC website at https://nsidc.org/data/nsidc-0771/versions/1. For this tutorial, we will access the dataset directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k\n\nImport packages\n\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#download-the-arctic-sea-ice-concentration-data",
    "href": "tutorials/python/calculating-sea-ice-extent.html#download-the-arctic-sea-ice-concentration-data",
    "title": "Calculating sea ice area and extent",
    "section": "Download the Arctic Sea Ice Concentration Data",
    "text": "Download the Arctic Sea Ice Concentration Data\n\nReview of the ERDDAP data request URL\nFor our first exercise, we will download sea ice concentration data that has been temporally subsetted: * A single month, December 2021\nand spatially subsetted: * Y grid values that have been subsetted from the full range (5337500m to -5337500m) to a reduced range (4843696m to -4858210m).\nThe ERDDAP data request URL for this data subset is presented below.\nhttps://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\"\nThe following table shows the component parts of the ERDDAP data request URL.\n\n\n\n\n\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID for dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nformat of file to download (netCDF)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariable from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)]\nTemporal range (2021-01-01)\n\n\nspatial_range\n[(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\nY and X axes ranges\n\n\n\n\n\nGenerate the ERDDAP data query URL from its component parts\n\nbase_url = 'https://polarwatch.noaa.gov/erddap/griddap/'\ndatasetID = 'nsidcG02202v4nhmday'\nfile_type = '.nc'\nquery_start = '?'\nvariable_name = 'cdr_seaice_conc_monthly'\ndate_range = '[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)]'\nspatial_range = '[(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]'\n\nurl = ''.join([base_url,\n               datasetID,\n               file_type,\n               query_start,\n               variable_name,\n               date_range,\n               spatial_range\n               ])\nurl\n\n'https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]'\n\n\n\n\nDownload the data as a netCDF file and load file data into Python\n\n# Download the data from ERDDAP URL as a netCDF file\nurllib.request.urlretrieve(url, \"sic.nc\")\n\n# Open the netCDF file to create an xarray dataset object\nds = xr.open_dataset(\"sic.nc\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 1, ygrid: 389, xgrid: 304)\nCoordinates:\n  * time                     (time) datetime64[ns] 2021-01-01\n  * ygrid                    (ygrid) float32 4.838e+06 4.812e+06 ... -4.862e+06\n  * xgrid                    (xgrid) float32 -3.838e+06 -3.812e+06 ... 3.738e+06\nData variables:\n    cdr_seaice_conc_monthly  (time, ygrid, xgrid) float32 ...\nAttributes: (12/65)\n    acknowledgement:                                     This project was sup...\n    cdm_data_type:                                       Grid\n    cdr_variable:                                        cdr_seaice_conc_monthly\n    comment:                                             The variable melt_on...\n    contributor_name:                                    Walter N. Meier, Flo...\n    contributor_role:                                    principal investigat...\n    ...                                                  ...\n    summary:                                             This data set provid...\n    time_coverage_duration:                              P1M\n    time_coverage_end:                                   2021-01-01T00:00:00Z\n    time_coverage_resolution:                            P1M\n    time_coverage_start:                                 2021-01-01T00:00:00Z\n    title:                                               Sea Ice Concentratio...xarray.DatasetDimensions:time: 1ygrid: 389xgrid: 304Coordinates: (3)time(time)datetime64[ns]2021-01-01_ChunkSizes :1024_CoordinateAxisType :Timeactual_range :[1.6094592e+09 1.6094592e+09]axis :Tioos_category :Timelong_name :ANSI datestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2021-01-01T00:00:00.000000000'], dtype='datetime64[ns]')ygrid(ygrid)float324.838e+06 4.812e+06 ... -4.862e+06_ChunkSizes :448actual_range :[-4862500.  4837500.]axis :Yioos_category :Locationlong_name :projection_grid_y_centersstandard_name :projection_y_coordinateunits :metersvalid_range :[-5350000.  5850000.]array([ 4837500.,  4812500.,  4787500., ..., -4812500., -4837500., -4862500.],\n      dtype=float32)xgrid(xgrid)float32-3.838e+06 -3.812e+06 ... 3.738e+06_ChunkSizes :304actual_range :[-3837500.  3737500.]axis :Xioos_category :Locationlong_name :projection_grid_x_centersstandard_name :projection_x_coordinateunits :metersvalid_range :[-3850000.  3750000.]array([-3837500., -3812500., -3787500., ...,  3687500.,  3712500.,  3737500.],\n      dtype=float32)Data variables: (1)cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...ancillary_variables :stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthlycolorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole lakes coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Northern Hemisphere Sea Ice Concentrationreferences :https://nsidc.org/data/g02202/versions/4/standard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][118256 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2021-01-01'], dtype='datetime64[ns]', name='time', freq=None))ygridPandasIndexPandasIndex(Float64Index([ 4837500.0,  4812500.0,  4787500.0,  4762500.0,  4737500.0,\n               4712500.0,  4687500.0,  4662500.0,  4637500.0,  4612500.0,\n              ...\n              -4637500.0, -4662500.0, -4687500.0, -4712500.0, -4737500.0,\n              -4762500.0, -4787500.0, -4812500.0, -4837500.0, -4862500.0],\n             dtype='float64', name='ygrid', length=389))xgridPandasIndexPandasIndex(Float64Index([-3837500.0, -3812500.0, -3787500.0, -3762500.0, -3737500.0,\n              -3712500.0, -3687500.0, -3662500.0, -3637500.0, -3612500.0,\n              ...\n               3512500.0,  3537500.0,  3562500.0,  3587500.0,  3612500.0,\n               3637500.0,  3662500.0,  3687500.0,  3712500.0,  3737500.0],\n             dtype='float64', name='xgrid', length=304))Attributes: (65)acknowledgement :This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.cdm_data_type :Gridcdr_variable :cdr_seaice_conc_monthlycomment :The variable melt_onset_day_cdr_seaice_conc_monthly is not available for this month.contributor_name :Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fishercontributor_role :principal investigator, author, author, software developer, software developer, software developerConventions :CF-1.6, ACDD-1.3, COARDScreator_email :nsidc@nsidc.orgcreator_name :NSIDCcreator_type :institutioncreator_url :https://nsidc.org/date_created :2023-02-22T23:18:04ZdefaultGraphQuery :cdr_seaice_conc_monthly[last]%5B(-5337500.0)%5D%5B(3737500.0)%5D&.draw=surfacegrid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3850000.0 25000.0 0 5850000.0 0 -25000.0grid_mapping_grid_boundary_bottom_projected_y :-5350000.0grid_mapping_grid_boundary_left_projected_x :-3850000.0grid_mapping_grid_boundary_right_projected_x :3750000.0grid_mapping_grid_boundary_top_projected_y :5850000.0grid_mapping_latitude_of_projection_origin :90.0grid_mapping_longitude_of_projection_origin :-45.0grid_mapping_name :polar_stereographicgrid_mapping_parent_grid_cell_column_subset_end :304.0grid_mapping_parent_grid_cell_column_subset_start :0.0grid_mapping_parent_grid_cell_row_subset_end :448.0grid_mapping_parent_grid_cell_row_subset_start :0.0grid_mapping_proj4text :+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_scaling_factor :1.0grid_mapping_semimajor_radius :6378273.0grid_mapping_semiminor_radius :6356889.449grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3411\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3411grid_mapping_standard_parallel :70.0grid_mapping_straight_vertical_longitude_from_pole :135.0grid_mapping_units :metershistory :HISTORY_ATTRIBUTE\n2023-09-13T18:20:14Z (local files)\n2023-09-13T18:20:14Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]id :https://doi.org/10.7265/sr8p-kc62infoUrl :https://nsidc.org/data/g02202/versions/4/institution :NSIDC &gt; National Snow and Ice Data Centerkeywords :algorithm, america, arctic, area, atlantic, barents, bay, beaufort, bering, bootstrap, canada, cdr_seaice_conc_monthly, center, chukchi, climate, common, concentration, continent, CONTINENT &gt; NORTH AMERICA &gt; CANADA &gt; HUDSON BAY, Continent &gt; North America &gt; Canada &gt; Hudson Bay, cryosphere, data, davis, day, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Arctic, Geographic Region &gt; Northern Hemisphere, Geographic Region &gt; Polar, goddard, gsfc, gulf, hemisphere, hudson, ice, ice distribution, lawrence, mayen, melt, melt_onset_day_cdr_seaice_conc_monthly, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, north, northern, norwegian, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Arctic Ocean, Ocean &gt; Arctic Ocean &gt; Barents Sea, Ocean &gt; Arctic Ocean &gt; Beaufort Sea, Ocean &gt; Arctic Ocean &gt; Chukchi Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Davis Straight, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; GULF OF ST LAWRENCE, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; North Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Norwegian Sea, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; SVALBARD AND JAN MAYEN, Ocean &gt; Pacific Ocean, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Bering Sea, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Sea Of Okhotsk, oceans, okhotsk, onset, over, pacific, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, straight, svalbard, tdim, team, versionkeywords_vocabulary :GCMD Science Keywordslicense :No constraints on data access or usemetadata_link :https://nsidc.org/data/g02202/versions/4/naming_authority :org.doi.dxplatform :DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17processing_level :NOAA Level 3product_version :v04r00program :NOAA Climate Data Record Programproj_crs_code :EPSG:3411proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.project :NOAA/NSIDC passive microwave sea ice concentration climate data recordreferences :Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7): 15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1sensor :SSMI/S &gt; Special Sensor Microwave Imager/Soundersoftware_version_id :git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897source :ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220901_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220902_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220903_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220904_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220905_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220906_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220907_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220908_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220909_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220910_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220911_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220912_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220913_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220914_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220915_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220916_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220917_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220918_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220919_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220920_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220921_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220922_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220923_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220924_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220925_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220926_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220927_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220928_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220929_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220930_f17_v04r00.ncsourceUrl :(local files)spatial_resolution :25kmstandard_name_vocabulary :CF Standard Name Table v70summary :This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).time_coverage_duration :P1Mtime_coverage_end :2021-01-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2021-01-01T00:00:00Ztitle :Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\n\n\n\n\nDisplay the sea ice cover data as a map\nThe sea ice concentration values range from zero (no ice cover) to 1 (100% ice cover). However, this dataset also includes values above 1 to flag features like lakes, coastline, and land. Therefore, included in the code below is a step to remove those flag values from the mapping workflow.\n\nimg = ds['cdr_seaice_conc_monthly'].squeeze()\n\n# Remove flag values\nimg = img.where(img &lt;= 1)\n\n# Make plot area\nfig, ax = plt.subplots(figsize=(8, 10))\n\n# Set the color palette\ncmap = mpl.cm.get_cmap(\"Blues_r\").copy()\ncmap.set_bad(color='gray')\n\n# show image\nshw = ax.imshow(img, cmap=cmap, vmin=0, vmax=1)\n\n# Make the colorbar\nbar = plt.colorbar(shw, shrink=0.75)\n\n# show plot with labels\nplt.xlabel('X Grid (m)')\nplt.ylabel('Y Grid (m)')\nbar.set_label('Sea Ice Cover (fractional coverage)')\nplt.show()"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#get-area-information-from-the-ancillary-grid-dataset",
    "href": "tutorials/python/calculating-sea-ice-extent.html#get-area-information-from-the-ancillary-grid-dataset",
    "title": "Calculating sea ice area and extent",
    "section": "Get area information from the ancillary grid dataset",
    "text": "Get area information from the ancillary grid dataset\nWhile the resolution of this data set is 25km (25km by 25km grid), the actual area of the grid depends on the grid projection. To obtain area value, we will need to:\n* Subset the Polar Stereographic Ancillary Grid Information dataset to match our SIC dataset and * Extract the area values for each grid cell.\n\nAccess the Ancillary Grid with OPeNDAP web services\nERDDAP allows you to access data using OPeNDAP web services. The OPeNDAP protocol allows you to create the xarray dataset object directly from the remote server, without downloading a data file onto your computer. When you request the subset of the dataset (e.g. the sub_area object below), the data are uploaded directly into an xarray data array.\n\n# Open xarray dataset object via an OPeNDAP connection\ngrid_url = 'https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k'\ngrid_area = xr.open_dataset(grid_url)\n\n# Subset grid area to match SIC data grids\nsub_area = grid_area.sel(x=slice(ds['xgrid'].min(), ds['xgrid'].max()),\n                         y=slice(ds['ygrid'].max(), ds['ygrid'].min())\n                         )\nsub_area\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:    (y: 389, x: 304)\nCoordinates:\n  * y          (y) float64 4.838e+06 4.812e+06 ... -4.838e+06 -4.862e+06\n  * x          (x) float64 -3.838e+06 -3.812e+06 ... 3.712e+06 3.738e+06\nData variables:\n    cell_area  (y, x) float64 ...\nAttributes: (12/52)\n    acknowledgement:                                     These data are produ...\n    cdm_data_type:                                       Grid\n    contributor_name:                                    J. Scott Stewart, Wa...\n    contributor_role:                                    Scientific Programme...\n    Conventions:                                         CF-1.6, ACDD-1.3, CO...\n    creator_name:                                        NASA National Snow a...\n    ...                                                  ...\n    publisher_type:                                      institution\n    publisher_url:                                       https://nsidc.org/daac\n    sourceUrl:                                           (local files)\n    standard_name_vocabulary:                            CF Standard Name Tab...\n    summary:                                             This data set provid...\n    title:                                               Polar Stereographic ...xarray.DatasetDimensions:y: 389x: 304Coordinates: (2)y(y)float644.838e+06 4.812e+06 ... -4.862e+06actual_range :[-5337500.  5837500.]axis :Yioos_category :Locationlong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metersvalid_range :[-5350000.  5850000.]array([ 4837500.,  4812500.,  4787500., ..., -4812500., -4837500., -4862500.])x(x)float64-3.838e+06 -3.812e+06 ... 3.738e+06actual_range :[-3837500.  3737500.]axis :Xioos_category :Locationlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metersvalid_range :[-3850000.  3750000.]array([-3837500., -3812500., -3787500., ...,  3687500.,  3712500.,  3737500.])Data variables: (1)cell_area(y, x)float64...colorBarMaximum :700000000.0colorBarMinimum :300000000.0comment :Surface area of grid cellcoverage_content_type :imageioos_category :Unknownlong_name :Grid Cell areastandard_name :cell_areaunits :meters^2valid_range :[3.82658854e+08 6.64448303e+08][118256 values with dtype=float64]Indexes: (2)yPandasIndexPandasIndex(Float64Index([ 4837500.0,  4812500.0,  4787500.0,  4762500.0,  4737500.0,\n               4712500.0,  4687500.0,  4662500.0,  4637500.0,  4612500.0,\n              ...\n              -4637500.0, -4662500.0, -4687500.0, -4712500.0, -4737500.0,\n              -4762500.0, -4787500.0, -4812500.0, -4837500.0, -4862500.0],\n             dtype='float64', name='y', length=389))xPandasIndexPandasIndex(Float64Index([-3837500.0, -3812500.0, -3787500.0, -3762500.0, -3737500.0,\n              -3712500.0, -3687500.0, -3662500.0, -3637500.0, -3612500.0,\n              ...\n               3512500.0,  3537500.0,  3562500.0,  3587500.0,  3612500.0,\n               3637500.0,  3662500.0,  3687500.0,  3712500.0,  3737500.0],\n             dtype='float64', name='x', length=304))Attributes: (52)acknowledgement :These data are produced and supported by the NASA National Snow and Ice Data Center Distributed Active Archive Center.cdm_data_type :Gridcontributor_name :J. Scott Stewart, Walter N. Meier, Donna J. Scottcontributor_role :Scientific Programmer, Project Scientist, Project LeadConventions :CF-1.6, ACDD-1.3, COARDScreator_name :NASA National Snow and Ice Data Center Distributed Active Archive Centercreator_type :groupcreator_url :https://www.nasa.gov/date_created :2022-03-21date_metadata_modified :2022-03-21date_modified :2022-03-21geospatial_bounds :POLYGON ((-3850000 5850000, 3750000 5850000, 3750000 -5350000, -3850000 -5350000, -3850000 5850000))geospatial_bounds_crs :EPSG:3411geospatial_x_resolution :25000 metersgeospatial_x_units :metersgeospatial_y_resolution :25000 metersgeospatial_y_units :metersgrid_mapping_crs_wkt :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],AUTHORITY[\"EPSG\",\"3411\"]]grid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3850000 25000 0 5850000 0 -25000grid_mapping_inverse_flattening :298.279411123064grid_mapping_latitude_of_projection_origin :90.0grid_mapping_long_name :NSIDC_NH_PolarStereo_25kmgrid_mapping_longitude_of_prime_meridian :0.0grid_mapping_name :polar_stereographicgrid_mapping_proj4text :+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_semi_major_axis :6378273.0grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],AUTHORITY[\"EPSG\",\"3411\"]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3411grid_mapping_standard_parallel :70.0grid_mapping_straight_vertical_longitude_from_pole :-45.0history :2023-09-13T18:20:35Z (local files)\n2023-09-13T18:20:35Z https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k.dasid :10.5067/N6INPBT8Y104infoUrl :https://doi.org/10.5067/N6INPBT8Y104institution :NASA National Snow and Ice Data Center Distributed Active Archive Centerkeywords :active, analysis, ancillary, archive, area, cell, cell_area, center, data, distributed, earth, EARTH SCIENCE SERVICES &gt; DATA ANALYSIS AND VISUALIZATION &gt; GEOGRAPHIC INFORMATION SYSTEMS, geographic, grid, ice, information, nasa, national, nsidc, polar, science, services, snow, stereo, systems, visualizationkeywords_vocabulary :GCMD Science Keywordslicense :Access Constraint: These data are freely, openly, and fully accessible, provided that you are logged into your NASA Earthdata profile (https://urs.earthdata.nasa.gov/);  Use Constraint: These data are freely, openly, and fully available to use without restrictions, provided that you cite the data according to the recommended citation at https://nsidc.org/about/use_copyright.html. For more information on the NASA EOSDIS Data Use Policy, see https://earthdata.nasa.gov/earth-observation-data/data-use-policy.metadata_link :https://doi.org/10.5067/N6INPBT8Y104naming_authority :org.doi.dxproduct_version :1.0program :NASA Earth Science Data and Information System (ESDIS)publisher_email :nsidc@nsidc.orgpublisher_institution :National Snow and Ice Data Center; Cooperative Institute for Research in Environmental Sciences; University of Colorado at Boulder; Boulder, COpublisher_name :NASA National Snow and Ice Data Center Distributed Active Archive Centerpublisher_type :institutionpublisher_url :https://nsidc.org/daacsourceUrl :(local files)standard_name_vocabulary :CF Standard Name Table v70summary :This data set provides the total on-Earth surface area values at the center of each grid cell of 25km polar stereographic gridded data sets (North) distributed by The National Snow and Ice Data Centertitle :Polar Stereographic Grid Cell Area Values of 25km gridded data sets , Polar Stereographic (North), Ancillary Data\n\n\n\n\nCombine the subsetted grid to the SIC dataset\nAdd subsetted area values from grid_area dataset as a new layer in the sea ice concentration dataset.\n\n# Add agrid area to the dataset\nds['area'] = (('ygrid', 'xgrid'), sub_area.cell_area.values)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 1, ygrid: 389, xgrid: 304)\nCoordinates:\n  * time                     (time) datetime64[ns] 2021-01-01\n  * ygrid                    (ygrid) float32 4.838e+06 4.812e+06 ... -4.862e+06\n  * xgrid                    (xgrid) float32 -3.838e+06 -3.812e+06 ... 3.738e+06\nData variables:\n    cdr_seaice_conc_monthly  (time, ygrid, xgrid) float32 ...\n    area                     (ygrid, xgrid) float64 4.266e+08 ... 4.289e+08\nAttributes: (12/65)\n    acknowledgement:                                     This project was sup...\n    cdm_data_type:                                       Grid\n    cdr_variable:                                        cdr_seaice_conc_monthly\n    comment:                                             The variable melt_on...\n    contributor_name:                                    Walter N. Meier, Flo...\n    contributor_role:                                    principal investigat...\n    ...                                                  ...\n    summary:                                             This data set provid...\n    time_coverage_duration:                              P1M\n    time_coverage_end:                                   2021-01-01T00:00:00Z\n    time_coverage_resolution:                            P1M\n    time_coverage_start:                                 2021-01-01T00:00:00Z\n    title:                                               Sea Ice Concentratio...xarray.DatasetDimensions:time: 1ygrid: 389xgrid: 304Coordinates: (3)time(time)datetime64[ns]2021-01-01_ChunkSizes :1024_CoordinateAxisType :Timeactual_range :[1.6094592e+09 1.6094592e+09]axis :Tioos_category :Timelong_name :ANSI datestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2021-01-01T00:00:00.000000000'], dtype='datetime64[ns]')ygrid(ygrid)float324.838e+06 4.812e+06 ... -4.862e+06_ChunkSizes :448actual_range :[-4862500.  4837500.]axis :Yioos_category :Locationlong_name :projection_grid_y_centersstandard_name :projection_y_coordinateunits :metersvalid_range :[-5350000.  5850000.]array([ 4837500.,  4812500.,  4787500., ..., -4812500., -4837500., -4862500.],\n      dtype=float32)xgrid(xgrid)float32-3.838e+06 -3.812e+06 ... 3.738e+06_ChunkSizes :304actual_range :[-3837500.  3737500.]axis :Xioos_category :Locationlong_name :projection_grid_x_centersstandard_name :projection_x_coordinateunits :metersvalid_range :[-3850000.  3750000.]array([-3837500., -3812500., -3787500., ...,  3687500.,  3712500.,  3737500.],\n      dtype=float32)Data variables: (2)cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...ancillary_variables :stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthlycolorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole lakes coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Northern Hemisphere Sea Ice Concentrationreferences :https://nsidc.org/data/g02202/versions/4/standard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][118256 values with dtype=float32]area(ygrid, xgrid)float644.266e+08 4.274e+08 ... 4.289e+08array([[4.26553150e+08, 4.27406844e+08, 4.28257483e+08, ...,\n        4.31628701e+08, 4.30790677e+08, 4.29949439e+08],\n       [4.27630452e+08, 4.28487364e+08, 4.29341214e+08, ...,\n        4.32725186e+08, 4.31883987e+08, 4.31039565e+08],\n       [4.28706202e+08, 4.29566333e+08, 4.30423392e+08, ...,\n        4.33820117e+08, 4.32975743e+08, 4.32128138e+08],\n       ...,\n       [4.27630452e+08, 4.28487364e+08, 4.29341214e+08, ...,\n        4.32725186e+08, 4.31883987e+08, 4.31039565e+08],\n       [4.26553150e+08, 4.27406844e+08, 4.28257483e+08, ...,\n        4.31628701e+08, 4.30790677e+08, 4.29949439e+08],\n       [4.25474341e+08, 4.26324815e+08, 4.27172243e+08, ...,\n        4.30530704e+08, 4.29695856e+08, 4.28857803e+08]])Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2021-01-01'], dtype='datetime64[ns]', name='time', freq=None))ygridPandasIndexPandasIndex(Float64Index([ 4837500.0,  4812500.0,  4787500.0,  4762500.0,  4737500.0,\n               4712500.0,  4687500.0,  4662500.0,  4637500.0,  4612500.0,\n              ...\n              -4637500.0, -4662500.0, -4687500.0, -4712500.0, -4737500.0,\n              -4762500.0, -4787500.0, -4812500.0, -4837500.0, -4862500.0],\n             dtype='float64', name='ygrid', length=389))xgridPandasIndexPandasIndex(Float64Index([-3837500.0, -3812500.0, -3787500.0, -3762500.0, -3737500.0,\n              -3712500.0, -3687500.0, -3662500.0, -3637500.0, -3612500.0,\n              ...\n               3512500.0,  3537500.0,  3562500.0,  3587500.0,  3612500.0,\n               3637500.0,  3662500.0,  3687500.0,  3712500.0,  3737500.0],\n             dtype='float64', name='xgrid', length=304))Attributes: (65)acknowledgement :This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.cdm_data_type :Gridcdr_variable :cdr_seaice_conc_monthlycomment :The variable melt_onset_day_cdr_seaice_conc_monthly is not available for this month.contributor_name :Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fishercontributor_role :principal investigator, author, author, software developer, software developer, software developerConventions :CF-1.6, ACDD-1.3, COARDScreator_email :nsidc@nsidc.orgcreator_name :NSIDCcreator_type :institutioncreator_url :https://nsidc.org/date_created :2023-02-22T23:18:04ZdefaultGraphQuery :cdr_seaice_conc_monthly[last]%5B(-5337500.0)%5D%5B(3737500.0)%5D&.draw=surfacegrid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3850000.0 25000.0 0 5850000.0 0 -25000.0grid_mapping_grid_boundary_bottom_projected_y :-5350000.0grid_mapping_grid_boundary_left_projected_x :-3850000.0grid_mapping_grid_boundary_right_projected_x :3750000.0grid_mapping_grid_boundary_top_projected_y :5850000.0grid_mapping_latitude_of_projection_origin :90.0grid_mapping_longitude_of_projection_origin :-45.0grid_mapping_name :polar_stereographicgrid_mapping_parent_grid_cell_column_subset_end :304.0grid_mapping_parent_grid_cell_column_subset_start :0.0grid_mapping_parent_grid_cell_row_subset_end :448.0grid_mapping_parent_grid_cell_row_subset_start :0.0grid_mapping_proj4text :+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_scaling_factor :1.0grid_mapping_semimajor_radius :6378273.0grid_mapping_semiminor_radius :6356889.449grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3411\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3411grid_mapping_standard_parallel :70.0grid_mapping_straight_vertical_longitude_from_pole :135.0grid_mapping_units :metershistory :HISTORY_ATTRIBUTE\n2023-09-13T18:20:14Z (local files)\n2023-09-13T18:20:14Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]id :https://doi.org/10.7265/sr8p-kc62infoUrl :https://nsidc.org/data/g02202/versions/4/institution :NSIDC &gt; National Snow and Ice Data Centerkeywords :algorithm, america, arctic, area, atlantic, barents, bay, beaufort, bering, bootstrap, canada, cdr_seaice_conc_monthly, center, chukchi, climate, common, concentration, continent, CONTINENT &gt; NORTH AMERICA &gt; CANADA &gt; HUDSON BAY, Continent &gt; North America &gt; Canada &gt; Hudson Bay, cryosphere, data, davis, day, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Arctic, Geographic Region &gt; Northern Hemisphere, Geographic Region &gt; Polar, goddard, gsfc, gulf, hemisphere, hudson, ice, ice distribution, lawrence, mayen, melt, melt_onset_day_cdr_seaice_conc_monthly, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, north, northern, norwegian, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Arctic Ocean, Ocean &gt; Arctic Ocean &gt; Barents Sea, Ocean &gt; Arctic Ocean &gt; Beaufort Sea, Ocean &gt; Arctic Ocean &gt; Chukchi Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Davis Straight, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; GULF OF ST LAWRENCE, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; North Sea, Ocean &gt; Atlantic Ocean &gt; North Atlantic Ocean &gt; Norwegian Sea, OCEAN &gt; ATLANTIC OCEAN &gt; NORTH ATLANTIC OCEAN &gt; SVALBARD AND JAN MAYEN, Ocean &gt; Pacific Ocean, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Bering Sea, Ocean &gt; Pacific Ocean &gt; North Pacific Ocean &gt; Sea Of Okhotsk, oceans, okhotsk, onset, over, pacific, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, straight, svalbard, tdim, team, versionkeywords_vocabulary :GCMD Science Keywordslicense :No constraints on data access or usemetadata_link :https://nsidc.org/data/g02202/versions/4/naming_authority :org.doi.dxplatform :DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17processing_level :NOAA Level 3product_version :v04r00program :NOAA Climate Data Record Programproj_crs_code :EPSG:3411proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.project :NOAA/NSIDC passive microwave sea ice concentration climate data recordreferences :Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7): 15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1sensor :SSMI/S &gt; Special Sensor Microwave Imager/Soundersoftware_version_id :git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897source :ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220901_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220902_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220903_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220904_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220905_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220906_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220907_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220908_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220909_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220910_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220911_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220912_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220913_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220914_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220915_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220916_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220917_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220918_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220919_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220920_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220921_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220922_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220923_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220924_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220925_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220926_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220927_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220928_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220929_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/north/daily/2022/seaice_conc_daily_nh_20220930_f17_v04r00.ncsourceUrl :(local files)spatial_resolution :25kmstandard_name_vocabulary :CF Standard Name Table v70summary :This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).time_coverage_duration :P1Mtime_coverage_end :2021-01-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2021-01-01T00:00:00Ztitle :Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#compute-sea-ice-area-and-extent",
    "href": "tutorials/python/calculating-sea-ice-extent.html#compute-sea-ice-area-and-extent",
    "title": "Calculating sea ice area and extent",
    "section": "Compute sea ice area and extent",
    "text": "Compute sea ice area and extent\nAlthough area and extent may sound the same, they are different measurements. * Sea ice area is the total region covered by ice, i.e. area that is 100% covered by ice. * Sea ice extent is the total region with at least 15 percent sea ice cover.\nTherefore, extent will give higher values than area.\n\n# Subset the dataset to exclude flag values (value &gt; 1)\nseaice_ds = ds.where(ds.cdr_seaice_conc_monthly &lt;= 1)\n\n# Set all cell with &lt; 15% ice cover to zero\n# Leave the other cells unchanged\ncells_15ice_andup = xr.where(seaice_ds.cdr_seaice_conc_monthly.squeeze() &lt; 0.15, \n                             0,  # Set to 0\n                             seaice_ds.cdr_seaice_conc_monthly.squeeze()   # Set to 1\n                             )\n\n# Calculate sea ice area\nicearea = seaice_ds.area * cells_15ice_andup\n\n# Convert the units from m^2 to km^2\nicearea_km = np.sum(icearea) / 1000000\nprint(\"Sea Ice Area (km^2): \", icearea_km.item())\n\n# Compute sea ice extent\n# Find all cells with &lt; 0.15 ice cover and set to 0, Set all other cells to 1\ncells_15ice_andup = xr.where(seaice_ds.cdr_seaice_conc_monthly.squeeze() &lt; 0.15,\n                             0,  # Set to 0\n                             1  # Set to 1\n                             )\n\n# Calculate sea ice extent\nextent = seaice_ds.area * cells_15ice_andup\nextent_km = np.sum(extent)/1000000\nprint(\"Sea Ice Extent (km^2):\", extent_km.item())\n\nSea Ice Area (km^2):  12528341.191722928\nSea Ice Extent (km^2): 13808725.557170859"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#create-a-time-series-with-12-months-of-data",
    "href": "tutorials/python/calculating-sea-ice-extent.html#create-a-time-series-with-12-months-of-data",
    "title": "Calculating sea ice area and extent",
    "section": "Create a time series with 12 months of data",
    "text": "Create a time series with 12 months of data\n\nFor the next exercise, download 12 months of SIC data from 2021. Then, compute sea ice area and extent for each month and plot the time series.\nThe first step is to change our ERDDAP data query URL to request the 12 month time period. To do this, change the second part of the Time coverage component of the URL December of 2021 (see the table below).\n\n\n\n\n\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID for dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nNetCDF (there are many other available file formats)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariables from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]\nTemporal range\n\n\nspatial_range\n[(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\nSpatial range\n\n\n\nThe modified ERDDAP data request URL for this data subset is presented below:\nurl=“https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:( 2021-12-01T00:00:00Z )][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]\nWe can generate the URL quickly by changing the “date_range” variable\n* From: date_range = '[(2021-01-01T00:00:00Z):1:(2021-01-01T00:00:00Z)]'\n* To: date_range = '[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]'\nThen rerunning the code to generate the ERDDAP data query URL.\n\ndate_range = '[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]'\n\nurl = ''.join([base_url,\n               datasetID,\n               file_type,\n               query_start,\n               variable_name,\n               date_range,\n               spatial_range\n               ])\nurl\n\n'https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(4843696.04):1:(-4858210.64)][(-3850000.0):1:(3750000.0)]'\n\n\n\n\nGenerate the sea ice area and extent time series\n\n# Download 12 months of data\nurllib.request.urlretrieve(url, \"sic12.nc\")\n\n# Open the netCDF file to create an Xarray dataset object\nds = xr.open_dataset(\"sic12.nc\")\n\n# Add grid area to the dataset\ncell_area = sub_area.cell_area.values\nds['area'] = (('ygrid', 'xgrid'), cell_area)\n\n# Subset the dataset to exclude flag values\nseaice_ds = ds.where(ds.cdr_seaice_conc_monthly &lt;= 1)\n\n# Find all cells with &lt; 0.15 ice cover and set to 0.\n# Leave the other cells unchanged\ncells_15ice_andup_ts = xr.where(seaice_ds.cdr_seaice_conc_monthly &lt; 0.15, \n                                0,  # Set to 0\n                                seaice_ds.cdr_seaice_conc_monthly\n                                )\n\n# Calculate sea ice area for each time layer\nicearea_timeseries = seaice_ds.area * cells_15ice_andup_ts\n\n# Sum area for each time step and convert to km^2\nicearea_timeseries_km = icearea_timeseries.sum(dim=['xgrid', 'ygrid']) / 1000000\n\n# Find all cells with &lt; 0.15 ice cover and set to 0. Set all other cells to 1\ncells_15ice_andup_ts = xr.where(seaice_ds.cdr_seaice_conc_monthly &lt; 0.15,\n                                0,  # Set to 0\n                                1  # Set to 1\n                                )\n\n# Calculate sea ice extent by month\nextent_timeseries = seaice_ds.area * cells_15ice_andup_ts\n\n# # Sum extent for each time step and convert units to km^2\nextent_timeseries_km = extent_timeseries.sum(dim=['xgrid', 'ygrid']) / 1000000\n\n\n\nPlot the sea ice area and extent time series\n\n\nfig, ax = plt.subplots(figsize=(10, 4))\n\n# Plot the data as a line\nax.plot(icearea_timeseries_km.time, \n        icearea_timeseries_km,\n        label='Sea ice area',\n        marker='o', \n        linestyle='-')\n\nax.plot(extent_timeseries_km.time,\n        extent_timeseries_km,\n        label='Sea ice extent',\n        marker='s', \n        linestyle='-')\n\n# Add a title and labels\nax.set_title('2021 Monthly Sea ice area and sea ice extent')\nax.set_xlabel('Date')\nax.set_ylabel('Area (km^2)')\n\n# Display the legend\nax.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "tutorials/python/calculating-sea-ice-extent.html#references",
    "href": "tutorials/python/calculating-sea-ice-extent.html#references",
    "title": "Calculating sea ice area and extent",
    "section": "References",
    "text": "References\n\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nPolarWatch Data Catalog\nWhat’s the difference between Sea ice area and extent?\nNSIDC Arctic Sea Ice News & Analysis\nClimate.gov Understanding Climate: sea ice extent\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html",
    "href": "tutorials/python/Tutorial1-basics.html",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "",
    "text": "History | Updated August 2023"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#objective",
    "href": "tutorials/python/Tutorial1-basics.html#objective",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab data hosted on an ERDDAP server from Python, how to work with NetCDF files in Python and how to make some maps and time-series of sea surface temperature."
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nLocating a satellite product in ERDDAP, manually changing the constraints and copying the URL defining the data request\nDownloading the resulting netCDF file\nOpening and examining the netCDF file\nMaking basic maps and time series plots"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#datasets-used",
    "href": "tutorials/python/Tutorial1-basics.html#datasets-used",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Datasets used",
    "text": "Datasets used\nCoralTemp Sea Surface Temperature product from the NOAA Coral Reef Watch program. The NOAA Coral Reef Watch (CRW) daily global 5km Sea Surface Temperature (SST) product, also known as CoralTemp, shows the nighttime ocean temperature measured at the surface. The SST scale ranges from -2 to 35 °C. The CoralTemp SST data product was developed from two, related reanalysis (reprocessed) SST products and a near real-time SST product. Spanning January 1, 1985 to the present, the CoralTemp SST is one of the best and most internally consistent daily global 5km SST products available. More information about the product: https://coralreefwatch.noaa.gov/product/5km/index_5km_sst.php\nWe will use the monthly composite of this product and download it from the NOAA CoastWatch ERDDAP server: https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.graph"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#import-python-modules",
    "href": "tutorials/python/Tutorial1-basics.html#import-python-modules",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Import Python modules",
    "text": "Import Python modules\n\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#download-data-from-erddap-using-python",
    "href": "tutorials/python/Tutorial1-basics.html#download-data-from-erddap-using-python",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "1. Download data from ERDDAP using Python",
    "text": "1. Download data from ERDDAP using Python\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure.\nFor example, the following page allows you to subset monthly sea surface temperature (SST) https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html\n\n\n\nerddap.png\n\n\n\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\nIn this specific example, the URL we generated is :\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D\n\n\nWith Python, run the following to download the data using the generated URL .\n\n# Below we have broken the url into parts and rejoin the them\n# to allow you to better see the url in the notebook.\nurl = ''.join(['https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?',\n               'sea_surface_temperature',\n               '%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D',\n               '%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D'\n               ])\n\nurllib.request.urlretrieve(url, \"sst.nc\")\n\n('sst.nc', &lt;http.client.HTTPMessage at 0x1ac0e35b0&gt;)"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#loading-netcdf4-data-into-python",
    "href": "tutorials/python/Tutorial1-basics.html#loading-netcdf4-data-into-python",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "2. Loading netCDF4 data into Python",
    "text": "2. Loading netCDF4 data into Python\nNow that we’ve downloaded the data locally, we can load it into Python and extract the variables of interest.\nThe xarray package makes it very convenient to work with NetCDF files. Documentation is available here: http://xarray.pydata.org/en/stable/why-xarray.html\n\nOpen the netCDF file as an xarray dataset object and examine the data structure.\n\nds = xr.open_dataset('sst.nc', decode_cf=True)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                  (time: 12, latitude: 202, longitude: 201)\nCoordinates:\n  * time                     (time) datetime64[ns] 2022-01-16 ... 2022-12-16\n  * latitude                 (latitude) float32 40.03 39.97 ... 30.02 29.98\n  * longitude                (longitude) float32 -80.02 -79.97 ... -70.07 -70.02\nData variables:\n    sea_surface_temperature  (time, latitude, longitude) float32 ...\nAttributes: (12/65)\n    acknowledgement:                  NOAA Coral Reef Watch program\n    cdm_data_type:                    Grid\n    comment:                          This is a product of NOAA Coral Reef Wa...\n    contributor_name:                 NOAA Coral Reef Watch program\n    contributor_role:                 Collecting source data and deriving pro...\n    Conventions:                      CF-1.6, ACDD-1.3, COARDS\n    ...                               ...\n    time_coverage_duration:           P1M\n    time_coverage_end:                2022-12-16T00:00:00Z\n    time_coverage_resolution:         P1M\n    time_coverage_start:              2022-01-16T00:00:00Z\n    title:                            SST and SST Anomaly, NOAA Global Coral ...\n    Westernmost_Easting:              -80.024994xarray.DatasetDimensions:time: 12latitude: 202longitude: 201Coordinates: (3)time(time)datetime64[ns]2022-01-16 ... 2022-12-16_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3240.03 39.97 39.93 ... 30.02 29.98_CoordinateAxisType :Latactual_range :[29.975004 40.025   ]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([40.025   , 39.975   , 39.92501 , ..., 30.075003, 30.025   , 29.975004],\n      dtype=float32)longitude(longitude)float32-80.02 -79.97 ... -70.07 -70.02_CoordinateAxisType :Lonactual_range :[-80.024994 -70.024994]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-80.024994, -79.975   , -79.924995, ..., -70.125   , -70.075   ,\n       -70.024994], dtype=float32)Data variables: (1)sea_surface_temperature(time, latitude, longitude)float32...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[487224 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-16', '2022-02-16', '2022-03-16', '2022-04-16',\n               '2022-05-16', '2022-06-16', '2022-07-16', '2022-08-16',\n               '2022-09-16', '2022-10-16', '2022-11-16', '2022-12-16'],\n              dtype='datetime64[ns]', name='time', freq=None))latitudePandasIndexPandasIndex(Index([40.025001525878906, 39.974998474121094, 39.925010681152344,\n        39.87500762939453,  39.82500457763672, 39.775001525878906,\n       39.724998474121094, 39.675010681152344,  39.62500762939453,\n        39.57500457763672,\n       ...\n        30.42500114440918, 30.374998092651367, 30.325002670288086,\n       30.274999618530273, 30.225004196166992,  30.17500114440918,\n       30.124998092651367, 30.075002670288086, 30.024999618530273,\n       29.975004196166992],\n      dtype='float32', name='latitude', length=202))longitudePandasIndexPandasIndex(Index([-80.02499389648438,  -79.9749984741211, -79.92499542236328,\n                  -79.875, -79.82499694824219, -79.77499389648438,\n        -79.7249984741211, -79.67499542236328,            -79.625,\n       -79.57499694824219,\n       ...\n        -70.4749984741211, -70.42499542236328,            -70.375,\n       -70.32499694824219, -70.27499389648438,  -70.2249984741211,\n       -70.17499542236328,            -70.125, -70.07499694824219,\n       -70.02499389648438],\n      dtype='float32', name='longitude', length=201))Attributes: (65)acknowledgement :NOAA Coral Reef Watch programcdm_data_type :Gridcomment :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite Version 3.1, derived from CoralTemp v1.0.contributor_name :NOAA Coral Reef Watch programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archive.Conventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch programcreator_name :NOAA Coral Reef Watch programcreator_type :groupcreator_url :https://coralreefwatch.noaa.govdate_created :2018-03-01T12:00:00Zdate_issued :2019-01-19T20:32:23Zdate_metadata_modified :2018-09-01T12:00:00Zdate_modified :2018-03-01T12:00:00ZEasternmost_Easting :-70.024994geospatial_bounds :POLYGON((-90.0 180.0, 90.0 180.0, 90.0 -180.0, -90.0 -180.0, -90.0 180.0))geospatial_bounds_crs :EPSG:4326geospatial_lat_max :40.025geospatial_lat_min :29.975004geospatial_lat_units :degrees_northgeospatial_lon_max :-70.024994geospatial_lon_min :-80.024994geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:32663grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Tue Jul 27 10:37:54 2021: ncrename -d lon,longitude -d lat,latitude -v lon,longitude -v lat,latitude -v sea surface temperature anomaly,sea_surface_temperature_anomaly /cwdata/coralreef/work/temp.nc\nMonthly data files for mean sea surface temperature (SST) and sea surface temperature anomaly (SST anomaly) were downloaded from ftp.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1/nc/v1.0/monthly. Monthly files were created that contain both SST and SST anomaly data, and a mask of earth surface classifications.\n2023-09-06T14:23:22Z (local files)\n2023-09-06T14:23:22Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5Did :Satellite_Global_5km_CoralTemp_SST_SSTA_Monthly_Mean_CompositeinfoUrl :https://coralreefwatch.noaa.gov/product/5km/index.phpinstitution :NOAA/NESDIS/STAR Coral Reef Watch programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, anomaly, array, characteristics, coral, crw, data, earth, Earth Science &gt; Land Surface &gt; Land Temperature &gt; Land Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature Anomaly, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, flag, global, information, infrared, land, latitude, longitude, mask, mean, month, monthly, national, nesdis, noaa, ocean, oceans, pixel, program, quality, reef, satellite, science, sea, sea_surface_temperature, sea_surface_temperature_anomaly, seawater, service, spectral, spectral/engineering, sst, star, surface, surface_temperature_anomaly, temperature, thermal, time, v.3.1, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of the Coral Reef Watch website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/product/5km/index.phpnaming_authority :gov.noaa.coralreefwatchNCO :\"4.6.3\"Northernmost_Northing :40.025platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :Derived from L4 satellite sea surface temperature analysisproduct_version :3.1program :NOAA Coral Reef Watch programproject :NOAA Coral Reef Watch programpublisher_email :erd.data at noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch programpublisher_name :NOAA NMFS SWFSC ERD, CoastWatch West Coast Nodepublisher_type :institutionpublisher_url :https://coralreefwatch.noaa.gov, https://coastwatch.pfeg.noaa.gov/references :https://coralreefwatch.noaa.gov/product/5km/index.php and https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :Coral Reef Watch CoralTemp v1.0sourceUrl :(local files)Southernmost_Northing :29.975004spatial_resolution :0.05 degreestandard_name_vocabulary :CF Standard Name Table v27summary :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite, derived from CoralTemp v1.0.time_coverage_duration :P1Mtime_coverage_end :2022-12-16T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :2022-01-16T00:00:00Ztitle :SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring, 5km, V.3.1, Monthly, 1985-PresentWesternmost_Easting :-80.024994\n\n\n\n\nExamine which coordinates and variables are included in the dataset.\n\n# List the coordinates\nprint('The coordinates variables:', list(ds.coords), '\\n')\n\n# List the data variables\nprint('The data variables:', list(ds.data_vars))\n\nThe coordinates variables: ['time', 'latitude', 'longitude'] \n\nThe data variables: ['sea_surface_temperature']\n\n\n\n\nExamine the structure of sea_surface_temperature.\n\nds.sea_surface_temperature.shape\n\n(12, 202, 201)\n\n\nThe dataset is a 3-D array with 12 time steps, each with 202 rows corresponding to latitudes and 201 columns corresponding to longitudes.\n\n\nList the dates for each time step.\nThe dataset has 12 time steps, one for each month between January 2022 and December 2022.\n\nds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 12)&gt;\narray(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 2022-01-16 2022-02-16 ... 2022-12-16\nAttributes:\n    _CoordinateAxisType:    Time\n    actual_range:           [1.6422912e+09 1.6711488e+09]\n    axis:                   T\n    coverage_content_type:  coordinate\n    ioos_category:          Time\n    long_name:              reference time of the last day of the composite t...\n    standard_name:          time\n    time_origin:            01-JAN-1970 00:00:00xarray.DataArray'time'time: 122022-01-16 2022-02-16 2022-03-16 ... 2022-10-16 2022-11-16 2022-12-16array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2022-01-16 ... 2022-12-16_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-16T00:00:00.000000000', '2022-02-16T00:00:00.000000000',\n       '2022-03-16T00:00:00.000000000', '2022-04-16T00:00:00.000000000',\n       '2022-05-16T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-08-16T00:00:00.000000000',\n       '2022-09-16T00:00:00.000000000', '2022-10-16T00:00:00.000000000',\n       '2022-11-16T00:00:00.000000000', '2022-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-16', '2022-02-16', '2022-03-16', '2022-04-16',\n               '2022-05-16', '2022-06-16', '2022-07-16', '2022-08-16',\n               '2022-09-16', '2022-10-16', '2022-11-16', '2022-12-16'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (8)_CoordinateAxisType :Timeactual_range :[1.6422912e+09 1.6711488e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00\n\n\n\n\nExamine the latitude coordinate variable\nTypically, the latitude coordinate variable will be in ascending order. However, in some datasets the order is reversed, i.e the order is descending.\nBy examining the first and last values on our latitude array (below), we can see that the values are descending.\n* In practice what this means is that when you slice (subset) using latitude later in this tutorial, you will put the largest latitude value first.\n\nprint('First latitude value', ds.latitude[0].item())\nprint('Last latitude value', ds.latitude[-1].item())\n\nFirst latitude value 40.025001525878906\nLast latitude value 29.975004196166992"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#working-with-the-data",
    "href": "tutorials/python/Tutorial1-basics.html#working-with-the-data",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "3. Working with the data",
    "text": "3. Working with the data\n\nCreating a map for for January 2022 (our first time step)\n\nFind the minimum and maximum SST values.\n\nprint('Minimum SST', np.nanmin(ds.sea_surface_temperature))\nprint('Maximum SST', np.nanmax(ds.sea_surface_temperature))\n\nMinimum SST 2.34\nMaximum SST 29.87\n\n\n\n\nUse the minimum and maximum SST to set some color breaks.\n\n# Sets color breaks from 2 to 30 with 0.05 steps\nlevs = np.arange(2, 30, 0.05)\n\n\n\nDefine a color palette.\n\njet = [\"blue\", \"#007FFF\", \"cyan\", \"#7FFF7F\",\n       \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"]\n\n\n\nSet color scale using the jet palette.\n\ncm = LinearSegmentedColormap.from_list('my_jet', jet, N=len(levs))\n\n\n\nPlot the SST map\nThe code also shows how to annotate the map by: - Adding points to the map (e.g. station locations) - Adding contour lines\n\nplt.contourf(ds.longitude, \n             ds.latitude, \n             ds.sea_surface_temperature[0, :, :], \n             levs,\n             cmap=cm)\n\n# Plot the colorbar\nplt.colorbar()\n\n# Annotation: Example of how to add points to the map\nplt.scatter(range(-74, -71), np.repeat(34, 3), c='black')\n\n# Annotation: Example of how to add a contour line\nplt.contour(ds.longitude, \n            ds.latitude, \n            ds.sea_surface_temperature[0, :, :], \n            levels=[14],\n            linewidths=1)\n\n# Add a title\nplt.title(\"Monthly Sea Surface Temperature - \" \n          + ds.time[0].dt.strftime('%b %Y').item())\nplt.show()"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#plotting-a-time-series",
    "href": "tutorials/python/Tutorial1-basics.html#plotting-a-time-series",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Plotting a time series",
    "text": "Plotting a time series\n\nSubset the following box from the data:\n\n36o to 38oN latitude\n-77o to -75oE longitude\n\nWe are going to generate a time series of mean SST within that box.\n\nFirst, subset the data:\n\nRemember!\nFor this product, latitudes are indexed in descending order (high to low). Therefore when you slice latitude, put the largest value first.\n\nda = ds.sel(latitude=slice(38, 36), longitude=slice(-77, -75))\n\n\n\nExamine the structure of the subsetted data.\nThe subset is a 3-D array with 12 time steps, each with 40 rows corresponding to latitudes and 40 columns corresponding to longitudes.\n\nda.sea_surface_temperature.shape\n\n(12, 40, 40)\n\n\n\n\nPlot the subsetted data\n\nplt.contourf(da.longitude, \n             da.latitude, \n             da.sea_surface_temperature[0, :, :], \n             levs,\n             cmap=cm)\nplt.colorbar()\nplt.title(\"Monthly Sea Surface Temperature \" \n          + ds.time[0].dt.strftime('%b %Y').item())\nplt.show()"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#compute-the-monthly-mean-for-each-month",
    "href": "tutorials/python/Tutorial1-basics.html#compute-the-monthly-mean-for-each-month",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Compute the monthly mean for each month",
    "text": "Compute the monthly mean for each month\n\nres = np.mean(da.sea_surface_temperature, axis=(1, 2))\n\n\nPlot the time-series\n\nplt.figure(figsize=(8, 4))\nplt.scatter(ds.time, res)\nplt.ylabel('SST (ºC)')\n\nText(0, 0.5, 'SST (ºC)')"
  },
  {
    "objectID": "tutorials/python/Tutorial1-basics.html#creating-a-map-of-average-sst-over-a-year",
    "href": "tutorials/python/Tutorial1-basics.html#creating-a-map-of-average-sst-over-a-year",
    "title": "Tutorial 1 - Basics of working with satellite data in Python",
    "section": "Creating a map of average SST over a year",
    "text": "Creating a map of average SST over a year\n\nCompute the yearly mean for the region\n\nmean_sst = np.mean(ds.sea_surface_temperature, axis=0)\n\n\n\nPlot the map of the 2022 average SST in the region\n\nplt.contourf(ds.longitude, ds.latitude, mean_sst, levs, cmap=cm)\nplt.colorbar()\nplt.title(\"Mean SST \" \n          + ds.time[0].dt.strftime('%b %Y').item() \n          + ' - '\n          + ds.time[11].dt.strftime('%b %Y').item())\n\nplt.show()"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html",
    "href": "tutorials/r/virtual_buoy_example.html",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Updated August 2023 \n\nThere are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov), ARGO floats program (http://www.argo.ucsd.edu) or CoastWatch ERDDAP data servers (https://coastwatch.pfeg.noaa.gov/erddap/). In situ buoy data are widely used to monitor environmental conditions. In the absence of in situ buoy data - whether the buoy operation is discontinued, interrupted, or limited - satellite data within temporal and spatial coverage of the desired locationcan be used to create a time series of a parameter of interest.\n\n\nThis tutorial will demonstrate how to create a time series from satellite data to gap-fill or replace buoy data.\n\n\n\n\nDownloading the satellite and buoy data from ERDDAP data server\nVisualizing the datasets\nReshaping the satellite data into a buoy data format\nResampling buoy data (aggregation) to match satellite data temporal resolution\nValidating the satellite data with the actual buoy data\nPerforming a linear regression of satellite vs. buoy data\nCreating a scatter plot of satellite vs. buoy data with the regression line\n\n\n\n\nSea-Surface Temperature, NOAA Geo-polar Blended Analysis Day+Night, GHRSST,Near Real-Time, Global 5km, 2019-Present, Daily\n.\nNDBC Standard Meteorological Buoy Data, 1970-present  NDBC Standard Meteorological Buoy Data  from the buoy station no. 46259 are from off the California coast at 34.737N latitude and 121.664E longitude.\n\n\n\n\nNOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center\n\n\n\n\n# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"utils\", \"ggplot2\", \"dplyr\", \"lubridate\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\nWe will download NDBC buoy data between January 16, 2022 and August 16, 2022 from the CoastWatch ERDDAP server.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\n# Set the ERDDAP data request URL\n \nbuoy_url &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?time%2Clongitude%2Clatitude%2Cwtmp&station%3E=%2246259%22&station%3C=%2246259%22&time%3E=2022-01-16T00%3A00%3A00Z&time%3C=2022-08-16T17%3A52%3A00Z\"\n\n# Set file name\nfname = 'buoy.csv'\n\n# Download file\ndownload.file(buoy_url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\n \nbuoy_df &lt;- read.csv(fname, skip=2, header=TRUE)\n\n# Name the columns\nnames(buoy_df) &lt;- c(\"utc\", \"lon\", \"lat\", \"sst\" )\n\n# Add additional date column\nbuoy_df$date &lt;- as.Date(buoy_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(buoy_df, 3)\n\n##                    utc      lon    lat  sst       date\n## 1 2022-01-16T00:56:00Z -121.664 34.732 13.4 2022-01-16\n## 2 2022-01-16T01:26:00Z -121.664 34.732 13.4 2022-01-16\n## 3 2022-01-16T01:56:00Z -121.664 34.732 13.3 2022-01-16\n\n\n\noptions(repr.plot.width = 10)\n\nggplot(buoy_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n # geom_point(size=.2, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celsius)\", title=\"SST from NDBC Buoy Station: 46259 (Aug 2022- Aug 2023) \")\n\n\n\n\nThe satellite Sea Surface Temperature (SST) product we will use is the NOAA GeoPolar Blended SST dataset (in Celsius), which blends data from many satellite sensors to obtain good daily coverage of the globe at 5km resolution, and then an interpolation method is applied to fill in data gaps.\nThe data request can be sent to a CoastWatch ERDDAP server via URL with a query string to specify the temporal and spatial coverage of interest. In this case, we want to subset the satellite data to match the buoy station location and time range.\n\n\n# Set ERDDAP URL for the satellite data\nurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisBLENDEDsstDNDaily.csv?analysed_sst%5B(2022-01-16T12:00:00Z):1:(2022-08-16T12:00:00Z)%5D%5B(34.737):1:(34.737)%5D%5B(-121.664):1:(-121.664)%5D\"\n\n# Set file name\nfname = 'sst.csv'\n\n# Download file\ndownload.file(url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\nsst_df &lt;- read.csv(fname, skip=2, header=TRUE)\nnames(sst_df) &lt;- c(\"utc\", \"lat\", \"lon\", \"sst\")\n\n# Add formatted data column\nsst_df$date &lt;- as.Date(sst_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(sst_df, 3)\n\n##                    utc    lat      lon      sst       date\n## 1 2022-01-18T12:00:00Z 34.725 -121.675 13.49999 2022-01-18\n## 2 2022-01-19T12:00:00Z 34.725 -121.675 13.44999 2022-01-19\n## 3 2022-01-20T12:00:00Z 34.725 -121.675 13.53999 2022-01-20\n\n\n\n\nApply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, a value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Filter data that are within the valid range (-2 and 45)\nsst_df_clean = sst_df %&gt;%\n  filter(sst &gt;=-2 & sst &lt;= 45)\n\n\n\n# Plot sea surface temperature values from satellite\np &lt;- ggplot(sst_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"Sea surface temperature from satellite\")\np\n\n\n\n\nThe sampling resolution for the buoy data is a sample every 30 minutes. However, the temporal resolution for the satellite dataset is daily. We will downsample the buoy data by computing daily mean to match the temporal resolution of the satellite data.\n# Aggregating (taking a mean value) grouped by day\nbuoy_ds &lt;- buoy_df %&gt;%\n  group_by(date = floor_date(date, unit=\"days\")) %&gt;%\n  summarise(mean_sst = mean(sst))\n\n# Show first 3 rows\nhead(buoy_ds, 3)\n\n## # A tibble: 3 × 2\n##   date       mean_sst\n##   &lt;date&gt;        &lt;dbl&gt;\n## 1 2022-01-16     13.4\n## 2 2022-01-17     13.5\n## 3 2022-01-18     13.6\n\n\n\nApply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Remove outliers sst values outside of -2 and 45 deg C\nbuoy_ds_clean = buoy_ds %&gt;%\n  filter(mean_sst &gt;=-2 & mean_sst &lt;= 45)\n\n\n\n# Plot daily mean sst\nggplot(buoy_ds_clean, aes(x = date, y = mean_sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"2022 Aug- 2023 Aug Downsampled Buoy SST\")\n\n\n\n\nWe will use dplyr::inner_join() function to merge the two data frames (satellite and buoy data) based on the dates that appear in both data frames.\n# Combine two data frames with date column where dates exist in both data frames\nmerged_df &lt;- inner_join(sst_df_clean[c(\"date\", \"sst\")],  buoy_ds_clean, by = \"date\")\n\n\n\n# Plot satellite sst and buoy daily mean sst \np &lt;- ggplot(merged_df, aes(x = date)) +  \n    geom_line(aes(y = sst, color = \"Satellite\")) +   \n    geom_line(aes(y = mean_sst, color = \"NDBC Buoy\")) +   \n    scale_color_manual(name = \"Data source\", \n                       values = c(\"Satellite\" = \"blue\", \"NDBC Buoy\" = \"orange\"))+\n    labs( x = \"Date\", y = \"Temperature (in Celsius)\", title=\"SST from Satellite and NDBC Buoy\" )+\n    theme(axis.text.x = element_text(angle = 0),plot.title=element_text(hjust=0.5))\np\n ## Perform a simple linear regression\n# Run linear regression \nmodel &lt;- lm(mean_sst ~ sst, data = merged_df)   \nsummary(model)\n\n## \n## Call:\n## lm(formula = mean_sst ~ sst, data = merged_df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.48812 -0.21354 -0.02782  0.14581  1.67408 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.54793    0.30272    1.81   0.0718 .  \n## sst          0.96142    0.02221   43.29   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4462 on 203 degrees of freedom\n## Multiple R-squared:  0.9023, Adjusted R-squared:  0.9018 \n## F-statistic:  1874 on 1 and 203 DF,  p-value: &lt; 2.2e-16\n\n\n\nggplot(merged_df, aes(x=sst, y=mean_sst)) +\n  geom_point(color=\"black\", size=1) +                      # Plot the data points\n  geom_smooth(method=\"lm\", se=FALSE) +\n  labs(x = \"SST from Buoy\", y = \"SST from Satellite\", title = \"Satellite vs Buoy data with regression line\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n## `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#objective",
    "href": "tutorials/r/virtual_buoy_example.html#objective",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "This tutorial will demonstrate how to create a time series from satellite data to gap-fill or replace buoy data."
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/virtual_buoy_example.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Downloading the satellite and buoy data from ERDDAP data server\nVisualizing the datasets\nReshaping the satellite data into a buoy data format\nResampling buoy data (aggregation) to match satellite data temporal resolution\nValidating the satellite data with the actual buoy data\nPerforming a linear regression of satellite vs. buoy data\nCreating a scatter plot of satellite vs. buoy data with the regression line"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#datasets-used",
    "href": "tutorials/r/virtual_buoy_example.html#datasets-used",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Sea-Surface Temperature, NOAA Geo-polar Blended Analysis Day+Night, GHRSST,Near Real-Time, Global 5km, 2019-Present, Daily\n.\nNDBC Standard Meteorological Buoy Data, 1970-present  NDBC Standard Meteorological Buoy Data  from the buoy station no. 46259 are from off the California coast at 34.737N latitude and 121.664E longitude."
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#references",
    "href": "tutorials/r/virtual_buoy_example.html#references",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "NOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#install-required-packages-and-load-libraries",
    "href": "tutorials/r/virtual_buoy_example.html#install-required-packages-and-load-libraries",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"utils\", \"ggplot2\", \"dplyr\", \"lubridate\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#download-ndbc-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#download-ndbc-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "We will download NDBC buoy data between January 16, 2022 and August 16, 2022 from the CoastWatch ERDDAP server.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\n# Set the ERDDAP data request URL\n \nbuoy_url &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/tabledap/cwwcNDBCMet.csv?time%2Clongitude%2Clatitude%2Cwtmp&station%3E=%2246259%22&station%3C=%2246259%22&time%3E=2022-01-16T00%3A00%3A00Z&time%3C=2022-08-16T17%3A52%3A00Z\"\n\n# Set file name\nfname = 'buoy.csv'\n\n# Download file\ndownload.file(buoy_url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\n \nbuoy_df &lt;- read.csv(fname, skip=2, header=TRUE)\n\n# Name the columns\nnames(buoy_df) &lt;- c(\"utc\", \"lon\", \"lat\", \"sst\" )\n\n# Add additional date column\nbuoy_df$date &lt;- as.Date(buoy_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(buoy_df, 3)\n\n##                    utc      lon    lat  sst       date\n## 1 2022-01-16T00:56:00Z -121.664 34.732 13.4 2022-01-16\n## 2 2022-01-16T01:26:00Z -121.664 34.732 13.4 2022-01-16\n## 3 2022-01-16T01:56:00Z -121.664 34.732 13.3 2022-01-16"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#visualize-sst-from-the-buoy",
    "href": "tutorials/r/virtual_buoy_example.html#visualize-sst-from-the-buoy",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "options(repr.plot.width = 10)\n\nggplot(buoy_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n # geom_point(size=.2, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celsius)\", title=\"SST from NDBC Buoy Station: 46259 (Aug 2022- Aug 2023) \")"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#download-the-satellite-sea-surface-temperature-sst-data",
    "href": "tutorials/r/virtual_buoy_example.html#download-the-satellite-sea-surface-temperature-sst-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "The satellite Sea Surface Temperature (SST) product we will use is the NOAA GeoPolar Blended SST dataset (in Celsius), which blends data from many satellite sensors to obtain good daily coverage of the globe at 5km resolution, and then an interpolation method is applied to fill in data gaps.\nThe data request can be sent to a CoastWatch ERDDAP server via URL with a query string to specify the temporal and spatial coverage of interest. In this case, we want to subset the satellite data to match the buoy station location and time range.\n\n\n# Set ERDDAP URL for the satellite data\nurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisBLENDEDsstDNDaily.csv?analysed_sst%5B(2022-01-16T12:00:00Z):1:(2022-08-16T12:00:00Z)%5D%5B(34.737):1:(34.737)%5D%5B(-121.664):1:(-121.664)%5D\"\n\n# Set file name\nfname = 'sst.csv'\n\n# Download file\ndownload.file(url, fname)\n\n\n# Read into data frame, skip first 2 rows that contain variable names and units\nsst_df &lt;- read.csv(fname, skip=2, header=TRUE)\nnames(sst_df) &lt;- c(\"utc\", \"lat\", \"lon\", \"sst\")\n\n# Add formatted data column\nsst_df$date &lt;- as.Date(sst_df$utc, tz = \"UTC\")\n\n# Show the first 3 rows\nhead(sst_df, 3)\n\n##                    utc    lat      lon      sst       date\n## 1 2022-01-18T12:00:00Z 34.725 -121.675 13.49999 2022-01-18\n## 2 2022-01-19T12:00:00Z 34.725 -121.675 13.44999 2022-01-19\n## 3 2022-01-20T12:00:00Z 34.725 -121.675 13.53999 2022-01-20"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#clean-up-the-data",
    "href": "tutorials/r/virtual_buoy_example.html#clean-up-the-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Apply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, a value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Filter data that are within the valid range (-2 and 45)\nsst_df_clean = sst_df %&gt;%\n  filter(sst &gt;=-2 & sst &lt;= 45)"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#visualize-the-satellite-sst-data",
    "href": "tutorials/r/virtual_buoy_example.html#visualize-the-satellite-sst-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot sea surface temperature values from satellite\np &lt;- ggplot(sst_df, aes(x = date, y = sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"Sea surface temperature from satellite\")\np"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#resample-the-buoy-data-to-match-the-satellite-data",
    "href": "tutorials/r/virtual_buoy_example.html#resample-the-buoy-data-to-match-the-satellite-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "The sampling resolution for the buoy data is a sample every 30 minutes. However, the temporal resolution for the satellite dataset is daily. We will downsample the buoy data by computing daily mean to match the temporal resolution of the satellite data.\n# Aggregating (taking a mean value) grouped by day\nbuoy_ds &lt;- buoy_df %&gt;%\n  group_by(date = floor_date(date, unit=\"days\")) %&gt;%\n  summarise(mean_sst = mean(sst))\n\n# Show first 3 rows\nhead(buoy_ds, 3)\n\n## # A tibble: 3 × 2\n##   date       mean_sst\n##   &lt;date&gt;        &lt;dbl&gt;\n## 1 2022-01-16     13.4\n## 2 2022-01-17     13.5\n## 3 2022-01-18     13.6"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#clean-up-the-downsampled-data",
    "href": "tutorials/r/virtual_buoy_example.html#clean-up-the-downsampled-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Apply a conservative allowable data range. For the lower end of the range, the freezing point of seawater (ca. -2). For the high end of the range, value unlikely to be seen in the area of interest (e.g. 45 degrees C).\n# Remove outliers sst values outside of -2 and 45 deg C\nbuoy_ds_clean = buoy_ds %&gt;%\n  filter(mean_sst &gt;=-2 & mean_sst &lt;= 45)"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#visualize-the-downsampled-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#visualize-the-downsampled-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot daily mean sst\nggplot(buoy_ds_clean, aes(x = date, y = mean_sst)) +\n  geom_line(color='blue') +\n  geom_point(size=.5, color='red')+\n  theme(axis.text.x = element_text(angle = 90),plot.title=element_text(hjust=0.5))+\n   labs(x=\"Date\", y=\"Sea Surface Temp (Celcius)\", title=\"2022 Aug- 2023 Aug Downsampled Buoy SST\")"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#merge-satellite-and-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#merge-satellite-and-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "We will use dplyr::inner_join() function to merge the two data frames (satellite and buoy data) based on the dates that appear in both data frames.\n# Combine two data frames with date column where dates exist in both data frames\nmerged_df &lt;- inner_join(sst_df_clean[c(\"date\", \"sst\")],  buoy_ds_clean, by = \"date\")"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#plot-both-satellite-and-buoy-data",
    "href": "tutorials/r/virtual_buoy_example.html#plot-both-satellite-and-buoy-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "# Plot satellite sst and buoy daily mean sst \np &lt;- ggplot(merged_df, aes(x = date)) +  \n    geom_line(aes(y = sst, color = \"Satellite\")) +   \n    geom_line(aes(y = mean_sst, color = \"NDBC Buoy\")) +   \n    scale_color_manual(name = \"Data source\", \n                       values = c(\"Satellite\" = \"blue\", \"NDBC Buoy\" = \"orange\"))+\n    labs( x = \"Date\", y = \"Temperature (in Celsius)\", title=\"SST from Satellite and NDBC Buoy\" )+\n    theme(axis.text.x = element_text(angle = 0),plot.title=element_text(hjust=0.5))\np\n ## Perform a simple linear regression\n# Run linear regression \nmodel &lt;- lm(mean_sst ~ sst, data = merged_df)   \nsummary(model)\n\n## \n## Call:\n## lm(formula = mean_sst ~ sst, data = merged_df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.48812 -0.21354 -0.02782  0.14581  1.67408 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.54793    0.30272    1.81   0.0718 .  \n## sst          0.96142    0.02221   43.29   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4462 on 203 degrees of freedom\n## Multiple R-squared:  0.9023, Adjusted R-squared:  0.9018 \n## F-statistic:  1874 on 1 and 203 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "tutorials/r/virtual_buoy_example.html#plot-satellite-vs.-buoy-data-and-overlay-the-regression-line",
    "href": "tutorials/r/virtual_buoy_example.html#plot-satellite-vs.-buoy-data-and-overlay-the-regression-line",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "ggplot(merged_df, aes(x=sst, y=mean_sst)) +\n  geom_point(color=\"black\", size=1) +                      # Plot the data points\n  geom_smooth(method=\"lm\", se=FALSE) +\n  labs(x = \"SST from Buoy\", y = \"SST from Satellite\", title = \"Satellite vs Buoy data with regression line\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n## `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "tutorials/r/subset-polar-data-with-shapefile.html",
    "href": "tutorials/r/subset-polar-data-with-shapefile.html",
    "title": "Subset and extract ims data",
    "section": "",
    "text": "Updated September 2024\n\n\n\n\nDownload sea ice satellite data from the PolarWatch ERDDAP data server\nImport geographical features of Lake Iliamna from a shapefile\nTransform data from one projection to another\nSubset the satellite data for Lake Iliamna\nVisualize data in different projection\n\n\n\n\nWorld Lake shape data\nThe world lake shapefile can be downloaded from ArcGIS Hub at https://hub.arcgis.com, and is also available in the resource/ directory of this tutorial folder. The file includes geographical features of all world lakes. For this exercise, only the features of Lake Illemna will be used.\nIMS Snow and Ice Analysis, Arctic, 4km, 2004 - Present, Daily (PolarWatch Preview)\nThe IMS dataset includes daily snow and ice coverage data for the Arctic with a 4-km resolution, available starting from 2004. The values in the dataset are categorical, representing five categories: 0 for areas outside the coverage zone, 1 for open water, 2 for land without snow, 3 for sea ice or lake ice, and 4 for snow-covered land. Data with a 1-km resolution are also available. Please contact us for more information.\n\n\n\nknitr::opts_chunk$set(\n  echo = TRUE,\n  fig.path = \"images/\",\n  warning = FALSE, message = FALSE\n)\n# Function to check if pkgs are installed, install missing pkgs, and load\n\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"sp\", \"ggplot2\" , \"rerddap\", \"RColorBrewer\", \"scales\", \"reshape2\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\nlibrary(terra)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(rerddap)"
  },
  {
    "objectID": "tutorials/r/subset-polar-data-with-shapefile.html#subset-data-in-polar-stereographic-projection-using-a-shape-file-fr",
    "href": "tutorials/r/subset-polar-data-with-shapefile.html#subset-data-in-polar-stereographic-projection-using-a-shape-file-fr",
    "title": "Subset and extract ims data",
    "section": "",
    "text": "Updated September 2024\n\n\n\n\nDownload sea ice satellite data from the PolarWatch ERDDAP data server\nImport geographical features of Lake Iliamna from a shapefile\nTransform data from one projection to another\nSubset the satellite data for Lake Iliamna\nVisualize data in different projection\n\n\n\n\nWorld Lake shape data\nThe world lake shapefile can be downloaded from ArcGIS Hub at https://hub.arcgis.com, and is also available in the resource/ directory of this tutorial folder. The file includes geographical features of all world lakes. For this exercise, only the features of Lake Illemna will be used.\nIMS Snow and Ice Analysis, Arctic, 4km, 2004 - Present, Daily (PolarWatch Preview)\nThe IMS dataset includes daily snow and ice coverage data for the Arctic with a 4-km resolution, available starting from 2004. The values in the dataset are categorical, representing five categories: 0 for areas outside the coverage zone, 1 for open water, 2 for land without snow, 3 for sea ice or lake ice, and 4 for snow-covered land. Data with a 1-km resolution are also available. Please contact us for more information.\n\n\n\nknitr::opts_chunk$set(\n  echo = TRUE,\n  fig.path = \"images/\",\n  warning = FALSE, message = FALSE\n)\n# Function to check if pkgs are installed, install missing pkgs, and load\n\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"sp\", \"ggplot2\" , \"rerddap\", \"RColorBrewer\", \"scales\", \"reshape2\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\nlibrary(terra)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(rerddap)"
  },
  {
    "objectID": "tutorials/r/subset-polar-data-with-shapefile.html#load-ims-sea-ice-data-from-erddap",
    "href": "tutorials/r/subset-polar-data-with-shapefile.html#load-ims-sea-ice-data-from-erddap",
    "title": "Subset and extract ims data",
    "section": "Load IMS Sea ice data from ERDDAP",
    "text": "Load IMS Sea ice data from ERDDAP\n\npw_url = \"https://polarwatch.noaa.gov/erddap/\"\ndataset_id = \"usnic_ims_4km\"\nvar_name = \"IMS_Surface_Values\"\ndat_info &lt;- info(datasetid = dataset_id, url = pw_url)\ndat_info"
  },
  {
    "objectID": "tutorials/r/subset-polar-data-with-shapefile.html#convert-ims-data-to-raster-s4-object",
    "href": "tutorials/r/subset-polar-data-with-shapefile.html#convert-ims-data-to-raster-s4-object",
    "title": "Subset and extract ims data",
    "section": "Convert IMS data to raster S4 object",
    "text": "Convert IMS data to raster S4 object\n\n# convert ims to raster S3 obj\nims_ras &lt;- terra::rast(ims)\n\n# plot the raster data\nplot(ims_ras)\n\n# get CRS of the ims data\ndata_crs &lt;- crs(ims_ras)"
  },
  {
    "objectID": "tutorials/r/subset-polar-data-with-shapefile.html#convert-the-lake-shape-to-raster-s4-object",
    "href": "tutorials/r/subset-polar-data-with-shapefile.html#convert-the-lake-shape-to-raster-s4-object",
    "title": "Subset and extract ims data",
    "section": "Convert the lake shape to raster S4 object",
    "text": "Convert the lake shape to raster S4 object\n\nshapes_polar &lt;- st_transform(lake_shp, data_crs)\nlake_ras &lt;- terra::vect(shapes_polar)\nplot(lake_ras)"
  },
  {
    "objectID": "tutorials/r/subset-polar-data-with-shapefile.html#crop-the-ims-data",
    "href": "tutorials/r/subset-polar-data-with-shapefile.html#crop-the-ims-data",
    "title": "Subset and extract ims data",
    "section": "Crop the IMS data",
    "text": "Crop the IMS data\n\n# crop to the bounding box of the lake\ncropped_lake &lt;- crop(ims_ras, lake_ras)\n\n# mask data with the lake shape\nmasked_lake &lt;- mask(cropped_lake, lake_ras)\nplot(masked_lake)"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "history | Modified March 2024\n\n\nThis tutorial will demonstrate how to extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like those produced by an animal telemetry tag, and ship track, or a glider track.\n\n\n\n\nImporting track data in csv file to data frame\nPlotting the latitude/longitude points onto a map\nUsing rerddapXtraco function to extract satellite data from an ERDDAP data server along a track\nPlotting the satellite data onto a map\n\n\n\n\nChlorophyll a concentration, the European Space Agency’s Ocean Colour Climate Change Initiative (OC-CCI) Monthly dataset v6.0\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nLoggerhead turtle telemetry track data\nThe turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. This dataset has been subsampled to reduce the data requests needed for this tutorial from over 1200 to 25. The track data are stored in the data folder in this project folder.\n\n\n\n# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                       \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\n# Import csv file into a data frame\nturtle_df &lt;- read.csv(\"../data/25317_05_subsampled.dat\")\n# Show 3 rows from the data frame\nhead(turtle_df,3)\n##   mean_lon mean_lat year month day\n## 1 176.6194 32.67873 2005     5   4\n## 2 175.8609 35.05773 2005     6  23\n## 3 180.5926 40.40576 2005     8  12\n\n\n\n# Download world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Map turtle tracks\nggplot(turtle_df, aes(mean_lon,mean_lat)) +\n  geom_path(group=1)+\n  geom_point(aes(x=mean_lon,y=mean_lat), pch=1, size=2 )+\n  geom_point(aes(x=mean_lon[1],y=mean_lat[1]),fill=\"green\", shape=24, size=3)+\n  geom_point(aes(x=mean_lon[length(mean_lon)],y=mean_lat[length(mean_lat)]), shape=22, size=3, fill=\"red\")+\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60))+\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with start (green) and end location (red)\")+\n  theme(plot.title=element_text(hjust=0.5), aspect.ratio=1/2)\n\nIn this exercise, two different ways of extracting data from ERDDAP data server along a track of xyt points are demonstrated:\n\nUsing the rerddapXtracto package which was written specifically for this task\nBy manually constructing a URL with the data data request\n\n\n\nWe will use the `rxtracto function of the rerddapXtracto package, which was written to simplify data extraction from ERDDAP servers.\nLet’s use data from the monthly product of the OC-CCI datasets.\nThe ERDDAP URL to the monthly product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-12-01 (at the day of this writing), which covers the track time range of 2005-05-04 to 2008-08-16.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n# Set dataset ID\ndataset &lt;- 'esa-cci-chla-monthly-v6-0'\n\n# Get data information from ERDDAP server\ndataInfo &lt;- rerddap::info(dataset, url= \"https://oceanwatch.pifsc.noaa.gov/erddap\")\n\n\n\n\nrerddap::info returns the metadata of the requested dataset. We can first understand the attributes dataInfo includes then examine each attribute.\n# Display the metadata\ndataInfo\n## &lt;ERDDAP info&gt; esa-cci-chla-monthly-v6-0 \n##  Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-04T00:00:00Z, 2023-12-01T00:00:00Z) \n##      latitude: (-89.97916666666666, 89.97916666666667) \n##      longitude: (0.020833333333314386, 359.97916666666663) \n##  Variables:  \n##      chlor_a: \n##          Units: mg m-3 \n##      chlor_a_log10_bias: \n##      chlor_a_log10_rmsd: \n##      MERIS_nobs_sum: \n##      MODISA_nobs_sum: \n##      OLCI_A_nobs_sum: \n##      OLCI_B_nobs_sum: \n##      SeaWiFS_nobs_sum: \n##      total_nobs_sum: \n##      VIIRS_nobs_sum:\n# Display data attributes\nnames(dataInfo)\n## [1] \"variables\" \"alldata\"   \"base_url\"\n# Examine attribute: variables\ndataInfo$variables\n##         variable_name data_type actual_range\n## 1             chlor_a     float             \n## 2  chlor_a_log10_bias     float             \n## 3  chlor_a_log10_rmsd     float             \n## 4      MERIS_nobs_sum     float             \n## 5     MODISA_nobs_sum     float             \n## 6     OLCI_A_nobs_sum     float             \n## 7     OLCI_B_nobs_sum     float             \n## 8    SeaWiFS_nobs_sum     float             \n## 9      total_nobs_sum     float             \n## 10     VIIRS_nobs_sum     float\n# Distribute attributes of dataInfo$alldata\nnames(dataInfo$alldata)\n##  [1] \"NC_GLOBAL\"          \"time\"               \"latitude\"          \n##  [4] \"longitude\"          \"chlor_a\"            \"MERIS_nobs_sum\"    \n##  [7] \"MODISA_nobs_sum\"    \"OLCI_A_nobs_sum\"    \"OLCI_B_nobs_sum\"   \n## [10] \"SeaWiFS_nobs_sum\"   \"VIIRS_nobs_sum\"     \"chlor_a_log10_bias\"\n## [13] \"chlor_a_log10_rmsd\" \"total_nobs_sum\"\n\n\nFirst we need to define the bounding box within which to search for coordinates. The rxtracto function allows you to set the size of the box used to collect data around the track points using the xlen and ylen arguments. The values for xlen and ylen are in degrees. For our example, we can use 0.2 degrees for both arguments. Note: You can also submit vectors for xlen and ylen, as long as they are the same length as xcoord, ycoord, and tcoord if you want to set a different search radius around each track point.\n# Set the variable we want to extract data from:\nparameter &lt;- 'chlor_a'\n\n# Set xlen, ylen to 0.2 degree\nxlen &lt;- 0.2 \nylen &lt;- 0.2\n\n# Create date column using year, month and day in a format ERDDAP will understand (eg. 2008-12-15)\nturtle_df$date &lt;- as.Date(paste(turtle_df$year, turtle_df$month, turtle_df$day, sep=\"-\"))\n\n# Get variables x, y, t coordinates from turtle track data\nxcoords &lt;- turtle_df$mean_lon\nycoords &lt;- turtle_df$mean_lat\ntcoords &lt;- turtle_df$date\n\n# Extract satellite data using x, y, t coordinates from turtle track data\nchl_track &lt;- rxtracto(dataInfo, \n                  parameter=parameter, \n                  xcoord=xcoords, ycoord=ycoords, \n                  tcoord=tcoords, xlen=xlen, ylen=ylen)\n\n\n\n\n# Check all variables extracted using rxtracto\nchl_track\n## $`mean chlor_a`\n##  [1] 0.26779765 0.12073122 0.30777924 0.31780368 0.28884829 0.36146353\n##  [7] 0.22923882 0.11644071 0.09268904 0.05536651 0.18447913 0.22765385\n## [13] 0.23869553 0.24669819 0.35838123 0.09624625 0.12024124 0.11400095\n## [19] 0.10017463 0.09397742 0.08515869 0.06913812 0.14883095 0.51560753\n## [25] 0.65806269\n## \n## $`stdev chlor_a`\n##  [1] 0.032191816 0.007231171 0.036716832 0.041052758 0.027952051 0.053364804\n##  [7] 0.024394244 0.007282479 0.003880810 0.001490017 0.040774493 0.025363286\n## [13] 0.014782180 0.013523678 0.036640145 0.004842596 0.004098601 0.003910613\n## [19] 0.003537558 0.005928580 0.007001476 0.004942355 0.011980482 0.099209610\n## [25] 0.149563991\n## \n## $n\n##  [1] 36 36 36 27 36 30 36 36 30 30 30 30 36 30 36 30 36 36 36 30 36 30 36 36 36\n## \n## $`satellite date`\n##  [1] \"2005-05-01T00:00:00Z\" \"2005-07-01T00:00:00Z\" \"2005-08-01T00:00:00Z\"\n##  [4] \"2005-10-01T00:00:00Z\" \"2005-12-01T00:00:00Z\" \"2006-01-01T00:00:00Z\"\n##  [7] \"2006-03-01T00:00:00Z\" \"2006-05-01T00:00:00Z\" \"2006-06-01T00:00:00Z\"\n## [10] \"2006-08-01T00:00:00Z\" \"2006-09-01T00:00:00Z\" \"2006-11-01T00:00:00Z\"\n## [13] \"2007-01-01T00:00:00Z\" \"2007-02-01T00:00:00Z\" \"2007-04-01T00:00:00Z\"\n## [16] \"2007-06-01T00:00:00Z\" \"2007-07-01T00:00:00Z\" \"2007-09-01T00:00:00Z\"\n## [19] \"2007-11-01T00:00:00Z\" \"2007-12-01T00:00:00Z\" \"2008-02-01T00:00:00Z\"\n## [22] \"2008-04-01T00:00:00Z\" \"2008-05-01T00:00:00Z\" \"2008-07-01T00:00:00Z\"\n## [25] \"2008-08-01T00:00:00Z\"\n## \n## $`requested lon min`\n##  [1] 176.5194 175.7609 180.4926 183.4102 186.8997 193.2152 198.9158 196.2679\n##  [9] 194.2116 192.7545 193.9788 191.9444 191.6600 194.9631 199.2066 205.5050\n## [17] 210.1805 215.6225 222.9073 225.5386 232.3064 239.4530 245.7716 248.4710\n## [25] 245.6579\n## \n## $`requested lon max`\n##  [1] 176.7194 175.9609 180.6926 183.6102 187.0997 193.4152 199.1158 196.4679\n##  [9] 194.4116 192.9545 194.1788 192.1444 191.8600 195.1631 199.4066 205.7050\n## [17] 210.3805 215.8225 223.1073 225.7386 232.5064 239.6530 245.9716 248.6710\n## [25] 245.8579\n## \n## $`requested lat min`\n##  [1] 32.57873 34.95773 40.30576 41.58480 37.26623 32.03793 32.01126 34.81224\n##  [9] 34.59661 36.99175 41.66933 38.12796 34.63858 31.63964 34.24324 35.02771\n## [17] 38.36083 39.23749 35.76793 30.08540 28.22859 25.88108 24.73662 23.62417\n## [25] 26.68177\n## \n## $`requested lat max`\n##  [1] 32.77873 35.15773 40.50576 41.78480 37.46623 32.23793 32.21126 35.01224\n##  [9] 34.79661 37.19175 41.86933 38.32796 34.83858 31.83964 34.44324 35.22771\n## [17] 38.56083 39.43749 35.96793 30.28540 28.42859 26.08108 24.93662 23.82417\n## [25] 26.88177\n## \n## $`requested z min`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## \n## $`requested z max`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## \n## $`requested date`\n##  [1] \"2005-05-04\" \"2005-06-23\" \"2005-08-12\" \"2005-10-01\" \"2005-11-20\"\n##  [6] \"2006-01-09\" \"2006-02-28\" \"2006-04-19\" \"2006-06-08\" \"2006-07-28\"\n## [11] \"2006-09-16\" \"2006-11-05\" \"2006-12-25\" \"2007-02-13\" \"2007-04-04\"\n## [16] \"2007-05-24\" \"2007-07-13\" \"2007-09-01\" \"2007-10-21\" \"2007-12-10\"\n## [21] \"2008-01-29\" \"2008-03-19\" \"2008-05-08\" \"2008-06-27\" \"2008-08-16\"\n## \n## $`median chlor_a`\n##  [1] 0.26985641 0.11935977 0.31413330 0.31312889 0.28226255 0.35456662\n##  [7] 0.22596541 0.11711950 0.09256660 0.05540323 0.18355133 0.22467585\n## [13] 0.24202415 0.24848759 0.34953472 0.09518800 0.11983451 0.11379882\n## [19] 0.10012896 0.09296544 0.08735247 0.06766215 0.14883141 0.49834299\n## [25] 0.67895702\n## \n## $`mad chlor_a`\n##  [1] 0.030100095 0.008344179 0.039171724 0.027213317 0.023952735 0.049566912\n##  [7] 0.022928175 0.009027836 0.003463391 0.001267676 0.035848973 0.026539111\n## [13] 0.016244819 0.011793729 0.035606685 0.003954114 0.002984454 0.002953619\n## [19] 0.002999692 0.003767908 0.003242842 0.003565519 0.015092995 0.109981245\n## [25] 0.133971250\n## \n## attr(,\"row.names\")\n##  [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n## [16] \"16\" \"17\" \"18\" \"19\" \"20\" \"21\" \"22\" \"23\" \"24\" \"25\"\n## attr(,\"class\")\n## [1] \"list\"          \"rxtractoTrack\"\nrxtracto computes statistics using all the pixels found in the search radius around each track point.\n\n\n\nWe will use the “plotTrack” function to plot the results. “plotTrack” is a function of the “rerddapXtracto” package designed specifically to plot the results of the “rxtracto” function. It provides an easy way to make a quick plot, however it’s not very customizable.\n# Plot tracks with color: algae specifically designed for chlorophyll\nplotTrack(chl_track, xcoords, ycoords, tcoords, size=3, plotColor = 'viridis')\n\n\n\n\nOne of the nice features of the “plotTrack” function is that it is very easy to make an animation of the track data. This will take a minute to run. It creates an animated gif that will display in the Rstudio viewer window once the encoding to gif is done.\n# Animate tracks\n\nmake180 &lt;- function(lon) {\n    ind &lt;- which(lon &gt; 180)\n    lon[ind] &lt;- lon[ind] - 360\n   return(lon)\n}\n\nplotTrack(chl_track, make180(xcoords), ycoords, tcoords, plotColor = 'viridis',\n                    animate = TRUE, cumulative = TRUE)\n## # A tibble: 25 × 7\n##    format width height colorspace matte filesize density\n##    &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n##  1 gif      672    480 sRGB       TRUE         0 72x72  \n##  2 gif      672    480 sRGB       TRUE         0 72x72  \n##  3 gif      672    480 sRGB       TRUE         0 72x72  \n##  4 gif      672    480 sRGB       TRUE         0 72x72  \n##  5 gif      672    480 sRGB       TRUE         0 72x72  \n##  6 gif      672    480 sRGB       TRUE         0 72x72  \n##  7 gif      672    480 sRGB       TRUE         0 72x72  \n##  8 gif      672    480 sRGB       TRUE         0 72x72  \n##  9 gif      672    480 sRGB       TRUE         0 72x72  \n## 10 gif      672    480 sRGB       TRUE         0 72x72  \n## # ℹ 15 more rows\n\n\n\n\n\nIf we to do an customization of the plot, its better to plot the dat ausing ggplot. We will first create a data frame that contains longitudes and latitudes from the turtle and associated satellite chlor-a values.\n# Create a data frame of coords from turtle and chlor_a values \nnew_df &lt;- as.data.frame(cbind(xcoords, ycoords,  \n                              chl_track$`requested lon min`, \n                              chl_track$`requested lon max`, \n                              chl_track$`requested lat min`, \n                              chl_track$`requested lon max`,  \n                              chl_track$`mean chlor_a`))\n\n# Set variable names\nnames(new_df) &lt;- c(\"Lon\", \"Lat\", \"Matchup_Lon_Lower\", \"Matchup_Lon_Upper\", \"Matchup_Lat_Lower\", \"Matchup_Lat_Upper\",  \"Chlor_a\")\nwrite.csv(new_df, \"matchup_df.csv\")\n\n\n\n# Import world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Draw the track positions with associated chlora values\nggplot(new_df) +\n  geom_point(aes(Lon,Lat,color=log(Chlor_a))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nFirst we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\ndata_url = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_1d_2018_0.csv?chlor_a\"\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data is severely affected by clouds (i.e. lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer gaps.\n# Set erddap address\nerddap &lt;- \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0.csv?chlor_a\"\n\n# Get longitude and latitude from turtle track data\nlon &lt;- turtle_df$mean_lon\nlat &lt;- turtle_df$mean_lat\n\n# Get time from turtle track data and convert into ERDDAP date format\ndates &lt;- mdy.date(turtle_df$month,turtle_df$day,turtle_df$year)\ndates2 &lt;- format(as.Date(dates), \"%Y-%m-%d\")\n\n# Initatilize tot variable where data will be downloaded to\ntot &lt;- rep(NA, 4)\n\n# Loop through each turtle track data\nfor (i in 1:dim(turtle_df)[1]) {\n\n   # Create erddap URL by adding lat, lon, dates of each track point \n   url &lt;-  paste(erddap, \"[(\", dates2[i], \"):1:(\", dates2[i], \")][(\", lat[i], \"):1:(\", lat[i], \")][(\", lon[i], \"):1:(\", lon[i], \")]\", sep = \"\")  \n   \n   # Request and load satelite data from ERDDAP\n   new &lt;- read.csv(url, skip=2, header = FALSE) \n   \n   # Append the data\n   tot &lt;- rbind(tot, new)   \n}\n\n# Delete the first row (default column names)\ntot &lt;- tot[-1, ]\n\n# Rename columns\nnames(tot) &lt;- c(\"chlo_date\", \"matched_lat\", \"matched_lon\", \"matched_chl.m\")\n\n# Create data frame combining turtle track data and the chlo-a data\nchl_track2 &lt;- data.frame(turtle_df, tot)\n\n# Write the data frame to csv file\nwrite.csv(chl_track2, 'turtle-track-chl.m.csv', row.names = FALSE)\n\n\n\n# Draw the track positions with associated chlora values\nggplot(chl_track2) +\n  geom_point(aes(mean_lon,mean_lat,color=log(matched_chl.m))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nHow do the chlorophyll values of the turtle track compare to values in the surrounding environment? Meaning does the turtle seem to have a preference for certain chlorophyll values? To look at this we will plot a histograms of the track chl valuesand those of the surrounding area.\nFirst we will get a 3D block of chl data from the region and of the turtle track over the span of time the turtle was in that area. We will use the ‘xtracto_3d’ function of rerddapXtracto to get the data. This data call will take a few minutes.\nchl_grid &lt;- rxtracto_3D(dataInfo, \n                  parameter=parameter, \n                  xcoord=c(min(xcoords),max(xcoords)), \n                  ycoord=c(min(ycoords),max(ycoords)), \n                  tcoord=c(min(tcoords),max(tcoords)))\n\nchl_area &lt;- as.vector(chl_grid$chlor_a) \n\n# remove NA values \nchl_area &lt;- chl_area[!is.na(chl_area)]\n\n# vector or turtle chlorophyll \n\nchl_turtle &lt;- chl_track$`mean chlor_a`\nNow we we plot histograms of all the chlorphyll values in the area, and those of the turtle track. Since we subset the turtletrack, and only have 25 points for this subsampopled dataset the turtle histogram isn’t as useful as it would be with a larger dataset.\nggplot(as.data.frame(chl_area)) + \n      geom_histogram(aes(x=chl_area,y=after_stat(density),color = \"darkgray\",fill='Area'),color='black', bins=50) + \n      geom_histogram(data=as.data.frame(chl_turtle), aes(x=chl_turtle,y=after_stat(density),color='green', fill='Turtle'),color='black',bins=50, alpha=.4) + \n      scale_x_continuous(limits = c(0,.9), expand = c(0, 0)) + \n      scale_y_continuous(limits = c(0,15), expand = c(0, 0)) +\n      labs(x='Chlorophyll values',y='Density') + \n      theme_bw() + \n      scale_fill_manual(values=c(\"darkgray\",\"green\"),'')\n\n\n\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html \\ This dataset is a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name.\n\n\n\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ \\ This dataset will likely be on a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name. \\ Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\n\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorDaily_Lon0360.html"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html#objective",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html#objective",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "This tutorial will demonstrate how to extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like those produced by an animal telemetry tag, and ship track, or a glider track."
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "Importing track data in csv file to data frame\nPlotting the latitude/longitude points onto a map\nUsing rerddapXtraco function to extract satellite data from an ERDDAP data server along a track\nPlotting the satellite data onto a map"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html#datasets-used",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html#datasets-used",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "Chlorophyll a concentration, the European Space Agency’s Ocean Colour Climate Change Initiative (OC-CCI) Monthly dataset v6.0\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nLoggerhead turtle telemetry track data\nThe turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. This dataset has been subsampled to reduce the data requests needed for this tutorial from over 1200 to 25. The track data are stored in the data folder in this project folder."
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html#install-required-packages-and-load-libraries",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html#install-required-packages-and-load-libraries",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                       \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html#import-the-track-data-into-a-data-frame",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html#import-the-track-data-into-a-data-frame",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Import csv file into a data frame\nturtle_df &lt;- read.csv(\"../data/25317_05_subsampled.dat\")\n# Show 3 rows from the data frame\nhead(turtle_df,3)\n##   mean_lon mean_lat year month day\n## 1 176.6194 32.67873 2005     5   4\n## 2 175.8609 35.05773 2005     6  23\n## 3 180.5926 40.40576 2005     8  12"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Download world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Map turtle tracks\nggplot(turtle_df, aes(mean_lon,mean_lat)) +\n  geom_path(group=1)+\n  geom_point(aes(x=mean_lon,y=mean_lat), pch=1, size=2 )+\n  geom_point(aes(x=mean_lon[1],y=mean_lat[1]),fill=\"green\", shape=24, size=3)+\n  geom_point(aes(x=mean_lon[length(mean_lon)],y=mean_lat[length(mean_lat)]), shape=22, size=3, fill=\"red\")+\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60))+\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with start (green) and end location (red)\")+\n  theme(plot.title=element_text(hjust=0.5), aspect.ratio=1/2)\n\nIn this exercise, two different ways of extracting data from ERDDAP data server along a track of xyt points are demonstrated:\n\nUsing the rerddapXtracto package which was written specifically for this task\nBy manually constructing a URL with the data data request\n\n\n\nWe will use the `rxtracto function of the rerddapXtracto package, which was written to simplify data extraction from ERDDAP servers.\nLet’s use data from the monthly product of the OC-CCI datasets.\nThe ERDDAP URL to the monthly product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-12-01 (at the day of this writing), which covers the track time range of 2005-05-04 to 2008-08-16.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n# Set dataset ID\ndataset &lt;- 'esa-cci-chla-monthly-v6-0'\n\n# Get data information from ERDDAP server\ndataInfo &lt;- rerddap::info(dataset, url= \"https://oceanwatch.pifsc.noaa.gov/erddap\")"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html#examine-metadata",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html#examine-metadata",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "rerddap::info returns the metadata of the requested dataset. We can first understand the attributes dataInfo includes then examine each attribute.\n# Display the metadata\ndataInfo\n## &lt;ERDDAP info&gt; esa-cci-chla-monthly-v6-0 \n##  Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-04T00:00:00Z, 2023-12-01T00:00:00Z) \n##      latitude: (-89.97916666666666, 89.97916666666667) \n##      longitude: (0.020833333333314386, 359.97916666666663) \n##  Variables:  \n##      chlor_a: \n##          Units: mg m-3 \n##      chlor_a_log10_bias: \n##      chlor_a_log10_rmsd: \n##      MERIS_nobs_sum: \n##      MODISA_nobs_sum: \n##      OLCI_A_nobs_sum: \n##      OLCI_B_nobs_sum: \n##      SeaWiFS_nobs_sum: \n##      total_nobs_sum: \n##      VIIRS_nobs_sum:\n# Display data attributes\nnames(dataInfo)\n## [1] \"variables\" \"alldata\"   \"base_url\"\n# Examine attribute: variables\ndataInfo$variables\n##         variable_name data_type actual_range\n## 1             chlor_a     float             \n## 2  chlor_a_log10_bias     float             \n## 3  chlor_a_log10_rmsd     float             \n## 4      MERIS_nobs_sum     float             \n## 5     MODISA_nobs_sum     float             \n## 6     OLCI_A_nobs_sum     float             \n## 7     OLCI_B_nobs_sum     float             \n## 8    SeaWiFS_nobs_sum     float             \n## 9      total_nobs_sum     float             \n## 10     VIIRS_nobs_sum     float\n# Distribute attributes of dataInfo$alldata\nnames(dataInfo$alldata)\n##  [1] \"NC_GLOBAL\"          \"time\"               \"latitude\"          \n##  [4] \"longitude\"          \"chlor_a\"            \"MERIS_nobs_sum\"    \n##  [7] \"MODISA_nobs_sum\"    \"OLCI_A_nobs_sum\"    \"OLCI_B_nobs_sum\"   \n## [10] \"SeaWiFS_nobs_sum\"   \"VIIRS_nobs_sum\"     \"chlor_a_log10_bias\"\n## [13] \"chlor_a_log10_rmsd\" \"total_nobs_sum\"\n\n\nFirst we need to define the bounding box within which to search for coordinates. The rxtracto function allows you to set the size of the box used to collect data around the track points using the xlen and ylen arguments. The values for xlen and ylen are in degrees. For our example, we can use 0.2 degrees for both arguments. Note: You can also submit vectors for xlen and ylen, as long as they are the same length as xcoord, ycoord, and tcoord if you want to set a different search radius around each track point.\n# Set the variable we want to extract data from:\nparameter &lt;- 'chlor_a'\n\n# Set xlen, ylen to 0.2 degree\nxlen &lt;- 0.2 \nylen &lt;- 0.2\n\n# Create date column using year, month and day in a format ERDDAP will understand (eg. 2008-12-15)\nturtle_df$date &lt;- as.Date(paste(turtle_df$year, turtle_df$month, turtle_df$day, sep=\"-\"))\n\n# Get variables x, y, t coordinates from turtle track data\nxcoords &lt;- turtle_df$mean_lon\nycoords &lt;- turtle_df$mean_lat\ntcoords &lt;- turtle_df$date\n\n# Extract satellite data using x, y, t coordinates from turtle track data\nchl_track &lt;- rxtracto(dataInfo, \n                  parameter=parameter, \n                  xcoord=xcoords, ycoord=ycoords, \n                  tcoord=tcoords, xlen=xlen, ylen=ylen)"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html#check-the-output-of-the-rxtracto-function",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html#check-the-output-of-the-rxtracto-function",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Check all variables extracted using rxtracto\nchl_track\n## $`mean chlor_a`\n##  [1] 0.26779765 0.12073122 0.30777924 0.31780368 0.28884829 0.36146353\n##  [7] 0.22923882 0.11644071 0.09268904 0.05536651 0.18447913 0.22765385\n## [13] 0.23869553 0.24669819 0.35838123 0.09624625 0.12024124 0.11400095\n## [19] 0.10017463 0.09397742 0.08515869 0.06913812 0.14883095 0.51560753\n## [25] 0.65806269\n## \n## $`stdev chlor_a`\n##  [1] 0.032191816 0.007231171 0.036716832 0.041052758 0.027952051 0.053364804\n##  [7] 0.024394244 0.007282479 0.003880810 0.001490017 0.040774493 0.025363286\n## [13] 0.014782180 0.013523678 0.036640145 0.004842596 0.004098601 0.003910613\n## [19] 0.003537558 0.005928580 0.007001476 0.004942355 0.011980482 0.099209610\n## [25] 0.149563991\n## \n## $n\n##  [1] 36 36 36 27 36 30 36 36 30 30 30 30 36 30 36 30 36 36 36 30 36 30 36 36 36\n## \n## $`satellite date`\n##  [1] \"2005-05-01T00:00:00Z\" \"2005-07-01T00:00:00Z\" \"2005-08-01T00:00:00Z\"\n##  [4] \"2005-10-01T00:00:00Z\" \"2005-12-01T00:00:00Z\" \"2006-01-01T00:00:00Z\"\n##  [7] \"2006-03-01T00:00:00Z\" \"2006-05-01T00:00:00Z\" \"2006-06-01T00:00:00Z\"\n## [10] \"2006-08-01T00:00:00Z\" \"2006-09-01T00:00:00Z\" \"2006-11-01T00:00:00Z\"\n## [13] \"2007-01-01T00:00:00Z\" \"2007-02-01T00:00:00Z\" \"2007-04-01T00:00:00Z\"\n## [16] \"2007-06-01T00:00:00Z\" \"2007-07-01T00:00:00Z\" \"2007-09-01T00:00:00Z\"\n## [19] \"2007-11-01T00:00:00Z\" \"2007-12-01T00:00:00Z\" \"2008-02-01T00:00:00Z\"\n## [22] \"2008-04-01T00:00:00Z\" \"2008-05-01T00:00:00Z\" \"2008-07-01T00:00:00Z\"\n## [25] \"2008-08-01T00:00:00Z\"\n## \n## $`requested lon min`\n##  [1] 176.5194 175.7609 180.4926 183.4102 186.8997 193.2152 198.9158 196.2679\n##  [9] 194.2116 192.7545 193.9788 191.9444 191.6600 194.9631 199.2066 205.5050\n## [17] 210.1805 215.6225 222.9073 225.5386 232.3064 239.4530 245.7716 248.4710\n## [25] 245.6579\n## \n## $`requested lon max`\n##  [1] 176.7194 175.9609 180.6926 183.6102 187.0997 193.4152 199.1158 196.4679\n##  [9] 194.4116 192.9545 194.1788 192.1444 191.8600 195.1631 199.4066 205.7050\n## [17] 210.3805 215.8225 223.1073 225.7386 232.5064 239.6530 245.9716 248.6710\n## [25] 245.8579\n## \n## $`requested lat min`\n##  [1] 32.57873 34.95773 40.30576 41.58480 37.26623 32.03793 32.01126 34.81224\n##  [9] 34.59661 36.99175 41.66933 38.12796 34.63858 31.63964 34.24324 35.02771\n## [17] 38.36083 39.23749 35.76793 30.08540 28.22859 25.88108 24.73662 23.62417\n## [25] 26.68177\n## \n## $`requested lat max`\n##  [1] 32.77873 35.15773 40.50576 41.78480 37.46623 32.23793 32.21126 35.01224\n##  [9] 34.79661 37.19175 41.86933 38.32796 34.83858 31.83964 34.44324 35.22771\n## [17] 38.56083 39.43749 35.96793 30.28540 28.42859 26.08108 24.93662 23.82417\n## [25] 26.88177\n## \n## $`requested z min`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## \n## $`requested z max`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## \n## $`requested date`\n##  [1] \"2005-05-04\" \"2005-06-23\" \"2005-08-12\" \"2005-10-01\" \"2005-11-20\"\n##  [6] \"2006-01-09\" \"2006-02-28\" \"2006-04-19\" \"2006-06-08\" \"2006-07-28\"\n## [11] \"2006-09-16\" \"2006-11-05\" \"2006-12-25\" \"2007-02-13\" \"2007-04-04\"\n## [16] \"2007-05-24\" \"2007-07-13\" \"2007-09-01\" \"2007-10-21\" \"2007-12-10\"\n## [21] \"2008-01-29\" \"2008-03-19\" \"2008-05-08\" \"2008-06-27\" \"2008-08-16\"\n## \n## $`median chlor_a`\n##  [1] 0.26985641 0.11935977 0.31413330 0.31312889 0.28226255 0.35456662\n##  [7] 0.22596541 0.11711950 0.09256660 0.05540323 0.18355133 0.22467585\n## [13] 0.24202415 0.24848759 0.34953472 0.09518800 0.11983451 0.11379882\n## [19] 0.10012896 0.09296544 0.08735247 0.06766215 0.14883141 0.49834299\n## [25] 0.67895702\n## \n## $`mad chlor_a`\n##  [1] 0.030100095 0.008344179 0.039171724 0.027213317 0.023952735 0.049566912\n##  [7] 0.022928175 0.009027836 0.003463391 0.001267676 0.035848973 0.026539111\n## [13] 0.016244819 0.011793729 0.035606685 0.003954114 0.002984454 0.002953619\n## [19] 0.002999692 0.003767908 0.003242842 0.003565519 0.015092995 0.109981245\n## [25] 0.133971250\n## \n## attr(,\"row.names\")\n##  [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n## [16] \"16\" \"17\" \"18\" \"19\" \"20\" \"21\" \"22\" \"23\" \"24\" \"25\"\n## attr(,\"class\")\n## [1] \"list\"          \"rxtractoTrack\"\nrxtracto computes statistics using all the pixels found in the search radius around each track point."
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html#plotting-the-results-using-plottrack",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html#plotting-the-results-using-plottrack",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "We will use the “plotTrack” function to plot the results. “plotTrack” is a function of the “rerddapXtracto” package designed specifically to plot the results of the “rxtracto” function. It provides an easy way to make a quick plot, however it’s not very customizable.\n# Plot tracks with color: algae specifically designed for chlorophyll\nplotTrack(chl_track, xcoords, ycoords, tcoords, size=3, plotColor = 'viridis')"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html#animating-the-track",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html#animating-the-track",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "One of the nice features of the “plotTrack” function is that it is very easy to make an animation of the track data. This will take a minute to run. It creates an animated gif that will display in the Rstudio viewer window once the encoding to gif is done.\n# Animate tracks\n\nmake180 &lt;- function(lon) {\n    ind &lt;- which(lon &gt; 180)\n    lon[ind] &lt;- lon[ind] - 360\n   return(lon)\n}\n\nplotTrack(chl_track, make180(xcoords), ycoords, tcoords, plotColor = 'viridis',\n                    animate = TRUE, cumulative = TRUE)\n## # A tibble: 25 × 7\n##    format width height colorspace matte filesize density\n##    &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n##  1 gif      672    480 sRGB       TRUE         0 72x72  \n##  2 gif      672    480 sRGB       TRUE         0 72x72  \n##  3 gif      672    480 sRGB       TRUE         0 72x72  \n##  4 gif      672    480 sRGB       TRUE         0 72x72  \n##  5 gif      672    480 sRGB       TRUE         0 72x72  \n##  6 gif      672    480 sRGB       TRUE         0 72x72  \n##  7 gif      672    480 sRGB       TRUE         0 72x72  \n##  8 gif      672    480 sRGB       TRUE         0 72x72  \n##  9 gif      672    480 sRGB       TRUE         0 72x72  \n## 10 gif      672    480 sRGB       TRUE         0 72x72  \n## # ℹ 15 more rows"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-track-locations.html#plotting-the-results-using-ggplot",
    "href": "tutorials/r/matchup-satellite-data-to-track-locations.html#plotting-the-results-using-ggplot",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "If we to do an customization of the plot, its better to plot the dat ausing ggplot. We will first create a data frame that contains longitudes and latitudes from the turtle and associated satellite chlor-a values.\n# Create a data frame of coords from turtle and chlor_a values \nnew_df &lt;- as.data.frame(cbind(xcoords, ycoords,  \n                              chl_track$`requested lon min`, \n                              chl_track$`requested lon max`, \n                              chl_track$`requested lat min`, \n                              chl_track$`requested lon max`,  \n                              chl_track$`mean chlor_a`))\n\n# Set variable names\nnames(new_df) &lt;- c(\"Lon\", \"Lat\", \"Matchup_Lon_Lower\", \"Matchup_Lon_Upper\", \"Matchup_Lat_Lower\", \"Matchup_Lat_Upper\",  \"Chlor_a\")\nwrite.csv(new_df, \"matchup_df.csv\")\n\n\n\n# Import world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Draw the track positions with associated chlora values\nggplot(new_df) +\n  geom_point(aes(Lon,Lat,color=log(Chlor_a))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nFirst we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\ndata_url = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_1d_2018_0.csv?chlor_a\"\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data is severely affected by clouds (i.e. lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer gaps.\n# Set erddap address\nerddap &lt;- \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0.csv?chlor_a\"\n\n# Get longitude and latitude from turtle track data\nlon &lt;- turtle_df$mean_lon\nlat &lt;- turtle_df$mean_lat\n\n# Get time from turtle track data and convert into ERDDAP date format\ndates &lt;- mdy.date(turtle_df$month,turtle_df$day,turtle_df$year)\ndates2 &lt;- format(as.Date(dates), \"%Y-%m-%d\")\n\n# Initatilize tot variable where data will be downloaded to\ntot &lt;- rep(NA, 4)\n\n# Loop through each turtle track data\nfor (i in 1:dim(turtle_df)[1]) {\n\n   # Create erddap URL by adding lat, lon, dates of each track point \n   url &lt;-  paste(erddap, \"[(\", dates2[i], \"):1:(\", dates2[i], \")][(\", lat[i], \"):1:(\", lat[i], \")][(\", lon[i], \"):1:(\", lon[i], \")]\", sep = \"\")  \n   \n   # Request and load satelite data from ERDDAP\n   new &lt;- read.csv(url, skip=2, header = FALSE) \n   \n   # Append the data\n   tot &lt;- rbind(tot, new)   \n}\n\n# Delete the first row (default column names)\ntot &lt;- tot[-1, ]\n\n# Rename columns\nnames(tot) &lt;- c(\"chlo_date\", \"matched_lat\", \"matched_lon\", \"matched_chl.m\")\n\n# Create data frame combining turtle track data and the chlo-a data\nchl_track2 &lt;- data.frame(turtle_df, tot)\n\n# Write the data frame to csv file\nwrite.csv(chl_track2, 'turtle-track-chl.m.csv', row.names = FALSE)\n\n\n\n# Draw the track positions with associated chlora values\nggplot(chl_track2) +\n  geom_point(aes(mean_lon,mean_lat,color=log(matched_chl.m))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nHow do the chlorophyll values of the turtle track compare to values in the surrounding environment? Meaning does the turtle seem to have a preference for certain chlorophyll values? To look at this we will plot a histograms of the track chl valuesand those of the surrounding area.\nFirst we will get a 3D block of chl data from the region and of the turtle track over the span of time the turtle was in that area. We will use the ‘xtracto_3d’ function of rerddapXtracto to get the data. This data call will take a few minutes.\nchl_grid &lt;- rxtracto_3D(dataInfo, \n                  parameter=parameter, \n                  xcoord=c(min(xcoords),max(xcoords)), \n                  ycoord=c(min(ycoords),max(ycoords)), \n                  tcoord=c(min(tcoords),max(tcoords)))\n\nchl_area &lt;- as.vector(chl_grid$chlor_a) \n\n# remove NA values \nchl_area &lt;- chl_area[!is.na(chl_area)]\n\n# vector or turtle chlorophyll \n\nchl_turtle &lt;- chl_track$`mean chlor_a`\nNow we we plot histograms of all the chlorphyll values in the area, and those of the turtle track. Since we subset the turtletrack, and only have 25 points for this subsampopled dataset the turtle histogram isn’t as useful as it would be with a larger dataset.\nggplot(as.data.frame(chl_area)) + \n      geom_histogram(aes(x=chl_area,y=after_stat(density),color = \"darkgray\",fill='Area'),color='black', bins=50) + \n      geom_histogram(data=as.data.frame(chl_turtle), aes(x=chl_turtle,y=after_stat(density),color='green', fill='Turtle'),color='black',bins=50, alpha=.4) + \n      scale_x_continuous(limits = c(0,.9), expand = c(0, 0)) + \n      scale_y_continuous(limits = c(0,15), expand = c(0, 0)) +\n      labs(x='Chlorophyll values',y='Density') + \n      theme_bw() + \n      scale_fill_manual(values=c(\"darkgray\",\"green\"),'')\n\n\n\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html \\ This dataset is a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name.\n\n\n\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ \\ This dataset will likely be on a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name. \\ Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\n\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorDaily_Lon0360.html"
  },
  {
    "objectID": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html",
    "href": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "In this exercise, you will combine satellite and buoy data by extracting satellite measurements around specific points defined by buoy locations and dates.\n- The focus of this exercise is on matching two data sources from different projections.\n- Similar tutorials for mid to lower latitudes can be found at https://github.com/coastwatch-training/CoastWatch-Tutorials.\n\n\n\nUsing ERDDAP to retrieve buoy data in CSV format and satellite data in netCDF format\nImporting and manipulating data with the pandas and xarray libraries\nResampling data to lower-resolution time steps\nConverting latitude and longitude coordinates to the polar stereographic projection\n\n\n\n\nIce Surface Temperature, NOAA-20 VIIRS, Near Real-Time, Polar Stereographic (North), 4-day\nThis dataset provides VIIRS sea ice surface temperature for the Arctic at a 750m resolution, collected by the NOAA-20 satellite. It includes near-real-time daily data and 4-day composites for the past three weeks. For this exercise, we will use 4-day composites data. This dataset is in a polar stereographic projection.\nInternational Arctic Buoy Programme (IABP) Buoy Data, Daily\nThis dataset is from the US International Arctic Buoy Programme and includes meteorological and oceanographic data from buoys. Dataset is updated daily and includes multiple variables. For this exercise, we will extract surface temperature data.\nSatellite Ice Surface Temperature (IST) is measured by the Visible Infrared Imaging Radiometer Suite (VIIRS) and captures the temperature of the surface layer of ice.\nBuoy Surface Temperature (Ts) is measured from the bottom of the buoy hull. If the buoy is floating, the reported temperature is of the sea surface. If the buoy is frozen into the ice or sitting on top of it, the reported temperature is of the ground or ice. The freezing temperature of seawater is about -1.8°C, so temperature readings below this indicate ground or ice temperatures.\nMore details can be found in the metadata section of the data products (click on the data links above).\n\n\n\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE)\n    if(!require(x,character.only = TRUE)) stop(\"Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ncdf4\", \"rerddap\", \"plotdap\", \"httr\",\n                       \"lubridate\", \"gridGraphics\",  \"mapdata\",\n                       \"ggplot2\", \"RColorBrewer\", \"grid\", \"PBSmapping\", \n                       \"rerddapXtracto\",\"dplyr\",\"viridis\",\"cmocean\", \"sf\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\n\n\nUse the info function from the rerddap package. The variable surface_temp will be used for this exercise.\nERDDAP_Node = \"https://polarwatch.noaa.gov/erddap\"\n\nNDBC_id = 'iabpv2_buoys'\nNDBC_info=info(datasetid = NDBC_id,url = ERDDAP_Node)\n\nprint(NDBC_info)\n## &lt;ERDDAP info&gt; iabpv2_buoys \n##  Base URL: https://polarwatch.noaa.gov/erddap \n##  Dataset Type: tabledap \n##  Variables:  \n##      air_temp: \n##          Range: -90.0, 44.78 \n##          Units: degree_C \n##      bp: \n##          Range: 850.0, 1185.9 \n##          Units: mBars \n##      buoy_id: \n##      buoy_owner: \n##      buoy_type: \n##      day_of_year: \n##          Range: 6.0E-4, 366.999 \n##      has_air_temp: \n##      has_bp: \n##      has_surface_temp: \n##      hemisphere: \n##      hour: \n##          Range: 0.0, 24.0 \n##      latitude: \n##          Range: -90.0, 90.0 \n##          Units: degrees_north \n##      logistics: \n##      longitude: \n##          Range: -180.0, 180.0 \n##          Units: degrees_east \n##      minute: \n##          Range: 0.0, 59.0 \n##      surface_temp: \n##          Range: -72.88, 45.0 \n##          Units: degree_C \n##      time: \n##          Range: 1.189717571E9, 1.729396802E9 \n##          Units: seconds since 1970-01-01T00:00:00Z \n##      year: \n##          Range: 2007.0, 2024.0\n\n\n\nbuoy &lt;- rerddap::tabledap(url = ERDDAP_Node, NDBC_id,\n                           fields=c('buoy_id', 'latitude',  'longitude', 'time', 'surface_temp', \n                           'has_surface_temp'), 'time&gt;=2023-08-01',   'time&lt;=2023-09-30'\n)\n\n# Create data frame with the downloaded data\nbuoy.df &lt;-data.frame(buoy_id=as.character(buoy$buoy_id),\n                     longitude=as.numeric(buoy$longitude),\n                     latitude=as.numeric(buoy$latitude),\n                     time=as.POSIXct(buoy$time, \"%Y-%m-%dT%H:%M:%S\", tz=\"UTC\"),\n                     surface_temp=as.numeric(buoy$surface_temp))\n\nsummary(buoy.df)\n##    buoy_id            longitude          latitude     \n##  Length:471572      Min.   :-180.00   Min.   :-74.00  \n##  Class :character   1st Qu.:-129.15   1st Qu.: 73.93  \n##  Mode  :character   Median : -25.04   Median : 82.74  \n##                     Mean   : -21.90   Mean   : 72.16  \n##                     3rd Qu.:  97.57   3rd Qu.: 85.20  \n##                     Max.   : 180.00   Max.   : 90.00  \n##                                                       \n##       time                         surface_temp   \n##  Min.   :2023-08-01 00:00:00.00   Min.   :-60.00  \n##  1st Qu.:2023-08-21 16:00:02.00   1st Qu.: -0.95  \n##  Median :2023-09-06 15:00:00.00   Median :  0.30  \n##  Mean   :2023-09-04 05:39:11.03   Mean   :  1.96  \n##  3rd Qu.:2023-09-18 17:00:23.00   3rd Qu.:  2.69  \n##  Max.   :2023-09-30 00:00:00.00   Max.   : 40.00  \n##                                   NA's   :144689\nhead(buoy.df)\n##           buoy_id longitude latitude                time surface_temp\n## 1 300234066034140  -28.5226  55.0168 2023-08-01 00:00:00         13.5\n## 2 300234066034140  -28.5226  55.0168 2023-08-01 01:00:02         13.4\n## 3 300234066034140  -28.5226  55.0168 2023-08-01 01:59:57         13.4\n## 4 300234066034140  -28.5618  55.0032 2023-08-01 03:00:00         13.4\n## 5 300234066034140  -28.5618  55.0032 2023-08-01 04:00:02         13.3\n## 6 300234066034140  -28.5618  55.0032 2023-08-01 04:59:57         13.3\n\n\n\n\nWe will first select one buoy (buoy id = “300534062897730”). The buoy records measurements at intervals of minutes, resulting in a high-resolution dataset. To align it with the daily resolution of the satellite dataset, we will downsample the buoy data.\n\n\nCheck the number of timesteps\n# Select one buoy (buoy id = \"300534062897730\")\ntarget.buoy &lt;- buoy.df %&gt;% filter(buoy_id == \"300534062897730\")\n\n# Print the number of timestamps before resampling\n# cat(\"# of timesteps before =\", nrow(target.buoy), \"\\n\")\n#print(c(\"# of timesteps before =\", nrow(target.buoy.daily)))\nsteps_before &lt;- length(buoy.df$time)\n\n# Resample to daily mean by averaging surface_temp values for each day\n# And rename surface_temp to temp_buoy\ntarget.buoy.daily &lt;- target.buoy %&gt;%\n  mutate(time = as.Date(time)) %&gt;% \n  group_by(time) %&gt;%\n  summarize(\n    buoy_id = first(buoy_id),\n    longitude = first(longitude),\n    latitude = first(latitude),\n    temp_buoy = mean(surface_temp, na.rm = TRUE))\n\n# Print the number of timesteps after resampling\n# cat(\"# of timesteps before =\", nrow(target.buoy.daily), \"\\n\")\nsteps_after &lt;- length(target.buoy.daily$time)\n\n\nhead(target.buoy.daily)\n## # A tibble: 6 × 5\n##   time       buoy_id         longitude latitude temp_buoy\n##   &lt;date&gt;     &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n## 1 2023-08-01 300534062897730     -144.     86.4     2.19 \n## 2 2023-08-02 300534062897730     -144.     86.4     1.52 \n## 3 2023-08-03 300534062897730     -142.     86.3     0.803\n## 4 2023-08-04 300534062897730     -142.     86.3     0.542\n## 5 2023-08-05 300534062897730     -142.     86.4     0.475\n## 6 2023-08-06 300534062897730     -142.     86.5     0.522\n\n\n\ncat(\"# of timesteps before =\", steps_before, \"# of timesteps after =\", steps_after)\n## # of timesteps before = 471572 # of timesteps after = 60\n#length(buoy.df$time)\n\n\n\n\nThe buoy locations are provided in latitude and longitude coordinates, whereas the satellite data are in a polar stereographic projection with locations in units of meters. We will convert the buoy locations from latitude and longitude to the corresponding columns and rows in the polar projection.\n# Define the projection using the PROJ4 string format\nproj4text &lt;- \"+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n\n# Convert the dataframe into an sf object (Spatial Dataframe)\ntarget.buoy.sf &lt;- st_as_sf(target.buoy.daily, coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\n# Reproject the data to the Polar Stereographic projection using the PROJ4 string\ntarget.buoy.projected &lt;- st_transform(target.buoy.sf, crs = proj4text)\n\n# Extract the projected coordinates\ntarget.buoy.projected$cols &lt;- st_coordinates(target.buoy.projected)[,1] # X (columns)\ntarget.buoy.projected$rows &lt;- st_coordinates(target.buoy.projected)[,2] # Y (rows)\n\n# Show the first 2 rows to verify that the 'cols' and 'rows' columns were added\nhead(target.buoy.projected, 2)\n## Simple feature collection with 2 features and 5 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -389549.6 ymin: 58944.53 xmax: -385824.4 ymax: 59121.58\n## Projected CRS: +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\n## # A tibble: 2 × 6\n##   time       buoy_id         temp_buoy             geometry     cols   rows\n##   &lt;date&gt;     &lt;chr&gt;               &lt;dbl&gt;          &lt;POINT [m]&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n## 1 2023-08-01 300534062897730      2.19 (-385824.4 58944.53) -385824. 58945.\n## 2 2023-08-02 300534062897730      1.52 (-389549.6 59121.58) -389550. 59122.\n# Select the first buoy location to pull corresponding satellite data\ntarget.buoy.cols &lt;- target.buoy.projected$cols[1]\ntarget.buoy.rows &lt;- target.buoy.projected$rows[1]\n\n# Verify the data\nprint(target.buoy.cols)\n## [1] -385824.4\nprint(target.buoy.rows)\n## [1] 58944.53\n\n\nLook at the metadata to check the metadata Note that the temperature is in degrees Kelvin.\nNDBC_id_2 = 'noaacwVIIRSn20icesrftempNP06Daily4Day'\nNDBC_info_2=info(datasetid = NDBC_id_2,url = ERDDAP_Node)\n\nprint(NDBC_info_2)\n## &lt;ERDDAP info&gt; noaacwVIIRSn20icesrftempNP06Daily4Day \n##  Base URL: https://polarwatch.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (2021-04-13T00:00:00Z, 2024-10-15T00:00:00Z) \n##      altitude: (0.0, 0.0) \n##      rows: (-3434002.5, 3434002.5) \n##      cols: (-3434002.5, 3434002.5) \n##  Variables:  \n##      IceSrfTemp: \n##          Units: Kelvin(K)\n\n\n\n\nUse the rxtracto function from the rerddapXtracto package\nzpos &lt;- rep(0., length(target.buoy.projected$time))\n\nsat_data &lt;- rxtracto(NDBC_info_2,\n                    xName=\"cols\",\n                    yName=\"rows\",\n                    tName=\"time\",\n                    zName=\"altitude\",\n                    parameter=\"IceSrfTemp\",\n                    xcoord = target.buoy.projected$cols,\n                    ycoord = target.buoy.projected$rows,\n                    tcoord = target.buoy.projected$time,\n                    zcoord = zpos\n                    )\nhead(sat_data)\n## $`mean IceSrfTemp`\n##  [1] 272.9286      NaN      NaN      NaN      NaN      NaN 271.0790 270.2815\n##  [9]      NaN      NaN      NaN 272.5218      NaN 271.7425 272.3054 270.4868\n## [17] 270.3914 273.3692 273.4933 272.3756 273.1550 273.1486 273.4222      NaN\n## [25]      NaN      NaN      NaN 269.4200 268.0554 267.6486 268.2197      NaN\n## [33]      NaN      NaN      NaN      NaN 266.4402 268.3176 268.0433 267.8826\n## [41] 268.3053      NaN      NaN      NaN      NaN      NaN      NaN 270.8179\n## [49]      NaN      NaN      NaN      NaN 264.4946 263.8606      NaN      NaN\n## [57] 256.9289      NaN      NaN      NaN\n## \n## $`stdev IceSrfTemp`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [51] NA NA NA NA NA NA NA NA NA NA\n## \n## $n\n##  [1] 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1\n## [39] 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0\n## \n## $`satellite date`\n##  [1] \"2023-08-01T00:00:00Z\" \"2023-08-02T00:00:00Z\" \"2023-08-03T00:00:00Z\"\n##  [4] \"2023-08-04T00:00:00Z\" \"2023-08-05T00:00:00Z\" \"2023-08-06T00:00:00Z\"\n##  [7] \"2023-08-07T00:00:00Z\" \"2023-08-08T00:00:00Z\" \"2023-08-09T00:00:00Z\"\n## [10] \"2023-08-10T00:00:00Z\" \"2023-08-11T00:00:00Z\" \"2023-08-12T00:00:00Z\"\n## [13] \"2023-08-13T00:00:00Z\" \"2023-08-14T00:00:00Z\" \"2023-08-15T00:00:00Z\"\n## [16] \"2023-08-16T00:00:00Z\" \"2023-08-17T00:00:00Z\" \"2023-08-18T00:00:00Z\"\n## [19] \"2023-08-19T00:00:00Z\" \"2023-08-20T00:00:00Z\" \"2023-08-21T00:00:00Z\"\n## [22] \"2023-08-22T00:00:00Z\" \"2023-08-23T00:00:00Z\" \"2023-08-24T00:00:00Z\"\n## [25] \"2023-08-25T00:00:00Z\" \"2023-08-26T00:00:00Z\" \"2023-08-27T00:00:00Z\"\n## [28] \"2023-08-28T00:00:00Z\" \"2023-08-29T00:00:00Z\" \"2023-08-30T00:00:00Z\"\n## [31] \"2023-08-31T00:00:00Z\" \"2023-09-01T00:00:00Z\" \"2023-09-02T00:00:00Z\"\n## [34] \"2023-09-03T00:00:00Z\" \"2023-09-04T00:00:00Z\" \"2023-09-05T00:00:00Z\"\n## [37] \"2023-09-06T00:00:00Z\" \"2023-09-07T00:00:00Z\" \"2023-09-08T00:00:00Z\"\n## [40] \"2023-09-09T00:00:00Z\" \"2023-09-10T00:00:00Z\" \"2023-09-11T00:00:00Z\"\n## [43] \"2023-09-12T00:00:00Z\" \"2023-09-13T00:00:00Z\" \"2023-09-14T00:00:00Z\"\n## [46] \"2023-09-15T00:00:00Z\" \"2023-09-16T00:00:00Z\" \"2023-09-17T00:00:00Z\"\n## [49] \"2023-09-18T00:00:00Z\" \"2023-09-19T00:00:00Z\" \"2023-09-20T00:00:00Z\"\n## [52] \"2023-09-21T00:00:00Z\" \"2023-09-22T00:00:00Z\" \"2023-09-23T00:00:00Z\"\n## [55] \"2023-09-24T00:00:00Z\" \"2023-09-25T00:00:00Z\" \"2023-09-26T00:00:00Z\"\n## [58] \"2023-09-27T00:00:00Z\" \"2023-09-28T00:00:00Z\" \"2023-09-29T00:00:00Z\"\n## \n## $`requested x min`\n##  [1] -385824.4 -389549.6 -398253.9 -399928.2 -383575.3 -376519.9 -373178.9\n##  [8] -369485.9 -364101.8 -358053.1 -344667.3 -339413.6 -325379.7 -308859.0\n## [15] -297005.5 -290218.6 -283776.4 -280170.8 -271276.3 -263223.8 -263830.1\n## [22] -269754.9 -268728.9 -262726.0 -258730.5 -262527.7 -277050.1 -274674.6\n## [29] -261436.0 -250715.5 -248618.1 -253833.2 -247254.1 -241801.9 -248913.6\n## [36] -253308.9 -253242.1 -259535.5 -256109.5 -263955.3 -260399.8 -254873.5\n## [43] -244906.9 -239308.2 -230283.9 -227856.9 -220466.8 -213128.6 -205585.0\n## [50] -194830.9 -185590.9 -183007.2 -178188.9 -176271.0 -179406.9 -180725.3\n## [57] -176656.0 -171027.2 -162577.7 -149611.3\n## \n## $`requested x max`\n##  [1] -385824.4 -389549.6 -398253.9 -399928.2 -383575.3 -376519.9 -373178.9\n##  [8] -369485.9 -364101.8 -358053.1 -344667.3 -339413.6 -325379.7 -308859.0\n## [15] -297005.5 -290218.6 -283776.4 -280170.8 -271276.3 -263223.8 -263830.1\n## [22] -269754.9 -268728.9 -262726.0 -258730.5 -262527.7 -277050.1 -274674.6\n## [29] -261436.0 -250715.5 -248618.1 -253833.2 -247254.1 -241801.9 -248913.6\n## [36] -253308.9 -253242.1 -259535.5 -256109.5 -263955.3 -260399.8 -254873.5\n## [43] -244906.9 -239308.2 -230283.9 -227856.9 -220466.8 -213128.6 -205585.0\n## [50] -194830.9 -185590.9 -183007.2 -178188.9 -176271.0 -179406.9 -180725.3\n## [57] -176656.0 -171027.2 -162577.7 -149611.3\n\n\n#sftemp_ds_subset$temp_sat &lt;- sftemp_ds_subset$IceSrfTemp - 273.15\ntemp_sat &lt;- sat_data$mean - 273.15\ntemp_sat\n##  [1]  -0.221441650           NaN           NaN           NaN           NaN\n##  [6]           NaN  -2.070959473  -2.868536377           NaN           NaN\n## [11]           NaN  -0.628179932           NaN  -1.407537842  -0.844641113\n## [16]  -2.663214111  -2.758581543   0.219171143   0.343347168  -0.774359131\n## [21]   0.004998779  -0.001409912   0.272210693           NaN           NaN\n## [26]           NaN           NaN  -3.729956055  -5.094610596  -5.501409912\n## [31]  -4.930303955           NaN           NaN           NaN           NaN\n## [36]           NaN  -6.709814453  -4.832434082  -5.106665039  -5.267431641\n## [41]  -4.844671631           NaN           NaN           NaN           NaN\n## [46]           NaN           NaN  -2.332067871           NaN           NaN\n## [51]           NaN           NaN  -8.655371094  -9.289373779           NaN\n## [56]           NaN -16.221136475           NaN           NaN           NaN\n#extract$mean\n\n\n\nAdd the satellite ice temperature to the buoy dataset. Not all buoy dates have corresponding satellite data. Any unmatched dates will be filled with NaN values.\ntarget.buoy.projected$temp_sat &lt;- temp_sat\nhead(target.buoy.projected)\n## Simple feature collection with 6 features and 6 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -399928.2 ymin: 46312.22 xmax: -376519.9 ymax: 59121.58\n## Projected CRS: +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\n## # A tibble: 6 × 7\n##   time       buoy_id temp_buoy             geometry     cols   rows temp_sat\n##   &lt;date&gt;     &lt;chr&gt;       &lt;dbl&gt;          &lt;POINT [m]&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n## 1 2023-08-01 300534…     2.19  (-385824.4 58944.53) -385824. 58945.   -0.221\n## 2 2023-08-02 300534…     1.52  (-389549.6 59121.58) -389550. 59122.  NaN    \n## 3 2023-08-03 300534…     0.803 (-398253.9 50891.54) -398254. 50892.  NaN    \n## 4 2023-08-04 300534…     0.542 (-399928.2 48358.67) -399928. 48359.  NaN    \n## 5 2023-08-05 300534…     0.475 (-383575.3 49983.71) -383575. 49984.  NaN    \n## 6 2023-08-06 300534…     0.522 (-376519.9 46312.22) -376520. 46312.  NaN\n\n\n\nVisualize the matched buoy and satellite datasets to assess the data alignment.\n# Create the plot\nggplot(target.buoy.projected, aes(x = time)) +\n  # Plot the buoy data\n  geom_point(aes(y = temp_buoy, color = 'Buoy Surface Temperature'), size =3) +\n  geom_line(aes(y = temp_buoy, color = 'Buoy Surface Temperature'), linewidth = 1, na.rm = TRUE) +\n  \n  # Plot the satellite (VIIRS Sea Ice Surface Temperature) data\n  geom_point(aes(y = temp_sat, color = 'VIIRS Sea Ice Surface Temperature'), shape = 15, size = 3) +\n  geom_line(aes(y = temp_sat, color = 'VIIRS Sea Ice Surface Temperature'), linewidth = 1, na.rm = TRUE) +\n  \n  # Set the y-axis limits\n  ylim(-20, 5) +\n  \n  # Labels and theme\n  labs(x = 'Time', y = 'Temperature (degrees C)', color = 'Legend') +\n  scale_color_manual(values = c('Buoy Surface Temperature' = 'red',\n                                'VIIRS Sea Ice Surface Temperature' = 'blue')) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#this-exercise-demonstrates-the-following-techniques",
    "href": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#this-exercise-demonstrates-the-following-techniques",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "Using ERDDAP to retrieve buoy data in CSV format and satellite data in netCDF format\nImporting and manipulating data with the pandas and xarray libraries\nResampling data to lower-resolution time steps\nConverting latitude and longitude coordinates to the polar stereographic projection"
  },
  {
    "objectID": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#data-used-in-this-exercise",
    "href": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#data-used-in-this-exercise",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "Ice Surface Temperature, NOAA-20 VIIRS, Near Real-Time, Polar Stereographic (North), 4-day\nThis dataset provides VIIRS sea ice surface temperature for the Arctic at a 750m resolution, collected by the NOAA-20 satellite. It includes near-real-time daily data and 4-day composites for the past three weeks. For this exercise, we will use 4-day composites data. This dataset is in a polar stereographic projection.\nInternational Arctic Buoy Programme (IABP) Buoy Data, Daily\nThis dataset is from the US International Arctic Buoy Programme and includes meteorological and oceanographic data from buoys. Dataset is updated daily and includes multiple variables. For this exercise, we will extract surface temperature data.\nSatellite Ice Surface Temperature (IST) is measured by the Visible Infrared Imaging Radiometer Suite (VIIRS) and captures the temperature of the surface layer of ice.\nBuoy Surface Temperature (Ts) is measured from the bottom of the buoy hull. If the buoy is floating, the reported temperature is of the sea surface. If the buoy is frozen into the ice or sitting on top of it, the reported temperature is of the ground or ice. The freezing temperature of seawater is about -1.8°C, so temperature readings below this indicate ground or ice temperatures.\nMore details can be found in the metadata section of the data products (click on the data links above)."
  },
  {
    "objectID": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#load-packages",
    "href": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#load-packages",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "pkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE)\n    if(!require(x,character.only = TRUE)) stop(\"Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ncdf4\", \"rerddap\", \"plotdap\", \"httr\",\n                       \"lubridate\", \"gridGraphics\",  \"mapdata\",\n                       \"ggplot2\", \"RColorBrewer\", \"grid\", \"PBSmapping\", \n                       \"rerddapXtracto\",\"dplyr\",\"viridis\",\"cmocean\", \"sf\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#load-buoy-data-iabp-from-polarwatch-erddap-data-server",
    "href": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#load-buoy-data-iabp-from-polarwatch-erddap-data-server",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "Use the info function from the rerddap package. The variable surface_temp will be used for this exercise.\nERDDAP_Node = \"https://polarwatch.noaa.gov/erddap\"\n\nNDBC_id = 'iabpv2_buoys'\nNDBC_info=info(datasetid = NDBC_id,url = ERDDAP_Node)\n\nprint(NDBC_info)\n## &lt;ERDDAP info&gt; iabpv2_buoys \n##  Base URL: https://polarwatch.noaa.gov/erddap \n##  Dataset Type: tabledap \n##  Variables:  \n##      air_temp: \n##          Range: -90.0, 44.78 \n##          Units: degree_C \n##      bp: \n##          Range: 850.0, 1185.9 \n##          Units: mBars \n##      buoy_id: \n##      buoy_owner: \n##      buoy_type: \n##      day_of_year: \n##          Range: 6.0E-4, 366.999 \n##      has_air_temp: \n##      has_bp: \n##      has_surface_temp: \n##      hemisphere: \n##      hour: \n##          Range: 0.0, 24.0 \n##      latitude: \n##          Range: -90.0, 90.0 \n##          Units: degrees_north \n##      logistics: \n##      longitude: \n##          Range: -180.0, 180.0 \n##          Units: degrees_east \n##      minute: \n##          Range: 0.0, 59.0 \n##      surface_temp: \n##          Range: -72.88, 45.0 \n##          Units: degree_C \n##      time: \n##          Range: 1.189717571E9, 1.729396802E9 \n##          Units: seconds since 1970-01-01T00:00:00Z \n##      year: \n##          Range: 2007.0, 2024.0\n\n\n\nbuoy &lt;- rerddap::tabledap(url = ERDDAP_Node, NDBC_id,\n                           fields=c('buoy_id', 'latitude',  'longitude', 'time', 'surface_temp', \n                           'has_surface_temp'), 'time&gt;=2023-08-01',   'time&lt;=2023-09-30'\n)\n\n# Create data frame with the downloaded data\nbuoy.df &lt;-data.frame(buoy_id=as.character(buoy$buoy_id),\n                     longitude=as.numeric(buoy$longitude),\n                     latitude=as.numeric(buoy$latitude),\n                     time=as.POSIXct(buoy$time, \"%Y-%m-%dT%H:%M:%S\", tz=\"UTC\"),\n                     surface_temp=as.numeric(buoy$surface_temp))\n\nsummary(buoy.df)\n##    buoy_id            longitude          latitude     \n##  Length:471572      Min.   :-180.00   Min.   :-74.00  \n##  Class :character   1st Qu.:-129.15   1st Qu.: 73.93  \n##  Mode  :character   Median : -25.04   Median : 82.74  \n##                     Mean   : -21.90   Mean   : 72.16  \n##                     3rd Qu.:  97.57   3rd Qu.: 85.20  \n##                     Max.   : 180.00   Max.   : 90.00  \n##                                                       \n##       time                         surface_temp   \n##  Min.   :2023-08-01 00:00:00.00   Min.   :-60.00  \n##  1st Qu.:2023-08-21 16:00:02.00   1st Qu.: -0.95  \n##  Median :2023-09-06 15:00:00.00   Median :  0.30  \n##  Mean   :2023-09-04 05:39:11.03   Mean   :  1.96  \n##  3rd Qu.:2023-09-18 17:00:23.00   3rd Qu.:  2.69  \n##  Max.   :2023-09-30 00:00:00.00   Max.   : 40.00  \n##                                   NA's   :144689\nhead(buoy.df)\n##           buoy_id longitude latitude                time surface_temp\n## 1 300234066034140  -28.5226  55.0168 2023-08-01 00:00:00         13.5\n## 2 300234066034140  -28.5226  55.0168 2023-08-01 01:00:02         13.4\n## 3 300234066034140  -28.5226  55.0168 2023-08-01 01:59:57         13.4\n## 4 300234066034140  -28.5618  55.0032 2023-08-01 03:00:00         13.4\n## 5 300234066034140  -28.5618  55.0032 2023-08-01 04:00:02         13.3\n## 6 300234066034140  -28.5618  55.0032 2023-08-01 04:59:57         13.3"
  },
  {
    "objectID": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#select-one-buoy-and-process-data",
    "href": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#select-one-buoy-and-process-data",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "We will first select one buoy (buoy id = “300534062897730”). The buoy records measurements at intervals of minutes, resulting in a high-resolution dataset. To align it with the daily resolution of the satellite dataset, we will downsample the buoy data.\n\n\nCheck the number of timesteps\n# Select one buoy (buoy id = \"300534062897730\")\ntarget.buoy &lt;- buoy.df %&gt;% filter(buoy_id == \"300534062897730\")\n\n# Print the number of timestamps before resampling\n# cat(\"# of timesteps before =\", nrow(target.buoy), \"\\n\")\n#print(c(\"# of timesteps before =\", nrow(target.buoy.daily)))\nsteps_before &lt;- length(buoy.df$time)\n\n# Resample to daily mean by averaging surface_temp values for each day\n# And rename surface_temp to temp_buoy\ntarget.buoy.daily &lt;- target.buoy %&gt;%\n  mutate(time = as.Date(time)) %&gt;% \n  group_by(time) %&gt;%\n  summarize(\n    buoy_id = first(buoy_id),\n    longitude = first(longitude),\n    latitude = first(latitude),\n    temp_buoy = mean(surface_temp, na.rm = TRUE))\n\n# Print the number of timesteps after resampling\n# cat(\"# of timesteps before =\", nrow(target.buoy.daily), \"\\n\")\nsteps_after &lt;- length(target.buoy.daily$time)\n\n\nhead(target.buoy.daily)\n## # A tibble: 6 × 5\n##   time       buoy_id         longitude latitude temp_buoy\n##   &lt;date&gt;     &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n## 1 2023-08-01 300534062897730     -144.     86.4     2.19 \n## 2 2023-08-02 300534062897730     -144.     86.4     1.52 \n## 3 2023-08-03 300534062897730     -142.     86.3     0.803\n## 4 2023-08-04 300534062897730     -142.     86.3     0.542\n## 5 2023-08-05 300534062897730     -142.     86.4     0.475\n## 6 2023-08-06 300534062897730     -142.     86.5     0.522\n\n\n\ncat(\"# of timesteps before =\", steps_before, \"# of timesteps after =\", steps_after)\n## # of timesteps before = 471572 # of timesteps after = 60\n#length(buoy.df$time)"
  },
  {
    "objectID": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#transform-buoy-coordinates-to-polar-projection",
    "href": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#transform-buoy-coordinates-to-polar-projection",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "The buoy locations are provided in latitude and longitude coordinates, whereas the satellite data are in a polar stereographic projection with locations in units of meters. We will convert the buoy locations from latitude and longitude to the corresponding columns and rows in the polar projection.\n# Define the projection using the PROJ4 string format\nproj4text &lt;- \"+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n\n# Convert the dataframe into an sf object (Spatial Dataframe)\ntarget.buoy.sf &lt;- st_as_sf(target.buoy.daily, coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\n# Reproject the data to the Polar Stereographic projection using the PROJ4 string\ntarget.buoy.projected &lt;- st_transform(target.buoy.sf, crs = proj4text)\n\n# Extract the projected coordinates\ntarget.buoy.projected$cols &lt;- st_coordinates(target.buoy.projected)[,1] # X (columns)\ntarget.buoy.projected$rows &lt;- st_coordinates(target.buoy.projected)[,2] # Y (rows)\n\n# Show the first 2 rows to verify that the 'cols' and 'rows' columns were added\nhead(target.buoy.projected, 2)\n## Simple feature collection with 2 features and 5 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -389549.6 ymin: 58944.53 xmax: -385824.4 ymax: 59121.58\n## Projected CRS: +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\n## # A tibble: 2 × 6\n##   time       buoy_id         temp_buoy             geometry     cols   rows\n##   &lt;date&gt;     &lt;chr&gt;               &lt;dbl&gt;          &lt;POINT [m]&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n## 1 2023-08-01 300534062897730      2.19 (-385824.4 58944.53) -385824. 58945.\n## 2 2023-08-02 300534062897730      1.52 (-389549.6 59121.58) -389550. 59122.\n# Select the first buoy location to pull corresponding satellite data\ntarget.buoy.cols &lt;- target.buoy.projected$cols[1]\ntarget.buoy.rows &lt;- target.buoy.projected$rows[1]\n\n# Verify the data\nprint(target.buoy.cols)\n## [1] -385824.4\nprint(target.buoy.rows)\n## [1] 58944.53\n\n\nLook at the metadata to check the metadata Note that the temperature is in degrees Kelvin.\nNDBC_id_2 = 'noaacwVIIRSn20icesrftempNP06Daily4Day'\nNDBC_info_2=info(datasetid = NDBC_id_2,url = ERDDAP_Node)\n\nprint(NDBC_info_2)\n## &lt;ERDDAP info&gt; noaacwVIIRSn20icesrftempNP06Daily4Day \n##  Base URL: https://polarwatch.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (2021-04-13T00:00:00Z, 2024-10-15T00:00:00Z) \n##      altitude: (0.0, 0.0) \n##      rows: (-3434002.5, 3434002.5) \n##      cols: (-3434002.5, 3434002.5) \n##  Variables:  \n##      IceSrfTemp: \n##          Units: Kelvin(K)"
  },
  {
    "objectID": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#extract-the-satellite-ice-surface-temperture-timeseries",
    "href": "tutorials/r/matchup-polar-satellite-data-to-buoy-data.html#extract-the-satellite-ice-surface-temperture-timeseries",
    "title": "Matching Satellite and Buoy Data",
    "section": "",
    "text": "Use the rxtracto function from the rerddapXtracto package\nzpos &lt;- rep(0., length(target.buoy.projected$time))\n\nsat_data &lt;- rxtracto(NDBC_info_2,\n                    xName=\"cols\",\n                    yName=\"rows\",\n                    tName=\"time\",\n                    zName=\"altitude\",\n                    parameter=\"IceSrfTemp\",\n                    xcoord = target.buoy.projected$cols,\n                    ycoord = target.buoy.projected$rows,\n                    tcoord = target.buoy.projected$time,\n                    zcoord = zpos\n                    )\nhead(sat_data)\n## $`mean IceSrfTemp`\n##  [1] 272.9286      NaN      NaN      NaN      NaN      NaN 271.0790 270.2815\n##  [9]      NaN      NaN      NaN 272.5218      NaN 271.7425 272.3054 270.4868\n## [17] 270.3914 273.3692 273.4933 272.3756 273.1550 273.1486 273.4222      NaN\n## [25]      NaN      NaN      NaN 269.4200 268.0554 267.6486 268.2197      NaN\n## [33]      NaN      NaN      NaN      NaN 266.4402 268.3176 268.0433 267.8826\n## [41] 268.3053      NaN      NaN      NaN      NaN      NaN      NaN 270.8179\n## [49]      NaN      NaN      NaN      NaN 264.4946 263.8606      NaN      NaN\n## [57] 256.9289      NaN      NaN      NaN\n## \n## $`stdev IceSrfTemp`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [51] NA NA NA NA NA NA NA NA NA NA\n## \n## $n\n##  [1] 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1\n## [39] 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0\n## \n## $`satellite date`\n##  [1] \"2023-08-01T00:00:00Z\" \"2023-08-02T00:00:00Z\" \"2023-08-03T00:00:00Z\"\n##  [4] \"2023-08-04T00:00:00Z\" \"2023-08-05T00:00:00Z\" \"2023-08-06T00:00:00Z\"\n##  [7] \"2023-08-07T00:00:00Z\" \"2023-08-08T00:00:00Z\" \"2023-08-09T00:00:00Z\"\n## [10] \"2023-08-10T00:00:00Z\" \"2023-08-11T00:00:00Z\" \"2023-08-12T00:00:00Z\"\n## [13] \"2023-08-13T00:00:00Z\" \"2023-08-14T00:00:00Z\" \"2023-08-15T00:00:00Z\"\n## [16] \"2023-08-16T00:00:00Z\" \"2023-08-17T00:00:00Z\" \"2023-08-18T00:00:00Z\"\n## [19] \"2023-08-19T00:00:00Z\" \"2023-08-20T00:00:00Z\" \"2023-08-21T00:00:00Z\"\n## [22] \"2023-08-22T00:00:00Z\" \"2023-08-23T00:00:00Z\" \"2023-08-24T00:00:00Z\"\n## [25] \"2023-08-25T00:00:00Z\" \"2023-08-26T00:00:00Z\" \"2023-08-27T00:00:00Z\"\n## [28] \"2023-08-28T00:00:00Z\" \"2023-08-29T00:00:00Z\" \"2023-08-30T00:00:00Z\"\n## [31] \"2023-08-31T00:00:00Z\" \"2023-09-01T00:00:00Z\" \"2023-09-02T00:00:00Z\"\n## [34] \"2023-09-03T00:00:00Z\" \"2023-09-04T00:00:00Z\" \"2023-09-05T00:00:00Z\"\n## [37] \"2023-09-06T00:00:00Z\" \"2023-09-07T00:00:00Z\" \"2023-09-08T00:00:00Z\"\n## [40] \"2023-09-09T00:00:00Z\" \"2023-09-10T00:00:00Z\" \"2023-09-11T00:00:00Z\"\n## [43] \"2023-09-12T00:00:00Z\" \"2023-09-13T00:00:00Z\" \"2023-09-14T00:00:00Z\"\n## [46] \"2023-09-15T00:00:00Z\" \"2023-09-16T00:00:00Z\" \"2023-09-17T00:00:00Z\"\n## [49] \"2023-09-18T00:00:00Z\" \"2023-09-19T00:00:00Z\" \"2023-09-20T00:00:00Z\"\n## [52] \"2023-09-21T00:00:00Z\" \"2023-09-22T00:00:00Z\" \"2023-09-23T00:00:00Z\"\n## [55] \"2023-09-24T00:00:00Z\" \"2023-09-25T00:00:00Z\" \"2023-09-26T00:00:00Z\"\n## [58] \"2023-09-27T00:00:00Z\" \"2023-09-28T00:00:00Z\" \"2023-09-29T00:00:00Z\"\n## \n## $`requested x min`\n##  [1] -385824.4 -389549.6 -398253.9 -399928.2 -383575.3 -376519.9 -373178.9\n##  [8] -369485.9 -364101.8 -358053.1 -344667.3 -339413.6 -325379.7 -308859.0\n## [15] -297005.5 -290218.6 -283776.4 -280170.8 -271276.3 -263223.8 -263830.1\n## [22] -269754.9 -268728.9 -262726.0 -258730.5 -262527.7 -277050.1 -274674.6\n## [29] -261436.0 -250715.5 -248618.1 -253833.2 -247254.1 -241801.9 -248913.6\n## [36] -253308.9 -253242.1 -259535.5 -256109.5 -263955.3 -260399.8 -254873.5\n## [43] -244906.9 -239308.2 -230283.9 -227856.9 -220466.8 -213128.6 -205585.0\n## [50] -194830.9 -185590.9 -183007.2 -178188.9 -176271.0 -179406.9 -180725.3\n## [57] -176656.0 -171027.2 -162577.7 -149611.3\n## \n## $`requested x max`\n##  [1] -385824.4 -389549.6 -398253.9 -399928.2 -383575.3 -376519.9 -373178.9\n##  [8] -369485.9 -364101.8 -358053.1 -344667.3 -339413.6 -325379.7 -308859.0\n## [15] -297005.5 -290218.6 -283776.4 -280170.8 -271276.3 -263223.8 -263830.1\n## [22] -269754.9 -268728.9 -262726.0 -258730.5 -262527.7 -277050.1 -274674.6\n## [29] -261436.0 -250715.5 -248618.1 -253833.2 -247254.1 -241801.9 -248913.6\n## [36] -253308.9 -253242.1 -259535.5 -256109.5 -263955.3 -260399.8 -254873.5\n## [43] -244906.9 -239308.2 -230283.9 -227856.9 -220466.8 -213128.6 -205585.0\n## [50] -194830.9 -185590.9 -183007.2 -178188.9 -176271.0 -179406.9 -180725.3\n## [57] -176656.0 -171027.2 -162577.7 -149611.3\n\n\n#sftemp_ds_subset$temp_sat &lt;- sftemp_ds_subset$IceSrfTemp - 273.15\ntemp_sat &lt;- sat_data$mean - 273.15\ntemp_sat\n##  [1]  -0.221441650           NaN           NaN           NaN           NaN\n##  [6]           NaN  -2.070959473  -2.868536377           NaN           NaN\n## [11]           NaN  -0.628179932           NaN  -1.407537842  -0.844641113\n## [16]  -2.663214111  -2.758581543   0.219171143   0.343347168  -0.774359131\n## [21]   0.004998779  -0.001409912   0.272210693           NaN           NaN\n## [26]           NaN           NaN  -3.729956055  -5.094610596  -5.501409912\n## [31]  -4.930303955           NaN           NaN           NaN           NaN\n## [36]           NaN  -6.709814453  -4.832434082  -5.106665039  -5.267431641\n## [41]  -4.844671631           NaN           NaN           NaN           NaN\n## [46]           NaN           NaN  -2.332067871           NaN           NaN\n## [51]           NaN           NaN  -8.655371094  -9.289373779           NaN\n## [56]           NaN -16.221136475           NaN           NaN           NaN\n#extract$mean\n\n\n\nAdd the satellite ice temperature to the buoy dataset. Not all buoy dates have corresponding satellite data. Any unmatched dates will be filled with NaN values.\ntarget.buoy.projected$temp_sat &lt;- temp_sat\nhead(target.buoy.projected)\n## Simple feature collection with 6 features and 6 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -399928.2 ymin: 46312.22 xmax: -376519.9 ymax: 59121.58\n## Projected CRS: +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\n## # A tibble: 6 × 7\n##   time       buoy_id temp_buoy             geometry     cols   rows temp_sat\n##   &lt;date&gt;     &lt;chr&gt;       &lt;dbl&gt;          &lt;POINT [m]&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n## 1 2023-08-01 300534…     2.19  (-385824.4 58944.53) -385824. 58945.   -0.221\n## 2 2023-08-02 300534…     1.52  (-389549.6 59121.58) -389550. 59122.  NaN    \n## 3 2023-08-03 300534…     0.803 (-398253.9 50891.54) -398254. 50892.  NaN    \n## 4 2023-08-04 300534…     0.542 (-399928.2 48358.67) -399928. 48359.  NaN    \n## 5 2023-08-05 300534…     0.475 (-383575.3 49983.71) -383575. 49984.  NaN    \n## 6 2023-08-06 300534…     0.522 (-376519.9 46312.22) -376520. 46312.  NaN\n\n\n\nVisualize the matched buoy and satellite datasets to assess the data alignment.\n# Create the plot\nggplot(target.buoy.projected, aes(x = time)) +\n  # Plot the buoy data\n  geom_point(aes(y = temp_buoy, color = 'Buoy Surface Temperature'), size =3) +\n  geom_line(aes(y = temp_buoy, color = 'Buoy Surface Temperature'), linewidth = 1, na.rm = TRUE) +\n  \n  # Plot the satellite (VIIRS Sea Ice Surface Temperature) data\n  geom_point(aes(y = temp_sat, color = 'VIIRS Sea Ice Surface Temperature'), shape = 15, size = 3) +\n  geom_line(aes(y = temp_sat, color = 'VIIRS Sea Ice Surface Temperature'), linewidth = 1, na.rm = TRUE) +\n  \n  # Set the y-axis limits\n  ylim(-20, 5) +\n  \n  # Labels and theme\n  labs(x = 'Time', y = 'Temperature (degrees C)', color = 'Legend') +\n  scale_color_manual(values = c('Buoy Surface Temperature' = 'red',\n                                'VIIRS Sea Ice Surface Temperature' = 'blue')) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html",
    "href": "tutorials/r/mask-shallow-ocean-color.html",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "Updated March 2024 \n\nRemotely sensed ocean color algorithms are calibrated for optically-deep waters, where the signal received by the satellite sensor originates from the water column without any bottom contribution.\nOptically shallow waters are those in which light reflected off the seafloor contributes significantly to the water-leaving signal, such as coral reefs, atolls, lagoons. This is known to affect geophysical variables derived by ocean-color algorithms, often leading to biased values in chlorophyll-a concentration for example.\nIn the tropical Pacific, optically-deep waters are typically deeper than 15 – 30 m. It is recommended to remove shallow-pixels, i.e., ocean color pixels that contain a portion (e.g., more than 5%) of shallow water area (less than 30m depth), from the study area before computing ocean color metrics (Couch et al., 2023).\n\n\nIn this tutorial, we demonstrate how to create a mask to remove ocean color pixels in the coastal shallow water that are contaminated by bottom reflectance.\n\n\n\n\nAccessing and Downloading satellite data from ERDDAP data server\nVisualizing the datasets\nMatching coarse-resolution ocean color data with fine-resolution bathymetry data\nCalculating percentage of shallow water area in each ocean color pixel\nCreating and applying value mask to datasets\nCalculating long-term climatology from monthly data\nOutputing dataset into netCDF format\n\n\n\n\nBathymetry data, ETOPO Global Relief Model integrates topography, bathymetry, and shoreline data, version 2022, 15 arc-second resolution\nOcean color data, ESA CCI chlorophyll-a concentration, 1998-2022, monthly\n\n\n\nCouch CS, Oliver TA, Dettloff K, Huntington B, Tanaka KR and Vargas-Ángel B (2023) Ecological and environmental predictors of juvenile coral density across the central and western Pacific. Front. Mar. Sci. 10:1192102.  doi: 10.3389/fmars.2023.1192102 \n\n\n\n# Load libraries\nlibrary(rerddap)\nlibrary(raster) \nlibrary(sp) \nlibrary(cmocean)\nlibrary(here)\nlibrary(ncdf4)\n\n\n\n# This is where the data are and where the plots will go\nDir &lt;- here()\n\n\n\nWe will access the ETOPO2022 bathymetry data and the monthly ESA CCI chlorophyll-a concentration data (1/1998-12/2022) for the island of Oahu from the OceanWatch ERDDAP server. We will also download the chlorophyll-a data and save it to local for future use.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\nWe will utilize the ’‘’rerddap’’’ R package to engage with the ERDDAP data server. The ’‘’rerddap’’’ package, created by Roy Mendelssohn (SWFSC) and Scott Chamberlain, is designed to simplify the process of importing data into R.\n# Bounding box for Oahu:\nlon_range = c(-158.39+360, -157.55+360)\nlat_range = c(21.14, 21.8)\n\n# Set ERDDAP URL\nERDDAP_Node = \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\n\n# Download bathymetry data with its unique ID \nETOPO_id = 'ETOPO_2022_v1_15s'\nETOPO_info=info(datasetid = ETOPO_id,url = ERDDAP_Node)\nbathy =  griddap(url = ERDDAP_Node, ETOPO_id, \n                 latitude = lat_range, longitude = lon_range)\n\n# Download ocean color data with its unique ID\nCCI_id = 'esa-cci-chla-monthly-v6-0'\nCCI_info=info(datasetid = CCI_id,url = ERDDAP_Node)\nvar=CCI_info$variable$variable_name\nchl = griddap(url = ERDDAP_Node, CCI_id, \n                   time = c('1998-01-01', '2022-12-01'),\n                   latitude = lat_range, longitude = lon_range,\n                   fields = var[1],\n                   store=disk('chl_data'))\n\n\n\nWe convert bathymetry and chlorophyll-a data to rasters for visulization.\n# Convert the data into a raster layer\nr_bathy=raster(bathy$summary$filename)\n\nplot(r_bathy,main=\"ETOPO Bathymetry (m)\")\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n# Convert the data into a raster layer\nr_chl=raster(chl$summary$filename,varname=var[1]) \n\nplot(log(r_chl),main=\"ESA CCI Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n\n\n\nThe ocean color data has coarser resolution (~4km) compared with the bathymetry data (~500m). We will calculate how much area (percentage) within each ocean color pixel is in shallow water (&lt;30m depth).\n#Convert raster bathymetry to SpatialPoints dataframe for counting\ndf_bathy = data.frame(rasterToPoints(r_bathy))\ncoordinates(df_bathy) &lt;- ~x+y\ncrs(df_bathy) = crs(r_chl[[1]])\n\n# Define a function to calculate the percentage of (smaller) bathymetry pixels in each (larger) Chl-a pixel that are shallow\npercent_shallow_pixels=function(depths,threshold=-30, na.rm=F){ \n  return(length(which(depths&gt;threshold))/length(depths)) \n} \n  \n# Build a raster of the chl-a grid, using the function to generate the shallow water area percentage to consider a pixel necessary to mask\nper_shallow =  rasterize(x = df_bathy,y=r_chl,fun=percent_shallow_pixels)[[2]]\nplot(per_shallow,main=\"% Shallow water\", col=cmocean('amp')(50))\n\n\n\n\n# Set a percentage threshold to create the shallow pixel mask\npercent_threshold = 0.05\ndepth_mask = r_chl/r_chl\ndepth_mask[,]= 1\ndepth_mask[per_shallow&gt;= percent_threshold]= NA\nplot(depth_mask,main=\"Shallow pixel mask\")\n\n\n\n\n# Read in the files previousely downloaded\nfiles = list.files('chl_data/', full.names = T)\n# Read the file into R and make it to rasterstack\nstack_chl = stack(files)\n# Convert raster data to dataframe for calculating climatology\ndf_chl = as.data.frame(rasterToPoints(stack_chl))\ndf_chl$z = rowMeans(df_chl[,3:dim(df_chl)[2]], na.rm = T)\n# Convert dataframe to raster for mapping\nr_chl_clim = rasterFromXYZ(df_chl[,c(\"x\", \"y\", \"z\")])\n# Map unmasked climatology\nplot(log(r_chl_clim),main=\"Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n# Apply Mask, calculate climatology and map\nr_chl_masked = mask(x = stack_chl, mask = depth_mask)\n# Convert masked raster data to dataframe for calculating climatology\ndf_chl_masked = as.data.frame(rasterToPoints(r_chl_masked))\ndf_chl_masked$z = rowMeans(df_chl_masked[,3:dim(df_chl_masked)[2]], na.rm = T)\n# Convert dataframe to raster for mapping\nr_chl_masked_clim = rasterFromXYZ(df_chl_masked[,c(\"x\", \"y\", \"z\")])\n# Map masked climatology\nplot(log(r_chl_masked_clim),main=\"Masked Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n\n\n\n# Grab var name and unit from unmasked nc file\nnc = nc_open(paste0(files))\nvariable_name = as.character(nc$var[[1]][2])\nvariable_unit = as.character(nc$var[[1]][8])\nx_name = nc$dim$longitude$name\ny_name = nc$dim$latitude$name\nz_name = nc$dim$time$name\nz_unit = nc$dim$time$units\nnc_close(nc)\n# Set a file name and output path for the masked data\nmasked_fln = 'esa_cci_monthly_chl-a_masked.nc'\nmask_path = paste0(Dir,  \"/output/\")\nif (!dir.exists(mask_path)) {\n  dir.create(mask_path)\n}\n# Write out masked nc.file\nwriteRaster(r_chl_masked,\n            paste0(mask_path, masked_fln),\n            overwrite = T,\n            varname = variable_name,\n            varunit = variable_unit,\n            xname = x_name,\n            yname = y_name,\n            zname = z_name,\n            zunit = z_unit)\n\n\n\nSpecial thanks to Kisei Tanaka from NOAA’s Pacific Islands Fisheries Science Center (PIFSC) for his contributions to this tutorial, which is adapted from the scripts he developed. Additionally, portions of this tutorial have been revised based on a previous version created by Melanie Abecassis and Thomas Oliver."
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#objective",
    "href": "tutorials/r/mask-shallow-ocean-color.html#objective",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "In this tutorial, we demonstrate how to create a mask to remove ocean color pixels in the coastal shallow water that are contaminated by bottom reflectance."
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/mask-shallow-ocean-color.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "Accessing and Downloading satellite data from ERDDAP data server\nVisualizing the datasets\nMatching coarse-resolution ocean color data with fine-resolution bathymetry data\nCalculating percentage of shallow water area in each ocean color pixel\nCreating and applying value mask to datasets\nCalculating long-term climatology from monthly data\nOutputing dataset into netCDF format"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#datasets-used",
    "href": "tutorials/r/mask-shallow-ocean-color.html#datasets-used",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "Bathymetry data, ETOPO Global Relief Model integrates topography, bathymetry, and shoreline data, version 2022, 15 arc-second resolution\nOcean color data, ESA CCI chlorophyll-a concentration, 1998-2022, monthly"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#references",
    "href": "tutorials/r/mask-shallow-ocean-color.html#references",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "Couch CS, Oliver TA, Dettloff K, Huntington B, Tanaka KR and Vargas-Ángel B (2023) Ecological and environmental predictors of juvenile coral density across the central and western Pacific. Front. Mar. Sci. 10:1192102.  doi: 10.3389/fmars.2023.1192102"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#load-libraries",
    "href": "tutorials/r/mask-shallow-ocean-color.html#load-libraries",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "# Load libraries\nlibrary(rerddap)\nlibrary(raster) \nlibrary(sp) \nlibrary(cmocean)\nlibrary(here)\nlibrary(ncdf4)"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#set-work-directory",
    "href": "tutorials/r/mask-shallow-ocean-color.html#set-work-directory",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "# This is where the data are and where the plots will go\nDir &lt;- here()"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#access-and-download-satellite-data",
    "href": "tutorials/r/mask-shallow-ocean-color.html#access-and-download-satellite-data",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "We will access the ETOPO2022 bathymetry data and the monthly ESA CCI chlorophyll-a concentration data (1/1998-12/2022) for the island of Oahu from the OceanWatch ERDDAP server. We will also download the chlorophyll-a data and save it to local for future use.\nThe data can be downloaded by sending a data request to the ERDDAP server via URL. The data request URL includes the dataset ID of interest and other query conditions if subset of the data product is of interest.\nTo learn more about how to set up ERDDAP URL data requests, please go to the ERDDAP module page.\nWe will utilize the ’‘’rerddap’’’ R package to engage with the ERDDAP data server. The ’‘’rerddap’’’ package, created by Roy Mendelssohn (SWFSC) and Scott Chamberlain, is designed to simplify the process of importing data into R.\n# Bounding box for Oahu:\nlon_range = c(-158.39+360, -157.55+360)\nlat_range = c(21.14, 21.8)\n\n# Set ERDDAP URL\nERDDAP_Node = \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\n\n# Download bathymetry data with its unique ID \nETOPO_id = 'ETOPO_2022_v1_15s'\nETOPO_info=info(datasetid = ETOPO_id,url = ERDDAP_Node)\nbathy =  griddap(url = ERDDAP_Node, ETOPO_id, \n                 latitude = lat_range, longitude = lon_range)\n\n# Download ocean color data with its unique ID\nCCI_id = 'esa-cci-chla-monthly-v6-0'\nCCI_info=info(datasetid = CCI_id,url = ERDDAP_Node)\nvar=CCI_info$variable$variable_name\nchl = griddap(url = ERDDAP_Node, CCI_id, \n                   time = c('1998-01-01', '2022-12-01'),\n                   latitude = lat_range, longitude = lon_range,\n                   fields = var[1],\n                   store=disk('chl_data'))"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#visualize-bathymetry-and-chlorophyll-a-data",
    "href": "tutorials/r/mask-shallow-ocean-color.html#visualize-bathymetry-and-chlorophyll-a-data",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "We convert bathymetry and chlorophyll-a data to rasters for visulization.\n# Convert the data into a raster layer\nr_bathy=raster(bathy$summary$filename)\n\nplot(r_bathy,main=\"ETOPO Bathymetry (m)\")\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n# Convert the data into a raster layer\nr_chl=raster(chl$summary$filename,varname=var[1]) \n\nplot(log(r_chl),main=\"ESA CCI Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE)"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#match-two-datasets-and-calculate-percentage-of-shallow-water-area-in-each-ocean-color-pixel",
    "href": "tutorials/r/mask-shallow-ocean-color.html#match-two-datasets-and-calculate-percentage-of-shallow-water-area-in-each-ocean-color-pixel",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "The ocean color data has coarser resolution (~4km) compared with the bathymetry data (~500m). We will calculate how much area (percentage) within each ocean color pixel is in shallow water (&lt;30m depth).\n#Convert raster bathymetry to SpatialPoints dataframe for counting\ndf_bathy = data.frame(rasterToPoints(r_bathy))\ncoordinates(df_bathy) &lt;- ~x+y\ncrs(df_bathy) = crs(r_chl[[1]])\n\n# Define a function to calculate the percentage of (smaller) bathymetry pixels in each (larger) Chl-a pixel that are shallow\npercent_shallow_pixels=function(depths,threshold=-30, na.rm=F){ \n  return(length(which(depths&gt;threshold))/length(depths)) \n} \n  \n# Build a raster of the chl-a grid, using the function to generate the shallow water area percentage to consider a pixel necessary to mask\nper_shallow =  rasterize(x = df_bathy,y=r_chl,fun=percent_shallow_pixels)[[2]]\nplot(per_shallow,main=\"% Shallow water\", col=cmocean('amp')(50))"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#create-a-mask-for-shallow-pixels",
    "href": "tutorials/r/mask-shallow-ocean-color.html#create-a-mask-for-shallow-pixels",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "# Set a percentage threshold to create the shallow pixel mask\npercent_threshold = 0.05\ndepth_mask = r_chl/r_chl\ndepth_mask[,]= 1\ndepth_mask[per_shallow&gt;= percent_threshold]= NA\nplot(depth_mask,main=\"Shallow pixel mask\")"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#calculate-long-term-climatology-and-compare-unmasked-and-masked-maps",
    "href": "tutorials/r/mask-shallow-ocean-color.html#calculate-long-term-climatology-and-compare-unmasked-and-masked-maps",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "# Read in the files previousely downloaded\nfiles = list.files('chl_data/', full.names = T)\n# Read the file into R and make it to rasterstack\nstack_chl = stack(files)\n# Convert raster data to dataframe for calculating climatology\ndf_chl = as.data.frame(rasterToPoints(stack_chl))\ndf_chl$z = rowMeans(df_chl[,3:dim(df_chl)[2]], na.rm = T)\n# Convert dataframe to raster for mapping\nr_chl_clim = rasterFromXYZ(df_chl[,c(\"x\", \"y\", \"z\")])\n# Map unmasked climatology\nplot(log(r_chl_clim),main=\"Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE) \n\n# Apply Mask, calculate climatology and map\nr_chl_masked = mask(x = stack_chl, mask = depth_mask)\n# Convert masked raster data to dataframe for calculating climatology\ndf_chl_masked = as.data.frame(rasterToPoints(r_chl_masked))\ndf_chl_masked$z = rowMeans(df_chl_masked[,3:dim(df_chl_masked)[2]], na.rm = T)\n# Convert dataframe to raster for mapping\nr_chl_masked_clim = rasterFromXYZ(df_chl_masked[,c(\"x\", \"y\", \"z\")])\n# Map masked climatology\nplot(log(r_chl_masked_clim),main=\"Masked Chl-a (log scale)\",col=cmocean('algae')(50))\ncontour(r_bathy,levels=c(-30,-1000,-2000),add=TRUE)"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#output-masked-chlorophyll-a-data-to-a-netcdf-file",
    "href": "tutorials/r/mask-shallow-ocean-color.html#output-masked-chlorophyll-a-data-to-a-netcdf-file",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "# Grab var name and unit from unmasked nc file\nnc = nc_open(paste0(files))\nvariable_name = as.character(nc$var[[1]][2])\nvariable_unit = as.character(nc$var[[1]][8])\nx_name = nc$dim$longitude$name\ny_name = nc$dim$latitude$name\nz_name = nc$dim$time$name\nz_unit = nc$dim$time$units\nnc_close(nc)\n# Set a file name and output path for the masked data\nmasked_fln = 'esa_cci_monthly_chl-a_masked.nc'\nmask_path = paste0(Dir,  \"/output/\")\nif (!dir.exists(mask_path)) {\n  dir.create(mask_path)\n}\n# Write out masked nc.file\nwriteRaster(r_chl_masked,\n            paste0(mask_path, masked_fln),\n            overwrite = T,\n            varname = variable_name,\n            varunit = variable_unit,\n            xname = x_name,\n            yname = y_name,\n            zname = z_name,\n            zunit = z_unit)"
  },
  {
    "objectID": "tutorials/r/mask-shallow-ocean-color.html#acknowledgements",
    "href": "tutorials/r/mask-shallow-ocean-color.html#acknowledgements",
    "title": "Mask shallow pixels for satellite ocean color datasets",
    "section": "",
    "text": "Special thanks to Kisei Tanaka from NOAA’s Pacific Islands Fisheries Science Center (PIFSC) for his contributions to this tutorial, which is adapted from the scripts he developed. Additionally, portions of this tutorial have been revised based on a previous version created by Melanie Abecassis and Thomas Oliver."
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html",
    "href": "tutorials/r/lis-chlora-dynamics.html",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "",
    "text": "History | Updated Apr 2025"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#objective",
    "href": "tutorials/r/lis-chlora-dynamics.html#objective",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab daily chlorophyll-a data hosted on an ERDDAP server using the griddap function in the rerrdap package, how to make temporal composites in R and how to make some maps and time-series of chlorophyll-a."
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "The tutorial demonstrates the following techniques:",
    "text": "The tutorial demonstrates the following techniques:\n\nAccessing gridded satellite data from an ERDDAP server using the rerddap package.\nSubsetting spatial and temporal data using latitude, longitude, and date ranges.\nConverting gridded data to tidy format for analysis using dplyr and lubridate.\nCalculating monthly and annual spatial averages of chlorophyll-a concentrations.\nCreating faceted maps of monthly chlorophyll-a using ggplot2 and viridis color scales.\nCreating an 8-day time series to analyze seasonal chlorophyll-a patterns.\nComparing chlorophyll-a seasonal cycles between regions (West vs. East Long Island Sound)."
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#datasets-used",
    "href": "tutorials/r/lis-chlora-dynamics.html#datasets-used",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Datasets used",
    "text": "Datasets used\nLong Island Sound Optimized water quailty datasets from OLCI Products developed by academic collaborators that have partnered with NOAA CoastWatch through a Sea Grant project titled “Actionable satellite water-quality data products in Long Island Sound for improved management and societal benefits”. The dataset includes daily Sentinal-3 OLCI (300 m) water quality indicators:\n\nChlorophyll-a (Chla “chlor_a”)\nAbsorption coefficient of Chromophoric Dissolved Organic Material at 300 nm (aCDOM(300) “cdom”)\nDissolved Organic Carbon (DOC “doc”)\nSuspended Particulate Matter (SPM “spm”). Chlor_a, cdom and doc are based on Long Island Sound optimized algorithms. Spm retrieved using the Nechad Algorithm.\n\nThis dataset covers the Long Island Sound region between 40.2° N - 41.5° N and 74° W - 71.8° W\nIn this tutorial we will use the daily Chlorophyll-a dataset. The data will be downloaded from the CoastWatch ERRDAP server: https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.html\nFor more information on each product refer to:\n\nChla: https://www.sciencedirect.com/science/article/pii/S1569843223000456\nCDOM and DOC: https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2023JG007767\nSPM: https://www.sciencedirect.com/science/article/abs/pii/S0034425709003617"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#install-and-load-packages",
    "href": "tutorials/r/lis-chlora-dynamics.html#install-and-load-packages",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Install and load packages",
    "text": "Install and load packages\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"tidyverse\", \"lubridate\", \"viridis\", \"ggplot2\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#select-the-satellite-dataset",
    "href": "tutorials/r/lis-chlora-dynamics.html#select-the-satellite-dataset",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Select the satellite dataset",
    "text": "Select the satellite dataset\nWe will load the daily Chlorophyll-a dataset from the CoastWatch ERDDAP server. The dataset ID is noaacwappsS3ABcolorLISDaily.\nWe will use the info function from the rerddap package to first obtain information about the dataset of interest, then we will import the data.\n# Set the ERDDAP URL\nerddap_url &lt;- \"https://coastwatch.noaa.gov/erddap\"\n\n# Set the dataset ID\ndataset_id &lt;- \"noaacwappsS3ABcolorLISDaily\"\n\n# Obtain data info using the erddap url and dataset ID\ndataInfo &lt;- rerddap::info(dataset_id,url=erddap_url)  \n\n# Examine the metadata dataset info\ndataInfo\n## &lt;ERDDAP info&gt; noaacwappsS3ABcolorLISDaily \n## Base URL: https://coastwatch.noaa.gov/erddap \n## Dataset Type: griddap \n## Dimensions (range):  \n##     time: (2017-01-01T00:00:00Z, 2025-02-28T00:00:00Z) \n##     latitude: (40.204, 41.5) \n##     longitude: (-74.0, -71.8049) \n## Variables:  \n##     cdom: \n##         Units: m^-1 \n##     chlor_a: \n##         Units: mg m^-3 \n##     doc: \n##         Units: Âµmole/liter \n##     spm: \n##         Units: mg L^-1"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#subset-the-data",
    "href": "tutorials/r/lis-chlora-dynamics.html#subset-the-data",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Subset the data",
    "text": "Subset the data\nFor this tutorial, we will be focusing on chloropyhll-a throughout 2022 in the Long Island Sound Range.\n# Set the time range\ntime_range &lt;- c(\"2022-01-01\", \"2022-12-31\")\n\n# Set the ranges for latitude and longitude\nlat_range &lt;- c(40.204, 41.5)\nlon_range &lt;- c(-74.0, -71.8049)\n\n# Set the parameter\nparameter &lt;- 'chlor_a'"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#extract-the-dataset",
    "href": "tutorials/r/lis-chlora-dynamics.html#extract-the-dataset",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Extract the dataset",
    "text": "Extract the dataset\n# Download the chlorophyll-a data\nchlor_data &lt;- griddap(\n  datasetx = dataset_id,\n  url = erddap_url,\n  time = time_range,\n  latitude = lat_range,       \n  longitude = lon_range,\n  fields = parameter\n)\n\n# View the data\nhead(chlor_data)"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#convert-to-a-tibble-and-add-datemonth-columns",
    "href": "tutorials/r/lis-chlora-dynamics.html#convert-to-a-tibble-and-add-datemonth-columns",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Convert to a tibble and add date/month columns",
    "text": "Convert to a tibble and add date/month columns\nConverting to a tibble makes the dataset tidy-verse friendly, so we can manipulate the data without headaches.\n# Convert to tibble and add date/month columns\ndf &lt;- chlor_data$data %&gt;%\n  as_tibble() %&gt;%\n  mutate(\n    time = as.Date(time),\n    month = floor_date(time, \"month\")\n  )\n\n# View the data\nprint(df)"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#calculate-monthly-mean-chlorophyll-a",
    "href": "tutorials/r/lis-chlora-dynamics.html#calculate-monthly-mean-chlorophyll-a",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Calculate monthly mean chlorophyll-a",
    "text": "Calculate monthly mean chlorophyll-a\nWe group the data by month, latitude, and longitude and compute the average chlorophyll-a for each pixel for each month. We also remove any missing values.\n# Calculate monthly mean chlor_a\nmonthly_mean &lt;- df %&gt;%\n  group_by(month, latitude, longitude) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\")\n\n# View the data\nprint(monthly_mean)"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#list-the-dates-for-each-time-step-after-calculating-the-monthly-means",
    "href": "tutorials/r/lis-chlora-dynamics.html#list-the-dates-for-each-time-step-after-calculating-the-monthly-means",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "List the dates for each time step after calculating the monthly means",
    "text": "List the dates for each time step after calculating the monthly means\nThe dataset now has 12 time steps, one for each month between January 2022 and December 2022.\nunique(monthly_mean$month)\n##[1] \"2022-01-01\" \"2022-02-01\" \"2022-03-01\" \"2022-04-01\" \"2022-05-01\" \"2022-06-01\" \n##\"2022-07-01\" \"2022-08-01\" \"2022-09-01\" \"2022-10-01\" \"2022-11-01\"\n##[12] \"2022-12-01\""
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#create-a-faceted-plot-of-monthly-mean-chlorophyll-a-for-2022",
    "href": "tutorials/r/lis-chlora-dynamics.html#create-a-faceted-plot-of-monthly-mean-chlorophyll-a-for-2022",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Create a faceted plot of monthly mean chlorophyll-a for 2022",
    "text": "Create a faceted plot of monthly mean chlorophyll-a for 2022\nUsing ggplot, we create a faceted spatial plot of chlorophyll-a with tiles colored by value, and one map per month of 2022.\nfacet_wrap tells ggplot to split the plot in 12 facets (one for each month) and ncol = 4 puts the 12 plots into 3 rows and 4 columns.\nggplot(monthly_mean, aes(x = longitude, y = latitude, fill = chlor_a)) +\n  geom_tile() +\n  scale_fill_viridis(\n    name = bquote(\"Chlorophyll-a (mg \"*m^{-3}*\")\"),\n    option = \"turbo\",\n    limits = c(0, 20),\n    na.value = \"transparent\"\n  ) +\n  scale_x_continuous(\n    breaks = c(-74, -73, -72),\n    labels = c(\"-74\", \"-73\", \"-72\")\n  ) +\n  coord_equal() +\n  facet_wrap(~format(month, \"%Y-%m-%d\"), ncol = 4) +\n  labs(x = \"Longitude\", y = \"Latitude\") +\n  theme_minimal(base_size = 12) +\n  theme(strip.text = element_text(size = 10))\n\n\n\nimages"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#compute-the-annual-average-for-the-region",
    "href": "tutorials/r/lis-chlora-dynamics.html#compute-the-annual-average-for-the-region",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Compute the annual average for the region",
    "text": "Compute the annual average for the region\nCalculate the annual average chlorophyll-a at each pixel by grouping the monthly data by latitude and longitude, then taking the mean across all months. We also remove any missing values.\nyearly_mean &lt;- monthly_mean %&gt;%\n  group_by(latitude, longitude) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\")"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#plot-the-map-of-the-2022-average-chlorophyll-a-in-the-region",
    "href": "tutorials/r/lis-chlora-dynamics.html#plot-the-map-of-the-2022-average-chlorophyll-a-in-the-region",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Plot the map of the 2022 average chlorophyll-a in the region",
    "text": "Plot the map of the 2022 average chlorophyll-a in the region\nggplot(yearly_mean, aes(x = longitude, y = latitude, fill = chlor_a)) +\n  geom_tile() +\n  scale_fill_viridis(\n    name = bquote(\"Chlorophyll-a (mg \"*m^{-3}*\")\"),\n    option = \"turbo\",\n    limits = c(0, 20),\n    na.value = \"transparent\"\n  ) +\n  coord_equal() +\n  labs(\n    title = \"Mean Chlorophyll-a\\nJan 2022 – Dec 2022\",\n    x = \"Longitude\", y = \"Latitude\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\nimages"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "href": "tutorials/r/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound",
    "text": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound\nSubset the data\n\nWest Long Island Sound between -73.9° to -73.1° W longitude\nEast Long Island Sound between -72.9° to -71.8° W longitude\n\nWe are going to generate a time series of mean chlorophyll-a within each box.\n# Subset West Long Island\nwest_df &lt;- df %&gt;%\n  filter(longitude &gt;= -73.9, longitude &lt;= -73.1)\n\n# Subset East Long Island\neast_df &lt;- df %&gt;%\n  filter(longitude &gt;= -72.9, longitude &lt;= -71.8)"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#examine-the-structure-of-the-subsetted-data",
    "href": "tutorials/r/lis-chlora-dynamics.html#examine-the-structure-of-the-subsetted-data",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Examine the structure of the subsetted data",
    "text": "Examine the structure of the subsetted data\nstr(west_df)\n\nstr(east_df)"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#resample-each-subset-to-8-day-means",
    "href": "tutorials/r/lis-chlora-dynamics.html#resample-each-subset-to-8-day-means",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Resample each subset to 8-day means",
    "text": "Resample each subset to 8-day means\n# Resample west_df\nwest_df &lt;- west_df %&gt;%\n  mutate(\n    period = as.Date(\"2022-01-01\") +\n      floor(as.numeric(difftime(time, as.Date(\"2022-01-01\"), units = \"days\")) / 8) * 8\n  )\n\n# Resample east_df\neast_df &lt;- east_df %&gt;%\n  mutate(\n    period = as.Date(\"2022-01-01\") +\n      floor(as.numeric(difftime(time, as.Date(\"2022-01-01\"), units = \"days\")) / 8) * 8\n  )"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#compute-a-time-series",
    "href": "tutorials/r/lis-chlora-dynamics.html#compute-a-time-series",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Compute a time series",
    "text": "Compute a time series\nNow, we will average all data within each subset across the latitude and longitude dimensions to produce a single time series.\nwest_ts &lt;- west_df %&gt;%\n  group_by(period) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(region = \"West LIS\")\n\neast_ts &lt;- east_df %&gt;%\n  group_by(period) %&gt;%\n  summarise(chlor_a = mean(chlor_a, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(region = \"East LIS\")"
  },
  {
    "objectID": "tutorials/r/lis-chlora-dynamics.html#plot-the-time-series",
    "href": "tutorials/r/lis-chlora-dynamics.html#plot-the-time-series",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Plot the time series",
    "text": "Plot the time series\n# Combine for plotting\nts_combined &lt;- bind_rows(west_ts, east_ts)\n\n# Plot the time series\nggplot(ts_combined, aes(x = period, y = chlor_a, color = region)) +\n  geom_line() +\n  geom_point(size = 1) +\n  scale_color_manual(values = c(\"West LIS\" = \"blue\", \"East LIS\" = \"red\")) +\n  labs(\n    title = \"Seasonal Cycle of Chlorophyll-a in Long Island Sound (2022)\",\n    x = \"Date\",\n    y = bquote(\"Chlorophyll-a (mg \"*m^{-3}*\")\"),\n    color = \"Region\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\nimages"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html",
    "title": "Extract data within a boundary",
    "section": "",
    "text": "history | Updated August 2023"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#background",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#background",
    "title": "Extract data within a boundary",
    "section": "Background",
    "text": "Background\nOne use for satellite observations is to supplement in situ sampling of geographical locations where the timespan, frequency measurements, spatial dimensions or remoteness of the locations, make physical sampling impossible or impractical. One drawback is that satellite data are often rectangular, whereas geographical locations can have irregular boundaries. Examples of boundaries include marine protected areas or marine physical, biological, and ecological divisions like the Longhurst Marine Provinces."
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#objectives",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#objectives",
    "title": "Extract data within a boundary",
    "section": "Objectives",
    "text": "Objectives\nIn this tutorial we will learn how to download a timeseries of SST satellite data from an ERDDAP server, and then mask the data to retain only the data within an irregular geographical boundary (polygon). We will then plot a yearly seasonal cycle from within the boundary."
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Extract data within a boundary",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data from an ERDDAP data server for a non-rectangular region using the rerddapXtracto package\nVisualizing data on a map\nPlotting a time-series of mean SST"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#datasets-used",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#datasets-used",
    "title": "Extract data within a boundary",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Geo-polar Blended Analysis Sea-Surface Temperature, Global, Monthlyly, 5km, 2019-Present\nThe NOAA geo-polar blended SST is a high resolution satellite-based gap-free sea surface temperature (SST) product that combines SST data from US, Japanese and European geostationary infrared imagers, and low-earth orbiting infrared (U.S. and European) SST data, into a single product. We will use the monthly composite. https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly\nLonghurst Marine Provinces\nThe dataset represents the division of the world oceans into provinces as defined by Longhurst (1995; 1998; 2006). This division has been based on the prevailing role of physical forcing as a regulator of phytoplankton distribution. The Longhurst Marine Provinces dataset is available online (https://www.marineregions.org/downloads.php) and within the shapes folder associated with this repository. For this tutorial we will use the Gulf Stream province (ProvCode: GFST)\n\n\n\n../images/longhurst.png"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#install-packages-and-load-libraries",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#install-packages-and-load-libraries",
    "title": "Extract data within a boundary",
    "section": "Install packages and load libraries",
    "text": "Install packages and load libraries\npkges = installed.packages()[,\"Package\"]\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n# create list of required packages\nlist.of.packages &lt;- c(\"ncdf4\", \"rerddap\",\"plotdap\", \"parsedate\", \n                      \"sp\", \"ggplot2\", \"RColorBrewer\", \"sf\", \n                      \"reshape2\", \"maps\", \"mapdata\", \n                      \"jsonlite\", \"rerddapXtracto\")\n\n# Run install and load function\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#load-boundary-coordinates",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#load-boundary-coordinates",
    "title": "Extract data within a boundary",
    "section": "Load boundary coordinates",
    "text": "Load boundary coordinates\nThe shapefile for the Longhurst marine provinces includes a list of regions. For this exercise, we will only use the boundary of one province, the Gulf Stream region (“GFST”).\n# Set directory path\ndir_path &lt;- '../resources/longhurst_v4_2010/'\n\n# Import shape files (Longhurst coordinates)\nshapes &lt;- read_sf(dsn = dir_path, layer = \"Longhurst_world_v4_2010\")\n\n# Example List of all the province names\nshapes$ProvCode\n##  [1] \"BPLR\" \"ARCT\" \"SARC\" \"NADR\" \"GFST\" \"NASW\" \"NATR\" \"WTRA\" \"ETRA\" \"SATL\"\n## [11] \"NECS\" \"CNRY\" \"GUIN\" \"GUIA\" \"NWCS\" \"MEDI\" \"CARB\" \"NASE\" \"BRAZ\" \"FKLD\"\n## [21] \"BENG\" \"MONS\" \"ISSG\" \"EAFR\" \"REDS\" \"ARAB\" \"INDE\" \"INDW\" \"AUSW\" \"BERS\"\n## [31] \"PSAE\" \"PSAW\" \"KURO\" \"NPPF\" \"NPSW\" \"TASM\" \"SPSG\" \"NPTG\" \"PNEC\" \"PEQD\"\n## [41] \"WARM\" \"ARCH\" \"ALSK\" \"CCAL\" \"CAMR\" \"CHIL\" \"CHIN\" \"SUND\" \"AUSE\" \"NEWZ\"\n## [51] \"SSTC\" \"SANT\" \"ANTA\" \"APLR\"\n# Get boundary coordinates for Gulf Stream region (GFST)\nGFST &lt;- shapes[shapes$ProvCode == \"GFST\",]\n\nxcoord &lt;- st_coordinates(GFST)[,1]\nycoord &lt;- st_coordinates(GFST)[,2]"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#select-the-satellite-dataset",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#select-the-satellite-dataset",
    "title": "Extract data within a boundary",
    "section": "Select the satellite dataset",
    "text": "Select the satellite dataset\nWe will load the sea surface temperature data from the geo-polar blended SST satellite data product hosted on the CoastWatch ERDDAP. The dataset ID for this data product is nesdisBLENDEDsstDNDaily.\nWe will use the info function from the rerddap package to first obtain information about the dataset of interest, then we will import the data.\n# Set ERDDAP URL\nerd_url = \"http://coastwatch.pfeg.noaa.gov/erddap/\"\n\n# Obtain data info using the erddap url and dataset ID\ndataInfo &lt;- rerddap::info('NOAA_DHW_monthly',url=erd_url)  \n\n# Examine the metadata dataset info\ndataInfo\n## &lt;ERDDAP info&gt; NOAA_DHW_monthly \n##  Base URL: http://coastwatch.pfeg.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1985-01-16T00:00:00Z, 2023-08-16T00:00:00Z) \n##      latitude: (-89.975, 89.975) \n##      longitude: (-179.975, 179.975) \n##  Variables:  \n##      mask: \n##          Units: pixel_classification \n##      sea_surface_temperature: \n##          Units: degree_C \n##      sea_surface_temperature_anomaly: \n##          Units: degree_C"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#set-the-options-for-the-polygon-data-extract",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#set-the-options-for-the-polygon-data-extract",
    "title": "Extract data within a boundary",
    "section": "Set the options for the polygon data extract",
    "text": "Set the options for the polygon data extract\nUsing the rxtractogon function, we will import the satellite data from erddap. The rxtractogon function takes the variable(s) of interest and the coordinates as input.\n\nFor the coordinates: determine the range of x, y, z, and time.\ntime coordinate: select the entire year of 2020\n\n# set the parameter to extract\nparameter &lt;- 'sea_surface_temperature'\n# set the time range\ntcoord &lt;- c(\"2020-01-16\", \"2020-12-16\")\n\n# We already extracted the xcoord (longitude) and ycoord (latitude) from the shapefiles \n# The dummy code below is just a placeholder indicating it is necessary to define what the longitude and latitude vectors are that make up the boundary of the polygon.\nxcoord &lt;- xcoord\nycoord &lt;- ycoord"
  },
  {
    "objectID": "tutorials/r/extract-satellite-data-within-boundary.html#extract-data-and-mask-it-using-rxtractogon",
    "href": "tutorials/r/extract-satellite-data-within-boundary.html#extract-data-and-mask-it-using-rxtractogon",
    "title": "Extract data within a boundary",
    "section": "Extract data and mask it using rxtractogon",
    "text": "Extract data and mask it using rxtractogon\n\nthe rxtractogon function automatically extracts data from the satellite dataset and masks out any data outside the polygon boundary.\n\nList the data\n\n## Request the data\nsatdata &lt;- rxtractogon(dataInfo, parameter=parameter, xcoord=xcoord, ycoord=ycoord,tcoord=tcoord)\n\n## List the returned data\nstr(satdata)\n## List of 6\n##  $ sea_surface_temperature: num [1:601, 1:202, 1:12] NA NA NA NA NA NA NA NA NA NA ...\n##  $ datasetname            : chr \"NOAA_DHW_monthly\"\n##  $ longitude              : num [1:601(1d)] -73.5 -73.5 -73.4 -73.4 -73.3 ...\n##  $ latitude               : num [1:202(1d)] 33.5 33.5 33.6 33.6 33.7 ...\n##  $ altitude               : logi NA\n##  $ time                   : POSIXlt[1:12], format: \"2020-01-16 00:00:00\" \"2020-02-16 00:00:00\" ...\n##  - attr(*, \"class\")= chr [1:2] \"list\" \"rxtracto3D\"\n\nPlot the data\n\nUse the plotBBox function in the rerddapXtracto package to quickly plot the data\n\nplotBBox(satdata, plotColor = 'thermal',maxpixels=1000000)\n\n\n\nPlot the mean seasonal temperature for the province\nsst_mean=apply(satdata$sea_surface_temperature,3,mean,na.rm=TRUE)\nplot(satdata$time,sst_mean,main='Gulf Stream Province Monthly Mean Temperature 2020',ylab='SSt (ºC)',xlab='',type='b')"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html",
    "href": "tutorials/r/calculate-seaice-extent.html",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "notebook filename | sea_ice_extent.Rmd\n\n\n\nSea ice cover measurements are key to polar ecological and climatological research. This measurement has gained attention because of the recent decrease in the Arctic sea ice cover. Satellite observations are essential for tracking sea ice cover, providing continuous global coverage extending back to 1978. Typically, sea ice cover is reported as sea ice concentration, which is the percent areal coverage of ice within a grid cell. Depending on the application, additional parameters of interest can be calculated from sea ice cover:\n\nSea ice area - the cumulative coverage of all gridded sections (area), including each grid that contains a minimum ice concentration of 15%.\n\nSea ice extent - the cumulative coverage of all griddedthe sum of the areas of all grid cells with at least 15% ice concentration\n\n\n\n\nThis tutorial will demonstrate how to calculate the sea ice area and extent using sea ice concentration and grid cell area data. Please visit the NSIDC website for more detailed descriptions of the calculations.\n\n\n\n\nDownloading and saving a netcdf file from the PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nDownloading and adding grid cell area data to the satellite data\nVisualizing data on a map\nComputing sea ice area and extent using sea ice concentration data\nPlotting a time series of sea ice area and extent\n\n\n\n\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere.\nThe Sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. Near-Real-Time data are also available at PolarWatch. (SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Northern Polar Stereographic projection (EPSG:3413). The resolution is 25km, meaning each grid cell in this data set represents a value that covers a 25km by 25km area. The dataset is available on the PolarWatch data portal and can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.graph\nPolar Stereographic Grid Cell Area Values of 25km grid, Polar Stereographic (North), NSIDC Ancillary Data.\nThis dataset includes the area (in m2) of each grid cell in the 25km resolution Northern Polar Stereographic projection. This dataset is available on the PolarWatch ERDDAP\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ggplot2\" ,\"ncdf4\",  \"RColorBrewer\", \"scales\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# Set up download method as libcurl, this is only needed for Windows machines\noptions(download.file.method=\"libcurl\", url.method=\"libcurl\")\n\n\n\nHere we download the average monthly sea ice concentration for the Arctic for 2021 (January to December). We are using the NSIDC Sea Ice Concentration Climate Data Record (NSIDC ID: G002202).\nThe ERDDAP data request URL for this data subset is presented below.\nhttps://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nThe following table shows the component parts of the ERDDAP data request URL.\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID of the dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nNetCDF (there are many other available file formats)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariables from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]\nTemporal\n\n\nspatial_range\n[(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nSpatial coverage\n\n\n\n` Note The metadata states that the _FillValue for this dataset is set to -999, however when the _FillValue attribute is found, the ncdf4 package maps all the missing values (_FillValue) to NA’s.\n# Set data request URL for PolarWatch ERDDAP data server\ndata_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\"\n\n\n# Send data request and download file to the file name\nf &lt;- 'sic.nc'\ndownload.file(data_url, destfile=f, mode=\"wb\")\n# Open netcdf file\nnc=nc_open('sic.nc')\n\n# Examine file metadata\n#print(nc)\n\n# Examine names of variables\nnames(nc$var)\n\n# Get first variable metadata\nvar1 &lt;- nc$var[[1]]\n\n# Examine variable metadata\n#print(var1)\n\n# Get variable values\nsic &lt;- ncvar_get(nc,var1$name)\n\n# Examine dimension of variables\ndim(sic)\n\n# Based on metadata, set xgrid, ygrid\nxgrid &lt;- var1$dim[[1]]$vals\nygrid &lt;- var1$dim[[2]]$vals\n\n# convert time variable to date format\ndates &lt;- as.POSIXlt(var1$dim[[3]]$vals,origin='1970-01-01',tz='GMT')\n# Close and remove the netCDF file and clear memories\nnc_close(nc)\nfile.remove('sic.nc')\n## [1] TRUE\n\n\n\nTo plot sea ice concentration data that are in xgrid and ygrid dimensions, we will create a data frame with coordinates (xgrid, ygrid) and associated sea ice concentration values.\n# Create a data frame with all combinations of xgrid and ygrid\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\n\n# Add sic data array to the data frame\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude the _FillValue listed in the metadata (2.53999) which corresponds to various pixels with no data (land, coast, missing data, etc...)\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# Map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous() + \n       scale_x_continuous() +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\") +\n      ggtitle(\"Sea Ice Concentration on Polar Steregraphic projection\")\n\n\n\n\nWhile the resolution of this data set is 25km, the actual area of each grid cell depends on the grid projection. We will download the grid cell area values from the PolarWatch ERDDAP.\ncell_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k.nc?cell_area%5B(5837500.0):1:(-5337500.0)%5D%5B(-3837500.0):1:(3737500.0)%5D\"\nf &lt;- 'gridcell.nc'\ndownload.file(cell_url, destfile=f, mode=\"wb\")\n\n\n\nJust like for the sea ice concentration dataset, we will examine the metadata and extract the variables of grid cell areas along with x and y grids.\n# Open netcdf file\nnc1=nc_open('gridcell.nc')\n\n# Examine names of variables\nnames(nc1$var)\n\n# Get first variable metadata\narea_var &lt;- nc1$var[[1]]\n\n# Examine area_var\nnames(area_var)\n\n# Get variable values\ncellarea =ncvar_get(nc1,area_var$name)\n\n# Examine dimension of variable values\ndim(cellarea)\n\n# Based on metadata, set xgrid, ygrid, time\nx_area &lt;- area_var$dim[[1]]$vals\ny_area &lt;- area_var$dim[[2]]$vals\n\n# Close and remove the netCDF file and clear memories\nnc_close(nc1)\nfile.remove('gridcell.nc')\n\n\n\nNow we have two data sets: sea ice concentration and grid cell areas for each grid of northern polar stereographic projection. While the spatial coverage of both data sets is identical, we will ensure the x and y coordinates of both data sets are correctly aligned.\n# Get indices in areas where x and y grids equal those of sic\nx_indices &lt;- match(xgrid, x_area)\ny_indices &lt;- match(ygrid, y_area)\n\n# Extract grid area\ngrid.match &lt;- cellarea[x_indices, y_indices]\n\n\n\nWe need to clean the data before computing the sea ice area and extent.\n\nThe dataset includes flag values indicating non-sea ice area such as land, lakes, etc.\n\ntask: remove flag values (2 and higher) by setting the flag values as Nan.\n\nFor this example of the sea ice area and extent calculations, a value of 0.15 of sea ice concentration value will be used as a threshold.\n\ntask: set sic value to 0 if the value is less than 0.15\n\n\nFor more detailed information about the flag values, go to the user guide. For the calculation of sea ice area and extent with a threshold, go to the NSIDC article.\n# Set sic values less than 0.15 to (applying 0.15 threshold)\nsic[sic &lt; 0.15] &lt;- 0\n\n# Set 0 for all flag values (&gt;2)\nsic[sic &gt; 1] &lt;- 0\n\n# Set NA to 0\nsic[is.na(sic)] &lt;- 0\n\n# Sic for extent calc\nsic_ext &lt;- sic\nsic_ext[sic_ext &gt;= 0.15] &lt;- 1\n\n\n# Perform element-wise multiplication for the first time step\narea_total &lt;- sic[,,1] * grid.match\next_total &lt;- sic_ext[,,1] * grid.match\n\n# Sum area and extent over all grid cells and convert from m^2 to km^2\narea &lt;- sum(area_total) / 1000000\nextent &lt;- sum(ext_total) / 1000000\n\nprint(paste(\"Sea Ice Area (km^2): \", floor(area)))\n## [1] \"Sea Ice Area (km^2):  12564015\"\nprint(paste(\"Sea Ice Extent (km^2): \", floor(extent)))\n## [1] \"Sea Ice Extent (km^2):  13905993\"\n\n\n\n# Replicate grid areas for all timestep\nrep_grid_areas &lt;- array(rep(grid.match, each=dim(sic)[3]), dim=dim(sic))\n\n# Perform element-wise multiplication\narea_total12 &lt;- sic * rep_grid_areas\next_total12 &lt;- sic_ext * rep_grid_areas\n\narea12 &lt;- apply(area_total12, c(3), sum)\next12 &lt;- apply(ext_total12, c(3), sum)\n\n\n\nupper = max(max(ext12), max(area12))\nlower = min(min(ext12), min(area12))\nplot(dates,ext12,type='o',pch=20,xlab='Date',ylab='Area (km^2)', col=\"orange\" , ylim=c(lower, upper),  main=\"2021 Monthly Sea ice area and sea ice extent\")\nlines(dates, area12, type='o', pch=20, col=\"blue\")\nlegend(\"topright\", legend=c(\"Sea ice Area\", \"Sea ice Extent\"),\n       col=c(\"blue\", \"orange\"), lty=1:1, cex=0.8)\nbox()\n\n\n\n\n\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nPolarWatch Data Catalog\nWhat’s the difference between Sea ice area and extent?\nNSIDC Arctic Sea Ice News & Analysis\nClimate.gov Understanding Climate: sea ice extent\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#background",
    "href": "tutorials/r/calculate-seaice-extent.html#background",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Sea ice cover measurements are key to polar ecological and climatological research. This measurement has gained attention because of the recent decrease in the Arctic sea ice cover. Satellite observations are essential for tracking sea ice cover, providing continuous global coverage extending back to 1978. Typically, sea ice cover is reported as sea ice concentration, which is the percent areal coverage of ice within a grid cell. Depending on the application, additional parameters of interest can be calculated from sea ice cover:\n\nSea ice area - the cumulative coverage of all gridded sections (area), including each grid that contains a minimum ice concentration of 15%.\n\nSea ice extent - the cumulative coverage of all griddedthe sum of the areas of all grid cells with at least 15% ice concentration"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#objective",
    "href": "tutorials/r/calculate-seaice-extent.html#objective",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "This tutorial will demonstrate how to calculate the sea ice area and extent using sea ice concentration and grid cell area data. Please visit the NSIDC website for more detailed descriptions of the calculations."
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/calculate-seaice-extent.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Downloading and saving a netcdf file from the PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nDownloading and adding grid cell area data to the satellite data\nVisualizing data on a map\nComputing sea ice area and extent using sea ice concentration data\nPlotting a time series of sea ice area and extent"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#datasets-used",
    "href": "tutorials/r/calculate-seaice-extent.html#datasets-used",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere.\nThe Sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. Near-Real-Time data are also available at PolarWatch. (SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Northern Polar Stereographic projection (EPSG:3413). The resolution is 25km, meaning each grid cell in this data set represents a value that covers a 25km by 25km area. The dataset is available on the PolarWatch data portal and can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.graph\nPolar Stereographic Grid Cell Area Values of 25km grid, Polar Stereographic (North), NSIDC Ancillary Data.\nThis dataset includes the area (in m2) of each grid cell in the 25km resolution Northern Polar Stereographic projection. This dataset is available on the PolarWatch ERDDAP\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ggplot2\" ,\"ncdf4\",  \"RColorBrewer\", \"scales\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# Set up download method as libcurl, this is only needed for Windows machines\noptions(download.file.method=\"libcurl\", url.method=\"libcurl\")"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#get-the-sea-ice-data-from-erddap",
    "href": "tutorials/r/calculate-seaice-extent.html#get-the-sea-ice-data-from-erddap",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Here we download the average monthly sea ice concentration for the Arctic for 2021 (January to December). We are using the NSIDC Sea Ice Concentration Climate Data Record (NSIDC ID: G002202).\nThe ERDDAP data request URL for this data subset is presented below.\nhttps://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nThe following table shows the component parts of the ERDDAP data request URL.\n\n\n\nName\nValue\nDescription\n\n\n\n\nbase_url\nhttps://polarwatch.noaa.gov/erddap/griddap\nERDDAP URL for gridded datasets\n\n\ndatasetID\nnsidcG02202v4nhmday\nUnique ID of the dataset from PolarWatch ERDDAP\n\n\nfile_type\n.nc\nNetCDF (there are many other available file formats)\n\n\nquery_start\n?\nDetails of the query follow the ?\n\n\nvariable_name\ncdr_seaice_conc_monthly\nVariables from the dataset\n\n\ndate_range\n[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)]\nTemporal\n\n\nspatial_range\n[(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\nSpatial coverage\n\n\n\n` Note The metadata states that the _FillValue for this dataset is set to -999, however when the _FillValue attribute is found, the ncdf4 package maps all the missing values (_FillValue) to NA’s.\n# Set data request URL for PolarWatch ERDDAP data server\ndata_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2021-01-01T00:00:00Z):1:(2021-12-01T00:00:00Z)][(5837500.0):1:(-5337500.0)][(-3850000.0):1:(3750000.0)]\"\n\n\n# Send data request and download file to the file name\nf &lt;- 'sic.nc'\ndownload.file(data_url, destfile=f, mode=\"wb\")\n# Open netcdf file\nnc=nc_open('sic.nc')\n\n# Examine file metadata\n#print(nc)\n\n# Examine names of variables\nnames(nc$var)\n\n# Get first variable metadata\nvar1 &lt;- nc$var[[1]]\n\n# Examine variable metadata\n#print(var1)\n\n# Get variable values\nsic &lt;- ncvar_get(nc,var1$name)\n\n# Examine dimension of variables\ndim(sic)\n\n# Based on metadata, set xgrid, ygrid\nxgrid &lt;- var1$dim[[1]]$vals\nygrid &lt;- var1$dim[[2]]$vals\n\n# convert time variable to date format\ndates &lt;- as.POSIXlt(var1$dim[[3]]$vals,origin='1970-01-01',tz='GMT')\n# Close and remove the netCDF file and clear memories\nnc_close(nc)\nfile.remove('sic.nc')\n## [1] TRUE"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#plot-sea-ice-concentration-data",
    "href": "tutorials/r/calculate-seaice-extent.html#plot-sea-ice-concentration-data",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "To plot sea ice concentration data that are in xgrid and ygrid dimensions, we will create a data frame with coordinates (xgrid, ygrid) and associated sea ice concentration values.\n# Create a data frame with all combinations of xgrid and ygrid\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\n\n# Add sic data array to the data frame\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude the _FillValue listed in the metadata (2.53999) which corresponds to various pixels with no data (land, coast, missing data, etc...)\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# Map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous() + \n       scale_x_continuous() +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\") +\n      ggtitle(\"Sea Ice Concentration on Polar Steregraphic projection\")"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#download-grid-cell-area-values",
    "href": "tutorials/r/calculate-seaice-extent.html#download-grid-cell-area-values",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "While the resolution of this data set is 25km, the actual area of each grid cell depends on the grid projection. We will download the grid cell area values from the PolarWatch ERDDAP.\ncell_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/pstere_gridcell_N25k.nc?cell_area%5B(5837500.0):1:(-5337500.0)%5D%5B(-3837500.0):1:(3737500.0)%5D\"\nf &lt;- 'gridcell.nc'\ndownload.file(cell_url, destfile=f, mode=\"wb\")"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#examine-grid-cell-dataset-metadata-and-extract-values",
    "href": "tutorials/r/calculate-seaice-extent.html#examine-grid-cell-dataset-metadata-and-extract-values",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Just like for the sea ice concentration dataset, we will examine the metadata and extract the variables of grid cell areas along with x and y grids.\n# Open netcdf file\nnc1=nc_open('gridcell.nc')\n\n# Examine names of variables\nnames(nc1$var)\n\n# Get first variable metadata\narea_var &lt;- nc1$var[[1]]\n\n# Examine area_var\nnames(area_var)\n\n# Get variable values\ncellarea =ncvar_get(nc1,area_var$name)\n\n# Examine dimension of variable values\ndim(cellarea)\n\n# Based on metadata, set xgrid, ygrid, time\nx_area &lt;- area_var$dim[[1]]$vals\ny_area &lt;- area_var$dim[[2]]$vals\n\n# Close and remove the netCDF file and clear memories\nnc_close(nc1)\nfile.remove('gridcell.nc')"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#match-cell-area-grids-with-sic-grids",
    "href": "tutorials/r/calculate-seaice-extent.html#match-cell-area-grids-with-sic-grids",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "Now we have two data sets: sea ice concentration and grid cell areas for each grid of northern polar stereographic projection. While the spatial coverage of both data sets is identical, we will ensure the x and y coordinates of both data sets are correctly aligned.\n# Get indices in areas where x and y grids equal those of sic\nx_indices &lt;- match(xgrid, x_area)\ny_indices &lt;- match(ygrid, y_area)\n\n# Extract grid area\ngrid.match &lt;- cellarea[x_indices, y_indices]"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#clean-sea-ice-concentration-data-for-sea-ice-area-calculation",
    "href": "tutorials/r/calculate-seaice-extent.html#clean-sea-ice-concentration-data-for-sea-ice-area-calculation",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "We need to clean the data before computing the sea ice area and extent.\n\nThe dataset includes flag values indicating non-sea ice area such as land, lakes, etc.\n\ntask: remove flag values (2 and higher) by setting the flag values as Nan.\n\nFor this example of the sea ice area and extent calculations, a value of 0.15 of sea ice concentration value will be used as a threshold.\n\ntask: set sic value to 0 if the value is less than 0.15\n\n\nFor more detailed information about the flag values, go to the user guide. For the calculation of sea ice area and extent with a threshold, go to the NSIDC article.\n# Set sic values less than 0.15 to (applying 0.15 threshold)\nsic[sic &lt; 0.15] &lt;- 0\n\n# Set 0 for all flag values (&gt;2)\nsic[sic &gt; 1] &lt;- 0\n\n# Set NA to 0\nsic[is.na(sic)] &lt;- 0\n\n# Sic for extent calc\nsic_ext &lt;- sic\nsic_ext[sic_ext &gt;= 0.15] &lt;- 1\n\n\n# Perform element-wise multiplication for the first time step\narea_total &lt;- sic[,,1] * grid.match\next_total &lt;- sic_ext[,,1] * grid.match\n\n# Sum area and extent over all grid cells and convert from m^2 to km^2\narea &lt;- sum(area_total) / 1000000\nextent &lt;- sum(ext_total) / 1000000\n\nprint(paste(\"Sea Ice Area (km^2): \", floor(area)))\n## [1] \"Sea Ice Area (km^2):  12564015\"\nprint(paste(\"Sea Ice Extent (km^2): \", floor(extent)))\n## [1] \"Sea Ice Extent (km^2):  13905993\""
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#generate-the-sea-ice-area-and-extent-time-series",
    "href": "tutorials/r/calculate-seaice-extent.html#generate-the-sea-ice-area-and-extent-time-series",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "# Replicate grid areas for all timestep\nrep_grid_areas &lt;- array(rep(grid.match, each=dim(sic)[3]), dim=dim(sic))\n\n# Perform element-wise multiplication\narea_total12 &lt;- sic * rep_grid_areas\next_total12 &lt;- sic_ext * rep_grid_areas\n\narea12 &lt;- apply(area_total12, c(3), sum)\next12 &lt;- apply(ext_total12, c(3), sum)"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#plot-the-sea-ice-area-and-extent-time-series",
    "href": "tutorials/r/calculate-seaice-extent.html#plot-the-sea-ice-area-and-extent-time-series",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "upper = max(max(ext12), max(area12))\nlower = min(min(ext12), min(area12))\nplot(dates,ext12,type='o',pch=20,xlab='Date',ylab='Area (km^2)', col=\"orange\" , ylim=c(lower, upper),  main=\"2021 Monthly Sea ice area and sea ice extent\")\nlines(dates, area12, type='o', pch=20, col=\"blue\")\nlegend(\"topright\", legend=c(\"Sea ice Area\", \"Sea ice Extent\"),\n       col=c(\"blue\", \"orange\"), lty=1:1, cex=0.8)\nbox()"
  },
  {
    "objectID": "tutorials/r/calculate-seaice-extent.html#references",
    "href": "tutorials/r/calculate-seaice-extent.html#references",
    "title": "Calculate sea ice extent",
    "section": "",
    "text": "NSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nPolarWatch Data Catalog\nWhat’s the difference between Sea ice area and extent?\nNSIDC Arctic Sea Ice News & Analysis\nClimate.gov Understanding Climate: sea ice extent\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html",
    "href": "tutorials/r/Tutorial1-basics.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "A tidyverse/ggplot version is also available here: https://github.com/jebyrnes/noaa_coastwatch_tutorial_1/blob/main/tutorial1-1.md\ncourtesy of Jarrett Byrnes from UMass Boston - http://byrneslab.net (Thank you Jarrett!!)"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#objective",
    "href": "tutorials/r/Tutorial1-basics.html#objective",
    "title": "CoastWatch Training",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab data hosted on an ERDDAP server from R, how to work with NetCDF files in R and how to make some maps and time-series of sea surface temperature."
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/Tutorial1-basics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "CoastWatch Training",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nLocating a satellite product in ERDDAP, manually changing the constraints and copying the URL defining the data request\nDownloading the resulting NetCDF file\nOpening and examining the NetCDF file\nMaking basic maps and time series plots"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#datasets-used",
    "href": "tutorials/r/Tutorial1-basics.html#datasets-used",
    "title": "CoastWatch Training",
    "section": "Datasets used",
    "text": "Datasets used\nCoralTemp Sea Surface Temperature product from the NOAA Coral Reef Watch program. The NOAA Coral Reef Watch (CRW) daily global 5km Sea Surface Temperature (SST) product, also known as CoralTemp, shows the nighttime ocean temperature measured at the surface. The SST scale ranges from -2 to 35 °C. The CoralTemp SST data product was developed from two, related reanalysis (reprocessed) SST products and a near real-time SST product. Spanning January 1, 1985 to the present, the CoralTemp SST is one of the best and most internally consistent daily global 5km SST products available. More information about the product: https://coralreefwatch.noaa.gov/product/5km/index_5km_sst.php\nWe will use the monthly composite of this product and download it from the NOAA CoastWatch ERDDAP server: https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.graph\n# Package names\npackages &lt;- c( \"ncdf4\",\"httr\")\n\n# Install packages not yet installed\ninstalled_packages &lt;- packages %in% rownames(installed.packages())\n\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages])\n}\n\n# Load packages \ninvisible(lapply(packages, library, character.only = TRUE))"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#downloading-data-from-r",
    "href": "tutorials/r/Tutorial1-basics.html#downloading-data-from-r",
    "title": "CoastWatch Training",
    "section": "1. Downloading data from R",
    "text": "1. Downloading data from R\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from R using the URL structure.\nFor example, the following page allows you to subset monthly sea surface temperature (SST) https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.html\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n NOTE: Notice that the latitudes are indexed from North to South (negative spacing)\nIn this specific example, the URL we generated is : https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D\nYou can also edit this URL manually.\nIn R, run the following to download the data using the generated URL (you need to copy it from your browser):\njunk &lt;- GET('https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.nc?sea_surface_temperature%5B(2022-01-16T00:00:00Z):1:(2022-12-16T00:00:00Z)%5D%5B(40):1:(30)%5D%5B(-80):1:(-70)%5D', write_disk(\"sst.nc\", overwrite=TRUE))"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#importing-the-downloaded-file-in-r",
    "href": "tutorials/r/Tutorial1-basics.html#importing-the-downloaded-file-in-r",
    "title": "CoastWatch Training",
    "section": "2. Importing the downloaded file in R",
    "text": "2. Importing the downloaded file in R\nNow that we’ve downloaded the data locally, we can import it and extract our variables of interest:\n\nopen the file\n\n\nnc &lt;- nc_open('sst.nc')\n\nexamine which variables are included in the dataset:\n\n\nnames(nc$var)\n\n## [1] \"sea_surface_temperature\"\n\nExtract sea_surface_temperature:\n\n\nv1 &lt;- nc$var[[1]]\nsst &lt;- ncvar_get(nc,v1)\n\nexamine the structure of sst:\n\n\ndim(sst)\n\n## [1] 201 202  12\nOur dataset is a 3-D array with 201 rows corresponding to longitudes, 202 columns corresponding to latitudes for each of the 12 time steps.\n\nget the dates for each time step:\n\n\ndates &lt;- as.POSIXlt(v1$dim[[3]]$vals,origin='1970-01-01',tz='GMT')\ndates\n\n##  [1] \"2022-01-16 GMT\" \"2022-02-16 GMT\" \"2022-03-16 GMT\" \"2022-04-16 GMT\"\n##  [5] \"2022-05-16 GMT\" \"2022-06-16 GMT\" \"2022-07-16 GMT\" \"2022-08-16 GMT\"\n##  [9] \"2022-09-16 GMT\" \"2022-10-16 GMT\" \"2022-11-16 GMT\" \"2022-12-16 GMT\"\n\nget the longitude and latitude values\n\n\nlon &lt;- v1$dim[[1]]$vals\nlat &lt;- v1$dim[[2]]$vals\n\nClose the netcdf file and remove the data and files that are not needed anymore.\n\n\nnc_close(nc)\nrm(junk,v1)\nfile.remove('sst.nc')\n\n## [1] TRUE"
  },
  {
    "objectID": "tutorials/r/Tutorial1-basics.html#working-with-the-extracted-data",
    "href": "tutorials/r/Tutorial1-basics.html#working-with-the-extracted-data",
    "title": "CoastWatch Training",
    "section": "3. Working with the extracted data",
    "text": "3. Working with the extracted data\n\nCreating a map for one time step\nLet’s create a map of SST for January 2022 (our first time step).\nYou will need to download the scale.R file and copy it to your working directory to plot the color scale properly.\n\nset some color breaks\n\n\nh &lt;- hist(sst[,,1], 100, plot=FALSE)\nbreaks &lt;- h$breaks\nn &lt;- length(breaks)-1\n\ndefine a color palette\n\n\njet.colors &lt;- colorRampPalette(c(\"blue\", \"#007FFF\", \"cyan\",\"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"))\n\nset color scale using the jet.colors palette\n\n\nc &lt;- jet.colors(n)\n\nprepare graphic window : left side for map, right side for color scale\n\n\nlayout(matrix(c(1,2), nrow=1, ncol=2), widths=c(7,2), heights=4)\npar(mar=c(3,3,3,1))\n\n#plot the SST map. Because this product was built with latitudes going from North to South, we need to reverse the lat vector because the 'image' function needs increasing values for the coordinates. We also need to flip the sst matrix along the 2d dimension so it plots correctly\nimage(lon,rev(lat),sst[,dim(sst)[2]:1,1],col=c,breaks=breaks,xlab='',ylab='',axes=TRUE,xaxs='i',yaxs='i',asp=1, main=paste(\"Monthly SST\", dates[1]))\n\n#example of how to add points to the map\npoints(-74:-71,rep(34,4), pch=20, cex=2)\n\n#example of how to add a contour (this is considered a new plot, not a feature, so you need to use par(new=TRUE)) to overlay it on top of the SST map\npar(new=TRUE)\ncontour(lon,rev(lat),sst[,dim(sst)[2]:1,1],levels=14,xaxs='i',yaxs='i',labcex=0.8,vfont = c(\"sans serif\", \"bold\"),axes=FALSE,asp=1)\n\n#plot color scale using 'image.scale' function from 'scale.R' script)\npar(mar=c(3,1,3,3))\nsource('scale.R')\nimage.scale(sst[,,1], col=c, breaks=breaks, horiz=FALSE, yaxt=\"n\",xlab='',ylab='',main='SST')\naxis(4, las=1)\nbox()\n\n\n\nPlotting a time series\nLet’s pick the following box : 36-38N, -77 to -75W.. We are going to generate a time series of mean SST within that box.\nI=which(lon&gt;=-77 & lon&lt;=-75)\nJ=which(lat&gt;=36 & lat&lt;=38)\nsst2=sst[I,J,]\nn=dim(sst2)[3]\nres=rep(NA,n)\nfor (i in 1:n)\nres[i]=mean(sst2[,,i],na.rm=TRUE)\nplot(1:n,res,axes=FALSE,type='o',pch=20,xlab='',ylab='SST (ºC)')\naxis(2)\naxis(1,1:n,format(dates,'%m'))\nbox()\n\n\n\nCreating a map of average SST over a year\nsst.yr=apply(sst[,,1:12],c(1,2),mean,na.rm=TRUE)\nh=hist(sst.yr, 100, plot=FALSE)\nbreaks=h$breaks\nn=length(breaks)-1\nc=jet.colors(n)\nlayout(matrix(c(1,2), nrow=1, ncol=2), widths=c(7,2), heights=4)\npar(mar=c(3,3,3,1))\nimage(lon,rev(lat),sst.yr[,dim(sst.yr)[2]:1],col=c,breaks=breaks,xlab='',ylab='',axes=TRUE,xaxs='i',yaxs='i',asp=1,main=paste(\"Mean SST\", format(dates[1],'%Y/%m/%d'),' - ',format(dates[12],'%Y/%m/%d')))\npar(mar=c(3,1,3,3))\nimage.scale(sst.yr, col=c, breaks=breaks, horiz=FALSE, yaxt=\"n\",xlab='',ylab='',main='SST')\naxis(4)\nbox()"
  },
  {
    "objectID": "tutorials/matlab/matchup-satellite-data-to-track-locations.html",
    "href": "tutorials/matlab/matchup-satellite-data-to-track-locations.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will teach you how to plot a loggerhead turtle track on a map. The turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. It transmitted for over 3 years and went all the way to the southern tip of Baja California!\nThe track data can be downloaded here: https://oceanwatch.pifsc.noaa.gov/files/25317_05.dat (You may need to copy and save the data.)\nWe’ll extract chlorophyll concentration and SST at each location along the track, and plot the data.\nLet’s load the track data.\nturtle = readtable(\"25317_05.dat\", \"Delimiter\", \",\");\n\n\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, in black\nplotm(turtle.mean_lat, turtle.mean_lon, 'k');\n\n% Mark the first location with a red triangle\nplotm(turtle.mean_lat(1), turtle.mean_lon(1), 'rv', 'MarkerFaceColor', 'r');\n\n% Add a title\ntitle('Turtle #25317');\ntightmap\n ### Now let’s extract data along the track\nWe are going to grab data from ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/griddap) so we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\n\n\n\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data are severely affected by clouds (i.e., lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer gaps. As a separate exercise, you can run all 3 temporal resolutions, and plot a time-series of each to compare.\n% Let's start by creating a shortcut to the link we're going to be calling\n% repeatedly\nMODIS = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0.csv?chlor_a\";\n\n% We also need to format the dates in a way that ERDDAP understands, i.e., 2010-12-15:\nturtle_datenum = datenum(turtle.year, turtle.month, turtle.day);\nturtle_dates = datestr(turtle_datenum, \"yyyy-mm-dd\");\nFor each date and location, we’ll extract a value of monthly chl-a concentration. To do this, we need to pass the needed parameters (which dataset, which date, which lon, and which lat) to ERDDAP by building the URL in a loop for each point of the track.\nNOTE: Because this is a very long track, running the loop on the entire track will take a while (about 5 mins). You could print the index value to the screen to gauge your progress, but this will slow down the loop. If the loop takes too long, just run it on the first ~100 points of the track, by changing the for statement below.\nIf the process breaks in the middle of the loop (sometimes there is an issue connecting to the ERDDAP server, which will cause an error and interrupt the loop), get the value of r, which will tell you which index the loop stopped at, and restart the loop there. For example, if the loop stopped at r = 163, restart the loop this way: for r = 163:1:height(turtle)\n% First, we'll create an empty matrix to hold the chlorophyll data.  This\n% isn't strictly necessary, but it will speed things up a little.\n% The data we extract will have 4 columns:\n% 1: date\n% 2: matched latitude\n% 3: matched longitude\n% 4: chlor_a\n% You can confirm this by pasting the URL below into a browser and viewing\n% the resulting data.  \nturtle_chl(1:height(turtle), 1:4) = NaN; \n\nfor r = 1:1:height(turtle)\n    % Create url from tag position\n    url = strcat(MODIS, '[(', num2str(turtle_dates(r, 1:10)), '):1:(', num2str(turtle_dates(r, 1:10)), ...\n       ')][(', num2str(turtle.mean_lat(r)), '):1:(', num2str(turtle.mean_lat(r)), ')][(', ...\n       num2str(turtle.mean_lon(r)), '):1:(', num2str(turtle.mean_lon(r)), ')]');\n    \n    % Access url\n    chl = webread(url);\n    \n    % Add data from url to our empty matrix\n    % First, time (there's probably a better way to do this...)\n    % We're going to keep time in the datenum format for now.\n    chl_time = chl.time{:};\n    turtle_chl(r,1) = datenum(datetime(chl_time(1:10), 'InputFormat', 'yyyy-MM-dd'));\n    \n    % Now the remaining variables\n    turtle_chl(r,2) = chl.latitude;\n    turtle_chl(r,3) = chl.longitude;\n    turtle_chl(r,4) = chl.chlor_a;\nend\nWe now have a value of monthly chlorophyll-a concentration for each location/date combination along the turtle track. Let’s save this information so we have it for future use.\n% There are two options for saving your output.  If you don't care about\n% including the header information, you can simply save the turtle_chl\n% matrix.\nwritematrix(turtle_chl, 'turtle_chl_NoHeader.csv');\n\n% To add the header, we just need to turn the matrix into a table.\nmatched_date = turtle_chl(:,1);\nmatched_lat = turtle_chl(:,2);\nmatched_lon = turtle_chl(:,3);\nmatched_chl = turtle_chl(:,4);\nturtle_chl_table = table(matched_date, matched_lat, matched_lon, matched_chl);\nwritetable(turtle_chl_table, 'turtle_chl_WithHeader.csv');\n\n% Note that: \n% 1) We kept the date in the 'datenum' format.  This can be changed to a\n% datevec if you'd like.  See the code in the previous tutorials for help\n% with this.\n% 2) We saved the files to our working directory.  If you want to save the\n% files elsewhere, just edit the path.\n\n\n\nExercise 1: Repeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v1_0.html\nExercise 2: Go to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ Note: some ERDDAPs are slower than others, so this could take a lot longer. If it takes too long, adjust the for loop to request data for only the first 100 days of our track.\n\n\n\n\n\nLet’s plot the track, color coded using values of monthly chlorophyll concentration. To do this, we’ll use the turtle_chl matrix we created above. We’ll also need to decide how to color code the track. Let’s take a look at the range of chlorophyll values.\n% Create a histogram with 30 bins\nfigure\nhistogram(turtle_chl(:,4), 30);\n Notice that the range of value is large, roughly 0 - 8 mg chl per m^3, but that nearly all the values are small. This suggests that we should log-transform the chlorophyll data. Let’s take a look at the log-transformed values.\n% Create a histogram with 30 bins\nfigure\nhistogram(log(turtle_chl(:,4)), 30);\n\n\n\nhistogram\n\n\nThe range of the log-transformed values is roughly -3 - 2, but most of the values are greater than -3 and less than 0. So, for our plot, we’ll use the log-transformed chlorophyll values and set the color range to -2.9 - 0.\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, with a marker size of 5 \n% Note that we're using 'scatterm' here instead of 'plotm'.  This is so\n% that we can control the colors of the individual points (here, based on\n% the log-transformed chlorophyll value).\nscatterm(turtle_chl(:,2), turtle_chl(:,3), 5, log(turtle_chl(:,4)), 'o', 'Filled');\n% Set the color map to jet colors, with 30 levels, ranging from -2.9 to 0.\ncolormap(jet(30));\ncaxis([-2.9 0]);\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'log(chl)';\n\n% Add a title\ntitle('Turtle #25317');\ntightmap\n\n\n\nTurtle track\n\n\n\n\n\nExercise 3: plot the track, color coded using values of monthly sea surface temperature. You can confirm for yourself that it’s not necessary to log-transform SST.\n\n\n\n\n\nIn the example above, we downloaded data from as close to the track position as possible. But, you could instead average all points within a given distance of a track position. Here’s how you’d do that.\n% Like last time, we'll create an empty matrix to hold the chlorophyll data.  This\n% isn't strictly necessary, but it will speed things up a little.\n% The data we extract will have 4 columns:\n% 1: date\n% 2: matched latitude\n% 3: matched longitude\n% 4: chlor_a\n% You can confirm this by pasting the URL below into a browser and viewing\n% the resulting data.  \nturtle_chl_radius(1:height(turtle), 1:4) = NaN; \n% We also need to define the radius of the area we want to average.  \n% For this example, let's say that radius is 0.1 degrees.  So, we want all\n% values within +/- 0.1 degrees of the track location.\nradius = 0.1;\n\n% When we create the url, we'll need to subtract this radius from the\n% minimum lat and lon, and add it to the maximum lat and lon.\nfor r = 1:1:height(turtle)\n    % Create url from tag position\n    url_rad = strcat(MODIS, '[(', num2str(turtle_dates(r, 1:10)), '):1:(', num2str(turtle_dates(r, 1:10)), ...\n       ')][(', num2str(turtle.mean_lat(r) + radius), '):1:(', num2str(turtle.mean_lat(r) - radius), ...\n       ')][(', num2str(turtle.mean_lon(r) - radius), '):1:(', num2str(turtle.mean_lon(r) + radius), ')]');\n    \n    % Access url\n    chl_rad = webread(url_rad);\n    \n    % The data we access via the url now has several lines.  We'll average\n    % the chlorophyll-a values.  \n    % We'll also average the lat and lon positions, but there are various\n    % options for how you could handle this (e.g., using the tag location\n    % instead)\n    \n    % Add data from url to our empty matrix\n    % First, time, which is the same for all rows \n    % We're going to keep time in the datenum format for now.\n    chl_rad_time = chl_rad.time{1,:};\n    turtle_chl_radius(r,1) = datenum(datetime(chl_rad_time(1:10), 'InputFormat', 'yyyy-MM-dd'));\n    \n    % Now the remaining variables\n    turtle_chl_radius(r,2) = mean(chl_rad.latitude);\n    turtle_chl_radius(r,3) = mean(chl_rad.longitude);\n    turtle_chl_radius(r,4) = mean(chl_rad.chlor_a);\nend\nSo far in our tutorials, we’ve been using Matlab’s built-in jet color palette. However, there are a lot of other color options that we could use. One tool with a range of palettes is the Climate Data Toolbox for Matlab. You can read how to install this add-on here: https://chadagreene.com/CDT/CDT_Getting_Started.html. Now that you’ve followed those steps, let’s use their algae color map to plot the chorlophyll values along the track.\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, with a marker size of 10 \n% Note that we're using 'scatterm' here instead of 'plotm'.  This is so\n% that we can control the colors of the individual points (here, based on\n% the log-transformed chlorophyll value).\nscatterm(turtle_chl_radius(:,2), turtle_chl_radius(:,3), 10, log(turtle_chl_radius(:,4)), 'o', 'Filled');\n\n% Set the color map to algae, with 30 levels, ranging from -2.9 to 0.\ncmocean('algae', 30);\ncaxis([-2.9 0]);\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'log(chl)';\n\n% Add a title\ntitle('Turtle #25317 - Averaging within +/- 0.1 degree of tracked location');\ntightmap\n\n\n\nTurtle tack log"
  },
  {
    "objectID": "tutorials/matlab/matchup-satellite-data-to-track-locations.html#extract-data-along-a-turtle-track",
    "href": "tutorials/matlab/matchup-satellite-data-to-track-locations.html#extract-data-along-a-turtle-track",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will teach you how to plot a loggerhead turtle track on a map. The turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. It transmitted for over 3 years and went all the way to the southern tip of Baja California!\nThe track data can be downloaded here: https://oceanwatch.pifsc.noaa.gov/files/25317_05.dat (You may need to copy and save the data.)\nWe’ll extract chlorophyll concentration and SST at each location along the track, and plot the data.\nLet’s load the track data.\nturtle = readtable(\"25317_05.dat\", \"Delimiter\", \",\");\n\n\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, in black\nplotm(turtle.mean_lat, turtle.mean_lon, 'k');\n\n% Mark the first location with a red triangle\nplotm(turtle.mean_lat(1), turtle.mean_lon(1), 'rv', 'MarkerFaceColor', 'r');\n\n% Add a title\ntitle('Turtle #25317');\ntightmap\n ### Now let’s extract data along the track\nWe are going to grab data from ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/griddap) so we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\n\n\n\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data are severely affected by clouds (i.e., lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer gaps. As a separate exercise, you can run all 3 temporal resolutions, and plot a time-series of each to compare.\n% Let's start by creating a shortcut to the link we're going to be calling\n% repeatedly\nMODIS = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0.csv?chlor_a\";\n\n% We also need to format the dates in a way that ERDDAP understands, i.e., 2010-12-15:\nturtle_datenum = datenum(turtle.year, turtle.month, turtle.day);\nturtle_dates = datestr(turtle_datenum, \"yyyy-mm-dd\");\nFor each date and location, we’ll extract a value of monthly chl-a concentration. To do this, we need to pass the needed parameters (which dataset, which date, which lon, and which lat) to ERDDAP by building the URL in a loop for each point of the track.\nNOTE: Because this is a very long track, running the loop on the entire track will take a while (about 5 mins). You could print the index value to the screen to gauge your progress, but this will slow down the loop. If the loop takes too long, just run it on the first ~100 points of the track, by changing the for statement below.\nIf the process breaks in the middle of the loop (sometimes there is an issue connecting to the ERDDAP server, which will cause an error and interrupt the loop), get the value of r, which will tell you which index the loop stopped at, and restart the loop there. For example, if the loop stopped at r = 163, restart the loop this way: for r = 163:1:height(turtle)\n% First, we'll create an empty matrix to hold the chlorophyll data.  This\n% isn't strictly necessary, but it will speed things up a little.\n% The data we extract will have 4 columns:\n% 1: date\n% 2: matched latitude\n% 3: matched longitude\n% 4: chlor_a\n% You can confirm this by pasting the URL below into a browser and viewing\n% the resulting data.  \nturtle_chl(1:height(turtle), 1:4) = NaN; \n\nfor r = 1:1:height(turtle)\n    % Create url from tag position\n    url = strcat(MODIS, '[(', num2str(turtle_dates(r, 1:10)), '):1:(', num2str(turtle_dates(r, 1:10)), ...\n       ')][(', num2str(turtle.mean_lat(r)), '):1:(', num2str(turtle.mean_lat(r)), ')][(', ...\n       num2str(turtle.mean_lon(r)), '):1:(', num2str(turtle.mean_lon(r)), ')]');\n    \n    % Access url\n    chl = webread(url);\n    \n    % Add data from url to our empty matrix\n    % First, time (there's probably a better way to do this...)\n    % We're going to keep time in the datenum format for now.\n    chl_time = chl.time{:};\n    turtle_chl(r,1) = datenum(datetime(chl_time(1:10), 'InputFormat', 'yyyy-MM-dd'));\n    \n    % Now the remaining variables\n    turtle_chl(r,2) = chl.latitude;\n    turtle_chl(r,3) = chl.longitude;\n    turtle_chl(r,4) = chl.chlor_a;\nend\nWe now have a value of monthly chlorophyll-a concentration for each location/date combination along the turtle track. Let’s save this information so we have it for future use.\n% There are two options for saving your output.  If you don't care about\n% including the header information, you can simply save the turtle_chl\n% matrix.\nwritematrix(turtle_chl, 'turtle_chl_NoHeader.csv');\n\n% To add the header, we just need to turn the matrix into a table.\nmatched_date = turtle_chl(:,1);\nmatched_lat = turtle_chl(:,2);\nmatched_lon = turtle_chl(:,3);\nmatched_chl = turtle_chl(:,4);\nturtle_chl_table = table(matched_date, matched_lat, matched_lon, matched_chl);\nwritetable(turtle_chl_table, 'turtle_chl_WithHeader.csv');\n\n% Note that: \n% 1) We kept the date in the 'datenum' format.  This can be changed to a\n% datevec if you'd like.  See the code in the previous tutorials for help\n% with this.\n% 2) We saved the files to our working directory.  If you want to save the\n% files elsewhere, just edit the path.\n\n\n\nExercise 1: Repeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v1_0.html\nExercise 2: Go to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ Note: some ERDDAPs are slower than others, so this could take a lot longer. If it takes too long, adjust the for loop to request data for only the first 100 days of our track.\n\n\n\n\n\nLet’s plot the track, color coded using values of monthly chlorophyll concentration. To do this, we’ll use the turtle_chl matrix we created above. We’ll also need to decide how to color code the track. Let’s take a look at the range of chlorophyll values.\n% Create a histogram with 30 bins\nfigure\nhistogram(turtle_chl(:,4), 30);\n Notice that the range of value is large, roughly 0 - 8 mg chl per m^3, but that nearly all the values are small. This suggests that we should log-transform the chlorophyll data. Let’s take a look at the log-transformed values.\n% Create a histogram with 30 bins\nfigure\nhistogram(log(turtle_chl(:,4)), 30);\n\n\n\nhistogram\n\n\nThe range of the log-transformed values is roughly -3 - 2, but most of the values are greater than -3 and less than 0. So, for our plot, we’ll use the log-transformed chlorophyll values and set the color range to -2.9 - 0.\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, with a marker size of 5 \n% Note that we're using 'scatterm' here instead of 'plotm'.  This is so\n% that we can control the colors of the individual points (here, based on\n% the log-transformed chlorophyll value).\nscatterm(turtle_chl(:,2), turtle_chl(:,3), 5, log(turtle_chl(:,4)), 'o', 'Filled');\n% Set the color map to jet colors, with 30 levels, ranging from -2.9 to 0.\ncolormap(jet(30));\ncaxis([-2.9 0]);\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'log(chl)';\n\n% Add a title\ntitle('Turtle #25317');\ntightmap\n\n\n\nTurtle track\n\n\n\n\n\nExercise 3: plot the track, color coded using values of monthly sea surface temperature. You can confirm for yourself that it’s not necessary to log-transform SST.\n\n\n\n\n\nIn the example above, we downloaded data from as close to the track position as possible. But, you could instead average all points within a given distance of a track position. Here’s how you’d do that.\n% Like last time, we'll create an empty matrix to hold the chlorophyll data.  This\n% isn't strictly necessary, but it will speed things up a little.\n% The data we extract will have 4 columns:\n% 1: date\n% 2: matched latitude\n% 3: matched longitude\n% 4: chlor_a\n% You can confirm this by pasting the URL below into a browser and viewing\n% the resulting data.  \nturtle_chl_radius(1:height(turtle), 1:4) = NaN; \n% We also need to define the radius of the area we want to average.  \n% For this example, let's say that radius is 0.1 degrees.  So, we want all\n% values within +/- 0.1 degrees of the track location.\nradius = 0.1;\n\n% When we create the url, we'll need to subtract this radius from the\n% minimum lat and lon, and add it to the maximum lat and lon.\nfor r = 1:1:height(turtle)\n    % Create url from tag position\n    url_rad = strcat(MODIS, '[(', num2str(turtle_dates(r, 1:10)), '):1:(', num2str(turtle_dates(r, 1:10)), ...\n       ')][(', num2str(turtle.mean_lat(r) + radius), '):1:(', num2str(turtle.mean_lat(r) - radius), ...\n       ')][(', num2str(turtle.mean_lon(r) - radius), '):1:(', num2str(turtle.mean_lon(r) + radius), ')]');\n    \n    % Access url\n    chl_rad = webread(url_rad);\n    \n    % The data we access via the url now has several lines.  We'll average\n    % the chlorophyll-a values.  \n    % We'll also average the lat and lon positions, but there are various\n    % options for how you could handle this (e.g., using the tag location\n    % instead)\n    \n    % Add data from url to our empty matrix\n    % First, time, which is the same for all rows \n    % We're going to keep time in the datenum format for now.\n    chl_rad_time = chl_rad.time{1,:};\n    turtle_chl_radius(r,1) = datenum(datetime(chl_rad_time(1:10), 'InputFormat', 'yyyy-MM-dd'));\n    \n    % Now the remaining variables\n    turtle_chl_radius(r,2) = mean(chl_rad.latitude);\n    turtle_chl_radius(r,3) = mean(chl_rad.longitude);\n    turtle_chl_radius(r,4) = mean(chl_rad.chlor_a);\nend\nSo far in our tutorials, we’ve been using Matlab’s built-in jet color palette. However, there are a lot of other color options that we could use. One tool with a range of palettes is the Climate Data Toolbox for Matlab. You can read how to install this add-on here: https://chadagreene.com/CDT/CDT_Getting_Started.html. Now that you’ve followed those steps, let’s use their algae color map to plot the chorlophyll values along the track.\nfigure\naxesm('mercator', 'MapLatLimit', [15 50], 'MapLonLimit', [120 255], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', 120:20:-100, 'PLabelLocation', 20:10:50, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Add the turtle track, with a marker size of 10 \n% Note that we're using 'scatterm' here instead of 'plotm'.  This is so\n% that we can control the colors of the individual points (here, based on\n% the log-transformed chlorophyll value).\nscatterm(turtle_chl_radius(:,2), turtle_chl_radius(:,3), 10, log(turtle_chl_radius(:,4)), 'o', 'Filled');\n\n% Set the color map to algae, with 30 levels, ranging from -2.9 to 0.\ncmocean('algae', 30);\ncaxis([-2.9 0]);\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'log(chl)';\n\n% Add a title\ntitle('Turtle #25317 - Averaging within +/- 0.1 degree of tracked location');\ntightmap\n\n\n\nTurtle tack log"
  },
  {
    "objectID": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html",
    "href": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "As an example, we are going to plot time-series of mean chlorophyll-a concentration from various sensors from 1997 to 2018 to look at the periods of overlap.\nWe are going to download data from SeaWiFS (1997-2010), MODIS (2002-present) and VIIRS (2012-present) and compare it to the ESA-CCI data which combines all 3 sensors into a homogeneous time-series.\nIn this tutorial, the URLs to the data are provided so you don’t have to search for them. But, if you weren’t sure what the URLs were, you could find them by searing the list of datasets hosted on the OceanWatch ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/index.html) and following the steps at the beginning of Tutoral 1.\nFor this tutoral, we’re interested in all time steps in the area bounded by 15 - 25N, 198 - 208E.\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nsw_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'time');\n\n% Convert this to [Y M D H M S]\nsw_time_ymdhms = datevec(sw_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(sw_time)];\n% Download the data of interest\nsw = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nswAVG(1:length(sw_time),1) = NaN;\nfor m = 1:1:length(sw_time)\n    swAVG(m,1) = mean(sw(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* sw m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nmodis_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'time'); \n\n% Convert this to [Y M D H M S]\nmodis_time_ymdhms = datevec(modis_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(modis_time)];\n\n% Download the data of interest\nmodis = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nmodisAVG(1:length(modis_time),1) = NaN;\nfor m = 1:1:length(modis_time)\n    modisAVG(m,1) = mean(modis(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* modis m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nviirs_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'time');\n\n% Convert this to [Y M D H M S]\nviirs_time_ymdhms = datevec(viirs_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(viirs_time)];\n% Download the data of interest\nviirs = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nviirsAVG(1:length(viirs_time),1) = NaN;\nfor m = 1:1:length(viirs_time)\n    viirsAVG(m,1) = mean(viirs(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* viirs m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nesa_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'time');\n\n% Convert this to [Y M D H M S]\nesa_time_ymdhms = datevec(esa_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(esa_time)];\n\n% Download the data of interest\nesa = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nesaAVG(1:length(esa_time),1) = NaN;\nfor m = 1:1:length(esa_time)\n    esaAVG(m,1) = mean(esa(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* esa m \n\n\n\nNow we can compare the spatial averages across the three sensors: SeaWiFS, MODIS, and VIIRS. We’ll do this by generating a plot the includes all three time series, which overlap to varying degrees.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'Color', [0 70 127]/255);\nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'Color', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'Color', [127 127 255]/255);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChloraophyll-a from MODIS and VIIRS\n\n\nYou can see that the values of chlorophyll-a concentration don’t match across sensors.\n\n\n\nThe OC-CCI data are from a blended product, that merges the three sensors.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'o', 'MarkerFaceColor', [0 70 127]/255, 'MarkerEdgeColor', ...\n    [0 70 127]/255); \nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'o', 'MarkerFaceColor', [147 213 0]/255, ...\n    'MarkerEdgeColor', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'o', 'MarkerFaceColor', [127 127 255]/255, ...\n    'MarkerEdgeColor', [127 127 255]/255);\nplot(datenum(esa_time_ymdhms), esaAVG, 'k', 'LineWidth', 2);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'OC-CCI', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChlorphyll from ESA OC-CCI"
  },
  {
    "objectID": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html#tutorial-2.-comparison-of-chlorophyll-data-from-different-sensors",
    "href": "tutorials/matlab/Tutorial2-timeseries-compare-sensors.html#tutorial-2.-comparison-of-chlorophyll-data-from-different-sensors",
    "title": "CoastWatch Training",
    "section": "",
    "text": "As an example, we are going to plot time-series of mean chlorophyll-a concentration from various sensors from 1997 to 2018 to look at the periods of overlap.\nWe are going to download data from SeaWiFS (1997-2010), MODIS (2002-present) and VIIRS (2012-present) and compare it to the ESA-CCI data which combines all 3 sensors into a homogeneous time-series.\nIn this tutorial, the URLs to the data are provided so you don’t have to search for them. But, if you weren’t sure what the URLs were, you could find them by searing the list of datasets hosted on the OceanWatch ERDDAP (https://oceanwatch.pifsc.noaa.gov/erddap/index.html) and following the steps at the beginning of Tutoral 1.\nFor this tutoral, we’re interested in all time steps in the area bounded by 15 - 25N, 198 - 208E.\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nsw_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'time');\n\n% Convert this to [Y M D H M S]\nsw_time_ymdhms = datevec(sw_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(sw_time)];\n% Download the data of interest\nsw = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/sw_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nswAVG(1:length(sw_time),1) = NaN;\nfor m = 1:1:length(sw_time)\n    swAVG(m,1) = mean(sw(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* sw m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nmodis_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'time'); \n\n% Convert this to [Y M D H M S]\nmodis_time_ymdhms = datevec(modis_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(modis_time)];\n\n% Download the data of interest\nmodis = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nmodisAVG(1:length(modis_time),1) = NaN;\nfor m = 1:1:length(modis_time)\n    modisAVG(m,1) = mean(modis(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* modis m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nviirs_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'time');\n\n% Convert this to [Y M D H M S]\nviirs_time_ymdhms = datevec(viirs_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(viirs_time)];\n% Download the data of interest\nviirs = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/noaa_snpp_chla_monthly', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nviirsAVG(1:length(viirs_time),1) = NaN;\nfor m = 1:1:length(viirs_time)\n    viirsAVG(m,1) = mean(viirs(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* viirs m \n\n\n\nIn Matlab, run the following code to view details about the data:\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0');\nThis allows us to see the variable names that we need for the code below, which downloads the data we’re interested in. After we download the data, we’re going to average the values of the area of interest for each month.\n% Download the data over area of interest\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\nesa_time = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'time');\n\n% Convert this to [Y M D H M S]\nesa_time_ymdhms = datevec(esa_time/86400 + datenum([1970 1 1 0 0 0])); \nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', 'longitude');\n\n% Find longitudes from 198 - 208 E\nlon_aoi = find(lon_full &gt;= 198 & lon_full &lt;= 208);\n\n% Find latitudes from 15 - 25 N\nlat_aoi = find(lat_full &gt;= 15 & lat_full &lt;= 25);\n\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) 1];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(esa_time)];\n\n% Download the data of interest\nesa = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v5-0', ...\n    'chlor_a', aoi_start, aoi_span);\n\n% Spatially average\nesaAVG(1:length(esa_time),1) = NaN;\nfor m = 1:1:length(esa_time)\n    esaAVG(m,1) = mean(esa(:,:,m), \"all\", \"omitnan\");\nend\n\n% Tidy up by deleting the variables we won't need again\nclear lat* lon* aoi* esa m \n\n\n\nNow we can compare the spatial averages across the three sensors: SeaWiFS, MODIS, and VIIRS. We’ll do this by generating a plot the includes all three time series, which overlap to varying degrees.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'Color', [0 70 127]/255);\nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'Color', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'Color', [127 127 255]/255);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChloraophyll-a from MODIS and VIIRS\n\n\nYou can see that the values of chlorophyll-a concentration don’t match across sensors.\n\n\n\nThe OC-CCI data are from a blended product, that merges the three sensors.\nfigure\nplot(datenum(sw_time_ymdhms), swAVG, 'o', 'MarkerFaceColor', [0 70 127]/255, 'MarkerEdgeColor', ...\n    [0 70 127]/255); \nhold on\nplot(datenum(modis_time_ymdhms), modisAVG, 'o', 'MarkerFaceColor', [147 213 0]/255, ...\n    'MarkerEdgeColor', [147 213 0]/255);\nplot(datenum(viirs_time_ymdhms), viirsAVG, 'o', 'MarkerFaceColor', [127 127 255]/255, ...\n    'MarkerEdgeColor', [127 127 255]/255);\nplot(datenum(esa_time_ymdhms), esaAVG, 'k', 'LineWidth', 2);\nset(gca,'XTick', datenum([2000 1 1 0 0 0]):5*365:datenum([2020 1 1 0 0 0]));\nset(gca,'XTickLabel', 2000:5:2020);\nlegend('SeaWiFS', 'MODIS', 'VIIRS', 'OC-CCI', 'Location', 'southwest');\nylabel('Chlorophyll-a');\n\n\n\nChlorphyll from ESA OC-CCI"
  },
  {
    "objectID": "tutorials/codegallery.html",
    "href": "tutorials/codegallery.html",
    "title": "Code Gallery",
    "section": "",
    "text": "This page lists CoastWatch code gallery tutorials.\nClick the eye icon to view the tutorial, box icon to view the required resources, or download to get directed to the source file.\n\n\n\n\n\n\n\n  \n    Category\n    \n      All\n      Data Access & SubsettingERDDAP BasicsSpatial Analysis & MappingTime Series\n    \n  \n\n  \n    Software\n\n    \n      Python ×\n    \n\n    \n      R ×\n    \n\n    \n      Matlab ×\n    \n\n    \n      Clear\n    \n  \n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nCategory\nPreview\nResources\nPython ↓\nR ↓\nMatlab ↓\n\n\n\n\nBasics of working with satellite data\nERDDAP Basics\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompare time series from different sensors\nTime Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMake a virtual buoy with satellite data\nTime Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nCalculating sea ice area and extent\nSpatial Analysis & Mapping\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n—\n\n\nWorking with data that crosses the antimeridian\nSpatial Analysis & Mapping\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nDefine a marine habitat\nSpatial Analysis & Mapping\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n—\n\n\nExtract data within a boundary\nData Access & Subsetting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to work with satellite data in Matlab in the Great Lakes\nERDDAP Basics\n\n\n\n\n\n—\n—\n—\n\n\n\n\n\n\n\nWorking with Great Lakes Surface Temperature Data\nData Access & Subsetting\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nAnalyze Great Lakes Ice Concentration\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nMulti-Sensor chlorophyll time series analysis for Lake Erie\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nLong-term lake surface temperature variability from Great Lakes Satellite Records\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nVisualizing JPSS Sea Ice Concentration products using Google Colab\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n—\n—\n\n\nLong Island Sound Chlorophyll-a Dynamics\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n—\n\n\nMap geographical and polarstereographic data on a projected map\nSpatial Analysis & Mapping\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nMask shallow pixels for satellite ocean color datasets\nSpatial Analysis & Mapping\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n—\n\n\nMatching polar data to animal track locations\nSpatial Analysis & Mapping\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nMatching satellite and buoy surface temperature data in polar regions\nTime Series\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n—\n\n\nComparing satellite and buoy sea surface temperature observations\nTime Series\n\n\n\n\n\n—\n—\n\n\n\n\n\n—\n\n\nMatchup satellite data to ship, glider, or animal tracks\nSpatial Analysis & Mapping\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n—\n\n\nMatching satellite chlorophyll to animal telemetry tracks\nSpatial Analysis & Mapping\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalculating anomaly and trend with sea ice thickness time series\nTime Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n\n\nSubset data in polar stereographic projection using a shapefile\nData Access & Subsetting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n—\n—\n\n\nTransforming satellite data from one map to another\nSpatial Analysis & Mapping\n\n\n\n\n\n—\n\n\n\n\n\n\n\n\n\n\n—\n\n\n\n\n\n    \n      Basics of working with satellite data\n      Access and analyze satellite-derived sea surface temperature using ERDDAP and NetCDF-based workflows. This tutorial demonstrates how to locate and subset a satellite SST product in ERDDAP, download gridded NetCDF data, examine its structure, and create basic spatial maps and regional time series. Users work with the NOAA Coral Reef Watch CoralTemp monthly sea surface temperature product to explore coordinate conventions, generate SST maps, compute regional averages, and visualize temporal variability.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature in the western North Atlantic Ocean along the US East Coast in 2022.\n          \n          \n          \n            \n              \n            \n            Map of the 2022 average sea surface temperature in the western North Atlantic Ocean along the US East Coast.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature in the western North Atlantic Ocean along the US East Coast in 2022.\n          \n          \n          \n            \n              \n            \n            Map of the 2022 average sea surface temperature in the western North Atlantic Ocean along the US East Coast.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Time series of sea surface temperature around the Hawaiian Islands in 2018.\n          \n          \n          \n            \n              \n            \n            Map of the 2018 average sea surface temperature in the Hawaiian Islands.\n          \n            ◀  1 / 2  ▶\n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      Compare time series from different sensors\n      Compare satellite chlorophyll-a time series from multiple ocean color sensors to understand differences during overlapping observation periods. This tutorial demonstrates how to use ERDDAP to extract spatially averaged chlorophyll-a time series from a defined region, examine dataset metadata, handle differences in coordinate conventions, and compare measurements across sensors through visualization. Monthly chlorophyll-a data from SeaWiFS, MODIS Aqua, NOAA VIIRS S-NPP, and the ESA Ocean Colour Climate Change Initiative (OC-CCI) are used to evaluate consistency and variability among sensors from 1997 to the present.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          \n            \n              \n            \n            Mean log-transformed chlorophyll-a concentration for the Gulf of Mexico region derived from SeaWiFS, MODIS Aqua, NOAA VIIRS S-NPP, and the ESA OC-CCI blended dataset.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Monthly chlorophyll-a time series from SeaWiFS, MODIS Aqua, VIIRS S-NPP, and the ESA OC-CCI dataset averaged over a Gulf of Mexico region, illustrating differences among sensors during periods of overlap.\n          \n          \n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      Make a virtual buoy with satellite data\n      Create a virtual ocean buoy using satellite data to extend or replace discontinued in situ observations. This tutorial demonstrates how to use ERDDAP to extract satellite sea surface temperature at a fixed location, build and clean a virtual buoy time series, resample the data to a lower temporal resolution, and analyze trends through visualization and linear regression. Data from NDBC Buoy 46259 are used alongside the NOAA GeoPolar Blended SST satellite dataset.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            National Data Buoy Center buoy 46259 matched up with sea surface temperature data.\n          \n          \n          \n            \n              \n            \n             Trend analysis of buoy and satellite data.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            National Data Buoy Center buoy 46259 matched up with sea surface temperature data.\n          \n          \n          \n            \n              \n            \n             Trend analysis of buoy and satellite data.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Calculating sea ice area and extent\n      Calculate sea ice area and extent from satellite-derived sea ice concentration to quantify seasonal and interannual variability in Arctic ice cover. This tutorial demonstrates how to use PolarWatch ERDDAP to retrieve gridded sea ice concentration data, incorporate grid cell area information, and apply standard concentration thresholds to compute sea ice area and extent. Users visualize sea ice concentration maps and generate monthly time series to examine changes in Arctic sea ice over time. Data from the NOAA/NSIDC Sea Ice Concentration Climate Data Record (Version 4) and a polar stereographic grid cell area dataset are used to perform the calculations for the Northern Hemisphere.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly mean sea ice concentration in the Northern Hemisphere derived from the NOAA/NSIDC Sea Ice Concentration Climate Data Record.\n          \n          \n          \n            \n              \n            \n            Monthly time series of Arctic sea ice area and sea ice extent computed from satellite-derived sea ice concentration using a 15% concentration threshold.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly mean sea ice concentration for the Arctic in 2021 shown in a Northern Polar Stereographic projection.\n          \n          \n          \n            \n              \n            \n            Monthly time series of Arctic sea ice area and sea ice extent for 2021 computed from satellite-derived sea ice concentration using a 15% concentration threshold.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Working with data that crosses the antimeridian\n      Work with satellite datasets that span the antimeridian by correcting longitude discontinuities for analysis and visualization. This tutorial demonstrates how to retrieve gridded satellite data defined on a −180° to +180° longitude system, subset regions that cross the antimeridian, convert longitude coordinates to a 0–360° system, and reorder the longitude axis to create a continuous spatial domain. The corrected data are then visualized on a map and saved for downstream analysis. Chlorophyll-a data from the NOAA gap-filled blended VIIRS ocean color dataset are used to illustrate antimeridian handling in the Bering Sea region.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Subset of satellite chlorophyll-a data crossing the antimeridian plotted using a −180° to +180° longitude convention. The map shows a visible discontinuity where data from opposite sides of the antimeridian are split and displayed at opposite edges of the domain.\n          \n          \n          \n            \n              \n            \n            The same satellite chlorophyll-a data after converting longitudes to a 0–360° convention and reordering the longitude axis. The antimeridian discontinuity is removed, resulting in a continuous spatial representation suitable for mapping and analysis.\n          \n            ◀  1 / 2  ▶\n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Define a marine habitat\n      Define a marine habitat using satellite sea surface temperature to identify regions associated with species–environment interactions. This tutorial demonstrates how to retrieve satellite SST from ERDDAP, subset data for a region and time of interest, and apply temperature-based thresholds to delineate a habitat band. The resulting temperature contours are visualized on a map to highlight areas associated with increased likelihood of interaction. Sea surface temperature data from the NOAA Coral Reef Watch CoralTemp product are used to illustrate habitat definition in the central North Pacific as part of the TurtleWatch framework.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature map with the TurtleWatch habitat band highlighted. The red band marks SST values between 17.5 °C and 18.5 °C, identifying regions associated with increased loggerhead sea turtle interactions based on the TurtleWatch framework.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature map with the TurtleWatch habitat band highlighted. The red band marks SST values between 17.5 °C and 18.5 °C, identifying regions associated with increased loggerhead sea turtle interactions based on the TurtleWatch framework.\n          \n          \n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Extract data within a boundary\n      Extract and analyze satellite data within an irregular geographic boundary to better represent real-world marine regions. This tutorial demonstrates how to download sea surface temperature data from ERDDAP, subset it using a bounding box, and apply a polygon mask to retain values only within a defined boundary. The masked data are then used to compute and visualize a seasonal temperature cycle for the region of interest. Sea surface temperature data from the NOAA Geo-Polar Blended SST product are combined with Longhurst Marine Province boundaries to illustrate region-based satellite analysis.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature masked to the Gulf Stream Longhurst Province (GFST).\n          \n          \n          \n            \n              \n            \n            Monthly mean sea surface temperature within the Gulf Stream Province for 2020.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Satellite sea surface temperature masked to the Gulf Stream Longhurst Province (GFST).\n          \n          \n          \n            \n              \n            \n            Monthly mean sea surface temperature within the Gulf Stream Province for 2020.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Monthly sea surface temperature within the Papahānaumokuākea Marine National Monument (PMNM) for April 2015.\n          \n          \n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      How to work with satellite data in Matlab in the Great Lakes\n      Access and analyze satellite sea surface temperature data in MATLAB using ERDDAP and NetCDF workflows. This tutorial demonstrates how to construct ERDDAP download URLs, read NetCDF variables directly into MATLAB, convert time coordinates, and subset data spatially and temporally. The workflow includes creating daily SST maps, generating regional mean time series, and computing average SST over a selected period. Satellite sea surface temperature data from NOAA CoastWatch are used to illustrate spatial and temporal analysis across the Great Lakes region.\n\n      \n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Daily satellite sea surface temperature (SST) across the Great Lakes on 21 July 2021, extracted from ERDDAP and visualized in a Mercator projection.\n          \n          \n          \n            \n              \n            \n            Time series of mean SST within a Lake Superior subregion showing daily temperature variability from 21–28 July 2021.\n          \n          \n          \n            \n              \n            \n            Mean satellite SST across the Great Lakes averaged over 21–28 July 2021, illustrating spatial temperature patterns derived from ERDDAP data.\n          \n            ◀  1 / 3  ▶\n          \n            View Matlab tutorial\n          \n        \n        \n      \n\n      Close\n    \n    \n    \n      Working with Great Lakes Surface Temperature Data\n      Access and analyze Great Lakes surface temperature using satellite observations in Python. This tutorial demonstrates how to download water surface temperature data from an ERDDAP server, open and inspect NetCDF files using xarray, and convert time variables into usable date formats. The extracted data are used to generate spatial maps of surface temperature, compute regional averages within user-defined bounding boxes, and visualize temporal variability through daily time series and monthly mean maps. Water surface temperature data from the Great Lakes Surface Environmental Analysis (GLSEA) ACSPO dataset are used to illustrate satellite-based analysis of Lake Erie.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Spatial subset of Lake Erie water surface temperature on June 1, 2023, extracted from ERDDAP and visualized for a focused region of interest.\n          \n          \n          \n            \n              \n            \n            Daily mean water surface temperature time series for a selected Lake Erie subregion during June 2023, illustrating short-term temporal variability.\n          \n          \n          \n            \n              \n            \n            Monthly mean water surface temperature across Lake Erie for June 2023, computed from daily satellite observations downloaded via ERDDAP.\n          \n            ◀  1 / 3  ▶\n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Analyze Great Lakes Ice Concentration \n      Extract and summarize satellite-derived ice concentration to characterize seasonal ice conditions in the Great Lakes. This tutorial demonstrates how to download ice concentration data from ERDDAP, subset the data spatially and temporally for a region of interest, and handle missing values in NetCDF files. The extracted data are used to generate maps of ice concentration for specific dates and to compute regional daily mean ice concentration time series. Ice concentration data from the NOAA Great Lakes Surface Environmental Analysis (GLSEA) product are used to illustrate regional ice variability in western Lake Erie.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Spatial distribution of ice concentration (%) in western Lake Erie on March 1, 2019, derived from the Great Lakes Ice Concentration product and visualized after subsetting the ERDDAP dataset to the region of interest.\n          \n          \n          \n            \n              \n            \n            Time series of daily mean ice concentration (%) for western Lake Erie during March 2019, calculated by averaging satellite-derived ice concentration over the selected spatial domain.\n          \n            ◀  1 / 2  ▶\n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Multi-Sensor chlorophyll time series analysis for Lake Erie\n      Analyze long-term changes in lake chlorophyll concentrations by combining satellite observations from multiple sensors. This tutorial demonstrates how to download chlorophyll-a data from ERDDAP for Lake Erie, process daily observations from MODIS (2002–2017) and VIIRS (2018–2023), and compute spatially averaged monthly and daily time series. The workflow shows how to handle fill values, aggregate data across space and time, and visualize chlorophyll variability across the sensor transition. By merging MODIS and VIIRS records, the tutorial provides a practical approach for creating a continuous multi-sensor time series to support long-term water quality analysis in the Great Lakes.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly mean chlorophyll-a concentration across Lake Erie for August 2009, illustrating the spatial distribution of phytoplankton biomass derived from satellite observations.\n          \n          \n          \n            \n              \n            \n            Spatially averaged monthly chlorophyll-a time series for Lake Erie from 2002–2017, showing seasonal variability and interannual changes captured by the MODIS sensor.\n          \n          \n          \n            \n              \n            \n            Daily spatially averaged chlorophyll-a concentrations for Lake Erie in 2023, highlighting short-term variability and bloom dynamics observed by the VIIRS sensor.\n          \n            ◀  1 / 3  ▶\n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Long-term lake surface temperature variability from Great Lakes Satellite Records\n      Analyze long-term patterns in Great Lakes water surface temperature using lakewide satellite-derived averages. This tutorial demonstrates how to retrieve daily average surface temperature data from ERDDAP, assemble a multi-year record spanning 2007 to the present, and visualize seasonal temperature variability across years. Daily temperature records are aligned by day of year to highlight the warmest, coldest, and average conditions for a given date, with the current year shown in context of the historical record. Using Great Lakes Surface Environmental Analysis (GLSEA) satellite products, the workflow illustrates how long-term lake temperature climatologies can be used to assess seasonal extremes and interannual variability across the Great Lakes.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Seasonal evolution of Lake Michigan average surface water temperature from 2007–2024, showing the current year in context of the long-term mean and highlighting the historically warmest and coldest years for the selected calendar day based on GLSEA satellite records.\n          \n          \n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Visualizing JPSS Sea Ice Concentration products using Google Colab\n      Visualize polar sea ice conditions by converting JPSS Sea Ice Concentration files into mapped images for quick inspection and reporting. This tutorial demonstrates how to obtain either Level-2 swath VIIRS ice concentration data or Level-3 daily gridded blended sea ice concentration products, load them into an analysis environment, and generate publication-ready maps for the Arctic or Antarctic. The workflow resamples swath observations onto a common polar grid when needed, applies consistent color scaling in percent ice concentration, and exports the final figures as PNGs.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Blended JPSS sea ice concentration for the Arctic on October 5, 2024, showing the spatial extent and intensity of ice cover derived from combined satellite observations and mapped onto a polar projection with ice concentration expressed as percent.\n          \n          \n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Long Island Sound Chlorophyll-a Dynamics\n      Analyze seasonal and spatial patterns in coastal chlorophyll-a by working with daily satellite observations from Long Island Sound. This tutorial demonstrates how to download chlorophyll-a data from ERDDAP, generate temporal composites at monthly and 8-day intervals, and subset the data to compare regional variability within the Sound. The workflow illustrates how to examine gridded satellite datasets, compute spatial averages, and visualize chlorophyll dynamics through maps and time-series plots. Chlorophyll-a data from Sentinel-3 OLCI, processed with Long Island Sound–optimized algorithms, are used to highlight differences between western and eastern regions and to explore seasonal water-quality variability in a complex coastal environment.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly mean chlorophyll-a concentrations in Long Island Sound during 2022, illustrating the seasonal evolution of phytoplankton biomass derived from daily Sentinel-3 OLCI observations.\n          \n          \n          \n            \n              \n            \n            Spatial distribution of mean chlorophyll-a concentration in Long Island Sound averaged over January–December 2022, highlighting persistent regional gradients across the estuary.\n          \n          \n          \n            \n              \n            \n            Eight-day averaged chlorophyll-a time series comparing western and eastern Long Island Sound, showing contrasting seasonal cycles and peak bloom timing during 2022.\n          \n            ◀  1 / 3  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly mean chlorophyll-a concentrations in Long Island Sound during 2022, illustrating the seasonal evolution of phytoplankton biomass derived from daily Sentinel-3 OLCI observations.\n          \n          \n          \n            \n              \n            \n            Spatial distribution of mean chlorophyll-a concentration in Long Island Sound averaged over January–December 2022, highlighting persistent regional gradients across the estuary.\n          \n          \n          \n            \n              \n            \n            Eight-day averaged chlorophyll-a time series comparing western and eastern Long Island Sound, showing contrasting seasonal cycles and peak bloom timing during 2022.\n          \n            ◀  1 / 3  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Map geographical and polarstereographic data on a projected map\n      Plot polar satellite data correctly by working across coordinate systems and projections. This tutorial demonstrates how to access polar sea ice concentration data from an ERDDAP server, interpret the dataset’s polar stereographic metadata (or EPSG code), and display the gridded x–y product on a matching projected basemap. It then shows how to overlay a second dataset provided in geographic coordinates (latitude/longitude) here, polar bear GPS tracks by transforming those points into the same map projection for direct visual comparison with the sea ice field.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Sea ice concentration from the NOAA/NSIDC Climate Data Record is displayed on a North Polar Stereographic map using the dataset’s native EPSG:3411 projection.\n          \n          \n          \n            \n              \n            \n            Monthly sea ice concentration is shown on a polar stereographic basemap with overlaid polar bear GPS locations in latitude–longitude coordinates.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Sea ice concentration from the NOAA/NSIDC Climate Data Record is displayed on a Polar Stereographic projection, illustrating how gridded polar satellite data are mapped in projected x–y coordinates.\n          \n          \n          \n            \n              \n            \n             Sea ice concentration mapped on a Polar Stereographic projection with polar bear GPS tracks overlaid.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Mask shallow pixels for satellite ocean color datasets\n      Remove optically shallow-water contamination from satellite ocean color data to improve the accuracy of derived biogeochemical metrics. This tutorial demonstrates how to download bathymetry and monthly chlorophyll-a data from ERDDAP, quantify the fraction of shallow water within each ocean color pixel, and construct a threshold-based mask to exclude pixels affected by bottom reflectance. The masked and unmasked datasets are then used to compute and compare long-term chlorophyll-a climatologies. By combining high-resolution bathymetry with coarse-resolution ocean color observations, the workflow illustrates a practical approach for preparing satellite datasets for robust analysis in coastal and reef-adjacent regions.\n\n      \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            High-resolution ETOPO bathymetry for the Oʻahu region showing depth contours used to distinguish optically shallow and deep waters.\n          \n          \n          \n            \n              \n            \n            Percentage of shallow water (&lt;30 m depth) contained within each coarse-resolution ocean color pixel, calculated by matching bathymetry to the chlorophyll grid.\n          \n          \n          \n            \n              \n            \n            Binary mask identifying ocean color pixels dominated by shallow water based on a user-defined shallow-area threshold.\n          \n          \n          \n            \n              \n            \n            Log-scaled chlorophyll-a climatology after applying the shallow-water mask, illustrating the removal of bottom-contaminated coastal pixels.\n          \n            ◀  1 / 4  ▶\n          \n            View R tutorial\n          \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Matching polar data to animal track locations\n      Extract and analyze satellite sea ice conditions along animal movement tracks in polar regions. This tutorial demonstrates how to combine satellite sea ice concentration data with animal telemetry observations to examine environmental conditions encountered along a tracked path. Using monthly sea ice concentration records from NOAA PolarWatch, the workflow shows how to subset gridded satellite data in polar stereographic coordinates, align it temporally and spatially with penguin telemetry locations, and extract coincident sea ice values along the track. The tutorial also illustrates how to visualize animal movement overlaid on sea ice maps and how to generate matched time series of satellite-derived sea ice concentration at each observation point.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly Antarctic sea ice concentration from the NOAA/NSIDC Climate Data Record is shown on a south polar stereographic map for the first available timestep.\n          \n          \n          \n            \n              \n            \n            Monthly sea ice concentration maps for January, February, and March are overlaid with Adelie penguin telemetry tracks.\n          \n          \n          \n            \n              \n            \n            Penguin track locations are colored by collocated sea ice concentration values extracted from the satellite dataset.\n          \n            ◀  1 / 3  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly sea ice concentration from the NOAA/NSIDC Climate Data Record is mapped for the first available time step to illustrate the polar stereographic satellite grid used for Antarctic matchups.\n          \n          \n          \n            \n              \n            \n            The Adelie penguin telemetry track is plotted in geographic coordinates, highlighting the start and end points used to extract satellite sea ice values along the animal’s path.\n          \n          \n          \n            \n              \n            \n            The penguin track is colored by the extracted monthly sea ice concentration at each location and date, showing how satellite conditions are sampled along a moving trajectory in Antarctica.\n          \n            ◀  1 / 3  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Matching satellite and buoy surface temperature data in polar regions\n      Combine satellite ice surface temperature composites with in situ buoy observations by matching satellite pixels to buoy locations and dates in the Arctic. This tutorial walks through how to query buoy surface temperature records from ERDDAP in tabular format, download polar-projected satellite Ice Surface Temperature (IST) data in NetCDF, and resample the buoy time series to comparable time steps. It then demonstrates how to convert buoy latitude/longitude positions into the satellite’s polar stereographic coordinate system, extract the nearest satellite IST values at each buoy time and location, and merge the two datasets for side-by-side comparison and visualization.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Time series comparison of buoy-measured surface temperature and collocated VIIRS ice surface temperature.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Time series comparison of buoy-measured surface temperature and collocated VIIRS ice surface temperature.\n          \n          \n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Comparing satellite and buoy sea surface temperature observations \n      This tutorial demonstrates how to match satellite-derived sea surface temperature (SST) with in situ buoy observations to evaluate satellite data accuracy. Using ERDDAP-hosted datasets, the workflow shows how to download and process buoy measurements, extract collocated satellite SST values, and compare the two datasets through statistical analysis and visualization.\n\n      \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Daily averaged buoy sea surface temperatures are compared with colocated satellite SST values along the California coast from August 1–10, 2023.\n          \n          \n          \n            \n              \n            \n            Satellite sea surface temperature fields for July 31, 2023 are shown with overlaid buoy locations colored by observed temperature.\n          \n            ◀  1 / 2  ▶\n          \n            View R tutorial\n          \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Matchup satellite data to ship, glider, or animal tracks\n      Extract and analyze satellite-derived environmental variables along moving platforms such as ship tracks, gliders, or animal telemetry paths. This tutorial demonstrates how to load track data defined by latitude, longitude, and time, visualize trajectories on a map, and retrieve colocated satellite observations from ERDDAP for each track position. Using a yellowfin tuna telemetry record as an example, satellite chlorophyll-a data from the ESA Ocean Colour Climate Change Initiative are matched to daily track locations, saved to a tabular format, and visualized to explore spatial and temporal variability along the track.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Chlorophyll-a concentrations extracted from satellite observations along a Yellowfin tuna telemetry track, with points colored by matched monthly chlorophyll values and symbols indicating the start and end of the track.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Yellowfin tuna track locations colored by the log of satellite-derived chlorophyll-a values extracted from the ESA OC-CCI monthly dataset.\n          \n          \n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Matching satellite chlorophyll to animal telemetry tracks\n      This tutorial demonstrates how satellite data can be matched to moving tracks defined by longitude, latitude, and time, such as those from ships, gliders, or animal telemetry. Using a subsampled loggerhead turtle track and the ESA Ocean Colour Climate Change Initiative (OC-CCI) monthly chlorophyll-a dataset (v6.0), the workflow loads track data from a file, visualizes the track and its start/end locations, extracts satellite chlorophyll values at each track point via ERDDAP, saves the matchup results to a CSV file, and maps the satellite-derived chlorophyll patterns along the track.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Chlorophyll-a concentrations from the ESA OC-CCI monthly product matched to locations along animal track #25317, with points colored by satellite-derived chlorophyll values and start/end positions indicated along the track.\n          \n          \n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Loggerhead turtle track locations colored by log-transformed ESA OC-CCI monthly chlorophyll-a values extracted from ERDDAP at each subsampled track point (May 2005–Aug 2008).\n          \n          \n          View R tutorial\n        \n        \n        \n        \n          Matlab output\n          \n          \n            \n              \n            \n            Loggerhead turtle (#25317) track colored by log-transformed monthly chlorophyll-a averaged within ±0.1° of each tag location using ERDDAP matchup requests.\n          \n          \n          View Matlab tutorial\n        \n        \n      \n\n      Close\n    \n    \n    \n      Calculating anomaly and trend with sea ice thickness time series\n      This tutorial demonstrates how to analyze variability and long-term change in Arctic sea ice thickness using gridded satellite data. Monthly mean sea ice thickness fields are derived from twice-daily observations accessed through the PolarWatch ERDDAP server, then compared against a multi-year climatological baseline to quantify anomalies. A 15-year reference period (2006–2020) is used to compute historical monthly means, which serve as the basis for anomaly calculations and trend assessment. Long-term trends in monthly sea ice thickness are estimated at each grid cell using the non-parametric Mann–Kendall method, allowing robust slope estimation without assumptions of normality.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly sea ice thickness anomalies for February (left) and September (right) in 2021, calculated as departures from the 2005–2020 climatological mean using Arctic sea ice thickness data from the NOAA CDR Extended Polar Pathfinder dataset.\n          \n          \n          \n            \n              \n            \n            Spatial distribution of the long-term September sea ice thickness trend across the Arctic, estimated for the 2006–2020 climatological period using a Mann–Kendall trend analysis applied to monthly mean sea ice thickness data.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          No preview image\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Subset data in polar stereographic projection using a shapefile\n      This exercise demonstrates how to subset satellite data provided in a polar stereographic projection using a lake boundary defined in a different coordinate reference system. The workflow includes downloading polar satellite data from PolarWatch ERDDAP, transforming a shapefile to match the satellite projection, and clipping the dataset to the extent of Lake Iliamna in Alaska. The results are visualized to illustrate projection handling and spatial subsetting of polar remote sensing data\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            IMS Snow and Ice Analysis data from PolarWatch for 30 July 2024 shown in its native polar stereographic projection, illustrating categorical surface conditions across the Northern Hemisphere.\n          \n          \n          \n            \n              \n            \n            Subset of the IMS Snow and Ice Analysis clipped to the Lake Iliamna region after transforming the lake shapefile into the satellite data’s polar stereographic projection, demonstrating successful reprojection and spatial subsetting.\n          \n            ◀  1 / 2  ▶\n          \n            View Python tutorial\n          \n        \n        \n        \n        \n      \n\n      Close\n    \n    \n    \n      Transforming satellite data from one map to another\n      This exercise demonstrates how to transform satellite data coordinates from one map projection to another in order to work consistently with datasets that use different coordinate reference systems. It walks through downloading sea ice concentration data from PolarWatch ERDDAP, inspecting CRS definitions, applying EPSG-based coordinate transformations, and adding the transformed coordinates back into a NetCDF dataset.\n\n      \n        \n        \n          Python output\n          \n          \n            \n              \n            \n            Monthly mean sea ice concentration for December 2022 from the NOAA/NSIDC Climate Data Record, displayed using transformed latitude–longitude coordinates on a global (Plate Carrée) map projection.\n          \n          \n          \n            \n              \n            \n            The same December 2022 sea ice concentration data visualized on a Southern Hemisphere polar stereographic projection.\n          \n            ◀  1 / 2  ▶\n          View Python tutorial\n        \n        \n        \n        \n          R output\n          \n          \n            \n              \n            \n            Monthly mean sea ice concentration for December 2022 from the NOAA/NSIDC Climate Data Record, displayed using transformed latitude–longitude coordinates on a global (Plate Carrée) map projection.\n          \n          \n          \n            \n              \n            \n            The same December 2022 sea ice concentration data visualized on a Southern Hemisphere polar stereographic projection, illustrating the improved representation of Antarctic sea ice when using a projection optimized for polar regions.\n          \n            ◀  1 / 2  ▶\n          View R tutorial\n        \n        \n        \n      \n\n      Close\n    \n\n\n\n\n\n\n✕",
    "crumbs": [
      "Training Tutorials",
      "Code Gallery"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html",
    "href": "trainings/upcoming/pgrsc26.html",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "",
    "text": "This 4-day satellite and ocean data training course will be held virtually during February 10-13 (FJT), 2026. It is co-hosted by CoastWatch/OceanWatch Central Pacific and the Pacific Islands Ocean Observing System (PacIOOS).\nClick here to Register.\nJoin course via googlemeet here",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#course-description",
    "href": "trainings/upcoming/pgrsc26.html#course-description",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "",
    "text": "This 4-day satellite and ocean data training course will be held virtually during February 10-13 (FJT), 2026. It is co-hosted by CoastWatch/OceanWatch Central Pacific and the Pacific Islands Ocean Observing System (PacIOOS).\nClick here to Register.\nJoin course via googlemeet here",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#learning-outcomes",
    "href": "trainings/upcoming/pgrsc26.html#learning-outcomes",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nLearn where to find satellite, remote sensing, and ocean parameter data\nBecome familiar with the ERDDAP platform to visualize, subset, and download data\nLearn to judge which products are appropriate for your application or who to contact to get guidance\nApply what you learn on a personal project so that you leave the course with ready-to-use workflows",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#course-logistics",
    "href": "trainings/upcoming/pgrsc26.html#course-logistics",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Course Logistics",
    "text": "Course Logistics\nThis course will be conducted entirely online. Anyone is free to sign up for the course, although it is targeted at participants in the Pacific Islands region, and the live sessions are scheduled to align with their workday. At the start of each day (9:00 am FJT, 11:00 am HST), there will be a live session where we will preview the material participants should go over that day, discuss the previous day’s material, and answer any questions. Each day, there will be a live Q&A session (2:00-3:00 pm FJT, 4:00-5:00 pm HST) to answer any questions regarding the materials, exercises, or the project you are working on.\nParticipants should expect to spend about 1-2 hours/day in live sessions and at least 2-3 hours/day working on their own, going through the course material at their own pace, and working on their project. All of the course materials are available online, and participants will go through them at their own pace, but there is a suggested list of modules to cover for each day of the course. Instructors will be available during the week to help or answer questions. The last day will be a 2-3 hour student presentation day (see below).",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#project",
    "href": "trainings/upcoming/pgrsc26.html#project",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Project",
    "text": "Project\nAs part of the course, participants are expected to come with a specific project to work on during the class. Participants get more out of the workshop if they have specific questions or projects to work on. Everyone will give a short (1 slide, 2-minute MAX) lightning talk during the last class session. The project can be as simple as making a map or a time series for the region of interest, for those who are new to working with satellite data, or as complex as a participant feels comfortable with. Any ancillary data needed for projects should be available on hand.",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#course-structure",
    "href": "trainings/upcoming/pgrsc26.html#course-structure",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Course Structure",
    "text": "Course Structure\nThe Day 1 live session will include an introduction to the course and the instructors. This will be an opportunity for participants to introduce themselves and briefly describe their class project. On Days 2 and 3, during the live session, the instructors will review the previous day’s homework, preview the course activities for the self-study periods, and answer any questions that have come up. Guest lectures and tools demos may also be included. Participants work at their own schedule and pace to complete the course content and work on their individual projects. The first few days feature video tutorials on satellite data, example software tutorials, and homework exercises. As the class progresses, participants will use the self-study period to work on their individual projects.",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#schedule",
    "href": "trainings/upcoming/pgrsc26.html#schedule",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nDay (FJT)\nTime (FJT)\nTopic\nPresenter\n\n\n\n\nDay 1 - February 10\n9:00 AM (live session)\nIntroduction to NOAA CoastWatch & PacIOOS\nDaisy Shi & Lauren Kaiser\n\n\n\n\nTools & Resources (ERDDAP & Voyager)\nDaisy Shi & Lauren Kaiser\n\n\n\n11:00 AM (Self-Paced Work)\nModule 1: Satellite 101 (Part 1 & Part 2)\n\n\n\n\n\nModule 2: Tools & Strategies for your Project\n\n\n\n\n\nTutorial 1: ERDDAP Basics\n\n\n\n\n\nTutorial 2: PacIOOS Voyager User Tutorial\n\n\n\n\n\nOptional Tutorial: MATLAB, R, or Python\n\n\n\n\n\nProject Development 1: Make a map on the ERDDAP make-a-graph interface with a dataset from the CoastWatch Data Catalog. Practice downloading the data as a netCDF file using the download interface (i.e., select the nc file format in ERDDAP).\n\n\n\n\n\nProject Development 2: Review presentation guidelines and examples from previous courses\n\n\n\n\n2:00 PM\nQ & A Session\n\n\n\nDay 2 - February 11\n9:00 AM (live session)\nOcean Color Satellite Data Products and Application in the Fisheries\nRyan Vandermeulen\n\n\n\n\nUsing Satellite Data with GIS\nLauren Kaiser\n\n\n\n11:00 AM (Self-Paced Work)\nModule 1: Satellite Ocean Color\n\n\n\n\n\nModule 2: Satellite Water Quality\n\n\n\n\n\nModule 3: Harmful Algal Blooms (HABS, Part 1 & Part 2)\n\n\n\n\n\nModule 4: What Dataset(s) to Choose\n\n\n\n\n\nArcGIS Tutorial 1: ArcGIS Tools Tutorial\n\n\n\n\n\nArcGIS Tutorial 2: Ocean Color & Water Quality\n\n\n\n\n\nMATLAB, R, or Python Tutorials: Comparison of chlorophyll data from different sensors\n\n\n\n\n\nProject Development 1: Identify which datasets are best suited for your application from OceanWatch Central Pacific, CoastWatch Search Tool, PacIOOS ERDDAP, and PacIOOS Search Tool.\n\n\n\n\n\nProject Development 2: Find the data on ERDDAP. Think about what date range and spatial resolution you need, and which time composite you decided to use (daily, weekly, or monthly). You should be able to explain why you chose the specific product.\n\n\n\n\n\nProject Development 3: Download data needed for your project and create a plot (map, time-series, etc.)\n\n\n\n\n2:00 PM\nQ & A Session\n\n\n\nDay 3 - February 12\n9:00 AM (live session)\nSea Surface Temperature Satellite Data and Applications in Coastal Regions\nKisei Tanaka\n\n\n\n\nData Demo\nLauren Kaiser\n\n\n\n11:00 AM (Self-Paced Work)\nModule 1: Satellite Sea Surface Temperature\n\n\n\n\n\nModule 2: Satellite Salinity, Wind, and Altimetry\n\n\n\n\n\nModule 3: Synthetic Aperture Radar (SAR)\n\n\n\n\n\nArcGIS Tutorial: Tracking Turtles & Temperature\n\n\n\n\n\nMATLAB, R, or Python Tutorial: Match satellite data to track locations\n\n\n\n\n\nProject Development 1: Create a slide. Include your name, affiliation, a short description of your project, one or two images (map, time series, histogram, cute picture) that you were able to make in relation to your project, what specific satellite product(s) and software you used\n\n\n\n\n\nProject Development 2: Optional: you can include cool picture(s) of animals or technology related to your project. If applicable: also include challenges, data products that you wish were available (satellite-related), needs unmet by current data/services offerings.\n\n\n\n\n\nProject Development 3: Upload your final slide(s) to the 2026 Paticipant Presentation folder.\n\n\n\n\n2:00 PM\nQ & A Session\n\n\n\nDay 4 - February 13\n9:00 AM (live session)\nParticipant Presentations (2-minute presentation on your slide(s) )\n\n\n\n\n\nCourse Feedback",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#contacts",
    "href": "trainings/upcoming/pgrsc26.html#contacts",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Contacts",
    "text": "Contacts\n\n\n\nName\nAffiliation\n\n\n\n\nDaisy Shi\nCoastWatch/Pacific OceanWatch, Operations Manager\n\n\nLauren Kaiser\nPacIOOS, Data Management Specialist\n\n\nRyan Vandermeulen\nNOAA Fisheries Satellite Coordinator\n\n\nKisei Tanaka\nNOAA PIFSC, Research Marine Biologist\n\n\nCara Wilson\nCoastWatch/West Coast Node, PI",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/pgrsc26.html#resources",
    "href": "trainings/upcoming/pgrsc26.html#resources",
    "title": "NOAA CoastWatch/PacIOOS Satellite and Ocean Data Training Course",
    "section": "Resources",
    "text": "Resources\n\nNOAA CoastWatch Website\nCoastWatch Training Lectures & Tutorials (on YouTube)\n\nLectures\nTutorials\n\nCoastwatch Tutorials (on GitHub)\nPacIOOS",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 PGRSC Course"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html",
    "href": "trainings/past/pgrsc24.html",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using information tools from PacIOOS for applications in the Pacific Islands region. This training will be held during the 2024 Pacific Islands GIS and Remote Sensing Users Conference in Suva, Fiji.\nClick here to Register.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html#course-description",
    "href": "trainings/past/pgrsc24.html#course-description",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using information tools from PacIOOS for applications in the Pacific Islands region. This training will be held during the 2024 Pacific Islands GIS and Remote Sensing Users Conference in Suva, Fiji.\nClick here to Register.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html#instructors",
    "href": "trainings/past/pgrsc24.html#instructors",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "Instructors",
    "text": "Instructors\n\n\n\nName\nAffiliation\n\n\n\n\nDaisy Shi\nCoastWatch/Pacific OceanWatch, node manager\n\n\nLauren Kaiser\nPacIOOS, data management specialist\n\n\nCara Wilson\nCoastWatch/West Coast Node, PI",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html#objectives",
    "href": "trainings/past/pgrsc24.html#objectives",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the basic types of products available from satellite data\nDemonstrate how to access data on ERDDAP servers\nIntroduce CoastWatch satellite data and training resources\nExplore additional data and information tools available at PacIOOS\nProvide hands-on time to access data and run tutorials",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html#schedule",
    "href": "trainings/past/pgrsc24.html#schedule",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime (Fiji Standard Time)\nTopic\nPresenter\n\n\n\n\n1:00 - 1:10\nWelcome & Introductions\nDaisy Shi & Lauren Kaiser\n\n\n1:10 - 1:20\nInteractive Questions\n\n\n\n1:20 - 1:35\nIntro to CoastWatch, Satellite Datasets & Data Portal\nDaisy Shi\n\n\n1:35 - 1:50\nIntro to OceanWatch, Data Accessibility & Usability\nDaisy Shi\n\n\n1:50 - 2:20\nIntro to PacIOOS, Website Walkthrough & Data Search\nLauren Kaiser\n\n\n2:20 - 2:30\nInteractive Questions\n\n\n\n2:30 - 2:45\nBreak\n\n\n\n2:45 - 2:55\nOverview of CoastWatch Tutorials\nDaisy Shi\n\n\n2:55 - 3:15\nERDDAP Demos\nDaisy Shi\n\n\n3:15 - 3:45\nArcGIS & QGIS Demos\nLauren Kaiser\n\n\n3:45 - 4:00\nBreak\n\n\n\n4:00 - 5:50\nHands-On time\nAll\n\n\n5:50 - 6:00\nInteractive Questions & Feedback",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/pgrsc24.html#resources",
    "href": "trainings/past/pgrsc24.html#resources",
    "title": "Access and Use Satellite Data and Decision-making tools for Ocean and Coastal Applications",
    "section": "Resources",
    "text": "Resources\n\nCoastwatch Tutorials (on GitHub)\nCoastwatch Lecture series\nGeostationary satellites covering Western Pacific\nPacIOOS\nPacIOOS Voyager",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 PGRSC Workshop"
    ]
  },
  {
    "objectID": "trainings/past/longislandsound25.html",
    "href": "trainings/past/longislandsound25.html",
    "title": "2025 Long Island Sound Class",
    "section": "",
    "text": "Virtual - Times vary daily, see schedule below (times are Eastern).\nNOAA CoastWatch is hosting this free, virtual training class:  Viewing and Analyzing Ocean/Coastal Events and Water Quality Using Satellites\nJoin Class Via Zoom Here",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Long Island Sound"
    ]
  },
  {
    "objectID": "trainings/past/longislandsound25.html#course-description",
    "href": "trainings/past/longislandsound25.html#course-description",
    "title": "2025 Long Island Sound Class",
    "section": "Course Description",
    "text": "Course Description\nMany satellite products are available for water quality applications and other uses from NOAA and other data providers. These include: chlorophyll, turbidity, sea surface temperature, organic matter, and more. In this course, learn how to use these satellite products for your region of interest using freely available tools. Address your needs and questions by creating maps and images, plotting a time series of varying conditions, or creating a virtual buoy for your study location. And other applications too!\nThis class is being offered in two Tiers as part of a larger Long Island Sound Project funded by New York/Connecticut Sea Grant.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Long Island Sound"
    ]
  },
  {
    "objectID": "trainings/past/longislandsound25.html#objectives",
    "href": "trainings/past/longislandsound25.html#objectives",
    "title": "2025 Long Island Sound Class",
    "section": "Objectives",
    "text": "Objectives\n\nTier I: Creating Images\nLearn to use tools to create images and maps of ocean or coastal features in your area of interest. Tools taught: CoastWatch Data Portal, ArcGIS, ERDDAP visualization server, and more.\n\n\nTier II: Analyzing Data for Your Study or Region\nWork more analytically with oceanographic satellite data. Learn R and/or Python techniques to access data on ERDDAP data servers for data extraction, map creation, time series analysis, matching data to your study site locations or ship tracks, creating a virtual buoy using satellite data in your location of choice, and other application skills.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Long Island Sound"
    ]
  },
  {
    "objectID": "trainings/past/longislandsound25.html#schedule",
    "href": "trainings/past/longislandsound25.html#schedule",
    "title": "2025 Long Island Sound Class",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nDay\nTime (ET)\nTopic\nPresenter\n\n\n\n\nMonday - March 31\n\nTier I and Tier II\n\n\n\n\n9:00 - 9:15\nPresentation 1: Overview – SeaGrant-funded Satellite Project\nJonathan Sherman\n\n\n\n9:15 - 9:45\nPresentation 2: Data Portal\nMichael Soracco\n\n\n\n9:45 - 10:15\nPresentation 3: ArcGIS\nMichael Soracco\n\n\n\n10:15 - 10:30\nBreak\n\n\n\n\n10:30 - 11:15\nPresentation 4: CoastWatch Utilities - CDAT  Files\nRon Vogel\n\n\n\n11:15 - 11:30\nQ & A\n\n\n\n\n11:30 - 12:15\nParticipant Exercise 1: Choose a tool and make a map  ArcGIS files, CDAT files\n\n\n\n\n12:15 - 1:15\nLunch break\n\n\n\n\n1:15 - 1:45\nPresentation 5: Choosing a Dataset\nJonathan Sherman\n\n\n\n1:45 - 2:45\nPresentation 6: ERDDAP\nRon Vogel\n\n\n\n2:45 - 3:00\nBreak\n\n\n\n\n3:00 - 3:30\nQ & A and Resources for Participants\n\n\n\n\n3:30 - 4:30\nParticipant Exercise 2: Choose a dataset from ERDDAP, download, make a map and a time series  Sample data list\n\n\n\nTuesday - April 1\n\nTier II (April 1–4)\n\n\n\n\n9:00 - 9:30\nPresentation 7: Satellite 101\nShelly Tomlinson\n\n\n\n9:30 - 10:30\nPresentation 8: CoastWatch Training Code (R and Python) – Capabilities and Tutorials  Tutorials GitHub page\nJonathan Sherman\n\n\n\n10:30 - 10:45\nBreak\n\n\n\n\n10:45 - 11:30\nPresentation 9: CoastWatch Utilities - Command Line  Files\nRon Vogel\n\n\n\n11:30 - 12:00\nOffice Hours Logistics, Mini-project & Slide Info, Q & A\n\n\n\n\n12:00 - 1:00\nLunch\n\n\n\n\n1:00 - 4:00\nOffice Hours: One-on-One\n\n\n\nWednesday - April 2\n\nParticipants work on their mini-project on their own time\n\n\n\nThursday - April 3\n9:00 - 9:15\nGauge Progress Poll\nBetty Staugler\n\n\n\n9:15 - 9:30\nPresentation 10: HAB Forecasts\nShelly Tomlinson\n\n\n\n9:30 - 9:45\nPresentation 11: COVID Impacts\nJonathan Sherman\n\n\n\n9:45 - 10:00\nPresentation 12: Participant Slide Examples from Past Classes\nRon Vogel\n\n\n\n10:00 - 12:00\nOffice Hours: Group Discussion or One-on-One\n\n\n\n\n12:00 - 1:00\nLunch\n\n\n\n\n1:00 - 4:00\nParticipants work on their mini-project on their own time\n\n\n\nFriday - April 4\n1:00 - 3:00\nFinal Mini-project Presentations (1 slide each)\nParticipants",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Long Island Sound"
    ]
  },
  {
    "objectID": "trainings/past/longislandsound25.html#resources",
    "href": "trainings/past/longislandsound25.html#resources",
    "title": "2025 Long Island Sound Class",
    "section": "Resources",
    "text": "Resources\n\nCoastWatch main website\nCoastWatch East Coast Regional Node website\nCoastWatch Data Access methods\nCoastwatch Coding Tutorials: R and Python (on GitHub)\nCoastwatch Lecture series\nCoastwatch Data Portal video tutorials\nCoastwatch ArcGIS lecture videos and tutorials\nCoastWatch Utilities\n\nCoastWatch Utilities Tutorials - CDAT and Command-Line\nCDAT demo videos on YouTube\n\nCoastWatch Help Desk\n\nEmail: coastwatch.info@noaa.gov\nPhone: +1-301-683-3335\nUser Forums",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Long Island Sound"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html",
    "href": "trainings/past/afs24.html",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using the Animal Telemetry Network Portal. This training was originally going to be held before the annual AFS (American Fisheries Society) meeting in Honolulu, Hawaii, but has been rescheduled to be an online course, open to all.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html#course-description",
    "href": "trainings/past/afs24.html#course-description",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using the Animal Telemetry Network Portal. This training was originally going to be held before the annual AFS (American Fisheries Society) meeting in Honolulu, Hawaii, but has been rescheduled to be an online course, open to all.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html#instructors",
    "href": "trainings/past/afs24.html#instructors",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Instructors",
    "text": "Instructors\n\n\n\nName\nAffiliation\n\n\n\n\nCara Wilson\nCoastWatch/West Coast Node, PI\n\n\nDale Robinson\nCoastWatch/West Coast Node, node manager\n\n\nMegan McKinzie\nATN Data Coordinator\n\n\nDaisy Shi\nCoastWatch/Pacific OceanWatch, node manager",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html#objectives",
    "href": "trainings/past/afs24.html#objectives",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the basic types of products available from satellite data\nDemonstate how to access data on ERDDAP servers\nExplore the data available on the Animal Telemetry Network portal\nIntroduce CoastWatch satellite data training resources\nProvide hands-on time to access data and try tutorials",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html#schedule",
    "href": "trainings/past/afs24.html#schedule",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n10:00 - 10:15\nTraining Overview - CoastWatch, ATN and the workshop component\nCara Wilson\n\n\n10:15 - 10:30\nGroup Introductions\nCara Wilson\n\n\n10:30 - 11:15\nCoastwatch satellite datasets and data portals\nCara Wilson\n\n\n11:15 - 11:30\nBreak\n\n\n\n11:30 - 12:00\nUsing the ERDDAP data server\nCara Wilson\n\n\n12:00 - 12:30\nAccessing ERDDAP using scripts (R, python)\nCara Wilson\n\n\n12:30 - 1:30\nLunch break\n\n\n\n1:30 - 2:00\nIntro to ATN and the DAC\nMegan McKinzie\n\n\n2:00 - 2:30\nDemo of ATN data portal\nMegan McKinzie\n\n\n2:30 - 3:00\nAccessing public ATN datasets\nMegan McKinzie\n\n\n3:00 - 3:15\nBreak\n\n\n\n3:15 - 3:30\nWorkshop, part 1: Linking CoastWatch and ATN data using scripts\nDaisy Shi\n\n\n3:30 - 4:45\nWorkshop, part 2: Hand’s on time\n\n\n\n4:45 - 5:00\nWrap up and final discussion\nAll",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "trainings/past/afs24.html#resources",
    "href": "trainings/past/afs24.html#resources",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Resources",
    "text": "Resources\n\nCoastwatch Tutorials (on GitHub)\nCoastwatch Lecture series\nAnimal telemetry Network",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 AFS Workshop"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CoastWatch Training Tutorials",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "trainings/past/icft25.html",
    "href": "trainings/past/icft25.html",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using the Animal Telemetry Network Portal. This training was originally going to be held before the annual ICFT (International Conference on Fish Telemetry) meeting in Traverse City, Michigan, but has been rescheduled to be an online course, open to all.\nLink to registration page",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/past/icft25.html#course-description",
    "href": "trainings/past/icft25.html#course-description",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "",
    "text": "Training on accessing Oceanographic Satellite Data from NOAA CoastWatch and using the Animal Telemetry Network Portal. This training was originally going to be held before the annual ICFT (International Conference on Fish Telemetry) meeting in Traverse City, Michigan, but has been rescheduled to be an online course, open to all.\nLink to registration page",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/past/icft25.html#instructors",
    "href": "trainings/past/icft25.html#instructors",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Instructors",
    "text": "Instructors\n\n\n\nName\nAffiliation\n\n\n\n\nCara Wilson\nCoastWatch/West Coast Node, PI\n\n\nDale Robinson\nCoastWatch/West Coast Node, node manager\n\n\nMegan McKinzie\nATN Data manager\n\n\nDaisy Shi\nCoastWatch/Pacific OceanWatch, node manager",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/past/icft25.html#objectives",
    "href": "trainings/past/icft25.html#objectives",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the basic types of products available from satellite data\nDemonstate how to access data on ERDDAP servers\nExplore the data available on the Animal Telemetry Network portal\nIntroduce CoastWatch satellite data training resources\nProvide hands-on time to access data and try tutorials",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/past/icft25.html#schedule",
    "href": "trainings/past/icft25.html#schedule",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Schedule",
    "text": "Schedule\nThursday, August 14, 2025\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n10:00 - 10:15\nTraining Overview - CoastWatch, ATN and the workshop component\nCara Wilson\n\n\n10:15 - 11:30\nCoastwatch satellite datasets and data portals\nCara Wilson\n\n\n11:30 - 11:45\nBreak\n\n\n\n11:45 - 12:15\nUsing the ERDDAP data server\nCara Wilson\n\n\n12:15 - 12:45\nAccessing ERDDAP using scripts (R, python)\nCara Wilson\n\n\n12:45 - 1:00\nDay 1 wrap-up\n\n\n\n\nFriday, August 15, 2025\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n10:00 - 10:30\nIntro to ATN and the DAC\nMegan McKinzie\n\n\n10:30 - 11:00\nDemo of ATN data portal\nMegan McKinzie\n\n\n11:00 - 11:30\nAccessing public ATN datasets\nMegan McKinzie\n\n\n11:30 - 11:45\nBreak\n\n\n\n11:45 - 12:00\nWorkshop, part 1: Linking CoastWatch and ATN data using scripts\nDaisy Shi\n\n\n12:00 - 12:45\nWorkshop, part 2: Hand’s on time\n\n\n\n12:45 - 13:00\nWrap up and final discussion\nAll",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/past/icft25.html#resources",
    "href": "trainings/past/icft25.html#resources",
    "title": "Satellite and Animal Telemetry Data Training",
    "section": "Resources",
    "text": "Resources\n\nCoastwatch Tutorials (on GitHub)\nCoastwatch Lecture series\nAnimal telemetry Network",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2025 Satellite and Animal Telemetry"
    ]
  },
  {
    "objectID": "trainings/past/officehours.html",
    "href": "trainings/past/officehours.html",
    "title": "CoastWatch Office Hours",
    "section": "",
    "text": "Hosted by the West Coast Node and PolarWatch\nevery other Thursday at 11 am PST\nUpcoming dates: Dec 4, 18\nEveryone is welcome to come to the CoastWatch Office Hour where people can:\n\nAsk questions about satellite data\nRequest help with accessing satellite data products\nGet troubleshooting assistance with code examples for discovering, accessing and working with satellite data\n\nCoastWatch Lectures\nCoastWatch Tutorials"
  },
  {
    "objectID": "trainings/past/seaice24.html",
    "href": "trainings/past/seaice24.html",
    "title": "2024 PolarWatch Sea Ice Training",
    "section": "",
    "text": "PolarWatch node of the CoastWatch is hosting a free, virtual training class on October 21, 2024 (9am-4pm Pacific Time).",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 Sea Ice Data Course"
    ]
  },
  {
    "objectID": "trainings/past/seaice24.html#course-description",
    "href": "trainings/past/seaice24.html#course-description",
    "title": "2024 PolarWatch Sea Ice Training",
    "section": "Course Description",
    "text": "Course Description\nMany satellite sea ice products are available for download from NOAA and many other data providers: e.g. sea ice concentration, sea ice thickness, sea ice age, sea ice temperature, and sea ice extent. It can often be challenging to know the differences between the products and how each can be applied to a user’s specific application. For example, the spatial resolutions of the products can vary widely, largely dependent on the type of satellite measurement the product is derived from (passive microwave, visible radiometry or synthetic aperture radar). Additionally, when working with data in the high-latitudes issues of data projection invariably arise and can complicate accessing and working with data. To address these issues, NOAA’s PolarWatch node has developed a 1-day (6 hour) online course with the following training objectives.",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 Sea Ice Data Course"
    ]
  },
  {
    "objectID": "trainings/past/seaice24.html#objectives",
    "href": "trainings/past/seaice24.html#objectives",
    "title": "2024 PolarWatch Sea Ice Training",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the basic types of sea-ice products available from satellite data\nGive an overview of working with different projections\nExplore the data available on the PolarWatch portal\nProvide hands-on time to access data and try tutorials\nIntroduce CoastWatch and other sea ice satellite data training resources",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 Sea Ice Data Course"
    ]
  },
  {
    "objectID": "trainings/past/seaice24.html#schedule",
    "href": "trainings/past/seaice24.html#schedule",
    "title": "2024 PolarWatch Sea Ice Training",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n9:00 - 9:30\nPresentation 1: Introduction to NOAA CoastWatch\nCara Wilson\n\n\n9:30 - 10:00\nPresentation 2: Overview of Sea Ice Remote Sensing\nLudovic Brucker\n\n\n10:00 - 10:30\nPresentation 3: JPSS Sea Ice Microlesson\nKevin Fuell\n\n\n10:30 - 10:45\nBreak\n\n\n\n10:45 - 11:15\nPresentation 4: Sea Ice from SAR\nChris Jackson\n\n\n11:15 - 11:30\nPresentation 5: Projections - Why they Matter\nMichael Soracco\n\n\n11:30 - 11:45\nPresentation 6: Ice in the Great Lakes\nAndrea VanderWoude\n\n\n11:45 - 12:45\nLunch break\n\n\n\n12:45 - 13:00\nPresentation 7: Projections in Action (Watch Video)\nPeter Hollemans\n\n\n13:00 - 13:30\nPresentation 8: ERDDAP Demo\nCara Wilson\n\n\n13:30 - 13:45\nPresentation 9: PolarWatch Portal Demo\nSunny Hospital\n\n\n13:45 - 14:00\nPresentation 10: CoastWatch Viewer Demo\nMichael Soracco\n\n\n14:00 - 14:15\nBreak\n\n\n\n14:15 - 14:30\nPresentation 11: Overview of Tutorials\nCara Wilson, Matthew Smith\n\n\n14:30 - 16:00\nHand’s on time, with instuctor’s guidance available",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 Sea Ice Data Course"
    ]
  },
  {
    "objectID": "trainings/past/seaice24.html#resources",
    "href": "trainings/past/seaice24.html#resources",
    "title": "2024 PolarWatch Sea Ice Training",
    "section": "Resources",
    "text": "Resources\n\nCoastwatch Tutorials (on GitHub)\nCoastwatch Lecture series\nJPSS Sea Ice Microlesson",
    "crumbs": [
      "Training Classes",
      "Past Trainings",
      "2024 Sea Ice Data Course"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html",
    "href": "trainings/upcoming/sat201_26.html",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "",
    "text": "This lecture series provides a deeper dive into satellite oceanography, exploring advanced topics beyond the regular CoastWatch satellite course. Link to registration page",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#course-description",
    "href": "trainings/upcoming/sat201_26.html#course-description",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "",
    "text": "This lecture series provides a deeper dive into satellite oceanography, exploring advanced topics beyond the regular CoastWatch satellite course. Link to registration page",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#schedule-attendance",
    "href": "trainings/upcoming/sat201_26.html#schedule-attendance",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "Schedule & Attendance",
    "text": "Schedule & Attendance\nFrequency: Sessions are held every Friday for one month.\nDuration: Approximately 2.5 hours per session.\nFlexibility: Attendance for all sessions is not required; feel free to join the topics most relevant to you.",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#curriculum",
    "href": "trainings/upcoming/sat201_26.html#curriculum",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "2026 Curriculum",
    "text": "2026 Curriculum\nThe inaugural 2026 course will cover the following subjects: * Alternative Data Access: Methods for accessing data not hosted on ERDDAP servers. * CoastWatch Utilities: An introduction to using the CoastWatch proprietary software suite. * Beyond Chlorophyll: Exploring ocean color products other than chlorophyll. * SAR Data: An introduction to Synthetic Aperture Radar.",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#schedule",
    "href": "trainings/upcoming/sat201_26.html#schedule",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "Schedule",
    "text": "Schedule\nFriday, July 10, 2026\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n11:00 - 11:45\nAccessing data not on ERDDAP servers\nDale Robinson\n\n\n11:45 - 12:30\na demo\n\n\n\n12:30 - 12:45\nBreak\n\n\n\n12:45 - 1:30\nQuestion & Answer and hand’s on session\n\n\n\n\nFriday, July 17, 2026\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n11:00 - 11:45\nIntroduction to using Coastwatch Utilities software\nPeter Hollemans\n\n\n11:45 - 12:30\na demo\n\n\n\n12:30 - 12:45\nBreak\n\n\n\n12:45 - 1:30\nQuestion & Answer and hand’s on session\n\n\n\n\nFriday, July 24, 2026 | Time (PST) | Topic | Presenter | |:————-|:—————————————————————————–|:—————————-| | 11:00 - 11:45 | Beyond Chlorophyll | Ryan Vandermeulan | | 11:45 - 12:30 | Beyond Chlorophyll Case Study | | | 12:30 - 12:45 | Break | |\n| 12:45 - 1:30 | Question & Answer and hand’s on session | |\nFriday, July 31, 2026\n\n\n\nTime (PST)\nTopic\nPresenter\n\n\n\n\n11:00 - 11:45\nIntroduction to SAR Data\n\n\n\n11:45 - 12:30\nSAR Case Study\n\n\n\n12:30 - 12:45\nBreak\n\n\n\n12:45 - 1:30\nQuestion & Answer and hand’s on session",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#instructors",
    "href": "trainings/upcoming/sat201_26.html#instructors",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "Instructors",
    "text": "Instructors\n\n\n\nName\nAffiliation\n\n\n\n\nCara Wilson\nCoastWatch/West Coast Node, PI\n\n\nDale Robinson\nCoastWatch/West Coast Node, node manager\n\n\nPeter Hollemans\nCoastWatch/Pacific OceanWatch, node manager",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "trainings/upcoming/sat201_26.html#resources",
    "href": "trainings/upcoming/sat201_26.html#resources",
    "title": "Satellite 201 Summer Lecture Series",
    "section": "Resources",
    "text": "Resources\n\nCoastwatch Tutorials (on GitHub)\nCoastwatch Lecture series",
    "crumbs": [
      "Training Classes",
      "Upcoming Trainings",
      "2026 Satellite 201 Summer Series"
    ]
  },
  {
    "objectID": "tutorials/matlab/Tutorial1-basics.html",
    "href": "tutorials/matlab/Tutorial1-basics.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands. Note: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset monthly SST data: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.html Select your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nerddap interface\n\n\nIn this specific example, the URL we generated is: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.nc?sea_surface_temperature%5B(2018-1-31T12:00:00Z):1:(2018-12-31T12:00:00Z)%5D%5B(17):1:(30)%5D%5B(195):1:(210)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly'); \nNotice that the full data set has four variables: time, latitude, longitude, and sea_surface_temperature. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\nTime Notice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'time');\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the year we’re interested in: 2018.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2018);\nLatitude and Longitude Before we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'longitude');\nNotice in the output above that sea_surface_temperature has the dimensions of longitude x latitude x time which means it has a size of 7200 x 3600 x 444. In the code below, we’ll create indices for our particular area of interest in the central North Pacific.\n% Find longitudes from 195 - 210 E\nlon_aoi = find(lon_full &gt;= 195 & lon_full &lt;= 210);\n\n% Find latitudes from 17 - 30 N\nlat_aoi = find(lat_full &gt;= 17 & lat_full &lt;= 30);\nSea Surface Temperature Now, we’ll access just the small amount of sea_surface_temperature data we’re interested in. We’ll do this by telling the computer to access the variable ‘sea_surface_temperature’, beginning at a specific location and time, and spanning our area and time of interest.\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', ...\n    'sea_surface_temperature', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 300 x 260 x 12. Before we see what these data look like, let’s create indices for the area and timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* % Delete every variable with 'aoi' or with 'full' in its name\n\n\n\nLet’s create a map for a single month, January 2018, the first month in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 100, 'fill', 'on');\ntitle(sprintf('Monthly SST %s', datestr(time_ymdhms(1,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(26,4), 202:1:205, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 20\ncontourm(lat, lon, sst(:,:,1)', [20 20], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\nJanuary SST\n\n\n\n\n\nLet’s pick the following box: 24-26N, 200-206E. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above to identify a subsetted area of interest.\n% Find longitudes from 200 - 206 E\nlon_aoi = find(lon &gt;= 200 & lon &lt;= 206);\n\n% Find latitudes from 24 - 26 N\nlat_aoi = find(lat &gt;= 24 & lat &lt;= 26);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 12 months\nsst_ts(1:12,1) = NaN;\nfor m = 1:1:12 \n    sst_ts(m,1) = mean(sst_subset(:,:,m), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,2), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\n\n\n\nSST time series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n\n% Average over time, which is the third dimention of our data\nsst_yr = mean(sst, 3, \"omitnan\");\n\n% Plot\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_yr', 100, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(12,:),'mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nJan mean sst"
  },
  {
    "objectID": "tutorials/matlab/Tutorial1-basics.html#tutorial-1.-how-to-work-with-satellite-data-in-matlab",
    "href": "tutorials/matlab/Tutorial1-basics.html#tutorial-1.-how-to-work-with-satellite-data-in-matlab",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands. Note: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset monthly SST data: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.html Select your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nerddap interface\n\n\nIn this specific example, the URL we generated is: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly.nc?sea_surface_temperature%5B(2018-1-31T12:00:00Z):1:(2018-12-31T12:00:00Z)%5D%5B(17):1:(30)%5D%5B(195):1:(210)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n\n% View data attributes and variables\nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly'); \nNotice that the full data set has four variables: time, latitude, longitude, and sea_surface_temperature. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\nTime Notice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'time');\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the year we’re interested in: 2018.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2018);\nLatitude and Longitude Before we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', 'longitude');\nNotice in the output above that sea_surface_temperature has the dimensions of longitude x latitude x time which means it has a size of 7200 x 3600 x 444. In the code below, we’ll create indices for our particular area of interest in the central North Pacific.\n% Find longitudes from 195 - 210 E\nlon_aoi = find(lon_full &gt;= 195 & lon_full &lt;= 210);\n\n% Find latitudes from 17 - 30 N\nlat_aoi = find(lat_full &gt;= 17 & lat_full &lt;= 30);\nSea Surface Temperature Now, we’ll access just the small amount of sea_surface_temperature data we’re interested in. We’ll do this by telling the computer to access the variable ‘sea_surface_temperature’, beginning at a specific location and time, and spanning our area and time of interest.\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1_monthly', ...\n    'sea_surface_temperature', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 300 x 260 x 12. Before we see what these data look like, let’s create indices for the area and timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* % Delete every variable with 'aoi' or with 'full' in its name\n\n\n\nLet’s create a map for a single month, January 2018, the first month in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 100, 'fill', 'on');\ntitle(sprintf('Monthly SST %s', datestr(time_ymdhms(1,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(26,4), 202:1:205, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 20\ncontourm(lat, lon, sst(:,:,1)', [20 20], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\nJanuary SST\n\n\n\n\n\nLet’s pick the following box: 24-26N, 200-206E. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above to identify a subsetted area of interest.\n% Find longitudes from 200 - 206 E\nlon_aoi = find(lon &gt;= 200 & lon &lt;= 206);\n\n% Find latitudes from 24 - 26 N\nlat_aoi = find(lat &gt;= 24 & lat &lt;= 26);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 12 months\nsst_ts(1:12,1) = NaN;\nfor m = 1:1:12 \n    sst_ts(m,1) = mean(sst_subset(:,:,m), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,2), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\n\n\n\nSST time series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n\n% Average over time, which is the third dimention of our data\nsst_yr = mean(sst, 3, \"omitnan\");\n\n% Plot\nfigure\naxesm('mercator', 'MapLatLimit', [17 30], 'MapLonLimit', [195 210], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -164:2:-150, 'PLabelLocation', 18:2:30, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_yr', 100, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(12,:),'mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(100));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nJan mean sst"
  },
  {
    "objectID": "tutorials/matlab/extract-satellite-data-within-boundary.html",
    "href": "tutorials/matlab/extract-satellite-data-within-boundary.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial uses the Xtractomatic package to download data from within the boundaries of the Papahanaumokuakea Marine National Monument (PMNM).\nThis tutorial will teach you how to extract and display SST values for a particular time period or average SST over the whole time-series available within a shapefile.\nThe shapefile for the PMNM boundaries can be downloaded here: http://sanctuaries.noaa.gov/library/imast_gis.html. Save the file https://sanctuaries.noaa.gov/library/imast/pmnm_py.zip on your computer and extract it. It would be easiest for the purposes of this tutorial if you place the pmnm_py folder in the directory you’re working in. But, if you want to keep it elsewhere, you’ll just need to edit the path name accordingly.\n\n\nWe’ll do this in two steps. First, we’ll download the satellite data for a footprint that’s slightly larger than our area of interest. Then, we’ll clip these data to only those which fall within the Monument.\n\n\n% As always, it's helpful it take a look at what we're working with: \nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN');\n```matlab\n\n\nWe can see in the information above that longitude is in the 0 - 360 degree format.  And we know from reading the ReadMe file for the monument boundaries that the shapefile longitude is in the -180 - 180 degree format.  This means we need convert the shapefile longitudes to a 0 - 360 format for indexing puposes (the native format will plot just fine). \n\n```matlab\n% Access the Lat and Lon coordinates\nPMNM = shaperead('pmnm_py/PMNM_py_files/PMNM_py.shp','UseGeoCoords',true);\n\n% Convert negative longitudes to positive values\nneg_lon = find(PMNM.Lon &lt; 0);\nPMNM.Lon(neg_lon) = PMNM.Lon(neg_lon) + 360;\nclear neg_lon\n\n% Find the minimum and maximum lat and lon values, for using to download\n% SST data\n[Lon_min, Lon_max] = bounds(PMNM.Lon);\n[Lat_min, Lat_max] = bounds(PMNM.Lat);\n\n% Now we can follow the steps we used in the earlier tutorials to download\n% the SST data\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n   'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \n\n% In this particular example, we're interested in March - November 2015\ntime_aoi = find(time_full_ymdhms(:,1) == 2015 & time_full_ymdhms(:,2) &gt;= 3 & ...\n    time_full_ymdhms(:,2) &lt;= 11);\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'longitude');\n\n% Find longitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlon_aoi = find(lon_full &gt;= floor(Lon_min) & lon_full &lt;= ceil(Lon_max));\n% Find latitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlat_aoi = find(lat_full &gt;= floor(Lat_min) & lat_full &lt;= ceil(Lat_max));\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\n\n% Download the data of interest\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'analysed_sst', aoi_start, aoi_span);\n\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* *min *max\n\n\n\nNow we have everything we need to clip the SST data to just those within the boundaries of the Monument. The code below borrows from the no-longer-supported xtractoMatlab: https://github.com/rmendels/xtractoMatlab. You can learn about other avenues to use this tool at: https://coastwatch.pfeg.noaa.gov/xtracto/.\n% The general premise here is that we're going to create a mesh grid of our\n% full domain (what we downloaded), identify all the points that are within\n% or on the polygon that defines the Monument, and set to NaN those that\n% are not.\n% Make the meshgrid and the mask\n[XLON, XLAT] = meshgrid(lon, lat);\n[IN ON] = inpolygon(XLON, XLAT, PMNM.Lon, PMNM.Lat);\nmask2D = IN | ON;\n\n% Replicate it over the number of time steps, which is the third dimension\n% of our sst variable\nmask3D = permute(repmat(mask2D,[1 1 size(sst,3)]),[2 1 3]);\n\n% Set to NaN all points not within the polygon\nsst(~mask3D) = NaN;\n\n\n\n\nThe extracted data contains several time steps (months) of sst data in the monument boundaries. Let’s make a plot of the second time step. Also, we can see above where we used ‘ncdisp’, that the units for these data are Kelvin. Let’s changes this to degrees Celsius when we make our map.\nfigure\naxesm('mercator', 'MapLatLimit', [18 32], 'MapLonLimit', [177 207], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -180:5:-155, 'PLabelLocation', 20:5:30, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Plot SST for the second time step, in degrees C, with 50 contour levels\ncontourm(lat, lon, sst(:,:,2)'-273.15, 50, 'fill', 'on'); \n\n% Title the map\ntitle(sprintf('SST %s', datestr(time_ymdhms(2,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 50 levels\ncolormap(jet(50));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\nOn your own! Plot the average SST for the period we downloaded. Here’s a hint to get you started:\nsst_avg = mean(sst, 3, \"omitnan\");\n\n\n\nSST"
  },
  {
    "objectID": "tutorials/matlab/extract-satellite-data-within-boundary.html#extract-data-within-a-shapefile-using-erddap",
    "href": "tutorials/matlab/extract-satellite-data-within-boundary.html#extract-data-within-a-shapefile-using-erddap",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial uses the Xtractomatic package to download data from within the boundaries of the Papahanaumokuakea Marine National Monument (PMNM).\nThis tutorial will teach you how to extract and display SST values for a particular time period or average SST over the whole time-series available within a shapefile.\nThe shapefile for the PMNM boundaries can be downloaded here: http://sanctuaries.noaa.gov/library/imast_gis.html. Save the file https://sanctuaries.noaa.gov/library/imast/pmnm_py.zip on your computer and extract it. It would be easiest for the purposes of this tutorial if you place the pmnm_py folder in the directory you’re working in. But, if you want to keep it elsewhere, you’ll just need to edit the path name accordingly.\n\n\nWe’ll do this in two steps. First, we’ll download the satellite data for a footprint that’s slightly larger than our area of interest. Then, we’ll clip these data to only those which fall within the Monument.\n\n\n% As always, it's helpful it take a look at what we're working with: \nncdisp('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN');\n```matlab\n\n\nWe can see in the information above that longitude is in the 0 - 360 degree format.  And we know from reading the ReadMe file for the monument boundaries that the shapefile longitude is in the -180 - 180 degree format.  This means we need convert the shapefile longitudes to a 0 - 360 format for indexing puposes (the native format will plot just fine). \n\n```matlab\n% Access the Lat and Lon coordinates\nPMNM = shaperead('pmnm_py/PMNM_py_files/PMNM_py.shp','UseGeoCoords',true);\n\n% Convert negative longitudes to positive values\nneg_lon = find(PMNM.Lon &lt; 0);\nPMNM.Lon(neg_lon) = PMNM.Lon(neg_lon) + 360;\nclear neg_lon\n\n% Find the minimum and maximum lat and lon values, for using to download\n% SST data\n[Lon_min, Lon_max] = bounds(PMNM.Lon);\n[Lat_min, Lat_max] = bounds(PMNM.Lat);\n\n% Now we can follow the steps we used in the earlier tutorials to download\n% the SST data\ntime_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n   'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \n\n% In this particular example, we're interested in March - November 2015\ntime_aoi = find(time_full_ymdhms(:,1) == 2015 & time_full_ymdhms(:,2) &gt;= 3 & ...\n    time_full_ymdhms(:,2) &lt;= 11);\nlat_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'latitude');\nlon_full = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'longitude');\n\n% Find longitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlon_aoi = find(lon_full &gt;= floor(Lon_min) & lon_full &lt;= ceil(Lon_max));\n% Find latitudes that span our area of interest\n% Rounding the minimum down and the maximum up\nlat_aoi = find(lat_full &gt;= floor(Lat_min) & lat_full &lt;= ceil(Lat_max));\n% Start coordinates\naoi_start = [lon_aoi(1) lat_aoi(1) time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon_aoi) length(lat_aoi) length(time_aoi)];\n\n% Download the data of interest\nsst = ncread('https://oceanwatch.pifsc.noaa.gov/erddap/griddap/goes-poes-monthly-ghrsst-RAN', ...\n    'analysed_sst', aoi_start, aoi_span);\n\n% Area and time indices, in a format Matlab is expecting\nlat = double(lat_full(lat_aoi));\nlon = double(lon_full(lon_aoi));\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi* *full* *min *max\n\n\n\nNow we have everything we need to clip the SST data to just those within the boundaries of the Monument. The code below borrows from the no-longer-supported xtractoMatlab: https://github.com/rmendels/xtractoMatlab. You can learn about other avenues to use this tool at: https://coastwatch.pfeg.noaa.gov/xtracto/.\n% The general premise here is that we're going to create a mesh grid of our\n% full domain (what we downloaded), identify all the points that are within\n% or on the polygon that defines the Monument, and set to NaN those that\n% are not.\n% Make the meshgrid and the mask\n[XLON, XLAT] = meshgrid(lon, lat);\n[IN ON] = inpolygon(XLON, XLAT, PMNM.Lon, PMNM.Lat);\nmask2D = IN | ON;\n\n% Replicate it over the number of time steps, which is the third dimension\n% of our sst variable\nmask3D = permute(repmat(mask2D,[1 1 size(sst,3)]),[2 1 3]);\n\n% Set to NaN all points not within the polygon\nsst(~mask3D) = NaN;\n\n\n\n\nThe extracted data contains several time steps (months) of sst data in the monument boundaries. Let’s make a plot of the second time step. Also, we can see above where we used ‘ncdisp’, that the units for these data are Kelvin. Let’s changes this to degrees Celsius when we make our map.\nfigure\naxesm('mercator', 'MapLatLimit', [18 32], 'MapLonLimit', [177 207], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -180:5:-155, 'PLabelLocation', 20:5:30, ...\n    'MLabelParallel', 'south'); % This is the basemap\n\n% Plot SST for the second time step, in degrees C, with 50 contour levels\ncontourm(lat, lon, sst(:,:,2)'-273.15, 50, 'fill', 'on'); \n\n% Title the map\ntitle(sprintf('SST %s', datestr(time_ymdhms(2,:), 'mmm-yyyy')));\n\n% Set the color map to jet colors, with 50 levels\ncolormap(jet(50));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\nOn your own! Plot the average SST for the period we downloaded. Here’s a hint to get you started:\nsst_avg = mean(sst, 3, \"omitnan\");\n\n\n\nSST"
  },
  {
    "objectID": "tutorials/matlab/matlab_basics_gl.html",
    "href": "tutorials/matlab/matlab_basics_gl.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands.\nNote: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset daily SST data:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.html\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nERDDAP\n\n\nIn this specific example, the URL we generated is:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.nc?sst%5B(2021-07-21T12:00:00Z):1:(2021-07-28T12:00:00Z)%5D%5B(38.8749871947229):1:(50.6059751976437)%5D%5B(-92.4199507342304):1:(-75.8816402880577)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n% View data attributes and variables\nncdisp('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS');\nNotice that the full data set has four variables: time, latitude, longitude, and sst. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\n\n\nNotice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the week we’re interested in: 21 - 28 July 2021.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2021 & time_full_ymdhms(:,2) == 7 ...\n    & time_full_ymdhms(:,3) &gt;= 21 & time_full_ymdhms(:,3) &lt;= 28);\n\n\n\nBefore we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'latitude');\nlon = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'longitude');\nNotice in the output above that sst has the dimensions of longitude x latitude x time which means it has a size of 1181 x 838 x 9961.\n\n\n\nNow, we’ll access just the small amount of sst data we’re interested in. We’ll do this by telling the computer to access the variable ‘sst’, beginning at a specific time and spanning our time of interest.\n% Start coordinates\naoi_start = [1 1 time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon) length(lat) length(time_aoi)];\nsst = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'sst', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 1181 x 838 x 8. Before we see what these data look like, let’s create indices for the timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi*  % Delete every variable with 'aoi' in its name\n\n\n\n\nLet’s create a map for a single day, 21 July 2021, the first day in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 10:0.5:25.5, 'fill', 'on');\ntitle(sprintf('Daily SST %s', datestr(time_ymdhms(1,:), 'dd-mmm-yyyy')));\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(45,5), -83:0.5:-81, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 15\ncontourm(lat, lon, sst(:,:,1)', [15 15], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Example of how to add a marker to tutorial author's home town, just for\n% fun\nplotm(45.8527, -87.0218, 'p');\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\ndaily SST\n\n\n\n\n\nLet’s pick a box encompassing Lake Superior: north of 46N and west of 84W. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above for time to identify a subsetted area of interest.\n% Find longitudes west of 84 W\nlon_aoi = find(lon &lt;= -84);\n\n% Find latitudes north of 46 N\nlat_aoi = find(lat &gt;= 46);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 8 days\nsst_ts(1:8,1) = NaN;\nfor d = 1:1:8 \n    sst_ts(d,1) = mean(sst_subset(:,:,d), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,3), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\nset(gca, 'XTick', time_ymdhms(:,3));\nset(gca, 'XTickLabel', datestr(time_ymdhms(:,:), 'mm/dd'))\n\n\n\ntime series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n% Average over time, which is the third dimention of our data\nsst_wk = mean(sst, 3, \"omitnan\");\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_wk', 10:0.5:25.5, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'dd-mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(8,:),'dd-mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nmean SST"
  },
  {
    "objectID": "tutorials/matlab/matlab_basics_gl.html#how-to-work-with-satellite-data-in-matlab",
    "href": "tutorials/matlab/matlab_basics_gl.html#how-to-work-with-satellite-data-in-matlab",
    "title": "CoastWatch Training",
    "section": "",
    "text": "This tutorial will show the steps to grab data in ERDDAP from Matlab, how to work with NetCDF files in Matlab, and how to make some maps and time-series of sea surface temperature (SST) around the main Hawaiian islands.\nNote: The mapping code in this tutorial uses the Mapping Toolbox. If you don’t have access to the Mapping Toolbox, you can still create things like filled contour plots of your data using ‘contourf’ or an open source package like M_map (https://www.eoas.ubc.ca/~rich/map.html) or the Climate Data Toolbox for Matlab (https://github.com/chadagreene/CDT).\n\n\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Matlab using the URL structure. For example, the following page allows you to subset daily SST data:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.html\nSelect your region and date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\n\n\n\nERDDAP\n\n\nIn this specific example, the URL we generated is:\nhttps://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.nc?sst%5B(2021-07-21T12:00:00Z):1:(2021-07-28T12:00:00Z)%5D%5B(38.8749871947229):1:(50.6059751976437)%5D%5B(-92.4199507342304):1:(-75.8816402880577)%5D\nYou can also edit this URL manually.\n\n\n\nIn Matlab, run the following code to view details about the data using a portion of the generated URL:\n% View data attributes and variables\nncdisp('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS');\nNotice that the full data set has four variables: time, latitude, longitude, and sst. Rather than downloading all these data, which would be very slow, we’ll use this information to access just the data we’re interested in. Note: this tutorial uses NetCDF files, but ERDDAP also allows you to download your data of interest as a MATLAB binary file (.mat). A number of other data format options are avalable in the ‘File type’ drop down shown above.\n\n\nNotice in the output above that the units for time are ‘seconds since 1970-01-01T00:00:00Z’. We can convert this into something that’s easier for us to work with. Matlab will convert this type of time to a friendly format using the ‘datevec’ function. But, Matlab does this assuming that the number you give it represents the number of days since January 0, 0000. We’ll get around these differences using the code below to align the two different ways of keeping time by:\n\nConverting ‘seconds since…’ to ‘days since…’ by dividing the output time by 86400 (60 seconds in a minute x 60 minutes in an hour x 24 hours in a day).\nAdding the time between Jan 0, 0000 and 1970-01-01 using the ‘datenum’ fuction. ‘datenum’ does the opposite of ‘datevec’. It converts time in [Y M D H M S] to days since January 0, 0000.\n\nAnd then we’ll convert the time to a friendly [Y M D H M S] format using the ‘datevec’ function.\n% Read the time indices, in their native units (seconds since\n% 1970-01-01T00:00:00Z')\ntime_full = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'time');\n\n% Convert this to [Y M D H M S]\ntime_full_ymdhms = datevec(time_full/86400 + datenum([1970 1 1 0 0 0])); \nNow we have an easy-to-use time index (‘time_ymdhms’) so we can access just the week we’re interested in: 21 - 28 July 2021.\n% Find 2018 (aoi = area of interest)\ntime_aoi = find(time_full_ymdhms(:,1) == 2021 & time_full_ymdhms(:,2) == 7 ...\n    & time_full_ymdhms(:,3) &gt;= 21 & time_full_ymdhms(:,3) &lt;= 28);\n\n\n\nBefore we can create a map, we also need to create indices for latitude and longitude. The output above shows us that the units for these are ‘degrees_north’ and ‘degrees_east’, repectively.\nlat = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'latitude');\nlon = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'longitude');\nNotice in the output above that sst has the dimensions of longitude x latitude x time which means it has a size of 1181 x 838 x 9961.\n\n\n\nNow, we’ll access just the small amount of sst data we’re interested in. We’ll do this by telling the computer to access the variable ‘sst’, beginning at a specific time and spanning our time of interest.\n% Start coordinates\naoi_start = [1 1 time_aoi(1)];\n\n% Coordinates to span\naoi_span = [length(lon) length(lat) length(time_aoi)];\nsst = ncread('https://coastwatch.glerl.noaa.gov/erddap/griddap/GLSEA_GCS', 'sst', aoi_start, aoi_span);\nNotice that our workspace now has a sst variable that’s sized 1181 x 838 x 8. Before we see what these data look like, let’s create indices for the timespan of data we downloaded and then tidy up our workspace. We’ll need the indices when we plot the data.\n% Area and time indices, in a format Matlab is expecting\ntime = time_full(time_aoi);\ntime_ymdhms = time_full_ymdhms(time_aoi,:); % Note that this variable has 6 columns, unlike the others\n\n% Tidying up\nclear *aoi*  % Delete every variable with 'aoi' in its name\n\n\n\n\nLet’s create a map for a single day, 21 July 2021, the first day in the time span we downloaded.\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst(:,:,1)', 10:0.5:25.5, 'fill', 'on');\ntitle(sprintf('Daily SST %s', datestr(time_ymdhms(1,:), 'dd-mmm-yyyy')));\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Example of how to mark points on the map\nplotm(repelem(45,5), -83:0.5:-81, 'ko', 'MarkerFaceColor', 'k');\n\n% Example of how to add a specific contour, here 15\ncontourm(lat, lon, sst(:,:,1)', [15 15], 'k');\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\n\n% Example of how to add a marker to tutorial author's home town, just for\n% fun\nplotm(45.8527, -87.0218, 'p');\ntightmap % This removes an additional frame around the map that can interfere with the labeling\n\n\n\ndaily SST\n\n\n\n\n\nLet’s pick a box encompassing Lake Superior: north of 46N and west of 84W. We are going to generate a time series of mean SST within that box. To do this, we’ll use the same strategy we used above for time to identify a subsetted area of interest.\n% Find longitudes west of 84 W\nlon_aoi = find(lon &lt;= -84);\n\n% Find latitudes north of 46 N\nlat_aoi = find(lat &gt;= 46);\n\n% Subset our new area of interest\nsst_subset = sst(lon_aoi, lat_aoi,:);\n\n% Average over the area for each of the 8 days\nsst_ts(1:8,1) = NaN;\nfor d = 1:1:8 \n    sst_ts(d,1) = mean(sst_subset(:,:,d), \"all\", \"omitnan\");\nend\n\n% Plot\nfigure\nplot(time_ymdhms(:,3), sst_ts, 'k-o', 'MarkerFaceColor', 'k');\nxlabel('Month');\nylabel('SST (Deg C)');\nset(gca, 'XTick', time_ymdhms(:,3));\nset(gca, 'XTickLabel', datestr(time_ymdhms(:,:), 'mm/dd'))\n\n\n\ntime series\n\n\n\n\n\nWe can also create a map of SST averaged of our full time period of interest. Let’s go back to using the full area we downloaded, too.\n% Average over time, which is the third dimention of our data\nsst_wk = mean(sst, 3, \"omitnan\");\nfigure\naxesm('mercator', 'MapLatLimit', [38.8 50.7], 'MapLonLimit', [-92.4 -75.8], 'MeridianLabel', 'on', ...\n    'ParallelLabel', 'on', 'MLabelLocation', -90:5:-80, 'PLabelLocation', 40:5:50, ...\n    'MLabelParallel', 'south');\ncontourm(lat, lon, sst_wk', 10:0.5:25.5, 'fill', 'on');\ntitle([sprintf('Mean SST %s', datestr(time_ymdhms(1,:),'dd-mmm-yyyy')) ...\n    sprintf(' - %s', datestr(time_ymdhms(8,:),'dd-mmm-yyyy'))]);\n\n% Set the color map to jet colors, with 100 levels\ncolormap(jet(32));\n\n% Add a color bar and label it\nc = colorbar;\nc.Label.String = 'SST';\n\n% Add land and color it grey\ngeoshow('landareas.shp', 'FaceColor', [0.5 0.5 0.5]);\ntightmap\n\n\n\nmean SST"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html",
    "title": "CoastWatch Training",
    "section": "",
    "text": "A tidyverse/ggplot version is also available here: https://github.com/jebyrnes/noaa_coastwatch_tutorial_1/blob/main/tutorial2-1.md Links to an external site.\ncourtesy of Jarrett Byrnes from UMass Boston - http://byrneslab.net (Thank you Jarrett!!)"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#background",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#background",
    "title": "CoastWatch Training",
    "section": "Background",
    "text": "Background\nSeveral ocean color sensors have been launched since 1997 to provide continuous global coverage for ocean color data. The sensors have differences in design and calibration, and different algorithms may be applied to generate chlorophyll values. Consequently, chlorophyll-a values can vary among the sensors during periods where measurements overlap.\nTo examine this phenomenon, we will download and plot time-series of chlorophyll-a concentrations from various sensors from 1997 to the present and see how the measurements compare during periods of overlap."
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#objective",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#objective",
    "title": "CoastWatch Training",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show how to extract a time-series from four different monthly satellite chlorophyll datasets for the period that each was in operation between 1997-present. It will showcase the use of the rerddap and rerddapXtracto packages, which have been developed to make it easier to interact with ERDDAP servers from R.\nMore information about the rerddap package can be found here: https://cran.r-project.org/web/packages/rerddap/index.html\nand here: https://cran.r-project.org/web/packages/rerddap/vignettes/Using_rerddap.html\nMore information about the rerddapXtracto package can be found here: https://cran.r-project.org/web/packages/rerddapXtracto/index.html\nand here: https://cran.r-project.org/web/packages/rerddapXtracto/vignettes/UsingrerddapXtracto.html"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "CoastWatch Training",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nUsing rerddapXtracto package to extract data from a rectangular area of the ocean over time\nUsing rerddap to retrieving information about a dataset from ERDDAP\nComparing results from different sensors\nAveraging data spatially\nProducing timeseries plots\nDrawing maps with satellite data"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "title": "CoastWatch Training",
    "section": "Datasets used",
    "text": "Datasets used\nSeaWiFS Chlorophyll-a, V.2018, Monthly, Global, 4km, 1997-2012 https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nMODIS Aqua, Chlorophyll-a, V.2022, Monthly, Global, 4km, 2002-present https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022SQ\nNOAA VIIRS S-NPP, Chlorophyll-a, Monthly, Global, 4km, 2012-present https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisVHNSQchlaMonthly\nESA CCI Ocean Colour Dataset, v6.0, Monthly, Global, 4km, 1997-Present This dataset was developed by the European Space Agency’s Climate Change Initiative. The dataset merges data from multiple sensors (MERIS, MODIS, VIIRS and SeaWiFS) to create a long timeseries (1997 to present) with better spatial coverage than any single sensor. Parameters include chlorophyll-a, remote sensing reflectance, diffuse attenuation coefficients, absorption coefficients, backscatter coefficients, and water classification. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorMonthly"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#load-packages",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#load-packages",
    "title": "CoastWatch Training",
    "section": "Load packages",
    "text": "Load packages\npackages &lt;- c( \"ncdf4\",\"plyr\",\"lubridate\",\"rerddap\",\"ggplot2\",\"plotdap\",\n               \"rerddapXtracto\",\"maps\", \"mapdata\",\"grid\", \"reshape2\", \"gridExtra\")\n\n# Install packages not yet installed\ninstalled_packages &lt;- packages %in% rownames(installed.packages())\n\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages])\n}\n\n# Load packages \ninvisible(lapply(packages, library, character.only = TRUE))"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "title": "CoastWatch Training",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nFirst we define the longitude-latitude boundaries of the region. The coordinates used here, between -95 to -90°W longitude and 25-30°N latitude, define an area in teh Gulf of Mexico.\nxcoord &lt;- c(-95,-90)\nycoord &lt;- c(25,30)"
  },
  {
    "objectID": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#get-information-about-the-dataset-we-will-be-downloading",
    "href": "tutorials/r/Tutorial2-timeseries-compare-sensors.html#get-information-about-the-dataset-we-will-be-downloading",
    "title": "CoastWatch Training",
    "section": "Get information about the dataset we will be downloading",
    "text": "Get information about the dataset we will be downloading\nDefine the URL of the ERDDAP we will be using:\nERDDAP_Node &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/\"\n\nGet monthly SeaWiFS data, which starts in 1997.\nGo to ERDDAP to find the name of the dataset for monthly SeaWIFS data: erdSW2018chlamday\nYou should always examine the dataset in ERDDAP to check the date range, names of the variables and dataset ID, to make sure your griddap calls are correct: https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nFirst we need to know what our variable is called. Let’s retrieve some metadata using the info function of the rerddap package:\ndataInfo &lt;- rerddap::info('erdSW2018chlamday', url=ERDDAP_Node)\nvar &lt;- dataInfo$variable$variable_name\n\n# Display the dataset metadata\ndataInfo\n\n## &lt;ERDDAP info&gt; erdSW2018chlamday \n##  Base URL: https://coastwatch.pfeg.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-16T00:00:00Z, 2010-12-16T00:00:00Z) \n##      latitude: (-89.95834, 89.95834) \n##      longitude: (-179.9583, 179.9584) \n##  Variables:  \n##      chlorophyll: \n##          Units: mg m^-3\n\n\nExtract satellite data with rxtracto_3D\nFor each dataset, we will extract satellite data for the entire length of the available timeseries.\n\nDates must be defined separately for each dataset. rxtracto_3D will crash if dates are entered that are not part of the timeseries.\n\nThe beginning (earliest) date to use in timeseries is obtained from the information returned in dataInfo.\n\nTo get the end (most recent) date to use in the timeseries, use the last option for time.\nThe variable name can change between datasets. For this dataset, the chloropyll variable is called chlorophyll, as seen in the metadata returned by dataInfo\n\n\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n# Set the altitude coordinate to zero\nzcoord &lt;- 0.\n\n# Extract the beginning and ending dates of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntcoord &lt;- c(tt[2],\"last\")\n** Run the SeaWiFS data extraction with rxtracto_3D:\n# Extract the timeseries data using rxtracto_3D\nchlSeaWiFS&lt;-rxtracto_3D(dataInfo,\n                        parameter=parameter,\n                        tcoord=tcoord,\n                        xcoord=xcoord,\n                        ycoord=ycoord)\n\n\nPlot data to show where it is in the world\nWe will use the plotBBox function of the rerddapXtracto package to make a quick map of the data\nmyFunc &lt;- function(x) log(x)\nplotBBox(chlSeaWiFS, plotColor = 'algae', myFunc = myFunc)\n\n\n\nGet monthly MODIS data, which starts in 2002.\ndataInfo &lt;- rerddap::info('erdMH1chlamday_R2022SQ', url=ERDDAP_Node)\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n#Extract the start and end times of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\n#Run rxtracto_3D\nchlMODIS&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord)\n\n\nGet monthly VIIRS data, which starts in 2012.\ndataInfo &lt;- rerddap::info('nesdisVHNSQchlaMonthly', url=ERDDAP_Node)\n# Extract the parameter name from the metadata in dataInfo\nparameter &lt;- dataInfo$variable$variable_name\n\n#Extract the start and end times of the dataset from the metadata in dataInfo\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\n\n# This dataset has an altitude dimensionm, so must include zcoord as an argument in the rxtracto_3D function Set the altitude coordinate to zero\nzcoord &lt;- 0.\n\n# Populate the time vector with the time_coverage_start from dataInfo\n# Use the \"last\" option for the ending date\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\n#Run rxtracto_3D\nchlVIIRS &lt;- rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord,\n                      zcoord=zcoord)\n\n# Remove extraneous zcoord dimension for chlorophyll \nchlVIIRS$chlor_a &lt;- drop(chlVIIRS$chlor_a)\n\n\nAverage data spatially and temporally\n\nspatially averages data for each time step within the area boundaries for each dataset.\n\ntemporally averages data for data in each timeseries onto a map, for each dataset.\n\n\n## Spatially average all the data within the box for each dataset.\n## The c(3) indicates the dimension to keep - in this case time \nchlSeaWiFS$avg &lt;- apply(chlSeaWiFS$chlorophyll, c(3),function(x) mean(x,na.rm=TRUE))\nchlMODIS$avg &lt;- apply(chlMODIS$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\nchlVIIRS$avg &lt;- apply(chlVIIRS$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\n\n## Temporally average all of the data into one map \n## The c(1,2) indicates the dimensions to keep - in this case latitude and longitude  \nchlSeaWiFS$avgmap &lt;- apply(chlSeaWiFS$chlorophyll,c(1,2),function(x) mean(x,na.rm=TRUE))\nchlMODIS$avgmap &lt;- apply(chlMODIS$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\nchlVIIRS$avgmap &lt;- apply(chlVIIRS$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\n\n\nPlot time series for the three datasets\nplot(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg, type='l', col=2,lwd=2, \n     xlab=\"\", xlim=as.Date(c(\"1997-12-01\",\"2024-06-01\")), \n     ylim=c(0.5,3.5), ylab=\"CHL\")\naxis(2)\npoints(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg,pch=20,col=2)\n\nlines(as.Date(chlMODIS$time), chlMODIS$avg, col=4, lwd=2)\npoints(as.Date(chlMODIS$time), chlMODIS$avg,pch=20,col=4)\n\nlines(as.Date(chlVIIRS$time), chlVIIRS$avg, col=3, lwd=2)\npoints(as.Date(chlVIIRS$time), chlVIIRS$avg,pch=20,col=3)\n\nlegend('topleft',legend=c('SeaWiFS','MODIS','VIIRS'),cex=0.6,col=c(2,4,3),lwd=2)\n\nYou can see that the values of chl-a concentration doesn’t always match between sensors.\n\n\nGet OC-CCI data (September 1997 to Dec 2022)\nIf you needed a single time series from 1997 to present, you would have to use the plot above to devise some method to reconcile the difference in values where two datasets overlap. Alternatively, you could use the ESA OC-CCI (ocean color climate change initiative) dataset, which blends data from many satellite missions into a single dataset, including data from SeaWiFS, MODIS, and VIIRS.\nAdd the ESA OC-CCI dataset to the plot above to see how it compares with data from the individual satellite missions.\ndataInfo &lt;- rerddap::info('pmlEsaCCI60OceanColorMonthly', url=ERDDAP_Node)\n\n# This identifies the parameter to choose - there are &gt; 60 in this dataset!\nparameter &lt;- 'chlor_a'\n\nglobal &lt;- dataInfo$alldata$NC_GLOBAL\ntt &lt;- global[ global$attribute_name %in% c('time_coverage_end','time_coverage_start'), \"value\", ]\ntcoord &lt;- c(tt[2],\"last\")\n\nchlOCCCI&lt;-rxtracto_3D(dataInfo,\n                      parameter=parameter,\n                      tcoord=tcoord,\n                      xcoord=xcoord,\n                      ycoord=ycoord)\n\n# Now spatially average the data into a timeseries\nchlOCCCI$avg &lt;- apply(chlOCCCI$chlor_a, c(3),function(x) mean(x,na.rm=TRUE))\n\n# Now temporally average the data into one map \nchlOCCCI$avgmap &lt;- apply(chlOCCCI$chlor_a,c(1,2),function(x) mean(x,na.rm=TRUE))\n\n\nMake another plot with CCI as well to compare\nplot(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg, type='l', col=2,lwd=2, \n     xlab=\"\", xlim=as.Date(c(\"1997-12-01\",\"2024-06-01\")), \n     ylim=c(0.5,3.5), ylab=\"CHL\")\naxis(2)\npoints(as.Date(chlSeaWiFS$time), chlSeaWiFS$avg,pch=20,col=2)\npoints(as.Date(chlMODIS$time), chlMODIS$avg,pch=20,col=4)\npoints(as.Date(chlVIIRS$time), chlVIIRS$avg,pch=20,col=3)\nlines(as.Date(chlOCCCI$time),chlOCCCI$avg,lwd=2)\n\nlegend('topleft',legend=c('SeaWiFS','MODIS','VIIRS','OC-CCI'),cex=0.6,col=c(2,4,3,1),\n       pch=c(20,20,20,NA),lty=c(NA,NA,NA,1),lwd=2)\n\ncoast &lt;- map_data(\"worldHires\", ylim = ycoord, xlim = xcoord)\n\n# Put arrays into format for ggplot\nmelt_map &lt;- function(lon,lat,var) {\n  dimnames(var) &lt;- list(Longitude=lon, Latitude=lat)\n  ret &lt;- melt(var,value.name=\"Chl\")\n}\n\n# Loop for making 4 maps\ndatasetnames &lt;- c(\"SeaWiFS\",\"MODIS\",\"VIIRS\",\"OC-CCI\")\n\nplot_list = list()\n\nfor(i in 1:4) {\n  \n  if(i == 1) chl &lt;- chlSeaWiFS\n  if(i == 2) chl &lt;- chlMODIS\n  if(i == 3) chl &lt;- chlVIIRS\n  if(i == 4) chl &lt;- chlOCCCI\n  \n   chlmap &lt;- melt_map(chl$longitude, chl$latitude, chl$avgmap)\n\n   p = ggplot(\n     data = chlmap, \n     aes(x = Longitude, y = Latitude, fill = log(Chl))) +\n         geom_tile(na.rm=T) +\n         geom_polygon(data = coast, aes(x=long, y = lat, group = group), fill = \"grey80\") +\n         theme_bw(base_size = 12) + ylab(\"Latitude\") + xlab(\"Longitude\") +\n         coord_fixed(1.3, xlim = c(-95,-90), ylim = ycoord) +\n         scale_fill_viridis_c(limits=c(-2.5,3)) +\n         ggtitle(paste(\"Average\", datasetnames[i])\n      ) \n\n  plot_list[[i]] = p\n}\n\n# Now print out maps into a png file.  Can't use par function with **ggplpot** to get \n# multiple plots per page.  Here using a function in the **grid** package\n\ngrid.arrange(plot_list[[1]],plot_list[[2]],plot_list[[3]],plot_list[[4]], nrow = 2)"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html",
    "href": "tutorials/r/define_marine_habitat.html",
    "title": "Define a marine habitat",
    "section": "",
    "text": "notebook filename | define_marine_habitat.Rmd"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#install-required-packages-and-load-libraries",
    "href": "tutorials/r/define_marine_habitat.html#install-required-packages-and-load-libraries",
    "title": "Define a marine habitat",
    "section": "Install required packages and load libraries",
    "text": "Install required packages and load libraries\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ncdf4\", \"rerddap\", \"plotdap\", \"RCurl\",  \n                       \"raster\", \"colorRamps\", \"maps\", \"mapdata\",\n                       \"ggplot2\", \"RColorBrewer\", \"rerddapXtracto\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#select-the-satellite-data",
    "href": "tutorials/r/define_marine_habitat.html#select-the-satellite-data",
    "title": "Define a marine habitat",
    "section": "Select the Satellite Data",
    "text": "Select the Satellite Data\n\nUse the CoralTemp SST dataset (ID CRW_sst_v3_1) from the OceanWatch ERDDAP server (https://oceanwatch.pifsc.noaa.gov/erddap/index.html)\n\nGather information about the dataset (metadata) using rerddap\n\nDisplay the information\n\n# Let's look at the metadata\n\n\nurl = \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\ndataInfo &lt;- rerddap::info('CRW_sst_v3_1',url=url)\nparameter &lt;- 'analysed_sst'\ndataInfo\n## &lt;ERDDAP info&gt; CRW_sst_v3_1 \n##  Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1985-01-01T12:00:00Z, 2023-09-09T12:00:00Z) \n##      latitude: (-89.975, 89.975) \n##      longitude: (0.025, 359.975) \n##  Variables:  \n##      analysed_sst: \n##          Units: degree_C \n##      sea_ice_fraction: \n##          Units: 1"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#get-satellite-data",
    "href": "tutorials/r/define_marine_habitat.html#get-satellite-data",
    "title": "Define a marine habitat",
    "section": "Get Satellite Data",
    "text": "Get Satellite Data\n\nSelect an area of the central North Pacific where the fishery operates: longitude range of 185 to 235 east and latitude range of 20 to 45 north\n\nSelect a date in the first quarter of the year when bycatch typically occurs: tcoord=c('2023-01-06', '2023-01-06')). tcoord needs to be a vector even if we are pulling only one day of data.\n\n# latitude and longitude of the vertices\nylim&lt;-c(20,45)\nxlim&lt;-c(185,235)\n\n# Extract the data\nSST &lt;- rxtracto_3D(dataInfo,xcoord=xlim,ycoord=ylim,parameter=parameter, \n                   tcoord=c('2023-01-06','2023-01-06'))\n\n# Drop command needed to reduce SST from a 3D variable to a 2D  one  \nSST$analysed_sst &lt;- drop(SST$analysed_sst)"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#make-a-quick-plot-using-plotbbox",
    "href": "tutorials/r/define_marine_habitat.html#make-a-quick-plot-using-plotbbox",
    "title": "Define a marine habitat",
    "section": "Make a quick plot using plotBBox",
    "text": "Make a quick plot using plotBBox\nplotBBox(SST, plotColor = 'thermal')\n\n         #,maxpixels=1000000)"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#define-and-plot-the-turtlewatch-temperature-band",
    "href": "tutorials/r/define_marine_habitat.html#define-and-plot-the-turtlewatch-temperature-band",
    "title": "Define a marine habitat",
    "section": "Define and plot the TurtleWatch temperature band",
    "text": "Define and plot the TurtleWatch temperature band\nSet the temperature band to 17.5-18.5 degrees C, as determined by the TurtleWatch program.\n## Define turtle temperature range\nmin.temp &lt;- 17.5\nmax.temp &lt;- 18.5\nCreate another variable for habitat temperature\nSet the habitat temperature to equal NA\nSST2 &lt;- SST\nSST2$analysed_sst[SST2$analysed_sst &gt;= min.temp & SST2$analysed_sst &lt;= max.temp] &lt;- NA\nplotBBox(SST2, plotColor = 'thermal')\n\nIt would be nicer to color in the TurtleWatch band (the NA values) with a different color. If you want to customize graphs, it’s better to use ggplot than the plotBBox that comes with the rerrdapXtracto package. Here we will use ggplot to plot the data. But first the data is reformatted for use in ggplot.\nRestructure the data\ndims &lt;- dim(SST2$analysed_sst)\nSST2.lf &lt;- expand.grid(x=SST$longitude,y=SST$latitude)\nSST2.lf$sst&lt;-array(SST2$analysed_sst,dims[1]*dims[2])"
  },
  {
    "objectID": "tutorials/r/define_marine_habitat.html#plot-the-data-using-ggplot",
    "href": "tutorials/r/define_marine_habitat.html#plot-the-data-using-ggplot",
    "title": "Define a marine habitat",
    "section": "Plot the Data using ‘ggplot’",
    "text": "Plot the Data using ‘ggplot’\ncoast &lt;- map_data(\"worldHires\", ylim = ylim, xlim = xlim)\n\npar(mar=c(3,3,.5,.5), las=1, font.axis=10)\n\nmyplot&lt;-ggplot(data = SST2.lf, aes(x = x, y = y, fill = sst)) +\n  geom_tile(na.rm=T) +\n  geom_polygon(data = coast, aes(x=long, y = lat, group = group), fill = \"grey80\") +\n  theme_bw(base_size = 15) + ylab(\"Latitude\") + xlab(\"Longitude\") +\n  coord_fixed(1.3,xlim = xlim, ylim = ylim) +\n  ggtitle(unique(as.Date(SST2$time))) +\n  scale_fill_gradientn(colours = rev(rainbow(12)),limits=c(5,30),na.value = \"firebrick4\") \n\nmyplot"
  },
  {
    "objectID": "tutorials/r/ice-thickness-climatology.html",
    "href": "tutorials/r/ice-thickness-climatology.html",
    "title": "R Notebook",
    "section": "",
    "text": "Calculating anomaly and trend with sea ice thickness time series\nIn this exercise, we will use the sea ice thickness data in the Arctic region, available through the PolarWatch data server, to study changes in monthly average sea ice thickness values. We will calculate both the long-term trend at each location as well as estimate a changing seasonal.\n\nThe exercise demonstrates the following techniques:\n\nDownloading, as a netcdf file, twice daily sea ice thickness data for a region sdelected at random for the years 1982 to late 2024.\nCalculating a monthly mean from the twice-daily data.\nCalculating the trend and changing seasonal of monthly sea ice thickness means using state-space models\nVisualizing the result of the state-space analysis.\n\n\n\nGetting the data\nFirst we will load the packages that will be used:\n#load needed libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(KFAS)\nlibrary(ncdf4)\nlibrary(tidyr)\nNext the script to download the data (it is advised not to run this because it can take a long time to download and can fail - the resulting file is included), the region selected in projected coordinates was chosen arbitarily:\ndownload_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/ncei_polarAPPX20_nhem.nc?cdr_sea_ice_thickness[(1982-10-31T14:00:00Z):1:(2024-10-31T14:00:00Z)][(-388546.6):1:(338411.6)][(-438681.7):1:(338411.6)]\"\ndownload.file(download_url,  \"ncei_polar.nc\", 'wb')\nThe next step is to read in the netcdf file:\nroot &lt;- nc_open('data/ncei_polar.nc')\ntime &lt;- ncvar_get(root, 'time')\nrows &lt;- ncvar_get(root, 'rows')\ncolumns &lt;- ncvar_get(root, 'columns')\nice_thick &lt;- ncvar_get(root, 'cdr_sea_ice_thickness')\nnc_close(root)\n“time” needs to be converted to an ‘R’ time, and then year and month extracted:\ntime &lt;- as.POSIXlt(time, origin = '1970-01-01', tz = \"GMT\")\nyears &lt;- year(time)\nuniqueYears &lt;- unique(years)\nmonths &lt;- month(time)\nOne solution to calculate the mean time series is to “melt” the data to long form, and then use functions like ‘apply()’ or ‘tapply()’ or any of the appropriate “tidyverse” functions to calculate the mean value for each month. Code below shows how to “melt” the data, but we will not do so because as you will find out you will quickly run out of memory and likely crash your R.\nout &lt;- list(year = years, month = months, rows = rows,  columns = columns)\ndf &lt;- as.data.frame(as.vector(ice_thick))\nmeta  &lt;- expand.grid(out, stringsAsFactors = FALSE)\nalldf &lt;-  cbind(meta, df)\nA simpler, less elegant but more straightforward method (and easier to debug) is to use loops:\nno_years &lt;- length(unique(years))\nmonth_avg &lt;- array(NA, dim = c(length(rows), length(columns), 12, no_years))\nfor (myMonth in 1:12){\n  for (yearCount in 1:length(uniqueYears)){\n    myYear &lt;- uniqueYears[yearCount]\n    data_point &lt;- which((months == myMonth) & (years == myYear))\n    temp_data &lt;- ice_thick[, , data_point]\n    month_avg[, , myMonth, yearCount] &lt;- apply(temp_data, c(1, 2), function(x) mean(x, na.rm = TRUE))\n  }\n}\n# re-from array to be a time-series at each point\nmonth_avg_series &lt;- array(month_avg, dim = c(length(rows), length(columns), 12*length(uniqueYears)))\n#  remove the last two months of 2024 which are missing\nmonth_avg_series &lt;- month_avg_series[, , 1:514]\n# create a date-time object to be used with plotting and other functions\ndate_time &lt;- seq.Date(from = as.Date(\"1982-01-01\"), to = as.Date(\"2024-10-01\"), by = \"month\")\nIn the code above, the “apply()” function applies the function “mean()” elementwise, and ‘month_avg_series’ just flattens the calculated array so that there is a time-series for each time period at each location, rather than being subscripted by month and year.\nIn order to examine the series, we will use a state-space decomposition of the data, which separates the data into a nonparametric trend and plus a seasonal component that can vary in phase and amplitude. This is implemented in the ‘R’ package ‘KFAS’. To start, a function is defined that sets up the state-space model, another that is used with the optimization routine to re-evaluate the function for the new parameters, and a function to call what is needed to do all of the calculation steps:\n\n### define the model in KFAS\nstate_space_decomp &lt;- function(dataSeries){\n  #  set model starting values\n  irreg_init &lt;- 0.5 * log(1)\n  level_init &lt;- 0.5 * log(.01)\n  season_init &lt;-  0.5 * log(.1)\n  modelts_inits &lt;- c(irreg_init, level_init, season_init)\n  # define the state-space model in KFAS\n  model_ice &lt;- SSModel(dataSeries ~ SSMtrend(degree = 1 , Q = list(NA)) +\n                        SSMseasonal(12, Q=NA, sea.type = \"trigonometric\"),  H = matrix(NA))\n  #  fit the model to the data\n  model_ice_Fit &lt;- fitSSM(model = model_ice, inits = modelts_inits, updatefn = update_modelts)\n  # calculate the smoothed values for the optimal parameters\n  smooth_ice &lt;- KFS(model_ice_Fit$model, filtering = \"state\", smoothing = \"state\")\n  # extract the estimated trend and seasonal\n  level &lt;-  signal(smooth_ice, states = 'level')$signal\n  season &lt;- signal(smooth_ice, states = 'season')$signal\n  smooths &lt;- data.frame(level = level, season = season)\n  \n}\n### define the function to update model for the optimization routine \nupdate_modelts &lt;- function(pars, model) {\n  finite_test &lt;- 0.5 * log(.000001)\n  if (pars[1] &lt; finite_test) {\n    pars[1] &lt;- finite_test\n  }\n  model$H[1,1,1] &lt;- exp(2. * pars[1])\n  temp3 &lt;- exp(c(2 * pars[2], rep((2 * pars[3]), 11)))\n  diag(model$Q[,,1]) &lt;-  temp3\n  return(model)\n}\n\nTo get an idea of the output from the state-space model we look at the first series and estimate the model:\ndataSeries &lt;- month_avg_series[1, 1, ]\n# make certain we start at the first actual value in the series\nnobs &lt;- length(na.omit(dataSeries))\nice_decomp &lt;- state_space_decomp(dataSeries)\nIn order to examine the output, some ‘ggplot2’ plotting functions are defined:\nplot_trend_data &lt;- function(dataSeries, level, date_time){\n  df &lt;- data.frame(\n    date_time &lt;- date_time,\n    data = dataSeries,\n    trend = level\n  )\n  \n  p &lt;- ggplot(df, aes(x = date_time)) +\n    geom_line(aes(y = data, color = \"Data\"), linewidth = 0.5) +    # Plot the data\n    geom_line(aes(y = trend, color = \"Trend\"), linewidth = 0.5) +  # Plot the trend\n    labs(title = \"Data and Trend Plot\",\n         x = \"Time\",\n         y = \"Ice Thickness\") +\n    scale_color_manual(values = c(\"Data\" = \"black\", \"Trend\" = \"red\")) +  # Customize colors\n    theme_minimal()\n  return(p)\n}\n\n\nplot_season &lt;- function(season, date_time){\n  df &lt;- data.frame(\n    date_time = date_time,\n    season = season\n  )\n  ggplot(df, aes(x = date_time, y = season)) +\n    geom_line(size = 0.5) +\n    labs(title = \"Ice Thickness Seasonal Component\", x = \"Time\", y = \"Ice Thickness\") +\n    theme_minimal()\n  \n}\n\nplot_season_month  &lt;- function(season, date_time){\n   myMonth &lt;- month(date_time)\n   myYear &lt;- year(date_time)\n   df &lt;- data.frame(\n         month = myMonth,  \n         year = myYear,   \n         season = season\n     )\n   \n     monthly_means &lt;- df %&gt;%\n           group_by(month) %&gt;%\n           summarise(mean_value = mean(season))\n     \n       df &lt;- df %&gt;%\n             left_join(monthly_means, by = \"month\")\n       \n         p &lt;- ggplot(df, aes(x = factor(month), y = season, group = year, color = factor(year))) +\n             geom_line() +\n             geom_line(aes(y = mean_value), color = \"gray\") +\n             labs(x = \"Month\", y = \"Values\", title = \"Monthly Series and Monthly Mean\") +\n             theme_minimal() +\n             theme(legend.title = element_blank())\n       return(p) \n}\n\n\n\nplot_season_polar  &lt;- function(season, date_time){\n  myMonth &lt;- month(date_time)\n  myYear &lt;- year(date_time)\n  df &lt;- data.frame(\n         month = myMonth,  \n         year = myYear,   \n         season = season\n     )\n   p &lt;- ggplot(df, aes(x = factor(month), y = season, group = year)) +\n         geom_line(aes(color = factor(year))) +\n         coord_polar() +\n         labs(x = \"Month\", y = \"Values\", title = \"Polar Plot of Time Series\") +\n         theme_minimal() +\n         theme(legend.position = \"right\") \n    return(p)\n}\nPlot the trend versus the series:\np &lt;- plot_trend_data(dataSeries, ice_decomp$level, date_time)\np\nPlot the seasonal:\np &lt;- plot_season(ice_decomp$season, date_time)\np\nIn interpreting the seasonal plot, even though in theory the seasonal and trend are independent, in practice since the ice thickness has a lower bound of zero, if the trend decreases this limits the amount the seasonal can vary downward.\nPlot each year’s season on one graph:\np &lt;- plot_season_month(ice_decomp$season, date_time)\np\nMake a polar plot of the seasonal:\np &lt;- plot_season_polar(ice_decomp$season, date_time)\np\nWhat can clearly be seen in the seasonal is how it has been slowly but consistently changing over roughly decadal time scales.\nTo examine another location just change the indices in the data array, that is set irow and jcol to the desired values and run the code below:\n    dataSeries &lt;- month_avg_series[irow, jcol, ]\n    # make certain we start at the first actual value in the series\n    ice_decomp &lt;- state_space_decomp(dataSeries)\n    p_trend &lt;- plot_trend_data(dataSeries, ice_decomp$level, date_time)\n    p_season &lt;- plot_season(ice_decomp$season, date_time)\n    p_season_month &lt;- plot_season_month(ice_decomp$season, date_time)\n    p_season_polar &lt;- plot_season_polar(ice_decomp$season, date_time)\n    \nTo get the state-space decomposition for all of the series, just iterate over rows and columns (this can take 5 minutes or there abouts so a good time to stretch you legs):\n#  create arrays of NA to store results\ntrends &lt;- array(NA_real_, dim = c(length(rows), length(columns), length(date_time)))\nseasons &lt;- array(NA_real_, dim = c(length(rows), length(columns), length(date_time)))\n\n# loop over rows and columns\nfor (irow in seq(1, length(rows))) {\n  for (jcol in seq(1, length(columns))) {\n    dataSeries &lt;- month_avg_series[irow, jcol, ]\n    # make certain we start at the first actual value in the series\n    ice_decomp &lt;- state_space_decomp(dataSeries)\n    trends[irow, jcol, ] &lt;- ice_decomp$level\n    seasons[irow, jcol, ] &lt;- ice_decomp$season\n  }\n}\nThis analysis looks at each location separately and can be informative, but a better analysis, beyond the scope of this tutorial, would be to model all the locations jointly, both to take into account spatial correlation as well as the fact that neighboring locations most like will have more similar locations, so some amount of spatial smootiing or regularization would be called for."
  },
  {
    "objectID": "tutorials/r/map-data-with-different-projections.html",
    "href": "tutorials/r/map-data-with-different-projections.html",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "history | Updated September 2023 \n\nNOAA PolarWatch distributes gridded and tabular oceanographic data for polar regions. Satellite data include geospatial information and most of them are in geographical coordinates (latitude and longitude). PolarWatch satellite data are often projected using Polar Stereographic Projections in x and y coordinates.\n\n\nThis tutorial will demonstrate how to plot a polar stereographic projected data on a projected map, and to add another dataset with geographical coordinates (latitude and longitude) onto the map.\n\n\n\n\nAccessing satellite data from ERDDAP\nMaking a projected map\nAdding projected data\nAdding geographical data\n\n\n\n\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\nThis dataset includes sea ice concentration data from the northern hemisphere, and is produced by the NOAA/NSIDC using the Climate Data Record algorithm. The resolution is 25km, meaning each grid in this data set represents a value that covers a 25km by 25km area. The dataset is avaialble from the NOAA PolarWatch Catalog.\nPolar bear tracking data  For the demonstrative purpose of adding a dataset in geographical coords (lat, lon) to the projected map, GPS data for a polar bear track were used. More information about the data can be found at https://borealisdata.ca/file.xhtml?fileId=151017&version=1.0\nR Packages\n\nncdf4 (reading data and metadata in netCDF format)\nggplot2, RColorBrewer, scales (mapping)\nreshape2 (data manipulation)\nrgdal (projection)\n\n\n\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"rgdal\",\"sp\", \"ggplot2\" ,\"ncdf4\",  \"RColorBrewer\", \"scales\", \"reshape2\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# download the sea ice data NetCDF file\nseaice_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4851137.11):1:(-4850758.92)][(-3850000.0):1:(3750000.0)]\"\nsea_ice_data_nc &lt;- download.file(seaice_url, destfile=\"../data/sea_ice_data.nc\", mode='wb')\n\n# file open\nseaice &lt;- nc_open('../data/sea_ice_data.nc')\n\n# print metadata\n#print(seaice)\n\n# get data into r variables \nxgrid &lt;- ncvar_get(seaice, \"xgrid\")\nygrid &lt;- ncvar_get(seaice, \"ygrid\")\nsic &lt;- ncvar_get(seaice, \"cdr_seaice_conc_monthly\")  #lat and lon\nfillvalue &lt;- ncatt_get(seaice, \"cdr_seaice_conc_monthly\", \"_FillValue\") #checkout fill value for missing data points\n\n# close \nnc_close(seaice)\n\n# create dataframe\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude fillvalue\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels=comma) + \n       scale_x_continuous(labels=comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\") +\n      ggtitle(\"Sea Ice Concentration on Polar Steregraphic projection\")\n ### Adding Polar bear track data onto the polar stereographic projection\n# read csv polar bear track data \npolartrack &lt;- read.csv(\"../data/PB_Argos.csv\")\npolarB &lt;- polartrack[polartrack$QualClass==\"B\",]\n\n# specify coordinate columns\ncoordinates(polarB) &lt;- c(\"Lon\", \"Lat\")\n\n# set data crs to 4326\nproj4string(polarB) &lt;-CRS(\"+init=epsg:4326\")\n\n# transform the data crs from EPSG:4326 to EPSG: 3413\npolar.3413 &lt;- spTransform(polarB, CRS(\"+init=epsg:3413\"))\n\n# for ggplot, convert spatial data to data.frame\npolar.3413.df&lt;-data.frame(polar.3413)\nnames(polar.3413.df)[names(polar.3413.df)==\"Lon\"]&lt;-\"x\"\nnames(polar.3413.df)[names(polar.3413.df)==\"Lat\"]&lt;-\"y\"\n\n\n\n\nggplot(data = sicd, aes(x = xgrid, y = ygrid) ) + \n        geom_tile(aes(fill=sic)) + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels = comma) + \n       scale_x_continuous(labels = comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\")+\n       ggtitle(\"SIC with polar bear tracks on Polar (red) Steregraphic projection\")+\n      geom_point(data=polar.3413.df, aes(x=x, y=y), color=\"red\", size=0.5)\n\n\n\n\n\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nNOAA PolarWatch Data Product Page (download, preview)"
  },
  {
    "objectID": "tutorials/r/map-data-with-different-projections.html#objective",
    "href": "tutorials/r/map-data-with-different-projections.html#objective",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "This tutorial will demonstrate how to plot a polar stereographic projected data on a projected map, and to add another dataset with geographical coordinates (latitude and longitude) onto the map."
  },
  {
    "objectID": "tutorials/r/map-data-with-different-projections.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/map-data-with-different-projections.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Accessing satellite data from ERDDAP\nMaking a projected map\nAdding projected data\nAdding geographical data"
  },
  {
    "objectID": "tutorials/r/map-data-with-different-projections.html#datasets-used",
    "href": "tutorials/r/map-data-with-different-projections.html#datasets-used",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Northern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\nThis dataset includes sea ice concentration data from the northern hemisphere, and is produced by the NOAA/NSIDC using the Climate Data Record algorithm. The resolution is 25km, meaning each grid in this data set represents a value that covers a 25km by 25km area. The dataset is avaialble from the NOAA PolarWatch Catalog.\nPolar bear tracking data  For the demonstrative purpose of adding a dataset in geographical coords (lat, lon) to the projected map, GPS data for a polar bear track were used. More information about the data can be found at https://borealisdata.ca/file.xhtml?fileId=151017&version=1.0\nR Packages\n\nncdf4 (reading data and metadata in netCDF format)\nggplot2, RColorBrewer, scales (mapping)\nreshape2 (data manipulation)\nrgdal (projection)\n\n\n\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"rgdal\",\"sp\", \"ggplot2\" ,\"ncdf4\",  \"RColorBrewer\", \"scales\", \"reshape2\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n# download the sea ice data NetCDF file\nseaice_url &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nhmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4851137.11):1:(-4850758.92)][(-3850000.0):1:(3750000.0)]\"\nsea_ice_data_nc &lt;- download.file(seaice_url, destfile=\"../data/sea_ice_data.nc\", mode='wb')\n\n# file open\nseaice &lt;- nc_open('../data/sea_ice_data.nc')\n\n# print metadata\n#print(seaice)\n\n# get data into r variables \nxgrid &lt;- ncvar_get(seaice, \"xgrid\")\nygrid &lt;- ncvar_get(seaice, \"ygrid\")\nsic &lt;- ncvar_get(seaice, \"cdr_seaice_conc_monthly\")  #lat and lon\nfillvalue &lt;- ncatt_get(seaice, \"cdr_seaice_conc_monthly\", \"_FillValue\") #checkout fill value for missing data points\n\n# close \nnc_close(seaice)\n\n# create dataframe\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude fillvalue\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels=comma) + \n       scale_x_continuous(labels=comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\") +\n      ggtitle(\"Sea Ice Concentration on Polar Steregraphic projection\")\n ### Adding Polar bear track data onto the polar stereographic projection\n# read csv polar bear track data \npolartrack &lt;- read.csv(\"../data/PB_Argos.csv\")\npolarB &lt;- polartrack[polartrack$QualClass==\"B\",]\n\n# specify coordinate columns\ncoordinates(polarB) &lt;- c(\"Lon\", \"Lat\")\n\n# set data crs to 4326\nproj4string(polarB) &lt;-CRS(\"+init=epsg:4326\")\n\n# transform the data crs from EPSG:4326 to EPSG: 3413\npolar.3413 &lt;- spTransform(polarB, CRS(\"+init=epsg:3413\"))\n\n# for ggplot, convert spatial data to data.frame\npolar.3413.df&lt;-data.frame(polar.3413)\nnames(polar.3413.df)[names(polar.3413.df)==\"Lon\"]&lt;-\"x\"\nnames(polar.3413.df)[names(polar.3413.df)==\"Lat\"]&lt;-\"y\""
  },
  {
    "objectID": "tutorials/r/map-data-with-different-projections.html#combine-the-sea-ice-concentration-data-and-the-polar-bear-tracking-data",
    "href": "tutorials/r/map-data-with-different-projections.html#combine-the-sea-ice-concentration-data-and-the-polar-bear-tracking-data",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "ggplot(data = sicd, aes(x = xgrid, y = ygrid) ) + \n        geom_tile(aes(fill=sic)) + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels = comma) + \n       scale_x_continuous(labels = comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\")+\n       ggtitle(\"SIC with polar bear tracks on Polar (red) Steregraphic projection\")+\n      geom_point(data=polar.3413.df, aes(x=x, y=y), color=\"red\", size=0.5)"
  },
  {
    "objectID": "tutorials/r/map-data-with-different-projections.html#references",
    "href": "tutorials/r/map-data-with-different-projections.html#references",
    "title": "Virtual Buoy example",
    "section": "",
    "text": "NSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)\nNOAA PolarWatch Data Product Page (download, preview)"
  },
  {
    "objectID": "tutorials/r/matchup-polar-data-to-animal-track-locations.html",
    "href": "tutorials/r/matchup-polar-data-to-animal-track-locations.html",
    "title": "Tracking Penguins in Antarctica",
    "section": "",
    "text": "Tracking Penguins in Antarctica\n\nModified October 2024\n\n\nOverview\nIn this exercise, you will learn how to extract satellite data in polar stereographic projection (defined by xgrid and ygrid) around a set of points specified by longitude, latitude, and time coordinates. These coordinates could represent data from animal telemetry tags, ship tracks, or glider tracks.\n\n\nThe exercise demonstrates the following techniques:\n\nLoading animal telemetry tags data from tab- or comma-separated files\nExtracting satellite data along a track\nPlotting animal tracks and satellite data on a map\n\n\n\nDatasets used in this exercise:\nSea Ice Concentration Satellite Data\nThis dataset contains daily and monthly Climate Data Records (CDR) of sea ice concentration, processed by the NOAA/NSIDC team for the Arctic at a 25 km resolution, spanning from 1978 to the most recent annual data processing update. The sea ice concentration data are derived from microwave remote sensing. Due to processing and quality control, CDR data has a slight delay in availability, but near real-time data is available for more recent dates..\nFor this tutorial, the monthly sea ice concentration data is used. To preview and download CDR data, visit NOAA PolarWatch CDR Data.\nAdelie Penguin Telemetry Track\nTelemetry data from Adelie penguins (Pygoscelis adeliae) were collected via Argos satellites in the Southern Ocean between October 29, 1996, and February 19, 2013, as part of the U.S. Antarctic Marine Living Resources project. Additionally, a turtle raised in captivity in Japan was tagged and released on May 4, 2005, in the Central Pacific.\nThe telemetry track dataset is included in the data/ folder of this module. For more information about the project and to download the full dataset, visit the NOAA NCEI webpage.\n\n\nInstall the required R libraries\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                      \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\", \"dplyr\",\n                      \"sf\", \"ggspatial\", \"rnaturalearth\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\nLoad the sea ice data from PolarWatch ERDDAP\n# ERDDAP URL\nERDDAP_Node = \"https://polarwatch.noaa.gov/erddap\"\n\n# Dataset ID\nNDBC_id = 'nsidcG02202v4shmday'\nNDBC_info=info(datasetid = NDBC_id,url = ERDDAP_Node)\n\n# Check the metadata\nprint(NDBC_info)\n## &lt;ERDDAP info&gt; nsidcG02202v4shmday \n##  Base URL: https://polarwatch.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1978-11-01T00:00:00Z, 2024-03-01T00:00:00Z) \n##      ygrid: (-3937500.0, 4337500.0) \n##      xgrid: (-3937500.0, 3937500.0) \n##  Variables:  \n##      cdr_seaice_conc_monthly: \n##          Units: 1 \n##      nsidc_bt_seaice_conc_monthly: \n##          Units: 1 \n##      nsidc_nt_seaice_conc_monthly: \n##          Units: 1 \n##      qa_of_cdr_seaice_conc_monthly: \n##      stdev_of_cdr_seaice_conc_monthly:\n# Set the parameters to get the first time step of the sea ice concentration data\ntime_range &lt;- c('1978-11-01T00:00:00Z', '1978-11-01T23:59:59Z')\n#y_range &lt;- c(-3950000.0, 4350000.0) # if the entire range is desired one doesn't have to include a range \n#x_range &lt;- c(-3950000.0, 3950000.0) # if the entire range is desired one doesn't have to include a range \nfield &lt;- 'cdr_seaice_conc_monthly'\n\n# Extract data\nsic &lt;- griddap(\n  url = ERDDAP_Node,\n  NDBC_id,\n  time = time_range,\n# ygrid = y_range,      # uncomment if subsetting is desired \n# xgrid = x_range,      # uncomment if subsetting is desired\n  fields = field\n)\n\n# Extract data into the data frame\nsic.df &lt;- data.frame(\n  x = sic$data$xgrid,\n  y = sic$data$ygrid,\n  cdr_seaice_conc_monthly = sic$data$cdr_seaice_conc_monthly\n)\n\n# Remove values greater than 1\nsic.df &lt;- sic.df[sic.df$cdr_seaice_conc_monthly &lt; 1, ]\n\n\nPlot sea ice data on a map\n# Load map of Antarctica\nantarctica &lt;- ne_countries(scale = \"medium\", continent = \"Antarctica\", returnclass = \"sf\")\n\n# Plot the data\nggplot() +\n  geom_tile(data = sic.df, aes(x = x, y = y, fill = cdr_seaice_conc_monthly)) +\n  scale_fill_gradient(name = \"Sea Ice Concentration\", low = \"#deebf7\", high = \"#08306b\", limits = c(0, 1)) +\n  geom_sf(data = antarctica, fill = \"antiquewhite\", color = NA) +\n  coord_sf(crs = st_crs(3412)) +\n  theme_minimal() +\n  theme(legend.position = \"right\") +\n  labs(title = \"Sea Ice Concentration (First Time Step)\", x = \"Longitude\", y = \"Latitude\") +\n  theme(panel.grid = element_blank())\n\n\n\nLoad penguin telemetry data from a local file\n# Import csv file into a data frame\npenguin_df &lt;- read.csv(\"../data/copa_adpe_ncei.csv\")\n\n# Show 3 rows from the data frame\nhead(penguin_df, 3)\n##   BirdId    Sex   Age Breed.Stage    DateGMT  TimeGMT  Latitude Longitude\n## 1  ADPE1 female adult  incubation 28/10/1997  7:54:00 -62.17167 -58.44500\n## 2  ADPE1 female adult  incubation 28/10/1997  9:32:00 -62.17333 -58.46333\n## 3  ADPE1 female adult  incubation 28/10/1997 18:15:00 -62.15833 -58.42667\n##   ArgosQuality\n## 1            2\n## 2            2\n## 3            1\n\n\nProcess Penguin Data\nFor this exercise, we will select ADPE24, a penguin whose recorded tracks are highest within the female group, and will follow her journey in the Antarctic.\n# Find BirdID with the most count by sex\nmost_bird_count &lt;- penguin_df %&gt;%\n  group_by(Sex) %&gt;%\n  summarize(BirdId = names(which.max(table(BirdId))))\n\nhead(most_bird_count, 1)\n## # A tibble: 1 × 2\n##   Sex    BirdId\n##   &lt;chr&gt;  &lt;chr&gt; \n## 1 female ADPE24\n# Extract ADPE24 track data\nadpe24 &lt;- penguin_df %&gt;% filter(BirdId == 'ADPE24')\n\n# Inspect the data\nhead(adpe24)\n##   BirdId    Sex   Age Breed.Stage    DateGMT  TimeGMT Latitude Longitude\n## 1 ADPE24 female adult      creche 16/01/2003 21:32:00  -62.173   -58.446\n## 2 ADPE24 female adult      creche 16/01/2003 22:02:00  -62.175   -58.451\n## 3 ADPE24 female adult      creche 16/01/2003 23:10:00  -62.184   -58.466\n## 4 ADPE24 female adult      creche 16/01/2003 23:10:00  -62.176   -58.448\n## 5 ADPE24 female adult      creche 16/01/2003 23:43:00  -62.177   -58.452\n## 6 ADPE24 female adult      creche 17/01/2003  0:07:00  -62.173   -58.445\n##   ArgosQuality\n## 1            3\n## 2            3\n## 3            1\n## 4            3\n## 5            3\n## 6            1\n# Convert DateGMT to Date format\nadpe24$DateGMT &lt;- as.Date(adpe24$DateGMT, format = \"%d/%m/%Y\")\n\n# Create Year_Month column\nadpe24$Year_Month &lt;- format(adpe24$DateGMT, \"%Y-%m\")\n\n# Convert TimeGMT to POSIXct format for times\nadpe24$TimeGMT &lt;- format(strptime(adpe24$TimeGMT, format = \"%H:%M:%S\"), \"%H:%M:%S\")\n\n# Get unique penguin dates\nadpe_dates &lt;- unique(adpe24$Year_Month)\n\ndate_range &lt;- range(adpe24$DateGMT)\n\n# Print results\nprint(paste(\"Date Range:\", date_range[1], \"to\", date_range[2]))\n## [1] \"Date Range: 2003-01-16 to 2003-03-09\"\nprint(paste(\"Unique Months:\", paste(adpe_dates, collapse = \", \")))\n## [1] \"Unique Months: 2003-01, 2003-02, 2003-03\"\n\n\nVisualize penguin tracks\n# Create the plot\nggplot() +\n  geom_sf(data = antarctica, fill = \"gray80\", color = \"gray50\") +\n  geom_path(data = adpe24, aes(x = Longitude, y = Latitude), color = \"black\", fill = \"black\") +\n  geom_point(data = adpe24, aes(x = Longitude, y = Latitude), shape = 20, size = 4) +\n  geom_point(data = adpe24[1, ], aes(x = Longitude, y = Latitude), color = \"green\", size = 5, shape = 17) +\n  geom_point(data = adpe24[nrow(adpe24), ], aes(x = Longitude, y = Latitude), color = \"red\", size = 5, shape = 15) +\n  coord_sf(xlim = c(min(adpe24$Longitude) - 5, max(adpe24$Longitude) + 5),\n           ylim = c(min(adpe24$Latitude) - 5, max(adpe24$Latitude) + 5),\n           expand = FALSE) +\n  labs(title = \"Penguin Track with Start (green) and End Location (red)\",\n       x = \"Longitude (deg)\", y = \"Latitude (deg)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n ### Resample Penguin data to match satellite data\n# Subset the penguin track data\nadpe24 &lt;- adpe24 %&gt;%\n  select(DateGMT, Latitude, Longitude) %&gt;%\n  mutate(DateGMT = as.Date(DateGMT, format = \"%d/%m/%Y\"))\n\n# Resample data daily\nadpe24_df &lt;- adpe24 %&gt;%\n  group_by(DateGMT) %&gt;%\n  summarise(Latitude = mean(Latitude, na.rm = TRUE),\n            Longitude = mean(Longitude, na.rm = TRUE))\n\n\nTransform the projection of the penguin locations\n# Convert to an sf object and transform to Polar Stereographic Projection\npenguin_sf &lt;- st_as_sf(adpe24_df, coords = c(\"Longitude\", \"Latitude\"), crs = 4326)\npenguin_sf &lt;- st_transform(penguin_sf, crs = 3412)\n\n# Extract x and y coordinates\ntransformed_coords &lt;- st_coordinates(penguin_sf)\nadpe24_df$xgrid &lt;- transformed_coords[, \"X\"]\nadpe24_df$ygrid &lt;- transformed_coords[, \"Y\"]\n\nhead(adpe24_df)\n## # A tibble: 6 × 5\n##   DateGMT    Latitude Longitude     xgrid    ygrid\n##   &lt;date&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 2003-01-16    -62.2     -58.5 -2618200. 1607416.\n## 2 2003-01-17    -62.2     -58.4 -2617487. 1608715.\n## 3 2003-01-18    -62.3     -57.7 -2580637. 1632458.\n## 4 2003-01-19    -62.5     -57.5 -2556440. 1626139.\n## 5 2003-01-20    -62.2     -58.5 -2619622. 1607983.\n## 6 2003-01-21    -62.2     -58.5 -2618872. 1607944.\n\n\nExtract satellite data to match penguin locations and date\n# Extract sea ice concentration data\nsic_penguin &lt;- rxtracto(\n  NDBC_info,\n  xName = \"xgrid\",\n  yName = \"ygrid\",\n  tName = \"time\",\n  parameter = \"cdr_seaice_conc_monthly\",\n  xcoord = adpe24_df$xgrid,\n  ycoord = adpe24_df$ygrid,\n  tcoord = adpe24_df$DateGMT,\n)\n\nhead(sic_penguin)\n## $`mean cdr_seaice_conc_monthly`\n##  [1] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.37 0.27\n## [16] 0.37 0.41 0.36 0.33 0.33 0.35 0.35 0.35 0.35 0.37 0.33 0.35 0.35 0.34 0.37\n## [31] 0.46 0.64 0.64 0.64 0.71 0.63 0.70 0.70 0.71 0.71 0.71 0.71 0.70 0.70 0.78\n## [46] 0.71 0.71 0.71 0.71 0.71 0.70 0.70 0.70\n## \n## $`stdev cdr_seaice_conc_monthly`\n##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [51] NA NA NA\n## \n## $n\n##  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n## [39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n## \n## $`satellite date`\n##  [1] \"2003-01-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n##  [4] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n##  [7] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [10] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [13] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [16] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [19] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [22] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [25] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [28] \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\" \"2003-02-01T00:00:00Z\"\n## [31] \"2003-02-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [34] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [37] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [40] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [43] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [46] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [49] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## [52] \"2003-03-01T00:00:00Z\" \"2003-03-01T00:00:00Z\"\n## \n## $`requested x min`\n##  [1] -2618200 -2617487 -2580637 -2556440 -2619622 -2618872 -2609300 -2581762\n##  [9] -2617878 -2618061 -2614421 -2535191 -2470714 -2414195 -2372472 -2345538\n## [17] -2314721 -2276201 -2266618 -2247613 -2234056 -2243316 -2245819 -2227527\n## [25] -2221971 -2248918 -2249757 -2237957 -2218441 -2209007 -2176294 -2139759\n## [33] -2134079 -2129105 -2114272 -2100165 -2083425 -2076899 -2070131 -2064975\n## [41] -2059881 -2058637 -2075336 -2086747 -2091354 -2104230 -2110452 -2114260\n## [49] -2118197 -2124732 -2131630 -2134295 -2149253\n## \n## $`requested x max`\n##  [1] -2618200 -2617487 -2580637 -2556440 -2619622 -2618872 -2609300 -2581762\n##  [9] -2617878 -2618061 -2614421 -2535191 -2470714 -2414195 -2372472 -2345538\n## [17] -2314721 -2276201 -2266618 -2247613 -2234056 -2243316 -2245819 -2227527\n## [25] -2221971 -2248918 -2249757 -2237957 -2218441 -2209007 -2176294 -2139759\n## [33] -2134079 -2129105 -2114272 -2100165 -2083425 -2076899 -2070131 -2064975\n## [41] -2059881 -2058637 -2075336 -2086747 -2091354 -2104230 -2110452 -2114260\n## [49] -2118197 -2124732 -2131630 -2134295 -2149253\nsic_penguin_df &lt;- data.frame(\n  time = as.Date(sic_penguin$`satellite date`),\n  xgrid = sic_penguin$`requested x min`,\n  ygrid = sic_penguin$`requested y min`,\n  matched_seaice_concen = sic_penguin$'mean cdr_seaice_conc_monthly'\n)\n\n\n# Merge the extracted data back into the penguin data frame\nadpe24_df &lt;- adpe24_df %&gt;%\n  mutate(matched_seaice_concen = sic_penguin$'mean cdr_seaice_conc_monthly')\n\nhead(adpe24_df)\n## # A tibble: 6 × 6\n##   DateGMT    Latitude Longitude     xgrid    ygrid matched_seaice_concen\n##   &lt;date&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;                 &lt;dbl&gt;\n## 1 2003-01-16    -62.2     -58.5 -2618200. 1607416.                     0\n## 2 2003-01-17    -62.2     -58.4 -2617487. 1608715.                     0\n## 3 2003-01-18    -62.3     -57.7 -2580637. 1632458.                     0\n## 4 2003-01-19    -62.5     -57.5 -2556440. 1626139.                     0\n## 5 2003-01-20    -62.2     -58.5 -2619622. 1607983.                     0\n## 6 2003-01-21    -62.2     -58.5 -2618872. 1607944.                     0\n\n\nPlot penguin tracks with matched sea ice concentration data\n# Create the base map with longitude and latitude limits, grid lines, and geographical features\nggplot() +\n  # Add a polygon layer for landmasses (adjust as needed for better visual presentation)\n  geom_sf(data = antarctica, fill = \"gray80\", color = \"gray50\") +  # Use world map or other basemap\n  \n  # Add penguin track with sea ice concentration\n  geom_point(data = adpe24_df, aes(x = Longitude, y = Latitude, color = matched_seaice_concen),\n             size = 2, alpha = 0.8) +\n  \n  # Start and end points\n  geom_point(data = adpe24_df[1,], aes(x = Longitude, y = Latitude), color = \"red\", size = 3, shape = 8, stroke = 2) +  # Start point\n  geom_point(data = adpe24_df[nrow(adpe24_df),], aes(x = Longitude, y = Latitude), color = \"orange\", size = 3, shape = 17, stroke = 2) +  # End point\n  \n  # Set the map projection and focus on South Pole region\n  coord_sf(xlim = c(-65, -44), ylim = c(-70, -60), expand = FALSE) +\n  \n  # Custom blue color palette for sea ice concentration (from light blue to dark blue)\n  scale_color_gradientn(\n    name = \"Sea Ice Concentration\", \n    colors = c(\"#dbe9f6\", \"#9ccffb\", \"#6fa9e7\", \"#3177c6\", \"#004494\"),  # Custom blue gradient\n    limits = c(0, 1), \n    breaks = seq(0, 1, by = 0.1),\n    guide = guide_colorbar(direction = \"vertical\")\n  ) +\n  \n  labs(title = \"Sea Ice Concentration Matchup to Penguin Track\",\n       x = \"Longitude\", y = \"Latitude\") +\n  \n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, size = 15), \n        axis.text = element_text(size = 10),\n        legend.position = \"right\") +\n  \n  guides(color = guide_colorbar(barwidth = 1, barheight = 10))"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "history | Modified July 2024\n\n\nThis tutorial will demonstrate how to extract satellite data around a set of points defined by longitude, latitude, and time coordinates from an animal telemetry tag that was acquired from the Animal Telemetry Network (https://ioos.noaa.gov/project/atn/).\n\n\n\n\nImporting track data in csv file to data frame\nPlotting the latitude/longitude points onto a map\nUsing rerddapXtraco function to extract satellite data from an ERDDAP data server along a track\nPlotting the satellite data onto a map\n\n\n\n\nChlorophyll a concentration, the European Space Agency’s Ocean Colour Climate Change Initiative (OC-CCI) Monthly dataset v6.0\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nYellowfin tuna telemetry track data\nMarine protected areas (MPAs) in pelagic regions is also called Blue Water. The Palmyra Bluewater Research (PBR) project seeks to understand the impact of MPAs on species and ecosystems by tracking at-sea movements of ten marine animal species at Palmyra Atoll (part of the U.S. Pacific Remote Islands Marine National Monument). All data were being collected from adult individuals between May 2022 and June 2023. They can be accessed via the Animal Telemetry Network (ATN) data portal for the PBR project under “Project Data”: (https://portal.atn.ioos.us/?ls=861Wqpd2#metadata/1f877c4c-7b50-49f5-be86-3354664e0cff/project/files)\nThe yellowfin tuna geolocation data is developed as part of the PBR project. This example track used in the tutorial is from May 2022 to November 2022. The track data has been previously downloaded, extracted, and stored in the data folder of this training module.\n\n\n\n# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                       \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\", \"stringr\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\n\nThe data you need for this exercise are already in the GitHub repository\nThe following step are show you how to download the data yourself\n\n\n\n\nFollow the link to the ATN website: https://portal.atn.ioos.us/?ls=O6vlufm7#map\n\nOn the right navigational panel, look for the “Palmyra Bluewater Research (PBR) Megafauna Movement Ecology Project, 2022-2023” tab.\nWithin the tab, scroll to find the telemetry tag labeled “Yellowfin tuna (233568)”.\nClick the search icon (maginifying glass) label next to the label to zoom into the area the area of the animal track.\n\n\n\n\nImage of the ATN portal webpage\n\n\n\n\n\n\nNext click the tag icon to the right of the search icon.\nThis page shows you details about the animal and the track.\n\n\n\n\nImage of the detail page for the Yellowfin Tuna #233568\n\n\n\n\n\n\nPress the “Project Data” tab near the top of the webpage to bring up the data file list.\nSearch for the animal id number (233568).\nClick on the link “THUALB_2022_04-PTT_233568.zip (8.6 MB)” to download the data.\n\n\n\n\nData download page\n\n\n\n\n\n\nThe download will be a zip file. You will need to unzip it.\nThe unzipped file folder contains many ancillary data files, but the one you are looking for is the CSV file (THUALB_2022_04-233568-4-GPE3.csv).\nYou don’t have to move this file into the data folder for this exercise. It is already there.\n\nBut if you download the file for a different animal track you would need to put the CSV file into the folder.\n\n\n\n\n\n# Import csv file into a data frame\nfile = \"../data/THUALB_2022_04-233568-5-GPE3.csv\"\npre_tuna_df &lt;- read.csv(file, skip = 5)\n\n# Show 3 rows from the data frame\nhead(pre_tuna_df, 3)\n##         DeployID    Ptt                 Date Most.Likely.Latitude\n## 1 THUALB_2022_04 233568 31-May-2022 19:00:00                5.875\n## 2 THUALB_2022_04 233568 01-Jun-2022 00:00:00                5.875\n## 3 THUALB_2022_04 233568 01-Jun-2022 04:56:15                5.850\n##   Most.Likely.Longitude Observation.Type Observed.SST Satellite.SST\n## 1              -162.125             User           NA            NA\n## 2              -162.100             None           NA            NA\n## 3              -161.975     Light - Dusk           NA            NA\n##   Observed.Depth Bathymetry.Depth Observation.LL..MSS. Observation.Score\n## 1             NA               NA                   NA          68.60585\n## 2             NA               NA                   NA                NA\n## 3            144             2908                   NA          43.16747\n##                Sunrise               Sunset\n## 1                                          \n## 2 01-Jun-2022 16:33:04 02-Jun-2022 04:59:36\n## 3\n# Convert longitudes to 0~360 (Re-center map to the dateline)\npre_tuna_df['Most.Likely.Longitude'] &lt;- pre_tuna_df['Most.Likely.Longitude'] + 360\n# Show converted data frame\nhead(pre_tuna_df, 3)\n##         DeployID    Ptt                 Date Most.Likely.Latitude\n## 1 THUALB_2022_04 233568 31-May-2022 19:00:00                5.875\n## 2 THUALB_2022_04 233568 01-Jun-2022 00:00:00                5.875\n## 3 THUALB_2022_04 233568 01-Jun-2022 04:56:15                5.850\n##   Most.Likely.Longitude Observation.Type Observed.SST Satellite.SST\n## 1               197.875             User           NA            NA\n## 2               197.900             None           NA            NA\n## 3               198.025     Light - Dusk           NA            NA\n##   Observed.Depth Bathymetry.Depth Observation.LL..MSS. Observation.Score\n## 1             NA               NA                   NA          68.60585\n## 2             NA               NA                   NA                NA\n## 3            144             2908                   NA          43.16747\n##                Sunrise               Sunset\n## 1                                          \n## 2 01-Jun-2022 16:33:04 02-Jun-2022 04:59:36\n## 3\n\n\n\npre_tuna_df$Date &lt;- as.Date(pre_tuna_df$Date, format = \"%d-%b-%Y\")\nhead(pre_tuna_df)\n##         DeployID    Ptt       Date Most.Likely.Latitude Most.Likely.Longitude\n## 1 THUALB_2022_04 233568 2022-05-31                5.875               197.875\n## 2 THUALB_2022_04 233568 2022-06-01                5.875               197.900\n## 3 THUALB_2022_04 233568 2022-06-01                5.850               198.025\n## 4 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n## 5 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n## 6 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n##   Observation.Type Observed.SST Satellite.SST Observed.Depth Bathymetry.Depth\n## 1             User           NA            NA             NA               NA\n## 2             None           NA            NA             NA               NA\n## 3     Light - Dusk           NA            NA            144             2908\n## 4             None           NA            NA             NA               NA\n## 5              SST         28.2      28.32458              1             2908\n## 6     Light - Dawn           NA            NA            112             2908\n##   Observation.LL..MSS. Observation.Score              Sunrise\n## 1                   NA          68.60585                     \n## 2                   NA                NA 01-Jun-2022 16:33:04\n## 3                   NA          43.16747                     \n## 4                   NA                NA                     \n## 5                   NA          76.62995                     \n## 6                   NA          54.92253                     \n##                 Sunset\n## 1                     \n## 2 02-Jun-2022 04:59:36\n## 3                     \n## 4                     \n## 5                     \n## 6\n\n\n\nThe track data has multiple longitude/latitude/time points for each date. That temporal resolution is much higher than the daily and month satellite datasets that are available. So, let’s reduce the multiple daily values for the animal track data to a single value for each day. The code below creates a new dataframe that bins data for each date and calculates the mean for selected columns.\nlibrary(dplyr)\ntuna_df &lt;- pre_tuna_df %&gt;% group_by(Date) %&gt;% summarize(Most.Likely.Latitude = mean(Most.Likely.Latitude),\n                                         Most.Likely.Longitude = mean(Most.Likely.Longitude),\n                                         Satellite.SST = mean(Satellite.SST, na.rm=TRUE),\n                                         Observed.SST = mean(Observed.SST, na.rm=TRUE),\n                                         Observed.Depth = mean(Observed.Depth, na.rm=TRUE),\n                                         Bathymetry.Depth = mean(Bathymetry.Depth, na.rm=TRUE),\n                                         )\n\ntuna_df\n## # A tibble: 177 × 7\n##    Date       Most.Likely.Latitude Most.Likely.Longitude Satellite.SST\n##    &lt;date&gt;                    &lt;dbl&gt;                 &lt;dbl&gt;         &lt;dbl&gt;\n##  1 2022-05-31                 5.88                  198.         NaN  \n##  2 2022-06-01                 5.88                  198           28.3\n##  3 2022-06-02                 5.92                  198.          28.3\n##  4 2022-06-03                 5.92                  198.          28.3\n##  5 2022-06-04                 5.98                  198.          28.3\n##  6 2022-06-05                 6.11                  198.          28.4\n##  7 2022-06-06                 6.28                  198.          28.3\n##  8 2022-06-07                 6.45                  197.          28.3\n##  9 2022-06-08                 6.51                  197.          28.2\n## 10 2022-06-09                 6.78                  197.          28.2\n## # ℹ 167 more rows\n## # ℹ 3 more variables: Observed.SST &lt;dbl&gt;, Observed.Depth &lt;dbl&gt;,\n## #   Bathymetry.Depth &lt;dbl&gt;\n\n\n\n# Download world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Map tuna tracks\nggplot(tuna_df, aes(Most.Likely.Longitude,Most.Likely.Latitude)) +\n  geom_path(group=1)+\n  geom_point(aes(x=Most.Likely.Longitude,y=Most.Likely.Latitude), pch=1, size=2 )+\n  geom_point(aes(x=Most.Likely.Longitude[1],y=Most.Likely.Latitude[1]),fill=\"green\", shape=24, size=3)+\n  geom_point(aes(x=Most.Likely.Longitude[length(Most.Likely.Longitude)],y=Most.Likely.Latitude[length(Most.Likely.Latitude)]), shape=22, size=3, fill=\"red\")+\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26))+\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with start (green) and end location (red)\")+\n  theme(plot.title=element_text(hjust=0.5), aspect.ratio=0.6)\n\nIn this exercise, two different ways of extracting data from ERDDAP data server along a track of xyt points are demonstrated:\n\nUsing the rerddapXtracto package which was written specifically for this task\nFor those who want to know what goes on “under the hood”, we will show how to manually construct ERDDAP data-request URLs to download the data.\n\n\n\nWe will use the `rxtracto function of the rerddapXtracto package, which was written to simplify data extraction from ERDDAP servers.\nLet’s use data from the monthly product of the OC-CCI datasets.\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data are severely affected by clouds (i.e. lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer data gaps.\nThe ERDDAP URL to the monthly product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-12-01 (at the day of this writing), which covers the track time range of 2022-05-30 to 2023-01-18.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n# Set dataset ID\ndataset &lt;- 'esa-cci-chla-monthly-v6-0'\n\n# Get data information from ERDDAP server\ndataInfo &lt;- rerddap::info(dataset, url= \"https://oceanwatch.pifsc.noaa.gov/erddap\")\n\n\n\n\nrerddap::info returns the metadata of the requested dataset. We can first understand the attributes dataInfo includes then examine each attribute.\n# Display the metadata\ndataInfo\n## &lt;ERDDAP info&gt; esa-cci-chla-monthly-v6-0 \n##  Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-04T00:00:00Z, 2023-12-01T00:00:00Z) \n##      latitude: (-89.97916666666666, 89.97916666666667) \n##      longitude: (0.020833333333314386, 359.97916666666663) \n##  Variables:  \n##      chlor_a: \n##          Units: mg m-3 \n##      chlor_a_log10_bias: \n##      chlor_a_log10_rmsd: \n##      MERIS_nobs_sum: \n##      MODISA_nobs_sum: \n##      OLCI_A_nobs_sum: \n##      OLCI_B_nobs_sum: \n##      SeaWiFS_nobs_sum: \n##      total_nobs_sum: \n##      VIIRS_nobs_sum:\n# Display data attributes\nnames(dataInfo)\n## [1] \"variables\" \"alldata\"   \"base_url\"\n# Examine attribute: variables\ndataInfo$variables\n##         variable_name data_type actual_range\n## 1             chlor_a     float             \n## 2  chlor_a_log10_bias     float             \n## 3  chlor_a_log10_rmsd     float             \n## 4      MERIS_nobs_sum     float             \n## 5     MODISA_nobs_sum     float             \n## 6     OLCI_A_nobs_sum     float             \n## 7     OLCI_B_nobs_sum     float             \n## 8    SeaWiFS_nobs_sum     float             \n## 9      total_nobs_sum     float             \n## 10     VIIRS_nobs_sum     float\n# Distribute attributes of dataInfo$alldata\nnames(dataInfo$alldata)\n##  [1] \"NC_GLOBAL\"          \"time\"               \"latitude\"          \n##  [4] \"longitude\"          \"chlor_a\"            \"MERIS_nobs_sum\"    \n##  [7] \"MODISA_nobs_sum\"    \"OLCI_A_nobs_sum\"    \"OLCI_B_nobs_sum\"   \n## [10] \"SeaWiFS_nobs_sum\"   \"VIIRS_nobs_sum\"     \"chlor_a_log10_bias\"\n## [13] \"chlor_a_log10_rmsd\" \"total_nobs_sum\"\n\n\nFirst we need to define the bounding box within which to search for coordinates. The rxtracto function allows you to set the size of the box used to collect data around the track points using the xlen and ylen arguments. The values for xlen and ylen are in degrees. For our example, we can use 0.2 degrees for both arguments. Note: You can also submit vectors for xlen and ylen, as long as they are the same length as xcoord, ycoord, and tcoord if you want to set a different search radius around each track point.\n# Set the variable we want to extract data from:\nparameter &lt;- 'chlor_a'\n\n# Set xlen, ylen to 0.2 degree\nxlen &lt;- 0.2 \nylen &lt;- 0.2\n\n# Create date column using year, month and day in a format ERDDAP will understand (eg. 2008-12-15)\n#tuna_df$date &lt;-as.Date(tuna_df$Date, format = \"%d-%b-%Y\")\n\n# Get variables x, y, t coordinates from tuna track data\nxcoords &lt;- tuna_df$Most.Likely.Longitude\nycoords &lt;- tuna_df$Most.Likely.Latitude\ntcoords &lt;- tuna_df$Date\n\n# Extract satellite data using x, y, t coordinates from tuna track data\nchl_track &lt;- rxtracto(dataInfo, \n                  parameter=parameter, \n                  xcoord=xcoords, ycoord=ycoords, \n                  tcoord=tcoords, xlen=xlen, ylen=ylen)\n\n\n\n\n# Check all variables extracted using rxtracto\nstr(chl_track)\n## List of 13\n##  $ mean chlor_a     : num [1:177] 0.35 0.34 0.349 0.367 0.276 ...\n##  $ stdev chlor_a    : num [1:177] 0.373 0.372 0.373 0.407 0.154 ...\n##  $ n                : int [1:177] 36 36 36 30 25 36 30 36 36 30 ...\n##  $ satellite date   : chr [1:177] \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" ...\n##  $ requested lon min: num [1:177] 198 198 198 198 198 ...\n##  $ requested lon max: num [1:177] 198 198 198 198 198 ...\n##  $ requested lat min: num [1:177] 5.78 5.79 5.83 5.83 5.88 ...\n##  $ requested lat max: num [1:177] 5.97 5.98 6.02 6.02 6.08 ...\n##  $ requested z min  : logi [1:177] NA NA NA NA NA NA ...\n##  $ requested z max  : logi [1:177] NA NA NA NA NA NA ...\n##  $ requested date   : chr [1:177] \"2022-05-31\" \"2022-06-01\" \"2022-06-02\" \"2022-06-03\" ...\n##  $ median chlor_a   : num [1:177] 0.235 0.227 0.232 0.236 0.232 ...\n##  $ mad chlor_a      : num [1:177] 0.017 0.0148 0.0172 0.0151 0.0192 ...\n##  - attr(*, \"row.names\")= chr [1:177] \"1\" \"2\" \"3\" \"4\" ...\n##  - attr(*, \"class\")= chr [1:2] \"list\" \"rxtractoTrack\"\n##  - attr(*, \"base_url\")= chr \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\n##  - attr(*, \"datasetid\")= chr \"esa-cci-chla-monthly-v6-0\"\nrxtracto computes statistics using all the pixels found in the search radius around each track point.\n\n\n\nWe will use the “plotTrack” function to plot the results. “plotTrack” is a function of the “rerddapXtracto” package designed specifically to plot the results of the “rxtracto” function. It provides an easy way to make a quick plot, however it’s not very customizable.\n# Plot tracks with color: algae specifically designed for chlorophyll\nplotTrack(chl_track, xcoords, ycoords, tcoords, size=3, plotColor = 'viridis')\n\n\n\n\nOne of the nice features of the “plotTrack” function is that it is very easy to make an animation of the track data. This will take a minute to run. It creates an animated gif that will display in the Rstudio viewer window once the encoding to gif is done. Note: this works with but doesn’t require the latest versions of R Studio or rerddapXtracto package (e.g., it works with R Studio Version 2023.12.1+402 and rerddapXtracto version 1.1.5).\n# Animate tracks\n\nmake180 &lt;- function(lon) {\n    ind &lt;- which(lon &gt; 180)\n    lon[ind] &lt;- lon[ind] - 360\n   return(lon)\n}\n\nplotTrack(chl_track,\n          make180(xcoords),\n          ycoords, tcoords,\n          plotColor = 'viridis',\n          animate = TRUE,\n          cumulative = TRUE)\n## # A tibble: 177 × 7\n##    format width height colorspace matte filesize density\n##    &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n##  1 gif      672    480 sRGB       TRUE         0 72x72  \n##  2 gif      672    480 sRGB       TRUE         0 72x72  \n##  3 gif      672    480 sRGB       TRUE         0 72x72  \n##  4 gif      672    480 sRGB       TRUE         0 72x72  \n##  5 gif      672    480 sRGB       TRUE         0 72x72  \n##  6 gif      672    480 sRGB       TRUE         0 72x72  \n##  7 gif      672    480 sRGB       TRUE         0 72x72  \n##  8 gif      672    480 sRGB       TRUE         0 72x72  \n##  9 gif      672    480 sRGB       TRUE         0 72x72  \n## 10 gif      672    480 sRGB       TRUE         0 72x72  \n## # ℹ 167 more rows\n\n\n\n\n\nIf we to do an customization of the plot, its better to plot the data using ggplot. We will first create a data frame that contains longitudes and latitudes from the tuna and associated satellite chlor-a values.\n# Create a data frame of coords from tuna and chlor_a values \nnew_df &lt;- as.data.frame(cbind(xcoords, ycoords,  \n                              chl_track$`requested lon min`, \n                              chl_track$`requested lon max`, \n                              chl_track$`requested lat min`, \n                              chl_track$`requested lon max`,  \n                              chl_track$`mean chlor_a`)\n                        )\n\n# Set variable names\nnames(new_df) &lt;- c(\"Lon\", \n                   \"Lat\", \n                   \"Matchup_Lon_Lower\",\n                   \"Matchup_Lon_Upper\",\n                   \"Matchup_Lat_Lower\",\n                   \"Matchup_Lat_Upper\", \n                   \"Chlor_a\")\n\nwrite.csv(new_df, \"tuna_matchup_df.csv\")\n\n\n\n# Import world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Draw the track positions with associated chlora values\nggplot(new_df) +\n  geom_point(aes(Lon,Lat,color=log(Chlor_a))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with chlor-a values\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nFirst we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\ndata_url = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a\"\nFor a refresher of how to construct an ERDDAP data-request URL, please review the ERDDAP tutorial “04-Erddapurl.md” at the following link: https://github.com/coastwatch-training/CoastWatch-Tutorials/blob/main/ERDDAP-basics/lessons/\n# Set erddap address\nerddap_base_url &lt;- \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a\"\n\n# Get longitude and latitude from tuna track data\nlon &lt;- tuna_df$Most.Likely.Longitude\nlat &lt;- tuna_df$Most.Likely.Latitude\n\n# Get time from tuna track data and convert into ERDDAP date format\ndates2 &lt;- as.Date(tuna_df$Date, format = \"%d-%b-%Y\")\n\n# Initatilize tot variable where data will be downloaded to\ntot &lt;- rep(NA, 4)\n\n# Loop through each tuna track data\nfor (i in 1:dim(tuna_df)[1]) {\n\n  # follow the progress of the loop\n  cat(\"\\014\")\n  cat(\" Loop \", i, \" of \", dim(tuna_df)[1])\n  \n  # Create erddap URL by adding lat, lon, dates of each track point \n   url &lt;-  paste(erddap_base_url,\n                 \"[(\", dates2[i], \"):1:(\", dates2[i],\n                 \")][(\", lat[i], \"):1:(\", lat[i],\n                 \")][(\", lon[i], \"):1:(\", lon[i], \")]\", sep = \"\")  \n   \n   # Request and load satelite data from ERDDAP\n   new &lt;- read.csv(url, skip=2, header = FALSE) \n   \n   # Append the data\n   tot &lt;- rbind(tot, new)   \n   \n}\n## \f Loop  1  of  177\f Loop  2  of  177\f Loop  3  of  177\f Loop  4  of  177\f Loop  5  of  177\f Loop  6  of  177\f Loop  7  of  177\f Loop  8  of  177\f Loop  9  of  177\f Loop  10  of  177\f Loop  11  of  177\f Loop  12  of  177\f Loop  13  of  177\f Loop  14  of  177\f Loop  15  of  177\f Loop  16  of  177\f Loop  17  of  177\f Loop  18  of  177\f Loop  19  of  177\f Loop  20  of  177\f Loop  21  of  177\f Loop  22  of  177\f Loop  23  of  177\f Loop  24  of  177\f Loop  25  of  177\f Loop  26  of  177\f Loop  27  of  177\f Loop  28  of  177\f Loop  29  of  177\f Loop  30  of  177\f Loop  31  of  177\f Loop  32  of  177\f Loop  33  of  177\f Loop  34  of  177\f Loop  35  of  177\f Loop  36  of  177\f Loop  37  of  177\f Loop  38  of  177\f Loop  39  of  177\f Loop  40  of  177\f Loop  41  of  177\f Loop  42  of  177\f Loop  43  of  177\f Loop  44  of  177\f Loop  45  of  177\f Loop  46  of  177\f Loop  47  of  177\f Loop  48  of  177\f Loop  49  of  177\f Loop  50  of  177\f Loop  51  of  177\f Loop  52  of  177\f Loop  53  of  177\f Loop  54  of  177\f Loop  55  of  177\f Loop  56  of  177\f Loop  57  of  177\f Loop  58  of  177\f Loop  59  of  177\f Loop  60  of  177\f Loop  61  of  177\f Loop  62  of  177\f Loop  63  of  177\f Loop  64  of  177\f Loop  65  of  177\f Loop  66  of  177\f Loop  67  of  177\f Loop  68  of  177\f Loop  69  of  177\f Loop  70  of  177\f Loop  71  of  177\f Loop  72  of  177\f Loop  73  of  177\f Loop  74  of  177\f Loop  75  of  177\f Loop  76  of  177\f Loop  77  of  177\f Loop  78  of  177\f Loop  79  of  177\f Loop  80  of  177\f Loop  81  of  177\f Loop  82  of  177\f Loop  83  of  177\f Loop  84  of  177\f Loop  85  of  177\f Loop  86  of  177\f Loop  87  of  177\f Loop  88  of  177\f Loop  89  of  177\f Loop  90  of  177\f Loop  91  of  177\f Loop  92  of  177\f Loop  93  of  177\f Loop  94  of  177\f Loop  95  of  177\f Loop  96  of  177\f Loop  97  of  177\f Loop  98  of  177\f Loop  99  of  177\f Loop  100  of  177\f Loop  101  of  177\f Loop  102  of  177\f Loop  103  of  177\f Loop  104  of  177\f Loop  105  of  177\f Loop  106  of  177\f Loop  107  of  177\f Loop  108  of  177\f Loop  109  of  177\f Loop  110  of  177\f Loop  111  of  177\f Loop  112  of  177\f Loop  113  of  177\f Loop  114  of  177\f Loop  115  of  177\f Loop  116  of  177\f Loop  117  of  177\f Loop  118  of  177\f Loop  119  of  177\f Loop  120  of  177\f Loop  121  of  177\f Loop  122  of  177\f Loop  123  of  177\f Loop  124  of  177\f Loop  125  of  177\f Loop  126  of  177\f Loop  127  of  177\f Loop  128  of  177\f Loop  129  of  177\f Loop  130  of  177\f Loop  131  of  177\f Loop  132  of  177\f Loop  133  of  177\f Loop  134  of  177\f Loop  135  of  177\f Loop  136  of  177\f Loop  137  of  177\f Loop  138  of  177\f Loop  139  of  177\f Loop  140  of  177\f Loop  141  of  177\f Loop  142  of  177\f Loop  143  of  177\f Loop  144  of  177\f Loop  145  of  177\f Loop  146  of  177\f Loop  147  of  177\f Loop  148  of  177\f Loop  149  of  177\f Loop  150  of  177\f Loop  151  of  177\f Loop  152  of  177\f Loop  153  of  177\f Loop  154  of  177\f Loop  155  of  177\f Loop  156  of  177\f Loop  157  of  177\f Loop  158  of  177\f Loop  159  of  177\f Loop  160  of  177\f Loop  161  of  177\f Loop  162  of  177\f Loop  163  of  177\f Loop  164  of  177\f Loop  165  of  177\f Loop  166  of  177\f Loop  167  of  177\f Loop  168  of  177\f Loop  169  of  177\f Loop  170  of  177\f Loop  171  of  177\f Loop  172  of  177\f Loop  173  of  177\f Loop  174  of  177\f Loop  175  of  177\f Loop  176  of  177\f Loop  177  of  177\n# Delete the first row (default column names)\ntot &lt;- tot[-1, ]\n\n# Rename columns\nnames(tot) &lt;- c(\"chlo_date\", \"matched_lat\", \"matched_lon\", \"matched_chl.m\")\n\n# Create data frame combining tuna track data and the chlo-a data\nchl_track2 &lt;- data.frame(tuna_df, tot)\n\n# Write the data frame to csv file\nwrite.csv(chl_track2, 'tuna-track-chl.m.csv', row.names = FALSE)\n\n\n\n# Draw the track positions with associated chlora values\nggplot(chl_track2) +\n  geom_point(aes(Most.Likely.Longitude,Most.Likely.Latitude,color=log(matched_chl.m))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nHow do the chlorophyll values of the tuna track compare to values in the surrounding environment? Meaning does the tuna seem to have a preference for certain chlorophyll values? To look at this we will plot a histograms of the track chl valuesand those of the surrounding area.\nFirst we will get a 3D block of chl data from the region and of the tuna track over the span of time the tuna was in that area. We will use the ‘xtracto_3d’ function of rerddapXtracto to get the data. This data call will take a few minutes.\nchl_grid &lt;- rxtracto_3D(dataInfo, \n                  parameter=parameter, \n                  xcoord=c(min(xcoords),max(xcoords)), \n                  ycoord=c(min(ycoords),max(ycoords)), \n                  tcoord=c(min(tcoords),max(tcoords)))\n\nchl_area &lt;- as.vector(chl_grid$chlor_a) \n\n# remove NA values \nchl_area &lt;- chl_area[!is.na(chl_area)]\n\n# vector or tuna chlorophyll \n\nchl_tuna &lt;- chl_track$`mean chlor_a`\nNow we we plot histograms of all the chlorphyll values in the area, and those of the tuna track.\nggplot(as.data.frame(chl_area)) + \n      geom_histogram(aes(x=chl_area,y=after_stat(density),color = \"darkgray\",fill='Area'),color='black', bins=50) + \n      geom_histogram(data=as.data.frame(chl_tuna), aes(x=chl_tuna,y=after_stat(density),color='green', fill='Tuna'),color='black',bins=50, alpha=.4) + \n      scale_x_continuous(limits = c(0,.9), expand = c(0, 0)) + \n      scale_y_continuous(limits = c(0,15), expand = c(0, 0)) +\n      labs(x='Chlorophyll values',y='Density') + \n      theme_bw() + \n      scale_fill_manual(values=c(\"darkgray\",\"green\"),'')\n\n\n\nRepeat the steps above with a different satellite dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html \\ This dataset is a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name.\n\n\n\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ \\ This dataset will likely be on a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name. \\ Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\n\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorDaily_Lon0360.html"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#objective",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#objective",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "This tutorial will demonstrate how to extract satellite data around a set of points defined by longitude, latitude, and time coordinates from an animal telemetry tag that was acquired from the Animal Telemetry Network (https://ioos.noaa.gov/project/atn/)."
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "Importing track data in csv file to data frame\nPlotting the latitude/longitude points onto a map\nUsing rerddapXtraco function to extract satellite data from an ERDDAP data server along a track\nPlotting the satellite data onto a map"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#datasets-used-in-this-exercise",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#datasets-used-in-this-exercise",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "Chlorophyll a concentration, the European Space Agency’s Ocean Colour Climate Change Initiative (OC-CCI) Monthly dataset v6.0\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nYellowfin tuna telemetry track data\nMarine protected areas (MPAs) in pelagic regions is also called Blue Water. The Palmyra Bluewater Research (PBR) project seeks to understand the impact of MPAs on species and ecosystems by tracking at-sea movements of ten marine animal species at Palmyra Atoll (part of the U.S. Pacific Remote Islands Marine National Monument). All data were being collected from adult individuals between May 2022 and June 2023. They can be accessed via the Animal Telemetry Network (ATN) data portal for the PBR project under “Project Data”: (https://portal.atn.ioos.us/?ls=861Wqpd2#metadata/1f877c4c-7b50-49f5-be86-3354664e0cff/project/files)\nThe yellowfin tuna geolocation data is developed as part of the PBR project. This example track used in the tutorial is from May 2022 to November 2022. The track data has been previously downloaded, extracted, and stored in the data folder of this training module."
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#install-required-packages-and-load-libraries",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#install-required-packages-and-load-libraries",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                       \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\", \"stringr\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#download-animal-track-data-from-the-atn-website",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#download-animal-track-data-from-the-atn-website",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "The data you need for this exercise are already in the GitHub repository\nThe following step are show you how to download the data yourself\n\n\n\n\nFollow the link to the ATN website: https://portal.atn.ioos.us/?ls=O6vlufm7#map\n\nOn the right navigational panel, look for the “Palmyra Bluewater Research (PBR) Megafauna Movement Ecology Project, 2022-2023” tab.\nWithin the tab, scroll to find the telemetry tag labeled “Yellowfin tuna (233568)”.\nClick the search icon (maginifying glass) label next to the label to zoom into the area the area of the animal track.\n\n\n\n\nImage of the ATN portal webpage\n\n\n\n\n\n\nNext click the tag icon to the right of the search icon.\nThis page shows you details about the animal and the track.\n\n\n\n\nImage of the detail page for the Yellowfin Tuna #233568\n\n\n\n\n\n\nPress the “Project Data” tab near the top of the webpage to bring up the data file list.\nSearch for the animal id number (233568).\nClick on the link “THUALB_2022_04-PTT_233568.zip (8.6 MB)” to download the data.\n\n\n\n\nData download page\n\n\n\n\n\n\nThe download will be a zip file. You will need to unzip it.\nThe unzipped file folder contains many ancillary data files, but the one you are looking for is the CSV file (THUALB_2022_04-233568-4-GPE3.csv).\nYou don’t have to move this file into the data folder for this exercise. It is already there.\n\nBut if you download the file for a different animal track you would need to put the CSV file into the folder."
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#import-the-track-data-into-a-data-frame",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#import-the-track-data-into-a-data-frame",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Import csv file into a data frame\nfile = \"../data/THUALB_2022_04-233568-5-GPE3.csv\"\npre_tuna_df &lt;- read.csv(file, skip = 5)\n\n# Show 3 rows from the data frame\nhead(pre_tuna_df, 3)\n##         DeployID    Ptt                 Date Most.Likely.Latitude\n## 1 THUALB_2022_04 233568 31-May-2022 19:00:00                5.875\n## 2 THUALB_2022_04 233568 01-Jun-2022 00:00:00                5.875\n## 3 THUALB_2022_04 233568 01-Jun-2022 04:56:15                5.850\n##   Most.Likely.Longitude Observation.Type Observed.SST Satellite.SST\n## 1              -162.125             User           NA            NA\n## 2              -162.100             None           NA            NA\n## 3              -161.975     Light - Dusk           NA            NA\n##   Observed.Depth Bathymetry.Depth Observation.LL..MSS. Observation.Score\n## 1             NA               NA                   NA          68.60585\n## 2             NA               NA                   NA                NA\n## 3            144             2908                   NA          43.16747\n##                Sunrise               Sunset\n## 1                                          \n## 2 01-Jun-2022 16:33:04 02-Jun-2022 04:59:36\n## 3\n# Convert longitudes to 0~360 (Re-center map to the dateline)\npre_tuna_df['Most.Likely.Longitude'] &lt;- pre_tuna_df['Most.Likely.Longitude'] + 360\n# Show converted data frame\nhead(pre_tuna_df, 3)\n##         DeployID    Ptt                 Date Most.Likely.Latitude\n## 1 THUALB_2022_04 233568 31-May-2022 19:00:00                5.875\n## 2 THUALB_2022_04 233568 01-Jun-2022 00:00:00                5.875\n## 3 THUALB_2022_04 233568 01-Jun-2022 04:56:15                5.850\n##   Most.Likely.Longitude Observation.Type Observed.SST Satellite.SST\n## 1               197.875             User           NA            NA\n## 2               197.900             None           NA            NA\n## 3               198.025     Light - Dusk           NA            NA\n##   Observed.Depth Bathymetry.Depth Observation.LL..MSS. Observation.Score\n## 1             NA               NA                   NA          68.60585\n## 2             NA               NA                   NA                NA\n## 3            144             2908                   NA          43.16747\n##                Sunrise               Sunset\n## 1                                          \n## 2 01-Jun-2022 16:33:04 02-Jun-2022 04:59:36\n## 3"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#convert-date-string-to-a-date-object",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#convert-date-string-to-a-date-object",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "pre_tuna_df$Date &lt;- as.Date(pre_tuna_df$Date, format = \"%d-%b-%Y\")\nhead(pre_tuna_df)\n##         DeployID    Ptt       Date Most.Likely.Latitude Most.Likely.Longitude\n## 1 THUALB_2022_04 233568 2022-05-31                5.875               197.875\n## 2 THUALB_2022_04 233568 2022-06-01                5.875               197.900\n## 3 THUALB_2022_04 233568 2022-06-01                5.850               198.025\n## 4 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n## 5 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n## 6 THUALB_2022_04 233568 2022-06-01                5.900               198.025\n##   Observation.Type Observed.SST Satellite.SST Observed.Depth Bathymetry.Depth\n## 1             User           NA            NA             NA               NA\n## 2             None           NA            NA             NA               NA\n## 3     Light - Dusk           NA            NA            144             2908\n## 4             None           NA            NA             NA               NA\n## 5              SST         28.2      28.32458              1             2908\n## 6     Light - Dawn           NA            NA            112             2908\n##   Observation.LL..MSS. Observation.Score              Sunrise\n## 1                   NA          68.60585                     \n## 2                   NA                NA 01-Jun-2022 16:33:04\n## 3                   NA          43.16747                     \n## 4                   NA                NA                     \n## 5                   NA          76.62995                     \n## 6                   NA          54.92253                     \n##                 Sunset\n## 1                     \n## 2 02-Jun-2022 04:59:36\n## 3                     \n## 4                     \n## 5                     \n## 6"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#bin-multiple-observations-from-each-day-into-daily-mean-values",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#bin-multiple-observations-from-each-day-into-daily-mean-values",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "The track data has multiple longitude/latitude/time points for each date. That temporal resolution is much higher than the daily and month satellite datasets that are available. So, let’s reduce the multiple daily values for the animal track data to a single value for each day. The code below creates a new dataframe that bins data for each date and calculates the mean for selected columns.\nlibrary(dplyr)\ntuna_df &lt;- pre_tuna_df %&gt;% group_by(Date) %&gt;% summarize(Most.Likely.Latitude = mean(Most.Likely.Latitude),\n                                         Most.Likely.Longitude = mean(Most.Likely.Longitude),\n                                         Satellite.SST = mean(Satellite.SST, na.rm=TRUE),\n                                         Observed.SST = mean(Observed.SST, na.rm=TRUE),\n                                         Observed.Depth = mean(Observed.Depth, na.rm=TRUE),\n                                         Bathymetry.Depth = mean(Bathymetry.Depth, na.rm=TRUE),\n                                         )\n\ntuna_df\n## # A tibble: 177 × 7\n##    Date       Most.Likely.Latitude Most.Likely.Longitude Satellite.SST\n##    &lt;date&gt;                    &lt;dbl&gt;                 &lt;dbl&gt;         &lt;dbl&gt;\n##  1 2022-05-31                 5.88                  198.         NaN  \n##  2 2022-06-01                 5.88                  198           28.3\n##  3 2022-06-02                 5.92                  198.          28.3\n##  4 2022-06-03                 5.92                  198.          28.3\n##  5 2022-06-04                 5.98                  198.          28.3\n##  6 2022-06-05                 6.11                  198.          28.4\n##  7 2022-06-06                 6.28                  198.          28.3\n##  8 2022-06-07                 6.45                  197.          28.3\n##  9 2022-06-08                 6.51                  197.          28.2\n## 10 2022-06-09                 6.78                  197.          28.2\n## # ℹ 167 more rows\n## # ℹ 3 more variables: Observed.SST &lt;dbl&gt;, Observed.Depth &lt;dbl&gt;,\n## #   Bathymetry.Depth &lt;dbl&gt;"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#plot-the-track-on-a-map",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#plot-the-track-on-a-map",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Download world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Map tuna tracks\nggplot(tuna_df, aes(Most.Likely.Longitude,Most.Likely.Latitude)) +\n  geom_path(group=1)+\n  geom_point(aes(x=Most.Likely.Longitude,y=Most.Likely.Latitude), pch=1, size=2 )+\n  geom_point(aes(x=Most.Likely.Longitude[1],y=Most.Likely.Latitude[1]),fill=\"green\", shape=24, size=3)+\n  geom_point(aes(x=Most.Likely.Longitude[length(Most.Likely.Longitude)],y=Most.Likely.Latitude[length(Most.Likely.Latitude)]), shape=22, size=3, fill=\"red\")+\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26))+\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with start (green) and end location (red)\")+\n  theme(plot.title=element_text(hjust=0.5), aspect.ratio=0.6)\n\nIn this exercise, two different ways of extracting data from ERDDAP data server along a track of xyt points are demonstrated:\n\nUsing the rerddapXtracto package which was written specifically for this task\nFor those who want to know what goes on “under the hood”, we will show how to manually construct ERDDAP data-request URLs to download the data.\n\n\n\nWe will use the `rxtracto function of the rerddapXtracto package, which was written to simplify data extraction from ERDDAP servers.\nLet’s use data from the monthly product of the OC-CCI datasets.\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data are severely affected by clouds (i.e. lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer data gaps.\nThe ERDDAP URL to the monthly product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-12-01 (at the day of this writing), which covers the track time range of 2022-05-30 to 2023-01-18.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n# Set dataset ID\ndataset &lt;- 'esa-cci-chla-monthly-v6-0'\n\n# Get data information from ERDDAP server\ndataInfo &lt;- rerddap::info(dataset, url= \"https://oceanwatch.pifsc.noaa.gov/erddap\")"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#examine-metadata",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#examine-metadata",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "rerddap::info returns the metadata of the requested dataset. We can first understand the attributes dataInfo includes then examine each attribute.\n# Display the metadata\ndataInfo\n## &lt;ERDDAP info&gt; esa-cci-chla-monthly-v6-0 \n##  Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (1997-09-04T00:00:00Z, 2023-12-01T00:00:00Z) \n##      latitude: (-89.97916666666666, 89.97916666666667) \n##      longitude: (0.020833333333314386, 359.97916666666663) \n##  Variables:  \n##      chlor_a: \n##          Units: mg m-3 \n##      chlor_a_log10_bias: \n##      chlor_a_log10_rmsd: \n##      MERIS_nobs_sum: \n##      MODISA_nobs_sum: \n##      OLCI_A_nobs_sum: \n##      OLCI_B_nobs_sum: \n##      SeaWiFS_nobs_sum: \n##      total_nobs_sum: \n##      VIIRS_nobs_sum:\n# Display data attributes\nnames(dataInfo)\n## [1] \"variables\" \"alldata\"   \"base_url\"\n# Examine attribute: variables\ndataInfo$variables\n##         variable_name data_type actual_range\n## 1             chlor_a     float             \n## 2  chlor_a_log10_bias     float             \n## 3  chlor_a_log10_rmsd     float             \n## 4      MERIS_nobs_sum     float             \n## 5     MODISA_nobs_sum     float             \n## 6     OLCI_A_nobs_sum     float             \n## 7     OLCI_B_nobs_sum     float             \n## 8    SeaWiFS_nobs_sum     float             \n## 9      total_nobs_sum     float             \n## 10     VIIRS_nobs_sum     float\n# Distribute attributes of dataInfo$alldata\nnames(dataInfo$alldata)\n##  [1] \"NC_GLOBAL\"          \"time\"               \"latitude\"          \n##  [4] \"longitude\"          \"chlor_a\"            \"MERIS_nobs_sum\"    \n##  [7] \"MODISA_nobs_sum\"    \"OLCI_A_nobs_sum\"    \"OLCI_B_nobs_sum\"   \n## [10] \"SeaWiFS_nobs_sum\"   \"VIIRS_nobs_sum\"     \"chlor_a_log10_bias\"\n## [13] \"chlor_a_log10_rmsd\" \"total_nobs_sum\"\n\n\nFirst we need to define the bounding box within which to search for coordinates. The rxtracto function allows you to set the size of the box used to collect data around the track points using the xlen and ylen arguments. The values for xlen and ylen are in degrees. For our example, we can use 0.2 degrees for both arguments. Note: You can also submit vectors for xlen and ylen, as long as they are the same length as xcoord, ycoord, and tcoord if you want to set a different search radius around each track point.\n# Set the variable we want to extract data from:\nparameter &lt;- 'chlor_a'\n\n# Set xlen, ylen to 0.2 degree\nxlen &lt;- 0.2 \nylen &lt;- 0.2\n\n# Create date column using year, month and day in a format ERDDAP will understand (eg. 2008-12-15)\n#tuna_df$date &lt;-as.Date(tuna_df$Date, format = \"%d-%b-%Y\")\n\n# Get variables x, y, t coordinates from tuna track data\nxcoords &lt;- tuna_df$Most.Likely.Longitude\nycoords &lt;- tuna_df$Most.Likely.Latitude\ntcoords &lt;- tuna_df$Date\n\n# Extract satellite data using x, y, t coordinates from tuna track data\nchl_track &lt;- rxtracto(dataInfo, \n                  parameter=parameter, \n                  xcoord=xcoords, ycoord=ycoords, \n                  tcoord=tcoords, xlen=xlen, ylen=ylen)"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#check-the-output-of-the-rxtracto-function",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#check-the-output-of-the-rxtracto-function",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "# Check all variables extracted using rxtracto\nstr(chl_track)\n## List of 13\n##  $ mean chlor_a     : num [1:177] 0.35 0.34 0.349 0.367 0.276 ...\n##  $ stdev chlor_a    : num [1:177] 0.373 0.372 0.373 0.407 0.154 ...\n##  $ n                : int [1:177] 36 36 36 30 25 36 30 36 36 30 ...\n##  $ satellite date   : chr [1:177] \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" \"2022-06-01T00:00:00Z\" ...\n##  $ requested lon min: num [1:177] 198 198 198 198 198 ...\n##  $ requested lon max: num [1:177] 198 198 198 198 198 ...\n##  $ requested lat min: num [1:177] 5.78 5.79 5.83 5.83 5.88 ...\n##  $ requested lat max: num [1:177] 5.97 5.98 6.02 6.02 6.08 ...\n##  $ requested z min  : logi [1:177] NA NA NA NA NA NA ...\n##  $ requested z max  : logi [1:177] NA NA NA NA NA NA ...\n##  $ requested date   : chr [1:177] \"2022-05-31\" \"2022-06-01\" \"2022-06-02\" \"2022-06-03\" ...\n##  $ median chlor_a   : num [1:177] 0.235 0.227 0.232 0.236 0.232 ...\n##  $ mad chlor_a      : num [1:177] 0.017 0.0148 0.0172 0.0151 0.0192 ...\n##  - attr(*, \"row.names\")= chr [1:177] \"1\" \"2\" \"3\" \"4\" ...\n##  - attr(*, \"class\")= chr [1:2] \"list\" \"rxtractoTrack\"\n##  - attr(*, \"base_url\")= chr \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\n##  - attr(*, \"datasetid\")= chr \"esa-cci-chla-monthly-v6-0\"\nrxtracto computes statistics using all the pixels found in the search radius around each track point."
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#plotting-the-results-using-plottrack",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#plotting-the-results-using-plottrack",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "We will use the “plotTrack” function to plot the results. “plotTrack” is a function of the “rerddapXtracto” package designed specifically to plot the results of the “rxtracto” function. It provides an easy way to make a quick plot, however it’s not very customizable.\n# Plot tracks with color: algae specifically designed for chlorophyll\nplotTrack(chl_track, xcoords, ycoords, tcoords, size=3, plotColor = 'viridis')"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#animating-the-track",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#animating-the-track",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "One of the nice features of the “plotTrack” function is that it is very easy to make an animation of the track data. This will take a minute to run. It creates an animated gif that will display in the Rstudio viewer window once the encoding to gif is done. Note: this works with but doesn’t require the latest versions of R Studio or rerddapXtracto package (e.g., it works with R Studio Version 2023.12.1+402 and rerddapXtracto version 1.1.5).\n# Animate tracks\n\nmake180 &lt;- function(lon) {\n    ind &lt;- which(lon &gt; 180)\n    lon[ind] &lt;- lon[ind] - 360\n   return(lon)\n}\n\nplotTrack(chl_track,\n          make180(xcoords),\n          ycoords, tcoords,\n          plotColor = 'viridis',\n          animate = TRUE,\n          cumulative = TRUE)\n## # A tibble: 177 × 7\n##    format width height colorspace matte filesize density\n##    &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n##  1 gif      672    480 sRGB       TRUE         0 72x72  \n##  2 gif      672    480 sRGB       TRUE         0 72x72  \n##  3 gif      672    480 sRGB       TRUE         0 72x72  \n##  4 gif      672    480 sRGB       TRUE         0 72x72  \n##  5 gif      672    480 sRGB       TRUE         0 72x72  \n##  6 gif      672    480 sRGB       TRUE         0 72x72  \n##  7 gif      672    480 sRGB       TRUE         0 72x72  \n##  8 gif      672    480 sRGB       TRUE         0 72x72  \n##  9 gif      672    480 sRGB       TRUE         0 72x72  \n## 10 gif      672    480 sRGB       TRUE         0 72x72  \n## # ℹ 167 more rows"
  },
  {
    "objectID": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#plotting-the-results-using-ggplot",
    "href": "tutorials/r/matchup-satellite-data-to-ATN_track-locations.html#plotting-the-results-using-ggplot",
    "title": "Matchup Satellite data to track locations",
    "section": "",
    "text": "If we to do an customization of the plot, its better to plot the data using ggplot. We will first create a data frame that contains longitudes and latitudes from the tuna and associated satellite chlor-a values.\n# Create a data frame of coords from tuna and chlor_a values \nnew_df &lt;- as.data.frame(cbind(xcoords, ycoords,  \n                              chl_track$`requested lon min`, \n                              chl_track$`requested lon max`, \n                              chl_track$`requested lat min`, \n                              chl_track$`requested lon max`,  \n                              chl_track$`mean chlor_a`)\n                        )\n\n# Set variable names\nnames(new_df) &lt;- c(\"Lon\", \n                   \"Lat\", \n                   \"Matchup_Lon_Lower\",\n                   \"Matchup_Lon_Upper\",\n                   \"Matchup_Lat_Lower\",\n                   \"Matchup_Lat_Upper\", \n                   \"Chlor_a\")\n\nwrite.csv(new_df, \"tuna_matchup_df.csv\")\n\n\n\n# Import world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Draw the track positions with associated chlora values\nggplot(new_df) +\n  geom_point(aes(Lon,Lat,color=log(Chlor_a))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with chlor-a values\") +\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nFirst we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\ndata_url = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a\"\nFor a refresher of how to construct an ERDDAP data-request URL, please review the ERDDAP tutorial “04-Erddapurl.md” at the following link: https://github.com/coastwatch-training/CoastWatch-Tutorials/blob/main/ERDDAP-basics/lessons/\n# Set erddap address\nerddap_base_url &lt;- \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a\"\n\n# Get longitude and latitude from tuna track data\nlon &lt;- tuna_df$Most.Likely.Longitude\nlat &lt;- tuna_df$Most.Likely.Latitude\n\n# Get time from tuna track data and convert into ERDDAP date format\ndates2 &lt;- as.Date(tuna_df$Date, format = \"%d-%b-%Y\")\n\n# Initatilize tot variable where data will be downloaded to\ntot &lt;- rep(NA, 4)\n\n# Loop through each tuna track data\nfor (i in 1:dim(tuna_df)[1]) {\n\n  # follow the progress of the loop\n  cat(\"\\014\")\n  cat(\" Loop \", i, \" of \", dim(tuna_df)[1])\n  \n  # Create erddap URL by adding lat, lon, dates of each track point \n   url &lt;-  paste(erddap_base_url,\n                 \"[(\", dates2[i], \"):1:(\", dates2[i],\n                 \")][(\", lat[i], \"):1:(\", lat[i],\n                 \")][(\", lon[i], \"):1:(\", lon[i], \")]\", sep = \"\")  \n   \n   # Request and load satelite data from ERDDAP\n   new &lt;- read.csv(url, skip=2, header = FALSE) \n   \n   # Append the data\n   tot &lt;- rbind(tot, new)   \n   \n}\n## \f Loop  1  of  177\f Loop  2  of  177\f Loop  3  of  177\f Loop  4  of  177\f Loop  5  of  177\f Loop  6  of  177\f Loop  7  of  177\f Loop  8  of  177\f Loop  9  of  177\f Loop  10  of  177\f Loop  11  of  177\f Loop  12  of  177\f Loop  13  of  177\f Loop  14  of  177\f Loop  15  of  177\f Loop  16  of  177\f Loop  17  of  177\f Loop  18  of  177\f Loop  19  of  177\f Loop  20  of  177\f Loop  21  of  177\f Loop  22  of  177\f Loop  23  of  177\f Loop  24  of  177\f Loop  25  of  177\f Loop  26  of  177\f Loop  27  of  177\f Loop  28  of  177\f Loop  29  of  177\f Loop  30  of  177\f Loop  31  of  177\f Loop  32  of  177\f Loop  33  of  177\f Loop  34  of  177\f Loop  35  of  177\f Loop  36  of  177\f Loop  37  of  177\f Loop  38  of  177\f Loop  39  of  177\f Loop  40  of  177\f Loop  41  of  177\f Loop  42  of  177\f Loop  43  of  177\f Loop  44  of  177\f Loop  45  of  177\f Loop  46  of  177\f Loop  47  of  177\f Loop  48  of  177\f Loop  49  of  177\f Loop  50  of  177\f Loop  51  of  177\f Loop  52  of  177\f Loop  53  of  177\f Loop  54  of  177\f Loop  55  of  177\f Loop  56  of  177\f Loop  57  of  177\f Loop  58  of  177\f Loop  59  of  177\f Loop  60  of  177\f Loop  61  of  177\f Loop  62  of  177\f Loop  63  of  177\f Loop  64  of  177\f Loop  65  of  177\f Loop  66  of  177\f Loop  67  of  177\f Loop  68  of  177\f Loop  69  of  177\f Loop  70  of  177\f Loop  71  of  177\f Loop  72  of  177\f Loop  73  of  177\f Loop  74  of  177\f Loop  75  of  177\f Loop  76  of  177\f Loop  77  of  177\f Loop  78  of  177\f Loop  79  of  177\f Loop  80  of  177\f Loop  81  of  177\f Loop  82  of  177\f Loop  83  of  177\f Loop  84  of  177\f Loop  85  of  177\f Loop  86  of  177\f Loop  87  of  177\f Loop  88  of  177\f Loop  89  of  177\f Loop  90  of  177\f Loop  91  of  177\f Loop  92  of  177\f Loop  93  of  177\f Loop  94  of  177\f Loop  95  of  177\f Loop  96  of  177\f Loop  97  of  177\f Loop  98  of  177\f Loop  99  of  177\f Loop  100  of  177\f Loop  101  of  177\f Loop  102  of  177\f Loop  103  of  177\f Loop  104  of  177\f Loop  105  of  177\f Loop  106  of  177\f Loop  107  of  177\f Loop  108  of  177\f Loop  109  of  177\f Loop  110  of  177\f Loop  111  of  177\f Loop  112  of  177\f Loop  113  of  177\f Loop  114  of  177\f Loop  115  of  177\f Loop  116  of  177\f Loop  117  of  177\f Loop  118  of  177\f Loop  119  of  177\f Loop  120  of  177\f Loop  121  of  177\f Loop  122  of  177\f Loop  123  of  177\f Loop  124  of  177\f Loop  125  of  177\f Loop  126  of  177\f Loop  127  of  177\f Loop  128  of  177\f Loop  129  of  177\f Loop  130  of  177\f Loop  131  of  177\f Loop  132  of  177\f Loop  133  of  177\f Loop  134  of  177\f Loop  135  of  177\f Loop  136  of  177\f Loop  137  of  177\f Loop  138  of  177\f Loop  139  of  177\f Loop  140  of  177\f Loop  141  of  177\f Loop  142  of  177\f Loop  143  of  177\f Loop  144  of  177\f Loop  145  of  177\f Loop  146  of  177\f Loop  147  of  177\f Loop  148  of  177\f Loop  149  of  177\f Loop  150  of  177\f Loop  151  of  177\f Loop  152  of  177\f Loop  153  of  177\f Loop  154  of  177\f Loop  155  of  177\f Loop  156  of  177\f Loop  157  of  177\f Loop  158  of  177\f Loop  159  of  177\f Loop  160  of  177\f Loop  161  of  177\f Loop  162  of  177\f Loop  163  of  177\f Loop  164  of  177\f Loop  165  of  177\f Loop  166  of  177\f Loop  167  of  177\f Loop  168  of  177\f Loop  169  of  177\f Loop  170  of  177\f Loop  171  of  177\f Loop  172  of  177\f Loop  173  of  177\f Loop  174  of  177\f Loop  175  of  177\f Loop  176  of  177\f Loop  177  of  177\n# Delete the first row (default column names)\ntot &lt;- tot[-1, ]\n\n# Rename columns\nnames(tot) &lt;- c(\"chlo_date\", \"matched_lat\", \"matched_lon\", \"matched_chl.m\")\n\n# Create data frame combining tuna track data and the chlo-a data\nchl_track2 &lt;- data.frame(tuna_df, tot)\n\n# Write the data frame to csv file\nwrite.csv(chl_track2, 'tuna-track-chl.m.csv', row.names = FALSE)\n\n\n\n# Draw the track positions with associated chlora values\nggplot(chl_track2) +\n  geom_point(aes(Most.Likely.Longitude,Most.Likely.Latitude,color=log(matched_chl.m))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(180,220),ylim = c(0,26)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Yellowfin Tuna Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\nHow do the chlorophyll values of the tuna track compare to values in the surrounding environment? Meaning does the tuna seem to have a preference for certain chlorophyll values? To look at this we will plot a histograms of the track chl valuesand those of the surrounding area.\nFirst we will get a 3D block of chl data from the region and of the tuna track over the span of time the tuna was in that area. We will use the ‘xtracto_3d’ function of rerddapXtracto to get the data. This data call will take a few minutes.\nchl_grid &lt;- rxtracto_3D(dataInfo, \n                  parameter=parameter, \n                  xcoord=c(min(xcoords),max(xcoords)), \n                  ycoord=c(min(ycoords),max(ycoords)), \n                  tcoord=c(min(tcoords),max(tcoords)))\n\nchl_area &lt;- as.vector(chl_grid$chlor_a) \n\n# remove NA values \nchl_area &lt;- chl_area[!is.na(chl_area)]\n\n# vector or tuna chlorophyll \n\nchl_tuna &lt;- chl_track$`mean chlor_a`\nNow we we plot histograms of all the chlorphyll values in the area, and those of the tuna track.\nggplot(as.data.frame(chl_area)) + \n      geom_histogram(aes(x=chl_area,y=after_stat(density),color = \"darkgray\",fill='Area'),color='black', bins=50) + \n      geom_histogram(data=as.data.frame(chl_tuna), aes(x=chl_tuna,y=after_stat(density),color='green', fill='Tuna'),color='black',bins=50, alpha=.4) + \n      scale_x_continuous(limits = c(0,.9), expand = c(0, 0)) + \n      scale_y_continuous(limits = c(0,15), expand = c(0, 0)) +\n      labs(x='Chlorophyll values',y='Density') + \n      theme_bw() + \n      scale_fill_manual(values=c(\"darkgray\",\"green\"),'')\n\n\n\nRepeat the steps above with a different satellite dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html \\ This dataset is a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name.\n\n\n\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ \\ This dataset will likely be on a different ERDDAP, so remember to change the base URL. \\ Set the new dataset ID and variable name. \\ Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\n\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorDaily_Lon0360.html"
  },
  {
    "objectID": "tutorials/r/matchup_satellite_buoy_data.html",
    "href": "tutorials/r/matchup_satellite_buoy_data.html",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "history | Updated March 2024\n\n\n\nThere are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov) and the ARGO floats program (http://www.argo.ucsd.edu). In situ buoy data are widely used to monitor environmental conditions.\nIn-situ buoy data can be used to evaluate the accuracy of satellite data.\n\n\n\nIn this exercise, we will learn how to match up satellite data to in situ buoy data using rerddap and rxtracto R packages.\n\n\n\n\nDownloading tabular data (buoy data) from CoastWatch ERDDAP data server\nRetrieving information about a dataset from ERDDAP\nSubsetting satellite data within a rectangular boundary\nMatching satellite data with the buoy data\nRunning statistical analysis to compare buoy and satellite data\nProducing satellite maps and overlaying buoy data\n\n\n\n\n\nThe sea surface temperature (SST) satellite data from the NOAA Geo-polar blended analysis\n The NDBC Standard Meteorological Buoy Data (dataset ID: cwwcNDBCMet)  is used for validating or ground truthing the satellite SST data\n\n\n\n\n# Function to check if pkgs are installed, install missing pkgs, and load\n\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE)\n    if(!require(x,character.only = TRUE)) stop(\"Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ncdf4\", \"rerddap\", \"plotdap\", \"httr\",\n                       \"lubridate\", \"gridGraphics\",  \"mapdata\",\n                       \"ggplot2\", \"RColorBrewer\", \"grid\", \"PBSmapping\", \n                       \"rerddapXtracto\",\"dplyr\",\"viridis\",\"cmocean\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\nExtract data using the rerddap::tabledap function\nUsing rerddap::tabledap function, we will request and download data with the following specifications:\n\nBuoy dataset ID: cwwcNDBCMet\nRegion boundaries: 35 to 40 north latitude and -125 to -120 east longitude\n\nTime span: 08/01/2023 to 08/10/2023\nVariables: station, latitude, longitude, time, and water temperature parameters\n\n# Subset and download tabular data from ERDDAP \n\nERDDAP_Node = \"https://coastwatch.pfeg.noaa.gov/erddap\"\n\nNDBC_id = 'cwwcNDBCMet'\nNDBC_info=info(datasetid = NDBC_id,url = ERDDAP_Node)\n\nbuoy &lt;- rerddap::tabledap( url = ERDDAP_Node, NDBC_id,\n  fields=c('station', 'latitude',  'longitude', 'time', 'wtmp'), \n  'time&gt;=2023-08-01',   'time&lt;=2023-08-10', \n  'latitude&gt;=35','latitude&lt;=40', 'longitude&gt;=-125','longitude&lt;=-120',\n  'wtmp&gt;0'\n)\n\n#Create data frame with the downloaded data\nbuoy.df &lt;-data.frame(station=buoy$station,\n                     longitude=as.numeric(buoy$longitude),\n                     latitude=as.numeric(buoy$latitude),\n                     time=strptime(buoy$time, \"%Y-%m-%dT%H:%M:%S\"),\n                     temp=as.numeric(buoy$wtmp))\n\n# Check for unique stations\nunique.sta &lt;- unique(buoy$sta)\nn.sta &lt;- length(unique.sta)\nn.sta\n## [1] 24\nsummary(buoy.df)\n##    station            longitude         latitude    \n##  Length:28725       Min.   :-124.0   Min.   :35.18  \n##  Class :character   1st Qu.:-123.1   1st Qu.:36.79  \n##  Mode  :character   Median :-122.2   Median :37.81  \n##                     Mean   :-122.3   Mean   :37.40  \n##                     3rd Qu.:-121.9   3rd Qu.:38.06  \n##                     Max.   :-120.8   Max.   :39.20  \n##       time                             temp      \n##  Min.   :2023-08-01 00:00:00.00   Min.   : 9.10  \n##  1st Qu.:2023-08-03 03:48:00.00   1st Qu.:11.90  \n##  Median :2023-08-05 09:18:00.00   Median :13.90  \n##  Mean   :2023-08-05 10:14:05.06   Mean   :14.95  \n##  3rd Qu.:2023-08-07 16:36:00.00   3rd Qu.:16.60  \n##  Max.   :2023-08-10 00:00:00.00   Max.   :23.90\nPlot the buoy data for the first 10 stations in buoy.df\nLet’s see what the buoy data looks like for our time period.\nplot(buoy.df$time, buoy.df$temp, type='n', xlab='Date', ylab='SST (ºC)',main='SST from the first 10 stations')\n\n\nfor (i in 1:10){\n  I=which(buoy.df$station==unique.sta[i])\n  lines(buoy.df$time[I],buoy.df$temp[I])\n}\n\nSelect buoy data closest in time to satellite data\nSince buoy data are hourly and the satellite data are daily, the buoy data needs to be averaged daily for each station.\nbuoy.df.day=buoy.df %&gt;%\n  mutate(date = floor_date(time, unit=\"days\")) %&gt;%\n  group_by(station, date) %&gt;%\n  summarize(\n    lon=mean(longitude),\n    lat=mean(latitude),\n    temp.day=mean(temp),\n    .groups=\"drop\"\n    )\n\nhead(buoy.df.day)\n## # A tibble: 6 × 5\n##   station date                  lon   lat temp.day\n##   &lt;chr&gt;   &lt;dttm&gt;              &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n## 1 46013   2023-08-01 00:00:00 -123.  38.2     10.4\n## 2 46013   2023-08-02 00:00:00 -123.  38.2     10.7\n## 3 46013   2023-08-03 00:00:00 -123.  38.2     10.6\n## 4 46013   2023-08-04 00:00:00 -123.  38.2     10.4\n## 5 46013   2023-08-05 00:00:00 -123.  38.2     10.7\n## 6 46013   2023-08-06 00:00:00 -123.  38.2     10.6\n\n\n\nWe will use Sea surface temperature (SST) satellite data from CoastWatch West code node ERDDAP server.\nURL: https://coastwatch.pfeg.noaa.gov/erddap/ Dataset ID:nesdisBLENDEDsstDNDaily\nurl=  'https://coastwatch.pfeg.noaa.gov/erddap/'\ndatasetid = 'nesdisBLENDEDsstDNDaily'\n\n# Get Data Information given dataset ID and URL\ndataInfo &lt;- rerddap::info(datasetid, url)\n\n# Show data Info\ndataInfo\n## &lt;ERDDAP info&gt; nesdisBLENDEDsstDNDaily \n##  Base URL: https://coastwatch.pfeg.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (2019-07-22T12:00:00Z, 2024-03-20T12:00:00Z) \n##      latitude: (-89.975, 89.975) \n##      longitude: (-179.975, 179.975) \n##  Variables:  \n##      analysed_sst: \n##          Units: degree_C \n##      analysis_error: \n##          Units: degree_C \n##      mask: \n##      sea_ice_fraction: \n##          Units: 1\nExtract the matchup data using rxtracto\nWe will extract satellite data for each buoy station.\n1. get coordinates of each buoy station 2. use the rxtracto function and the buoy coordinates to download satellite data closest to each station\n# Set the variable name of interest from the satellite data\nparameter &lt;- 'analysed_sst'\n\n# Set x,y,t,z coordinates based on buoy data\nxcoord &lt;- buoy.df.day$lon\nycoord &lt;- buoy.df.day$lat\ntcoord &lt;- buoy.df.day$date\n\n\n# Extract satellite data \nextract &lt;- rxtracto(dataInfo, parameter=parameter, \n                    tcoord=tcoord,\n                    xcoord=xcoord,\n                    ycoord=ycoord,\n                    xlen=.01,ylen=.01)\n                     \nbuoy.df.day$sst&lt;-extract$`mean analysed_sst`\nGet subset of data where a satellite value was found\n\nOur satellite product is gap-free (gaps due to clouds were filled using some interpolation) but it has a spatial resolution of 5km. Some buoy stations may be so close to shore that they end up in the landmask of the satellite data. So let’s find the stations that were matched up to an SST pixel.\n\n# Get subset of data where there is a satellite value \ngoodbuoy&lt;-subset(buoy.df.day, sst &gt; 0)\nunique.sta&lt;-unique(goodbuoy$station)\nnbuoy&lt;-length(unique.sta)\nndata&lt;-length(goodbuoy$station)\n\n\n\n\nPlot the satellite SST verses the buoy temperature to visualize how well the two datasets match each other.\n\n# Set up map title \nmain=\"California coast, 8/1/23-8/10/23\"   \n\np &lt;- ggplot(goodbuoy, aes(temp.day, sst,color=lat)) + \n     coord_fixed(xlim=c(8,25),ylim=c(8,25)) \np + geom_point() + \n  ylab('Satellite SST')  + \n  xlab('Buoy average daily SST') +\n  scale_x_continuous(minor_breaks = seq(8, 25)) + \n  scale_y_continuous(minor_breaks = seq(8, 25)) + \n  #geom_abline(a=fit[1],b=fit[2]) +\n  #annotation_custom(my_grob) + \n  #scale_color_gradientn(colours = \"viridis\", name=\"Buoy\\nLatitude\") +\n  scale_color_viridis(discrete = FALSE, name=\"Buoy\\nLatitude\") +\n  labs(title=main) + theme(plot.title = element_text(size=20, face=\"bold\", vjust=2)) \n\nRun a linear regression of Blended SST versus the buoy data. * The R squared is close to 1 (0.8733) * The slope is 0.7151\nlmHeight = lm(sst~temp.day, data = goodbuoy)\nsummary(lmHeight)\n## \n## Call:\n## lm(formula = sst ~ temp.day, data = goodbuoy)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -2.21936 -0.47676  0.02142  0.40927  2.19949 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  3.65951    0.27549   13.28   &lt;2e-16 ***\n## temp.day     0.71469    0.01976   36.17   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7322 on 195 degrees of freedom\n## Multiple R-squared:  0.8703, Adjusted R-squared:  0.8696 \n## F-statistic:  1309 on 1 and 195 DF,  p-value: &lt; 2.2e-16\n\n\n\nExtract blended SST data for August 1st, 2023\n# First define the box and time limits of the requested data \nylim&lt;-c(32,42)\nxlim&lt;-c(-127,-118)\n\n# Extract the monthly satellite data\nSST &lt;- rxtracto_3D(dataInfo,xcoord=xlim,ycoord=ylim,parameter=parameter, \n                   tcoord=c('2023-08-01','2023-08-01'))\n\nSST$sst &lt;- drop(SST$analysed_sst)\nCreate the map frame for the satellite data and buoy SST overlay\nmapFrame&lt;- function(longitude,latitude,sst){\n  dims&lt;-dim(sst)\n  sst&lt;-array(sst,dims[1]*dims[2])\n  sstFrame&lt;-expand.grid(x=longitude,y=latitude)\n  sstFrame$sst&lt;-sst\n  return(sstFrame)\n}\n\nsstFrame&lt;-mapFrame(SST$longitude,SST$latitude,SST$sst)\ncoast &lt;- map_data(\"worldHires\", ylim = ylim, xlim = xlim)\nmy.col &lt;- colorRampPalette(rev(brewer.pal(11, \"RdYlBu\")))(22-13) \n\nbuoy2&lt;-subset(buoy.df.day, month(date)==8 &day(date)==1 & temp.day &gt; 0)\nCreate the map\nmyplot&lt;-ggplot(data = sstFrame, aes(x = x, y = y, fill = sst)) +\n  geom_tile(na.rm=T) +\n  geom_polygon(data = coast, aes(x=long, y = lat, group = group), fill = \"grey80\") +\n  theme_bw(base_size = 15) + ylab(\"Latitude\") + xlab(\"Longitude\") +\n  coord_fixed(1.3,xlim = xlim, ylim = ylim) +\n  scale_fill_cmocean(name = 'thermal',limits=c(10,25),na.value = NA) +\n  ggtitle(paste(\"Satellite SST and buoy temperature (circles) \\n\", unique(as.Date(SST$time)))) +\n  geom_point(data=buoy2, aes(x=lon,y=lat,color=temp.day),size=3,shape=21,color=\"black\") + \n  scale_color_cmocean(name = 'thermal',limits=c(10,25),na.value =\"grey20\") \n  \nmyplot\n\n\n\n\n\nNOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center\nRerddap R Package reference"
  },
  {
    "objectID": "tutorials/r/matchup_satellite_buoy_data.html#background",
    "href": "tutorials/r/matchup_satellite_buoy_data.html#background",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "There are buoys in many locations around the world that provide data streams of oceanic and atmospheric parameters. The data are often available through data centers like the National Data Buoy Center (NDBC https://www.ndbc.noaa.gov) and the ARGO floats program (http://www.argo.ucsd.edu). In situ buoy data are widely used to monitor environmental conditions.\nIn-situ buoy data can be used to evaluate the accuracy of satellite data."
  },
  {
    "objectID": "tutorials/r/matchup_satellite_buoy_data.html#objective",
    "href": "tutorials/r/matchup_satellite_buoy_data.html#objective",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "In this exercise, we will learn how to match up satellite data to in situ buoy data using rerddap and rxtracto R packages."
  },
  {
    "objectID": "tutorials/r/matchup_satellite_buoy_data.html#the-exercise-demonstrates-the-following-techniques",
    "href": "tutorials/r/matchup_satellite_buoy_data.html#the-exercise-demonstrates-the-following-techniques",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "Downloading tabular data (buoy data) from CoastWatch ERDDAP data server\nRetrieving information about a dataset from ERDDAP\nSubsetting satellite data within a rectangular boundary\nMatching satellite data with the buoy data\nRunning statistical analysis to compare buoy and satellite data\nProducing satellite maps and overlaying buoy data"
  },
  {
    "objectID": "tutorials/r/matchup_satellite_buoy_data.html#datasets-used",
    "href": "tutorials/r/matchup_satellite_buoy_data.html#datasets-used",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "The sea surface temperature (SST) satellite data from the NOAA Geo-polar blended analysis\n The NDBC Standard Meteorological Buoy Data (dataset ID: cwwcNDBCMet)  is used for validating or ground truthing the satellite SST data"
  },
  {
    "objectID": "tutorials/r/matchup_satellite_buoy_data.html#install-required-packages-and-load-libraries",
    "href": "tutorials/r/matchup_satellite_buoy_data.html#install-required-packages-and-load-libraries",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "# Function to check if pkgs are installed, install missing pkgs, and load\n\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE)\n    if(!require(x,character.only = TRUE)) stop(\"Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c( \"ncdf4\", \"rerddap\", \"plotdap\", \"httr\",\n                       \"lubridate\", \"gridGraphics\",  \"mapdata\",\n                       \"ggplot2\", \"RColorBrewer\", \"grid\", \"PBSmapping\", \n                       \"rerddapXtracto\",\"dplyr\",\"viridis\",\"cmocean\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}"
  },
  {
    "objectID": "tutorials/r/matchup_satellite_buoy_data.html#downloading-buoy-data-from-erddap",
    "href": "tutorials/r/matchup_satellite_buoy_data.html#downloading-buoy-data-from-erddap",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "Extract data using the rerddap::tabledap function\nUsing rerddap::tabledap function, we will request and download data with the following specifications:\n\nBuoy dataset ID: cwwcNDBCMet\nRegion boundaries: 35 to 40 north latitude and -125 to -120 east longitude\n\nTime span: 08/01/2023 to 08/10/2023\nVariables: station, latitude, longitude, time, and water temperature parameters\n\n# Subset and download tabular data from ERDDAP \n\nERDDAP_Node = \"https://coastwatch.pfeg.noaa.gov/erddap\"\n\nNDBC_id = 'cwwcNDBCMet'\nNDBC_info=info(datasetid = NDBC_id,url = ERDDAP_Node)\n\nbuoy &lt;- rerddap::tabledap( url = ERDDAP_Node, NDBC_id,\n  fields=c('station', 'latitude',  'longitude', 'time', 'wtmp'), \n  'time&gt;=2023-08-01',   'time&lt;=2023-08-10', \n  'latitude&gt;=35','latitude&lt;=40', 'longitude&gt;=-125','longitude&lt;=-120',\n  'wtmp&gt;0'\n)\n\n#Create data frame with the downloaded data\nbuoy.df &lt;-data.frame(station=buoy$station,\n                     longitude=as.numeric(buoy$longitude),\n                     latitude=as.numeric(buoy$latitude),\n                     time=strptime(buoy$time, \"%Y-%m-%dT%H:%M:%S\"),\n                     temp=as.numeric(buoy$wtmp))\n\n# Check for unique stations\nunique.sta &lt;- unique(buoy$sta)\nn.sta &lt;- length(unique.sta)\nn.sta\n## [1] 24\nsummary(buoy.df)\n##    station            longitude         latitude    \n##  Length:28725       Min.   :-124.0   Min.   :35.18  \n##  Class :character   1st Qu.:-123.1   1st Qu.:36.79  \n##  Mode  :character   Median :-122.2   Median :37.81  \n##                     Mean   :-122.3   Mean   :37.40  \n##                     3rd Qu.:-121.9   3rd Qu.:38.06  \n##                     Max.   :-120.8   Max.   :39.20  \n##       time                             temp      \n##  Min.   :2023-08-01 00:00:00.00   Min.   : 9.10  \n##  1st Qu.:2023-08-03 03:48:00.00   1st Qu.:11.90  \n##  Median :2023-08-05 09:18:00.00   Median :13.90  \n##  Mean   :2023-08-05 10:14:05.06   Mean   :14.95  \n##  3rd Qu.:2023-08-07 16:36:00.00   3rd Qu.:16.60  \n##  Max.   :2023-08-10 00:00:00.00   Max.   :23.90\nPlot the buoy data for the first 10 stations in buoy.df\nLet’s see what the buoy data looks like for our time period.\nplot(buoy.df$time, buoy.df$temp, type='n', xlab='Date', ylab='SST (ºC)',main='SST from the first 10 stations')\n\n\nfor (i in 1:10){\n  I=which(buoy.df$station==unique.sta[i])\n  lines(buoy.df$time[I],buoy.df$temp[I])\n}\n\nSelect buoy data closest in time to satellite data\nSince buoy data are hourly and the satellite data are daily, the buoy data needs to be averaged daily for each station.\nbuoy.df.day=buoy.df %&gt;%\n  mutate(date = floor_date(time, unit=\"days\")) %&gt;%\n  group_by(station, date) %&gt;%\n  summarize(\n    lon=mean(longitude),\n    lat=mean(latitude),\n    temp.day=mean(temp),\n    .groups=\"drop\"\n    )\n\nhead(buoy.df.day)\n## # A tibble: 6 × 5\n##   station date                  lon   lat temp.day\n##   &lt;chr&gt;   &lt;dttm&gt;              &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n## 1 46013   2023-08-01 00:00:00 -123.  38.2     10.4\n## 2 46013   2023-08-02 00:00:00 -123.  38.2     10.7\n## 3 46013   2023-08-03 00:00:00 -123.  38.2     10.6\n## 4 46013   2023-08-04 00:00:00 -123.  38.2     10.4\n## 5 46013   2023-08-05 00:00:00 -123.  38.2     10.7\n## 6 46013   2023-08-06 00:00:00 -123.  38.2     10.6"
  },
  {
    "objectID": "tutorials/r/matchup_satellite_buoy_data.html#download-satellite-sst-sea-surface-temperature-data",
    "href": "tutorials/r/matchup_satellite_buoy_data.html#download-satellite-sst-sea-surface-temperature-data",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "We will use Sea surface temperature (SST) satellite data from CoastWatch West code node ERDDAP server.\nURL: https://coastwatch.pfeg.noaa.gov/erddap/ Dataset ID:nesdisBLENDEDsstDNDaily\nurl=  'https://coastwatch.pfeg.noaa.gov/erddap/'\ndatasetid = 'nesdisBLENDEDsstDNDaily'\n\n# Get Data Information given dataset ID and URL\ndataInfo &lt;- rerddap::info(datasetid, url)\n\n# Show data Info\ndataInfo\n## &lt;ERDDAP info&gt; nesdisBLENDEDsstDNDaily \n##  Base URL: https://coastwatch.pfeg.noaa.gov/erddap \n##  Dataset Type: griddap \n##  Dimensions (range):  \n##      time: (2019-07-22T12:00:00Z, 2024-03-20T12:00:00Z) \n##      latitude: (-89.975, 89.975) \n##      longitude: (-179.975, 179.975) \n##  Variables:  \n##      analysed_sst: \n##          Units: degree_C \n##      analysis_error: \n##          Units: degree_C \n##      mask: \n##      sea_ice_fraction: \n##          Units: 1\nExtract the matchup data using rxtracto\nWe will extract satellite data for each buoy station.\n1. get coordinates of each buoy station 2. use the rxtracto function and the buoy coordinates to download satellite data closest to each station\n# Set the variable name of interest from the satellite data\nparameter &lt;- 'analysed_sst'\n\n# Set x,y,t,z coordinates based on buoy data\nxcoord &lt;- buoy.df.day$lon\nycoord &lt;- buoy.df.day$lat\ntcoord &lt;- buoy.df.day$date\n\n\n# Extract satellite data \nextract &lt;- rxtracto(dataInfo, parameter=parameter, \n                    tcoord=tcoord,\n                    xcoord=xcoord,\n                    ycoord=ycoord,\n                    xlen=.01,ylen=.01)\n                     \nbuoy.df.day$sst&lt;-extract$`mean analysed_sst`\nGet subset of data where a satellite value was found\n\nOur satellite product is gap-free (gaps due to clouds were filled using some interpolation) but it has a spatial resolution of 5km. Some buoy stations may be so close to shore that they end up in the landmask of the satellite data. So let’s find the stations that were matched up to an SST pixel.\n\n# Get subset of data where there is a satellite value \ngoodbuoy&lt;-subset(buoy.df.day, sst &gt; 0)\nunique.sta&lt;-unique(goodbuoy$station)\nnbuoy&lt;-length(unique.sta)\nndata&lt;-length(goodbuoy$station)"
  },
  {
    "objectID": "tutorials/r/matchup_satellite_buoy_data.html#compare-results-for-satellite-and-buoy",
    "href": "tutorials/r/matchup_satellite_buoy_data.html#compare-results-for-satellite-and-buoy",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "Plot the satellite SST verses the buoy temperature to visualize how well the two datasets match each other.\n\n# Set up map title \nmain=\"California coast, 8/1/23-8/10/23\"   \n\np &lt;- ggplot(goodbuoy, aes(temp.day, sst,color=lat)) + \n     coord_fixed(xlim=c(8,25),ylim=c(8,25)) \np + geom_point() + \n  ylab('Satellite SST')  + \n  xlab('Buoy average daily SST') +\n  scale_x_continuous(minor_breaks = seq(8, 25)) + \n  scale_y_continuous(minor_breaks = seq(8, 25)) + \n  #geom_abline(a=fit[1],b=fit[2]) +\n  #annotation_custom(my_grob) + \n  #scale_color_gradientn(colours = \"viridis\", name=\"Buoy\\nLatitude\") +\n  scale_color_viridis(discrete = FALSE, name=\"Buoy\\nLatitude\") +\n  labs(title=main) + theme(plot.title = element_text(size=20, face=\"bold\", vjust=2)) \n\nRun a linear regression of Blended SST versus the buoy data. * The R squared is close to 1 (0.8733) * The slope is 0.7151\nlmHeight = lm(sst~temp.day, data = goodbuoy)\nsummary(lmHeight)\n## \n## Call:\n## lm(formula = sst ~ temp.day, data = goodbuoy)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -2.21936 -0.47676  0.02142  0.40927  2.19949 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  3.65951    0.27549   13.28   &lt;2e-16 ***\n## temp.day     0.71469    0.01976   36.17   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7322 on 195 degrees of freedom\n## Multiple R-squared:  0.8703, Adjusted R-squared:  0.8696 \n## F-statistic:  1309 on 1 and 195 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "tutorials/r/matchup_satellite_buoy_data.html#create-a-map-of-sst-and-overlay-the-buoy-data",
    "href": "tutorials/r/matchup_satellite_buoy_data.html#create-a-map-of-sst-and-overlay-the-buoy-data",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "Extract blended SST data for August 1st, 2023\n# First define the box and time limits of the requested data \nylim&lt;-c(32,42)\nxlim&lt;-c(-127,-118)\n\n# Extract the monthly satellite data\nSST &lt;- rxtracto_3D(dataInfo,xcoord=xlim,ycoord=ylim,parameter=parameter, \n                   tcoord=c('2023-08-01','2023-08-01'))\n\nSST$sst &lt;- drop(SST$analysed_sst)\nCreate the map frame for the satellite data and buoy SST overlay\nmapFrame&lt;- function(longitude,latitude,sst){\n  dims&lt;-dim(sst)\n  sst&lt;-array(sst,dims[1]*dims[2])\n  sstFrame&lt;-expand.grid(x=longitude,y=latitude)\n  sstFrame$sst&lt;-sst\n  return(sstFrame)\n}\n\nsstFrame&lt;-mapFrame(SST$longitude,SST$latitude,SST$sst)\ncoast &lt;- map_data(\"worldHires\", ylim = ylim, xlim = xlim)\nmy.col &lt;- colorRampPalette(rev(brewer.pal(11, \"RdYlBu\")))(22-13) \n\nbuoy2&lt;-subset(buoy.df.day, month(date)==8 &day(date)==1 & temp.day &gt; 0)\nCreate the map\nmyplot&lt;-ggplot(data = sstFrame, aes(x = x, y = y, fill = sst)) +\n  geom_tile(na.rm=T) +\n  geom_polygon(data = coast, aes(x=long, y = lat, group = group), fill = \"grey80\") +\n  theme_bw(base_size = 15) + ylab(\"Latitude\") + xlab(\"Longitude\") +\n  coord_fixed(1.3,xlim = xlim, ylim = ylim) +\n  scale_fill_cmocean(name = 'thermal',limits=c(10,25),na.value = NA) +\n  ggtitle(paste(\"Satellite SST and buoy temperature (circles) \\n\", unique(as.Date(SST$time)))) +\n  geom_point(data=buoy2, aes(x=lon,y=lat,color=temp.day),size=3,shape=21,color=\"black\") + \n  scale_color_cmocean(name = 'thermal',limits=c(10,25),na.value =\"grey20\") \n  \nmyplot"
  },
  {
    "objectID": "tutorials/r/matchup_satellite_buoy_data.html#references",
    "href": "tutorials/r/matchup_satellite_buoy_data.html#references",
    "title": "Match up satellite and buoy data",
    "section": "",
    "text": "NOAA CoastWatch Westcoast Node Data Catalog\nNOAA National Data Buoy Center\nRerddap R Package reference"
  },
  {
    "objectID": "tutorials/r/transforming-coords-from-crs-to-crs.html",
    "href": "tutorials/r/transforming-coords-from-crs-to-crs.html",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "history | Create July 2023 | Updated August 2023\n\n\n\nMap projections try to portray the earth’s spherical surface on a flat surface. A coordinate reference system (CRS) defines how the two-dimensional, projected map relates to real places on the earth. Which map projection and CRS to use depends on the region in which you are working and the analysis you will do.\nNOAA PolarWatch distributes gridded and tabular oceanographic data for polar regions.\nMost of the satellite data in the PolarWatch data catalog use a projection based on a Geographic Coordinate Reference System, where the X and Y coordinates are longitude and latitude, respectively. Geographical coordinates work well in many parts of the globe, but within polar regions, features tend to be very distorted. A Polar Stereographic projection often is a better choice for polar regions. For example, the NSIDC’s Polar Stereographic Projections, which were developed to optimize mapping of sea ice, have only a 6% distortion of the grid at the poles and no distortion at 70º, a latitude close to where the marginal ice zones occur. The NOAA NSIDC Sea Ice Concentration Climate Data Record dataset, for example, is in a polar stereographic projection.\nWhen working with satellite datasets with a mix of map projections, it is often necessary to transform all the data to a common projection. In this exercise, we will learn to transform coordinates from one projection to another.\n\n\n\nIn this tutorial, we will learn to transform dataset coordinates from one projection to another.\n\n\n\n\nDownloading and saving a netCDF file from PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nConvert the netcdf data into a dataframe\nTransforming coordinates using EPSG codes\nMapping data using the transformed coordinates\n\n\n\n\nSea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-2022, Monthly The sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Southern Polar Stereographic projection (EPSG:3031). The resolution is 25km, meaning each pixel in this data set represents a value that covers a 25km by 25km area. The dataset can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday\n\n\nThis code block will check if required packages are installed, and will install missing packages.\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"ncdf4\" , \"sf\", \"ggplot2\",\"scales\", \"RColorBrewer\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\n# download the sea ice data NetCDF file\nurl &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]\"\n\nsic &lt;- download.file(url, destfile=\"sic.nc\", mode='wb')\n\n# file open\nds &lt;- nc_open('sic.nc')\n\n# print metadata\nprint(ds)\n\n## File sic.nc (NC_FORMAT_CLASSIC):\n## \n##      1 variables (excluding dimension variables):\n##         float cdr_seaice_conc_monthly[xgrid,ygrid,time]   \n##             _FillValue: 2.53999996185303\n##             ancillary_variables: stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthly\n##             colorBarMaximum: 1\n##             colorBarMinimum: 0\n##             colorBarPalette: KT_ice\n##             datum: +ellps=urn:ogc:def:crs:EPSG::4326\n##             flag_meanings: pole_hole lakes coastal land_mask missing_data\n##             flag_values: -5\n##              flag_values: -4\n##              flag_values: -3\n##              flag_values: -2\n##              flag_values: -1\n##             ioos_category: Ice Distribution\n##             long_name: NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration\n##             references: https://nsidc.org/data/g02202/versions/4/\n##             standard_name: sea_ice_area_fraction\n##             units: 1\n##             valid_range: 0\n##              valid_range: 1\n## \n##      3 dimensions:\n##         time  Size:1 \n##             _ChunkSizes: 1024\n##             _CoordinateAxisType: Time\n##             actual_range: 1669852800\n##              actual_range: 1669852800\n##             axis: T\n##             calendar: gregorian\n##             ioos_category: Time\n##             long_name: ANSI date\n##             standard_name: time\n##             time_origin: 01-JAN-1970 00:00:00\n##             units: seconds since 1970-01-01T00:00:00Z\n##         ygrid  Size:332 \n##             _ChunkSizes: 332\n##             actual_range: -3937500\n##              actual_range: 4337500\n##             axis: Y\n##             ioos_category: Location\n##             long_name: projection_grid_y_centers\n##             standard_name: projection_y_coordinate\n##             units: meters\n##             valid_range: -3950000\n##              valid_range: 4350000\n##         xgrid  Size:316 \n##             _ChunkSizes: 316\n##             actual_range: -3937500\n##              actual_range: 3937500\n##             axis: X\n##             ioos_category: Location\n##             long_name: projection_grid_x_centers\n##             standard_name: projection_x_coordinate\n##             units: meters\n##             valid_range: -3950000\n##              valid_range: 3950000\n## \n##     65 global attributes:\n##         acknowledgement: This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.\n##         cdm_data_type: Grid\n##         cdr_variable: cdr_seaice_conc_monthly\n##         contributor_name: Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fisher\n##         contributor_role: principal investigator, author, author, software developer, software developer, software developer\n##         Conventions: CF-1.6, ACDD-1.3, COARDS\n##         creator_email: nsidc@nsidc.org\n##         creator_name: NSIDC\n##         creator_type: institution\n##         creator_url: https://nsidc.org/\n##         date_created: 2023-02-22T23:17:53Z\n##         defaultGraphQuery: cdr_seaice_conc_monthly%5Blast%5D%5B(4337500.0):(-3937500.0)%5D%5B(-3937500.0):(3937500.0)%5D&.draw=surface\n##         grid_mapping_false_easting: 0\n##         grid_mapping_false_northing: 0\n##         grid_mapping_GeoTransform: -3950000.0 25000.0 0 4350000.0 0 -25000.0\n##         grid_mapping_grid_boundary_bottom_projected_y: -3950000\n##         grid_mapping_grid_boundary_left_projected_x: -3950000\n##         grid_mapping_grid_boundary_right_projected_x: 3950000\n##         grid_mapping_grid_boundary_top_projected_y: 4350000\n##         grid_mapping_latitude_of_projection_origin: -90\n##         grid_mapping_longitude_of_projection_origin: 0\n##         grid_mapping_name: polar_stereographic\n##         grid_mapping_parent_grid_cell_column_subset_end: 316\n##         grid_mapping_parent_grid_cell_column_subset_start: 0\n##         grid_mapping_parent_grid_cell_row_subset_end: 332\n##         grid_mapping_parent_grid_cell_row_subset_start: 0\n##         grid_mapping_proj4text: +proj=stere +lat_0=-90 +lat_ts=-70 +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defs\n##         grid_mapping_scaling_factor: 1\n##         grid_mapping_semimajor_radius: 6378273\n##         grid_mapping_semiminor_radius: 6356889.449\n##         grid_mapping_spatial_ref: PROJCS[\"NSIDC Sea Ice Polar Stereographic South\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",-70],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3412\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]\n##         grid_mapping_srid: urn:ogc:def:crs:EPSG::3412\n##         grid_mapping_standard_parallel: -70\n##         grid_mapping_straight_vertical_longitude_from_pole: 180\n##         grid_mapping_units: meters\n##         history: Tue Jan  5 13:40:25 2021: ncks -x -v goddard_merged_seaice_conc_monthly ./previous_blank_ncs/S_monthly_blank.nc ./S_monthly_blank.nc\n## 2023-09-13T19:25:12Z (local files)\n## 2023-09-13T19:25:12Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]\n##         id: https://doi.org/10.7265/sr8p-kc62\n##         infoUrl: https://nsidc.org/data/g02202/versions/4/\n##         institution: NSIDC &gt; National Snow and Ice Data Center\n##         keywords: algorithm, area, bellingshausen, bootstrap, cdr_seaice_conc_monthly, center, climate, common, concentration, cryosphere, data, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Polar, Geographic Region &gt; Southern Hemisphere, goddard, gsfc, hemisphere, ice, ice distribution, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Southern Ocean, Ocean &gt; Southern Ocean &gt; Bellingshausen Sea, Ocean &gt; Southern Ocean &gt; Ross Sea, Ocean &gt; Southern Ocean &gt; Weddell Sea, oceans, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, ross, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, southern, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, tdim, team, version, weddell\n##         keywords_vocabulary: GCMD Science Keywords\n##         license: No constraints on data access or use\n##         metadata_link: https://nsidc.org/data/g02202/versions/4/\n##         naming_authority: org.doi.dx\n##         NCO: \"4.5.4\"\n##         platform: DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17\n##         processing_level: NOAA Level 3\n##         product_version: v04r00\n##         program: NOAA Climate Data Record Program\n##         proj_crs_code: EPSG:3412\n##         proj_crs_code_description: The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.\n##         project: NOAA/NSIDC passive microwave sea ice concentration climate data record\n##         references: Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7):    15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1\n##         sensor: SSMI/S &gt; Special Sensor Microwave Imager/Sounder\n##         software_version_id: git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897\n##         source: ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220701_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220702_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220703_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220704_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220705_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220706_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220707_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220708_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220709_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220710_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220711_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220712_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220713_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220714_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220715_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220716_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220717_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220718_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220719_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220720_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220721_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220722_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220723_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220724_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220725_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220726_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220727_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220728_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220729_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220730_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220731_f17_v04r00.nc\n##         sourceUrl: (local files)\n##         spatial_resolution: 25km\n##         standard_name_vocabulary: CF Standard Name Table v70\n##         summary: This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).\n##         time_coverage_duration: P1M\n##         time_coverage_end: 2022-12-01T00:00:00Z\n##         time_coverage_resolution: P1M\n##         time_coverage_start: 2022-12-01T00:00:00Z\n##         title: Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\n\n# get data into r variables \nxgrid &lt;- ncvar_get(ds, \"xgrid\")\nygrid &lt;- ncvar_get(ds, \"ygrid\")\nsic &lt;- ncvar_get(ds, \"cdr_seaice_conc_monthly\")  #lat and lon\ndim(sic)\n\n## [1] 316 332\n\n# close \nnc_close(ds)\n\n\n\n# create dataframe\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude fillvalue\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels=comma) + \n       scale_x_continuous(labels=comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\")+ggtitle(\"Sea Ice Concentration in Polar Steregraphic projection\")\n\n\n\n\n\nWhen transforming from one CRS to another, it is important to inspect CRS definitions and the transformation function for proper transformation. We will transform from CRS EPSG: 3031 (NSIDC Polar Stereographic South) to EPSG: 4326 (geographic coordinate system)\nxy_sf &lt;- st_as_sf(sicd, coords=c(\"xgrid\", \"ygrid\"), crs=3031)\n\n# st_transform output order: lat , lon\nlatlon_sf &lt;- st_transform(xy_sf, crs=4326)\n\nlatlon_df &lt;- as.data.frame(st_coordinates(latlon_sf))\nnames(latlon_df) &lt;- c(\"Lat\", \"Lon\")\nseaiceconc &lt;- sicd$sic\n# create dataframe and add names\nsicdf_latlon &lt;- data.frame(cbind(latlon_df,seaiceconc))\nhead(na.omit(sicdf_latlon), 5)\n\n##         Lat       Lon seaiceconc\n## 1 -42.23257 -39.49708          0\n## 2 -42.05101 -39.62425          0\n## 3 -41.86840 -39.75110          0\n## 4 -41.68474 -39.87763          0\n## 5 -41.50003 -40.00383          0\n\n\nsic_sf &lt;- st_as_sf(sicdf_latlon, coords = c('Lat', 'Lon'))\nst_crs(sic_sf) = \"4326\"\n\n# plot sea ice concentration on an unprojected map\nggplot(sic_sf) + geom_sf(aes(color = seaiceconc)) + labs(title = \"Sea Ice Concentration of Antarctica\")\n\nBecause the data were in the polar stereographic projection, mapping the data onto a different projection (global map projection) above, doesn’t make the data fit well on the map.\n\n\n\n\n\nNOAA PolarWatch Data Product Page (download, preview)\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)"
  },
  {
    "objectID": "tutorials/r/transforming-coords-from-crs-to-crs.html#background",
    "href": "tutorials/r/transforming-coords-from-crs-to-crs.html#background",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "Map projections try to portray the earth’s spherical surface on a flat surface. A coordinate reference system (CRS) defines how the two-dimensional, projected map relates to real places on the earth. Which map projection and CRS to use depends on the region in which you are working and the analysis you will do.\nNOAA PolarWatch distributes gridded and tabular oceanographic data for polar regions.\nMost of the satellite data in the PolarWatch data catalog use a projection based on a Geographic Coordinate Reference System, where the X and Y coordinates are longitude and latitude, respectively. Geographical coordinates work well in many parts of the globe, but within polar regions, features tend to be very distorted. A Polar Stereographic projection often is a better choice for polar regions. For example, the NSIDC’s Polar Stereographic Projections, which were developed to optimize mapping of sea ice, have only a 6% distortion of the grid at the poles and no distortion at 70º, a latitude close to where the marginal ice zones occur. The NOAA NSIDC Sea Ice Concentration Climate Data Record dataset, for example, is in a polar stereographic projection.\nWhen working with satellite datasets with a mix of map projections, it is often necessary to transform all the data to a common projection. In this exercise, we will learn to transform coordinates from one projection to another."
  },
  {
    "objectID": "tutorials/r/transforming-coords-from-crs-to-crs.html#objective",
    "href": "tutorials/r/transforming-coords-from-crs-to-crs.html#objective",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "In this tutorial, we will learn to transform dataset coordinates from one projection to another."
  },
  {
    "objectID": "tutorials/r/transforming-coords-from-crs-to-crs.html#this-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/transforming-coords-from-crs-to-crs.html#this-tutorial-demonstrates-the-following-techniques",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "Downloading and saving a netCDF file from PolarWatch ERDDAP data server\nAccessing satellite data and metadata in polar stereographic projection\nConvert the netcdf data into a dataframe\nTransforming coordinates using EPSG codes\nMapping data using the transformed coordinates"
  },
  {
    "objectID": "tutorials/r/transforming-coords-from-crs-to-crs.html#dataset-used",
    "href": "tutorials/r/transforming-coords-from-crs-to-crs.html#dataset-used",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-2022, Monthly The sea ice concentration (SIC) dataset used in this exercise is produced by NOAA NSIDC from passive microwave sensors as part of the Climate Data Record. It is a science quality dataset of monthly averages that extends from 1978-2022. SIC is reported as the fraction (0 to 1) of each grid cell that is covered by ice. The data are mapped in the Southern Polar Stereographic projection (EPSG:3031). The resolution is 25km, meaning each pixel in this data set represents a value that covers a 25km by 25km area. The dataset can be downloaded directly from the PolarWatch ERDDAP at the following link: https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday\n\n\nThis code block will check if required packages are installed, and will install missing packages.\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\nlist.of.packages &lt;- c(\"ncdf4\" , \"sf\", \"ggplot2\",\"scales\", \"RColorBrewer\")\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\n\n# download the sea ice data NetCDF file\nurl &lt;- \"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]\"\n\nsic &lt;- download.file(url, destfile=\"sic.nc\", mode='wb')\n\n# file open\nds &lt;- nc_open('sic.nc')\n\n# print metadata\nprint(ds)\n\n## File sic.nc (NC_FORMAT_CLASSIC):\n## \n##      1 variables (excluding dimension variables):\n##         float cdr_seaice_conc_monthly[xgrid,ygrid,time]   \n##             _FillValue: 2.53999996185303\n##             ancillary_variables: stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthly\n##             colorBarMaximum: 1\n##             colorBarMinimum: 0\n##             colorBarPalette: KT_ice\n##             datum: +ellps=urn:ogc:def:crs:EPSG::4326\n##             flag_meanings: pole_hole lakes coastal land_mask missing_data\n##             flag_values: -5\n##              flag_values: -4\n##              flag_values: -3\n##              flag_values: -2\n##              flag_values: -1\n##             ioos_category: Ice Distribution\n##             long_name: NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration\n##             references: https://nsidc.org/data/g02202/versions/4/\n##             standard_name: sea_ice_area_fraction\n##             units: 1\n##             valid_range: 0\n##              valid_range: 1\n## \n##      3 dimensions:\n##         time  Size:1 \n##             _ChunkSizes: 1024\n##             _CoordinateAxisType: Time\n##             actual_range: 1669852800\n##              actual_range: 1669852800\n##             axis: T\n##             calendar: gregorian\n##             ioos_category: Time\n##             long_name: ANSI date\n##             standard_name: time\n##             time_origin: 01-JAN-1970 00:00:00\n##             units: seconds since 1970-01-01T00:00:00Z\n##         ygrid  Size:332 \n##             _ChunkSizes: 332\n##             actual_range: -3937500\n##              actual_range: 4337500\n##             axis: Y\n##             ioos_category: Location\n##             long_name: projection_grid_y_centers\n##             standard_name: projection_y_coordinate\n##             units: meters\n##             valid_range: -3950000\n##              valid_range: 4350000\n##         xgrid  Size:316 \n##             _ChunkSizes: 316\n##             actual_range: -3937500\n##              actual_range: 3937500\n##             axis: X\n##             ioos_category: Location\n##             long_name: projection_grid_x_centers\n##             standard_name: projection_x_coordinate\n##             units: meters\n##             valid_range: -3950000\n##              valid_range: 3950000\n## \n##     65 global attributes:\n##         acknowledgement: This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.\n##         cdm_data_type: Grid\n##         cdr_variable: cdr_seaice_conc_monthly\n##         contributor_name: Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fisher\n##         contributor_role: principal investigator, author, author, software developer, software developer, software developer\n##         Conventions: CF-1.6, ACDD-1.3, COARDS\n##         creator_email: nsidc@nsidc.org\n##         creator_name: NSIDC\n##         creator_type: institution\n##         creator_url: https://nsidc.org/\n##         date_created: 2023-02-22T23:17:53Z\n##         defaultGraphQuery: cdr_seaice_conc_monthly%5Blast%5D%5B(4337500.0):(-3937500.0)%5D%5B(-3937500.0):(3937500.0)%5D&.draw=surface\n##         grid_mapping_false_easting: 0\n##         grid_mapping_false_northing: 0\n##         grid_mapping_GeoTransform: -3950000.0 25000.0 0 4350000.0 0 -25000.0\n##         grid_mapping_grid_boundary_bottom_projected_y: -3950000\n##         grid_mapping_grid_boundary_left_projected_x: -3950000\n##         grid_mapping_grid_boundary_right_projected_x: 3950000\n##         grid_mapping_grid_boundary_top_projected_y: 4350000\n##         grid_mapping_latitude_of_projection_origin: -90\n##         grid_mapping_longitude_of_projection_origin: 0\n##         grid_mapping_name: polar_stereographic\n##         grid_mapping_parent_grid_cell_column_subset_end: 316\n##         grid_mapping_parent_grid_cell_column_subset_start: 0\n##         grid_mapping_parent_grid_cell_row_subset_end: 332\n##         grid_mapping_parent_grid_cell_row_subset_start: 0\n##         grid_mapping_proj4text: +proj=stere +lat_0=-90 +lat_ts=-70 +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defs\n##         grid_mapping_scaling_factor: 1\n##         grid_mapping_semimajor_radius: 6378273\n##         grid_mapping_semiminor_radius: 6356889.449\n##         grid_mapping_spatial_ref: PROJCS[\"NSIDC Sea Ice Polar Stereographic South\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",-70],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3412\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]\n##         grid_mapping_srid: urn:ogc:def:crs:EPSG::3412\n##         grid_mapping_standard_parallel: -70\n##         grid_mapping_straight_vertical_longitude_from_pole: 180\n##         grid_mapping_units: meters\n##         history: Tue Jan  5 13:40:25 2021: ncks -x -v goddard_merged_seaice_conc_monthly ./previous_blank_ncs/S_monthly_blank.nc ./S_monthly_blank.nc\n## 2023-09-13T19:25:12Z (local files)\n## 2023-09-13T19:25:12Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.nc?cdr_seaice_conc_monthly[(2022-12-01T00:00:00Z):1:(2022-12-01T00:00:00Z)][(4350000.0):1:(-3950000.0)][(-3950000.0):1:(3950000.0)]\n##         id: https://doi.org/10.7265/sr8p-kc62\n##         infoUrl: https://nsidc.org/data/g02202/versions/4/\n##         institution: NSIDC &gt; National Snow and Ice Data Center\n##         keywords: algorithm, area, bellingshausen, bootstrap, cdr_seaice_conc_monthly, center, climate, common, concentration, cryosphere, data, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Polar, Geographic Region &gt; Southern Hemisphere, goddard, gsfc, hemisphere, ice, ice distribution, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Southern Ocean, Ocean &gt; Southern Ocean &gt; Bellingshausen Sea, Ocean &gt; Southern Ocean &gt; Ross Sea, Ocean &gt; Southern Ocean &gt; Weddell Sea, oceans, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, ross, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, southern, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, tdim, team, version, weddell\n##         keywords_vocabulary: GCMD Science Keywords\n##         license: No constraints on data access or use\n##         metadata_link: https://nsidc.org/data/g02202/versions/4/\n##         naming_authority: org.doi.dx\n##         NCO: \"4.5.4\"\n##         platform: DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17\n##         processing_level: NOAA Level 3\n##         product_version: v04r00\n##         program: NOAA Climate Data Record Program\n##         proj_crs_code: EPSG:3412\n##         proj_crs_code_description: The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.\n##         project: NOAA/NSIDC passive microwave sea ice concentration climate data record\n##         references: Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7):    15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251–2267, https://doi.org/10.1175/JCLI-D-16-0408.1\n##         sensor: SSMI/S &gt; Special Sensor Microwave Imager/Sounder\n##         software_version_id: git@bitbucket.org:nsidc/seaice_cdr.git@c9c632e73530554d8acfac9090baeb1e35755897\n##         source: ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220701_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220702_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220703_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220704_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220705_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220706_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220707_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220708_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220709_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220710_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220711_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220712_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220713_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220714_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220715_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220716_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220717_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220718_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220719_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220720_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220721_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220722_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220723_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220724_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220725_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220726_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220727_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220728_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220729_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220730_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2022/seaice_conc_daily_sh_20220731_f17_v04r00.nc\n##         sourceUrl: (local files)\n##         spatial_resolution: 25km\n##         standard_name_vocabulary: CF Standard Name Table v70\n##         summary: This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).\n##         time_coverage_duration: P1M\n##         time_coverage_end: 2022-12-01T00:00:00Z\n##         time_coverage_resolution: P1M\n##         time_coverage_start: 2022-12-01T00:00:00Z\n##         title: Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\n\n# get data into r variables \nxgrid &lt;- ncvar_get(ds, \"xgrid\")\nygrid &lt;- ncvar_get(ds, \"ygrid\")\nsic &lt;- ncvar_get(ds, \"cdr_seaice_conc_monthly\")  #lat and lon\ndim(sic)\n\n## [1] 316 332\n\n# close \nnc_close(ds)\n\n\n\n# create dataframe\nsicd &lt;- expand.grid(xgrid=xgrid, ygrid=ygrid)\nsicd$sic &lt;- array(sic, dim(xgrid)*dim(ygrid))\n\n# exclude fillvalue\nsicd$sic[sicd$sic &gt; 2] &lt;- NA \n\n# map sea ice concentration\nggplot(data = sicd, aes(x = xgrid, y = ygrid, fill=sic) ) + \n       geom_tile() + \n       coord_fixed(ratio = 1) + \n       scale_y_continuous(labels=comma) + \n       scale_x_continuous(labels=comma) +\n       scale_fill_gradientn(colours=rev(brewer.pal(n = 3, name = \"Blues\")),na.value=\"tan\")+ggtitle(\"Sea Ice Concentration in Polar Steregraphic projection\")"
  },
  {
    "objectID": "tutorials/r/transforming-coords-from-crs-to-crs.html#transforming-from-crs-to-crs",
    "href": "tutorials/r/transforming-coords-from-crs-to-crs.html#transforming-from-crs-to-crs",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "When transforming from one CRS to another, it is important to inspect CRS definitions and the transformation function for proper transformation. We will transform from CRS EPSG: 3031 (NSIDC Polar Stereographic South) to EPSG: 4326 (geographic coordinate system)\nxy_sf &lt;- st_as_sf(sicd, coords=c(\"xgrid\", \"ygrid\"), crs=3031)\n\n# st_transform output order: lat , lon\nlatlon_sf &lt;- st_transform(xy_sf, crs=4326)\n\nlatlon_df &lt;- as.data.frame(st_coordinates(latlon_sf))\nnames(latlon_df) &lt;- c(\"Lat\", \"Lon\")\nseaiceconc &lt;- sicd$sic\n# create dataframe and add names\nsicdf_latlon &lt;- data.frame(cbind(latlon_df,seaiceconc))\nhead(na.omit(sicdf_latlon), 5)\n\n##         Lat       Lon seaiceconc\n## 1 -42.23257 -39.49708          0\n## 2 -42.05101 -39.62425          0\n## 3 -41.86840 -39.75110          0\n## 4 -41.68474 -39.87763          0\n## 5 -41.50003 -40.00383          0\n\n\nsic_sf &lt;- st_as_sf(sicdf_latlon, coords = c('Lat', 'Lon'))\nst_crs(sic_sf) = \"4326\"\n\n# plot sea ice concentration on an unprojected map\nggplot(sic_sf) + geom_sf(aes(color = seaiceconc)) + labs(title = \"Sea Ice Concentration of Antarctica\")\n\nBecause the data were in the polar stereographic projection, mapping the data onto a different projection (global map projection) above, doesn’t make the data fit well on the map."
  },
  {
    "objectID": "tutorials/r/transforming-coords-from-crs-to-crs.html#references",
    "href": "tutorials/r/transforming-coords-from-crs-to-crs.html#references",
    "title": "Transforming satellite data from one map projection to another",
    "section": "",
    "text": "NOAA PolarWatch Data Product Page (download, preview)\nNSIDC Data Product Description\nNSIDC Data Product User Guide (pdf)"
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "",
    "text": "CoastWatch Python Exercises"
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#background",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#background",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Background",
    "text": "Background\nSeveral ocean color sensors have been launched since 1997 to provide continuous global coverage for ocean color data. The sensors have differences in design and calibration, and different algorithms may be applied to generate chlorophyll values. Consequently, chlorophyll-a values can vary among the sensors during periods where measurements overlap.\nTo examine this phenomenon, we will download and plot a time series of chlorophyll-a concentrations from various sensors that collected data between 1997 and the present to see how the measurements compare during periods of overlap."
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#objective",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#objective",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show how to extract a time series from four different monthly satellite chlorophyll datasets for the period that each was in operation between 1997-present."
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nUsing xarray to extract data from a rectangular area of the ocean over time\nRetrieving information about a dataset from ERDDAP\nComparing results from different sensors\nAveraging data spatially\nProducing time-series plots\nDrawing maps with satellite data"
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#datasets-used",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Datasets used",
    "text": "Datasets used\nSeaWiFS Chlorophyll-a, V.2018, Monthly, Global, 4km, 1997-2012\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday\nMODIS Aqua, Chlorophyll-a, V.2022, Monthly, Global, 4km, 2002-present\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022SQ\nNOAA VIIRS S-NPP, Chlorophyll-a, Monthly, Global, 4km, 2012-present\nhttps://coastwatch.noaa.gov/erddap/griddap/noaacwNPPVIIRSSQchlaMonthly\nESA CCI Ocean Colour Dataset, v6.0, Monthly, Global, 4km, 1997-Present\nThis dataset was developed by the European Space Agency’s Climate Change Initiative. The dataset merges data from multiple sensors (MERIS, MODIS, VIIRS and SeaWiFS) to create a long time series (1997 to present) with better spatial coverage than any single sensor. Parameters include chlorophyll a, remote sensing reflectance, diffuse attenuation coefficients, absorption coefficients, backscatter coefficients, and water classification.\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorMonthly"
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#import-required-packages",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#import-required-packages",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Import required packages",
    "text": "Import required packages\n\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter"
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#define-the-area-to-extract",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nFor each dataset we will extract data for an area in the Gulf of Mexico between -95 to -90°W longitude and 25-30°N latitude.\nSet up variables with the minimum and maximum values from the longitude and latitude ranges.\n\nlon_min = -95.\nlon_max = -90.\nlat_min = 25.\nlat_max = 30."
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#get-the-seawifs-data",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#get-the-seawifs-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get the SeaWiFS data",
    "text": "Get the SeaWiFS data\n\nOpen a dataset object in xarray\n\nurl_sw = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday'\nsw_ds = xr.open_dataset(url_sw)\nsw_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:      (time: 157, latitude: 2160, longitude: 4320)\nCoordinates:\n  * time         (time) datetime64[ns] 1997-09-16 1997-10-16 ... 2010-12-16\n  * latitude     (latitude) float32 89.96 89.88 89.79 ... -89.79 -89.88 -89.96\n  * longitude    (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nData variables:\n    chlorophyll  (time, latitude, longitude) float32 ...\nAttributes: (12/50)\n    _lastModified:                     2018-01-31T04:58:26.000Z\n    _NCProperties:                     version=1|netcdflibversion=4.4.1.1|hdf...\n    cdm_data_type:                     Grid\n    Conventions:                       CF-1.6, COARDS, ACDD-1.3\n    creator_email:                     data@oceancolor.gsfc.nasa.gov\n    creator_name:                      NASA/GSFC/OBPG\n    ...                                ...\n    summary:                           NASA GSFC Ocean Color Web distributes ...\n    temporal_range:                    10-day\n    time_coverage_end:                 2010-12-16T00:00:00Z\n    time_coverage_start:               1997-09-16T00:00:00Z\n    title:                             Chlorophyll-a, Orbview-2 SeaWiFS, R201...\n    Westernmost_Easting:               -179.9583xarray.DatasetDimensions:time: 157latitude: 2160longitude: 4320Coordinates: (3)time(time)datetime64[ns]1997-09-16 ... 2010-12-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000', '1998-02-16T00:00:00.000000000',\n       '1998-03-16T00:00:00.000000000', '1998-04-16T00:00:00.000000000',\n       '1998-05-16T00:00:00.000000000', '1998-06-16T00:00:00.000000000',\n       '1998-07-16T00:00:00.000000000', '1998-08-16T00:00:00.000000000',\n       '1998-09-16T00:00:00.000000000', '1998-10-16T00:00:00.000000000',\n       '1998-11-16T00:00:00.000000000', '1998-12-16T00:00:00.000000000',\n       '1999-01-16T00:00:00.000000000', '1999-02-16T00:00:00.000000000',\n       '1999-03-16T00:00:00.000000000', '1999-04-16T00:00:00.000000000',\n       '1999-05-16T00:00:00.000000000', '1999-06-16T00:00:00.000000000',\n       '1999-07-16T00:00:00.000000000', '1999-08-16T00:00:00.000000000',\n       '1999-09-16T00:00:00.000000000', '1999-10-16T00:00:00.000000000',\n       '1999-11-16T00:00:00.000000000', '1999-12-16T00:00:00.000000000',\n       '2000-01-16T00:00:00.000000000', '2000-02-16T00:00:00.000000000',\n       '2000-03-16T00:00:00.000000000', '2000-04-16T00:00:00.000000000',\n       '2000-05-16T00:00:00.000000000', '2000-06-16T00:00:00.000000000',\n       '2000-07-16T00:00:00.000000000', '2000-08-16T00:00:00.000000000',\n       '2000-09-16T00:00:00.000000000', '2000-10-16T00:00:00.000000000',\n       '2000-11-16T00:00:00.000000000', '2000-12-16T00:00:00.000000000',\n       '2001-01-16T00:00:00.000000000', '2001-02-16T00:00:00.000000000',\n       '2001-03-16T00:00:00.000000000', '2001-04-16T00:00:00.000000000',\n       '2001-05-16T00:00:00.000000000', '2001-06-16T00:00:00.000000000',\n       '2001-07-16T00:00:00.000000000', '2001-08-16T00:00:00.000000000',\n       '2001-09-16T00:00:00.000000000', '2001-10-16T00:00:00.000000000',\n       '2001-11-16T00:00:00.000000000', '2001-12-16T00:00:00.000000000',\n       '2002-01-16T00:00:00.000000000', '2002-02-16T00:00:00.000000000',\n       '2002-03-16T00:00:00.000000000', '2002-04-16T00:00:00.000000000',\n       '2002-05-16T00:00:00.000000000', '2002-06-16T00:00:00.000000000',\n       '2002-07-16T00:00:00.000000000', '2002-08-16T00:00:00.000000000',\n       '2002-09-16T00:00:00.000000000', '2002-10-16T00:00:00.000000000',\n       '2002-11-16T00:00:00.000000000', '2002-12-16T00:00:00.000000000',\n       '2003-01-16T00:00:00.000000000', '2003-02-16T00:00:00.000000000',\n       '2003-03-16T00:00:00.000000000', '2003-04-16T00:00:00.000000000',\n       '2003-05-16T00:00:00.000000000', '2003-06-16T00:00:00.000000000',\n       '2003-07-16T00:00:00.000000000', '2003-08-16T00:00:00.000000000',\n       '2003-09-16T00:00:00.000000000', '2003-10-16T00:00:00.000000000',\n       '2003-11-16T00:00:00.000000000', '2003-12-16T00:00:00.000000000',\n       '2004-01-16T00:00:00.000000000', '2004-02-16T00:00:00.000000000',\n       '2004-03-16T00:00:00.000000000', '2004-04-16T00:00:00.000000000',\n       '2004-05-16T00:00:00.000000000', '2004-06-16T00:00:00.000000000',\n       '2004-07-16T00:00:00.000000000', '2004-08-16T00:00:00.000000000',\n       '2004-09-16T00:00:00.000000000', '2004-10-16T00:00:00.000000000',\n       '2004-11-16T00:00:00.000000000', '2004-12-16T00:00:00.000000000',\n       '2005-01-16T00:00:00.000000000', '2005-02-16T00:00:00.000000000',\n       '2005-03-16T00:00:00.000000000', '2005-04-16T00:00:00.000000000',\n       '2005-05-16T00:00:00.000000000', '2005-06-16T00:00:00.000000000',\n       '2005-07-16T00:00:00.000000000', '2005-08-16T00:00:00.000000000',\n       '2005-09-16T00:00:00.000000000', '2005-10-16T00:00:00.000000000',\n       '2005-11-16T00:00:00.000000000', '2005-12-16T00:00:00.000000000',\n       '2006-01-16T00:00:00.000000000', '2006-02-16T00:00:00.000000000',\n       '2006-03-16T00:00:00.000000000', '2006-04-16T00:00:00.000000000',\n       '2006-05-16T00:00:00.000000000', '2006-06-16T00:00:00.000000000',\n       '2006-07-16T00:00:00.000000000', '2006-08-16T00:00:00.000000000',\n       '2006-09-16T00:00:00.000000000', '2006-10-16T00:00:00.000000000',\n       '2006-11-16T00:00:00.000000000', '2006-12-16T00:00:00.000000000',\n       '2007-01-16T00:00:00.000000000', '2007-02-16T00:00:00.000000000',\n       '2007-03-16T00:00:00.000000000', '2007-04-16T00:00:00.000000000',\n       '2007-05-16T00:00:00.000000000', '2007-06-16T00:00:00.000000000',\n       '2007-07-16T00:00:00.000000000', '2007-08-16T00:00:00.000000000',\n       '2007-09-16T00:00:00.000000000', '2007-10-16T00:00:00.000000000',\n       '2007-11-16T00:00:00.000000000', '2007-12-16T00:00:00.000000000',\n       '2008-01-16T00:00:00.000000000', '2008-04-16T00:00:00.000000000',\n       '2008-05-16T00:00:00.000000000', '2008-06-16T00:00:00.000000000',\n       '2008-07-16T00:00:00.000000000', '2008-08-16T00:00:00.000000000',\n       '2008-09-16T00:00:00.000000000', '2008-10-16T00:00:00.000000000',\n       '2008-11-16T00:00:00.000000000', '2008-12-16T00:00:00.000000000',\n       '2009-01-16T00:00:00.000000000', '2009-02-16T00:00:00.000000000',\n       '2009-03-16T00:00:00.000000000', '2009-04-16T00:00:00.000000000',\n       '2009-06-16T00:00:00.000000000', '2009-07-16T00:00:00.000000000',\n       '2009-08-16T00:00:00.000000000', '2009-09-16T00:00:00.000000000',\n       '2009-10-16T00:00:00.000000000', '2009-11-16T00:00:00.000000000',\n       '2009-12-16T00:00:00.000000000', '2010-01-16T00:00:00.000000000',\n       '2010-02-16T00:00:00.000000000', '2010-03-16T00:00:00.000000000',\n       '2010-04-16T00:00:00.000000000', '2010-05-16T00:00:00.000000000',\n       '2010-06-16T00:00:00.000000000', '2010-07-16T00:00:00.000000000',\n       '2010-08-16T00:00:00.000000000', '2010-09-16T00:00:00.000000000',\n       '2010-10-16T00:00:00.000000000', '2010-11-16T00:00:00.000000000',\n       '2010-12-16T00:00:00.000000000'], dtype='datetime64[ns]')latitude(latitude)float3289.96 89.88 89.79 ... -89.88 -89.96_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([ 89.958336,  89.875   ,  89.79167 , ..., -89.791664, -89.87501 ,\n       -89.958336], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_CoordinateAxisType :Lonactual_range :[-179.9583  179.9584]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79166, ...,  179.79167,  179.87502,\n        179.95836], dtype=float32)Data variables: (1)chlorophyll(time, latitude, longitude)float32...colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll Concentration, OCI Algorithmreferences :Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.standard_name :concentration_of_chlorophyll_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001[1464998400 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16', '1998-02-16', '1998-03-16', '1998-04-16',\n               '1998-05-16', '1998-06-16',\n               ...\n               '2010-03-16', '2010-04-16', '2010-05-16', '2010-06-16',\n               '2010-07-16', '2010-08-16', '2010-09-16', '2010-10-16',\n               '2010-11-16', '2010-12-16'],\n              dtype='datetime64[ns]', name='time', length=157, freq=None))latitudePandasIndexPandasIndex(Index([ 89.95833587646484,             89.875,  89.79167175292969,\n        89.70833587646484,             89.625,  89.54167175292969,\n        89.45833587646484,             89.375,  89.29167175292969,\n        89.20833587646484,\n       ...\n       -89.20833587646484, -89.29166412353516, -89.37500762939453,\n       -89.45833587646484, -89.54166412353516, -89.62500762939453,\n       -89.70833587646484, -89.79166412353516, -89.87500762939453,\n       -89.95833587646484],\n      dtype='float32', name='latitude', length=2160))longitudePandasIndexPandasIndex(Index([ -179.9583282470703,            -179.875, -179.79165649414062,\n        -179.7083282470703,            -179.625, -179.54165649414062,\n        -179.4583282470703,            -179.375, -179.29165649414062,\n        -179.2083282470703,\n       ...\n        179.20835876464844,   179.2916717529297,  179.37501525878906,\n        179.45835876464844,   179.5416717529297,  179.62501525878906,\n        179.70835876464844,   179.7916717529297,  179.87501525878906,\n        179.95835876464844],\n      dtype='float32', name='longitude', length=4320))Attributes: (50)_lastModified :2018-01-31T04:58:26.000Z_NCProperties :version=1|netcdflibversion=4.4.1.1|hdf5libversion=1.8.18cdm_data_type :GridConventions :CF-1.6, COARDS, ACDD-1.3creator_email :data@oceancolor.gsfc.nasa.govcreator_name :NASA/GSFC/OBPGcreator_type :groupcreator_url :https://oceandata.sci.gsfc.nasa.govdate_created :2018-01-31T04:58:26.000ZEasternmost_Easting :179.9584geospatial_lat_max :89.95834geospatial_lat_min :-89.95834geospatial_lat_units :degrees_northgeospatial_lon_max :179.9584geospatial_lon_min :-179.9583geospatial_lon_units :degrees_eastgrid_mapping_name :latitude_longitudehistory :These R2018.0 data files were downloaded from https://oceandata.sci.gsfc.nasa.gov/SeaWiFS/Mapped/Monthly/9km/chlor_a to NOAA NMFS SWFSC by erd.data@noaa.gov ERD on 2018-03-05.\n2023-09-06T13:45:15Z (local files)\n2023-09-06T13:45:15Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSW2018chlamday.dasidentifier_product_doi :10.5067/ORBVIEW-2/SEAWIFS/L3M/CHL/2018identifier_product_doi_authority :https://dx.doi.orginfoUrl :https://oceandata.sci.gsfc.nasa.govinstitution :NASA/GSFC OBPGinstrument :SeaWiFSkeywords :algorithm, biology, center, chemistry, chlor_a, chlorophyll, color, concentration, concentration_of_chlorophyll_in_sea_water, data, Earth Science &gt; Oceans &gt; Ocean Chemistry &gt; Chlorophyll, Earth Science &gt; Oceans &gt; Ocean Optics &gt; Ocean Color, field, field-of-view, flight, goddard, group, gsfc, image, L3, level, level-3, mapped, nasa, noaa, obpg, ocean, ocean color, oceans, oci, optics, orbview, orbview-2, palette, processing, sea, sea-wide, seawater, seawifs, sensor, smi, space, standard, view, water, widekeywords_vocabulary :GCMD Science Keywordsl2_flag_names :ATMFAIL,LAND,HILT,HISATZEN,STRAYLIGHT,CLDICE,COCCOLITH,LOWLW,CHLWARN,CHLFAIL,NAVWARN,MAXAERITER,ATMWARN,HISOLZEN,NAVFAIL,FILTER,HIGLINTlicense :https://science.nasa.gov/earth-science/earth-science-data/data-information-policy/\n\nPlease cite: NASA Goddard Space Flight Center, Ocean Ecology Laboratory, Ocean Biology Processing Group. Sea-viewing Wide Field-of-view Sensor (SeaWiFS) R2018.0 Chlorophyll Data; NASA OB.DAAC, Greenbelt, MD, USA. doi: https://dx.doi.org/10.5067/ORBVIEW-2/SEAWIFS/L3M/CHL/2018 .\n\nThe data may be used and redistributed for free but is not intended\nfor legal use, since it may contain inaccuracies. Neither the data\nContributor, ERD, NOAA, nor the United States Government, nor any\nof their employees or contractors, makes any warranty, express or\nimplied, including warranties of merchantability and fitness for a\nparticular purpose, or assumes any legal liability for the accuracy,\ncompleteness, or usefulness, of this information.map_projection :Equidistant Cylindricalmeasure :Meannaming_authority :gov.noaa.pfeg.coastwatchNorthernmost_Northing :89.95834platform :Orbview-2processing_level :L3 Mappedprocessing_version :2018.0project :Ocean Biology Processing Group (NASA/GSFC/OBPG)publisher_email :data@oceancolor.gsfc.nasa.govpublisher_name :NASA/GSFC/OBPGpublisher_type :grouppublisher_url :https://oceandata.sci.gsfc.nasa.govreferences :SeaWiFS information: https://oceancolor.gsfc.nasa.gov/SeaWiFS/ . NASA Ocean\nColor information: https://oceancolor.gsfc.nasa.gov/\nProcessing reference: O'Reilly, J.E., Maritorena, S., Mitchell, B.G., Siegel, D.A., Carder, K.L., Garver, S.A., Kahru, M. and McClain, C. (1998). Ocean color chlorophyll algorithms for SeaWiFS. J. Geophys. Res., 103: 24, 937-24, 953.\nProcessing reference: O'Reilly, J. E., and 21 others. 2000. Ocean color chlorophyll a algorithms for SeaWiFS, OC2 and OC4: Version 4. SeaWiFS Postlaunch Calibration and Validation Analyses, part 3. NASA SeaWiFS technical report series. pp. 8 226 22.\nProcessing reference: Fu, G., Baith, K. S., and McClain, C. R. (1998). SeaDAS: The SeaWiFS Data Analysis System. Proceedings of \"The 4th Pacific Ocean Remote Sensing Conference\", Qingdao, China, July 28-31, 1998, 73-79.\nValidation reference: Hooker, S.B., and C.R. McClain (2000). The Calibration and Validation of SeaWiFS Data. Prog. Oceanogr., 45, 427-465.\nR2014.0 processing reference: Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.\nR2018.0 reprocessing information: https://oceancolor.gsfc.nasa.gov/reprocessing/r2018/seawifs/sourceUrl :(local files)Southernmost_Northing :-89.95834spatialResolution :9.28 kmstandard_name_vocabulary :CF Standard Name Table v70summary :NASA GSFC Ocean Color Web distributes science-quality chlorophyll-a\nconcentration data from the Sea-viewing Wide Field-of-view Sensor (SeaWiFS)\non the Orbview-2 satellite. This version is the 2018.0 Reprocessing (R2018.0). https://oceancolor.gsfc.nasa.gov/reprocessing/r2018/seawifs/\n\nThe SeaWiFS instrument was launched by Orbital Sciences Corporation on the\nOrbView-2 (a.k.a. SeaStar) satellite in August 1997, and collected data from\nSeptember 1997 until the end of mission in December 2010. SeaWiFS had 8\nspectral bands from 412 to 865 nm. It collected global data at 4 km\nresolution, and local data (limited onboard storage and direct broadcast)\nat 1 km. The mission and sensor were optimized for ocean color measurements,\nwith a local noon (descending) equator crossing time orbit, fore-and-aft\ntilt capability, full dynamic range, and low polarization sensitivity.temporal_range :10-daytime_coverage_end :2010-12-16T00:00:00Ztime_coverage_start :1997-09-16T00:00:00Ztitle :Chlorophyll-a, Orbview-2 SeaWiFS, R2018.0, 0.1�, Global, 1997-2010 (Monthly Composite)Westernmost_Easting :-179.9583\n\n\n\n\nPrint out some useful metadata\nYou can view all of the metadata above in the dataset object. Let’s print out some metadata items to point a few things out: * The SeaWiFS dataset spans 13 years, from 1997 to 2010\n* The chlorophyll variable is called “chlorophyll”. Knowing this is important because variable names are not standardized, and we will need to know the exact variable name to extract the data. * Checking the first and last value of latitude can tell us if the latitude values are in ascending or descending order.\n\nprint('earliest date =', sw_ds.time.values[0])\nprint('most recent date =', sw_ds.time.values[-1], '\\n')\nprint('variable:', list(sw_ds.data_vars.keys()), '\\n')\n\nprint(\"Is latitude's first value --&gt;\", round(sw_ds.latitude[0].item(), 6))\nprint('greater than') \nprint(\"latitude's last value --&gt;\", round(sw_ds.latitude[-1].item(), 6))\n\nprint(sw_ds.latitude[0].item() &gt; sw_ds.latitude[-1].item())\n\n\nearliest date = 1997-09-16T00:00:00.000000000\nmost recent date = 2010-12-16T00:00:00.000000000 \n\nvariable: ['chlorophyll'] \n\nIs latitude's first value --&gt; 89.958336\ngreater than\nlatitude's last value --&gt; -89.958336\nTrue\n\n\n\n\nPay attention to the first and last values of latitude in the dataset\nIn a netCDF file that completely follows accepted standards, the latitude values are ascending; the values go from lowest to highest (south to north). Therefore, when we use the slice function (below) to subset the dataset we would list the lowest value in our subset followed by the highest.\n* slice(lat_min, lat_max)\nHowever, for some datasets the latitude values are in descending order, meaning the files were built with latitudes indexed from highest to lowest (north to south). It is a common occurrence and it impacts how we subset that dataset, so you need to be aware of it.\n* With latitude values in descending order, if you use “slice(lat_min, lat_max)” you will get no data, because there are no latitude values between lat_min and lat_max. * However, by reversing the order within slice by using “slice(lat_max, lat_min)” you will get data.\nFor the SeaWiFS dataset, the metadata above show that the first latitude value (89.958336) is greater than the last (-89.958336). The latitude values are in descending order.\n* There are methods in xarray to flip the latitude dimension. A simpler solution is to use a logic step that determines if latitude values are descending, then set slice values to use the higher value first (see below).\n\n# The lat1 and lat2 values are used in the slice function\n# At first we set them as if the dataset is compliant with standards\nlat1 = lat_min\nlat2 = lat_max\n\n# Then switch them if latitude values are descending\nif sw_ds.latitude[0].item() &gt; sw_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\n\n\nSubset the data from the dataset object.\nNote that so far we have not downloaded data. We have only set up how we want to download the data. * The download will happen when we request to use data, like when creating the map below.\n\n\nsw_subset = sw_ds['chlorophyll'].sel(time=slice(sw_ds.time[0], sw_ds.time[-1]),\n                                     latitude=slice(lat1, lat2),\n                                     longitude=slice(lon_min, lon_max)\n                                     )\nsw_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlorophyll' (time: 157, latitude: 60, longitude: 60)&gt;\n[565200 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 1997-09-16 1997-10-16 ... 2010-12-16\n  * latitude   (latitude) float32 29.96 29.87 29.79 29.71 ... 25.21 25.12 25.04\n  * longitude  (longitude) float32 -94.96 -94.88 -94.79 ... -90.21 -90.12 -90.04\nAttributes:\n    colorBarMaximum:  30.0\n    colorBarMinimum:  0.03\n    colorBarScale:    Log\n    ioos_category:    Ocean Color\n    long_name:        Chlorophyll Concentration, OCI Algorithm\n    references:       Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a a...\n    standard_name:    concentration_of_chlorophyll_in_sea_water\n    units:            mg m^-3\n    valid_max:        100.0\n    valid_min:        0.001xarray.DataArray'chlorophyll'time: 157latitude: 60longitude: 60...[565200 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]1997-09-16 ... 2010-12-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000', '1998-02-16T00:00:00.000000000',\n       '1998-03-16T00:00:00.000000000', '1998-04-16T00:00:00.000000000',\n       '1998-05-16T00:00:00.000000000', '1998-06-16T00:00:00.000000000',\n       '1998-07-16T00:00:00.000000000', '1998-08-16T00:00:00.000000000',\n       '1998-09-16T00:00:00.000000000', '1998-10-16T00:00:00.000000000',\n       '1998-11-16T00:00:00.000000000', '1998-12-16T00:00:00.000000000',\n       '1999-01-16T00:00:00.000000000', '1999-02-16T00:00:00.000000000',\n       '1999-03-16T00:00:00.000000000', '1999-04-16T00:00:00.000000000',\n       '1999-05-16T00:00:00.000000000', '1999-06-16T00:00:00.000000000',\n       '1999-07-16T00:00:00.000000000', '1999-08-16T00:00:00.000000000',\n       '1999-09-16T00:00:00.000000000', '1999-10-16T00:00:00.000000000',\n       '1999-11-16T00:00:00.000000000', '1999-12-16T00:00:00.000000000',\n       '2000-01-16T00:00:00.000000000', '2000-02-16T00:00:00.000000000',\n       '2000-03-16T00:00:00.000000000', '2000-04-16T00:00:00.000000000',\n       '2000-05-16T00:00:00.000000000', '2000-06-16T00:00:00.000000000',\n       '2000-07-16T00:00:00.000000000', '2000-08-16T00:00:00.000000000',\n       '2000-09-16T00:00:00.000000000', '2000-10-16T00:00:00.000000000',\n       '2000-11-16T00:00:00.000000000', '2000-12-16T00:00:00.000000000',\n       '2001-01-16T00:00:00.000000000', '2001-02-16T00:00:00.000000000',\n       '2001-03-16T00:00:00.000000000', '2001-04-16T00:00:00.000000000',\n       '2001-05-16T00:00:00.000000000', '2001-06-16T00:00:00.000000000',\n       '2001-07-16T00:00:00.000000000', '2001-08-16T00:00:00.000000000',\n       '2001-09-16T00:00:00.000000000', '2001-10-16T00:00:00.000000000',\n       '2001-11-16T00:00:00.000000000', '2001-12-16T00:00:00.000000000',\n       '2002-01-16T00:00:00.000000000', '2002-02-16T00:00:00.000000000',\n       '2002-03-16T00:00:00.000000000', '2002-04-16T00:00:00.000000000',\n       '2002-05-16T00:00:00.000000000', '2002-06-16T00:00:00.000000000',\n       '2002-07-16T00:00:00.000000000', '2002-08-16T00:00:00.000000000',\n       '2002-09-16T00:00:00.000000000', '2002-10-16T00:00:00.000000000',\n       '2002-11-16T00:00:00.000000000', '2002-12-16T00:00:00.000000000',\n       '2003-01-16T00:00:00.000000000', '2003-02-16T00:00:00.000000000',\n       '2003-03-16T00:00:00.000000000', '2003-04-16T00:00:00.000000000',\n       '2003-05-16T00:00:00.000000000', '2003-06-16T00:00:00.000000000',\n       '2003-07-16T00:00:00.000000000', '2003-08-16T00:00:00.000000000',\n       '2003-09-16T00:00:00.000000000', '2003-10-16T00:00:00.000000000',\n       '2003-11-16T00:00:00.000000000', '2003-12-16T00:00:00.000000000',\n       '2004-01-16T00:00:00.000000000', '2004-02-16T00:00:00.000000000',\n       '2004-03-16T00:00:00.000000000', '2004-04-16T00:00:00.000000000',\n       '2004-05-16T00:00:00.000000000', '2004-06-16T00:00:00.000000000',\n       '2004-07-16T00:00:00.000000000', '2004-08-16T00:00:00.000000000',\n       '2004-09-16T00:00:00.000000000', '2004-10-16T00:00:00.000000000',\n       '2004-11-16T00:00:00.000000000', '2004-12-16T00:00:00.000000000',\n       '2005-01-16T00:00:00.000000000', '2005-02-16T00:00:00.000000000',\n       '2005-03-16T00:00:00.000000000', '2005-04-16T00:00:00.000000000',\n       '2005-05-16T00:00:00.000000000', '2005-06-16T00:00:00.000000000',\n       '2005-07-16T00:00:00.000000000', '2005-08-16T00:00:00.000000000',\n       '2005-09-16T00:00:00.000000000', '2005-10-16T00:00:00.000000000',\n       '2005-11-16T00:00:00.000000000', '2005-12-16T00:00:00.000000000',\n       '2006-01-16T00:00:00.000000000', '2006-02-16T00:00:00.000000000',\n       '2006-03-16T00:00:00.000000000', '2006-04-16T00:00:00.000000000',\n       '2006-05-16T00:00:00.000000000', '2006-06-16T00:00:00.000000000',\n       '2006-07-16T00:00:00.000000000', '2006-08-16T00:00:00.000000000',\n       '2006-09-16T00:00:00.000000000', '2006-10-16T00:00:00.000000000',\n       '2006-11-16T00:00:00.000000000', '2006-12-16T00:00:00.000000000',\n       '2007-01-16T00:00:00.000000000', '2007-02-16T00:00:00.000000000',\n       '2007-03-16T00:00:00.000000000', '2007-04-16T00:00:00.000000000',\n       '2007-05-16T00:00:00.000000000', '2007-06-16T00:00:00.000000000',\n       '2007-07-16T00:00:00.000000000', '2007-08-16T00:00:00.000000000',\n       '2007-09-16T00:00:00.000000000', '2007-10-16T00:00:00.000000000',\n       '2007-11-16T00:00:00.000000000', '2007-12-16T00:00:00.000000000',\n       '2008-01-16T00:00:00.000000000', '2008-04-16T00:00:00.000000000',\n       '2008-05-16T00:00:00.000000000', '2008-06-16T00:00:00.000000000',\n       '2008-07-16T00:00:00.000000000', '2008-08-16T00:00:00.000000000',\n       '2008-09-16T00:00:00.000000000', '2008-10-16T00:00:00.000000000',\n       '2008-11-16T00:00:00.000000000', '2008-12-16T00:00:00.000000000',\n       '2009-01-16T00:00:00.000000000', '2009-02-16T00:00:00.000000000',\n       '2009-03-16T00:00:00.000000000', '2009-04-16T00:00:00.000000000',\n       '2009-06-16T00:00:00.000000000', '2009-07-16T00:00:00.000000000',\n       '2009-08-16T00:00:00.000000000', '2009-09-16T00:00:00.000000000',\n       '2009-10-16T00:00:00.000000000', '2009-11-16T00:00:00.000000000',\n       '2009-12-16T00:00:00.000000000', '2010-01-16T00:00:00.000000000',\n       '2010-02-16T00:00:00.000000000', '2010-03-16T00:00:00.000000000',\n       '2010-04-16T00:00:00.000000000', '2010-05-16T00:00:00.000000000',\n       '2010-06-16T00:00:00.000000000', '2010-07-16T00:00:00.000000000',\n       '2010-08-16T00:00:00.000000000', '2010-09-16T00:00:00.000000000',\n       '2010-10-16T00:00:00.000000000', '2010-11-16T00:00:00.000000000',\n       '2010-12-16T00:00:00.000000000'], dtype='datetime64[ns]')latitude(latitude)float3229.96 29.87 29.79 ... 25.12 25.04_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([29.958334, 29.874998, 29.791666, 29.708334, 29.624998, 29.541666,\n       29.458334, 29.374998, 29.291666, 29.208334, 29.124998, 29.041666,\n       28.958334, 28.874998, 28.791666, 28.708334, 28.624998, 28.541666,\n       28.458334, 28.374998, 28.291666, 28.208334, 28.124998, 28.041666,\n       27.958334, 27.874998, 27.791666, 27.708334, 27.624998, 27.541666,\n       27.458334, 27.374998, 27.291666, 27.208334, 27.124998, 27.041666,\n       26.958334, 26.874998, 26.791666, 26.708334, 26.624998, 26.541666,\n       26.458334, 26.374998, 26.291666, 26.208334, 26.124998, 26.041666,\n       25.958334, 25.874998, 25.791662, 25.708334, 25.624998, 25.541662,\n       25.458334, 25.374998, 25.291662, 25.208334, 25.124998, 25.041662],\n      dtype=float32)longitude(longitude)float32-94.96 -94.88 ... -90.12 -90.04_CoordinateAxisType :Lonactual_range :[-179.9583  179.9584]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-94.958336, -94.875   , -94.791664, -94.708336, -94.625   , -94.541664,\n       -94.458336, -94.375   , -94.291664, -94.208336, -94.125   , -94.041664,\n       -93.958336, -93.875   , -93.791664, -93.708336, -93.625   , -93.541664,\n       -93.458336, -93.375   , -93.291664, -93.208336, -93.125   , -93.041664,\n       -92.958336, -92.875   , -92.791664, -92.708336, -92.625   , -92.541664,\n       -92.458336, -92.375   , -92.291664, -92.208336, -92.125   , -92.041664,\n       -91.958336, -91.875   , -91.791664, -91.708336, -91.625   , -91.541664,\n       -91.458336, -91.375   , -91.291664, -91.208336, -91.125   , -91.041664,\n       -90.958336, -90.875   , -90.791664, -90.708336, -90.625   , -90.541664,\n       -90.458336, -90.375   , -90.291664, -90.208336, -90.125   , -90.041664],\n      dtype=float32)Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16', '1998-02-16', '1998-03-16', '1998-04-16',\n               '1998-05-16', '1998-06-16',\n               ...\n               '2010-03-16', '2010-04-16', '2010-05-16', '2010-06-16',\n               '2010-07-16', '2010-08-16', '2010-09-16', '2010-10-16',\n               '2010-11-16', '2010-12-16'],\n              dtype='datetime64[ns]', name='time', length=157, freq=None))latitudePandasIndexPandasIndex(Index([ 29.95833396911621, 29.874998092651367,  29.79166603088379,\n        29.70833396911621, 29.624998092651367,  29.54166603088379,\n        29.45833396911621, 29.374998092651367,  29.29166603088379,\n        29.20833396911621, 29.124998092651367,  29.04166603088379,\n        28.95833396911621, 28.874998092651367,  28.79166603088379,\n        28.70833396911621, 28.624998092651367,  28.54166603088379,\n        28.45833396911621, 28.374998092651367,  28.29166603088379,\n        28.20833396911621, 28.124998092651367,  28.04166603088379,\n        27.95833396911621, 27.874998092651367,  27.79166603088379,\n        27.70833396911621, 27.624998092651367,  27.54166603088379,\n        27.45833396911621, 27.374998092651367,  27.29166603088379,\n        27.20833396911621, 27.124998092651367,  27.04166603088379,\n        26.95833396911621, 26.874998092651367,  26.79166603088379,\n        26.70833396911621, 26.624998092651367,  26.54166603088379,\n        26.45833396911621, 26.374998092651367,  26.29166603088379,\n        26.20833396911621, 26.124998092651367,  26.04166603088379,\n        25.95833396911621, 25.874998092651367, 25.791662216186523,\n        25.70833396911621, 25.624998092651367, 25.541662216186523,\n        25.45833396911621, 25.374998092651367, 25.291662216186523,\n        25.20833396911621, 25.124998092651367, 25.041662216186523],\n      dtype='float32', name='latitude'))longitudePandasIndexPandasIndex(Index([-94.95833587646484,            -94.875, -94.79166412353516,\n       -94.70833587646484,            -94.625, -94.54166412353516,\n       -94.45833587646484,            -94.375, -94.29166412353516,\n       -94.20833587646484,            -94.125, -94.04166412353516,\n       -93.95833587646484,            -93.875, -93.79166412353516,\n       -93.70833587646484,            -93.625, -93.54166412353516,\n       -93.45833587646484,            -93.375, -93.29166412353516,\n       -93.20833587646484,            -93.125, -93.04166412353516,\n       -92.95833587646484,            -92.875, -92.79166412353516,\n       -92.70833587646484,            -92.625, -92.54166412353516,\n       -92.45833587646484,            -92.375, -92.29166412353516,\n       -92.20833587646484,            -92.125, -92.04166412353516,\n       -91.95833587646484,            -91.875, -91.79166412353516,\n       -91.70833587646484,            -91.625, -91.54166412353516,\n       -91.45833587646484,            -91.375, -91.29166412353516,\n       -91.20833587646484,            -91.125, -91.04166412353516,\n       -90.95833587646484,            -90.875, -90.79166412353516,\n       -90.70833587646484,            -90.625, -90.54166412353516,\n       -90.45833587646484,            -90.375, -90.29166412353516,\n       -90.20833587646484,            -90.125, -90.04166412353516],\n      dtype='float32', name='longitude'))Attributes: (10)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll Concentration, OCI Algorithmreferences :Hu, C., Lee Z., and Franz, B.A. (2012). Chlorophyll-a algorithms for oligotrophic oceans: A novel approach based on three-band reflectance difference, J. Geophys. Res., 117, C01011, doi:10.1029/2011JC007395.standard_name :concentration_of_chlorophyll_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001\n\n\n\n\nPlot data to show where it is in the world.\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\nax1.set_extent([240, 300, 5, 45], ccrs.PlateCarree())\n\n# Set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(235, 305, 20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(0, 50, 10), crs=ccrs.PlateCarree())\n\n# Add features to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# Format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nnp.log10(sw_subset[-1]).plot.pcolormesh(ax=ax1, \n                                        transform=ccrs.PlateCarree(), \n                                        cmap='jet', \n                                        cbar_kwargs={'label': \"log chlorophyll (mg m-3)\"})\n\nplt.title('Time series data location - Gulf of Mexico')\n\nText(0.5, 1.0, 'Time series data location - Gulf of Mexico')\n\n\n\n\n\n\n\n\n\n\n\nCompute the monthly mean over the region\n\nswAVG = sw_subset.mean(dim=['latitude','longitude'])\nswAVG.head()\n\n# If you are running low on memory, uncomment the next line\n# del sw_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlorophyll' (time: 5)&gt;\narray([0.59386134, 0.59238297, 0.68359953, 0.81557316, 0.85900825],\n      dtype=float32)\nCoordinates:\n  * time     (time) datetime64[ns] 1997-09-16 1997-10-16 ... 1998-01-16xarray.DataArray'chlorophyll'time: 50.5939 0.5924 0.6836 0.8156 0.859array([0.59386134, 0.59238297, 0.68359953, 0.81557316, 0.85900825],\n      dtype=float32)Coordinates: (1)time(time)datetime64[ns]1997-09-16 ... 1998-01-16_CoordinateAxisType :Timeactual_range :[8.7436800e+08 1.2924576e+09]axis :Tioos_category :Timelong_name :Centered Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-16T00:00:00.000000000', '1997-10-16T00:00:00.000000000',\n       '1997-11-16T00:00:00.000000000', '1997-12-16T00:00:00.000000000',\n       '1998-01-16T00:00:00.000000000'], dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-16', '1997-10-16', '1997-11-16', '1997-12-16',\n               '1998-01-16'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)"
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#get-monthly-modis-data",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#get-monthly-modis-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get monthly MODIS data",
    "text": "Get monthly MODIS data\n\nRepeat the steps above to get data for the MODIS Aqua chlorophyll dataset\n\nurl_modis = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                      'erddap',\n                      'griddap',\n                      'erdMH1chlamday_R2022SQ'\n                      ])\nmodis_ds = xr.open_dataset(url_modis)\nmodis_ds\n\nprint('earliest date =', modis_ds.time.values[0])\nprint('latest date =', modis_ds.time.values[-1], '\\n')\nprint('variables:', modis_ds.data_vars.keys(), '\\n')\nprint('Is the first latitude value --&gt;', modis_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', modis_ds.latitude[-1].item())\n\nprint(modis_ds.latitude[0].item() &gt; modis_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif modis_ds.latitude[0].item() &gt; modis_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\nmodis_subset = modis_ds['chlor_a'].sel(time=slice(modis_ds.time[0], modis_ds.time[-1]),\n                                       latitude=slice(lat1, lat2),\n                                       longitude=slice(lon_min, lon_max)\n                                       )\n\nmodisAVG = modis_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del modis_subset \n\nearliest date = 2002-07-16T00:00:00.000000000\nlatest date = 2023-07-16T00:00:00.000000000 \n\nvariables: KeysView(Data variables:\n    chlor_a  (time, latitude, longitude) float32 ...) \n\nIs the first latitude value --&gt; 89.97916412353516\ngreater than the last latitude value --&gt; -89.97917175292969\nTrue"
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#get-monthly-viirs-data",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#get-monthly-viirs-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get monthly VIIRS data",
    "text": "Get monthly VIIRS data\n\nRepeat the steps above to get data for the VIIRS SNPP chlorophyll dataset\n\nurl_viirs = '/'.join(['https://coastwatch.noaa.gov',\n                        'erddap',\n                        'griddap',\n                        'noaacwNPPVIIRSSQchlaMonthly'\n                        ])\nviirs_ds = xr.open_dataset(url_viirs)\nviirs_ds\n\nprint('earliest date =', viirs_ds.time.values[0])\nprint('latest date =', viirs_ds.time.values[-1], '\\n')\nprint('variables:', viirs_ds.data_vars.keys(), '\\n')\n\nprint('Is the first latitude value --&gt;', viirs_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', viirs_ds.latitude[-1].item())\n\nprint(viirs_ds.latitude[0].item() &gt; viirs_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif viirs_ds.latitude[0].item() &gt; viirs_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\nviirs_subset = modis_ds['chlor_a'].sel(time=slice(viirs_ds.time[0], viirs_ds.time[-1]),\n                                       latitude=slice(lat1, lat2),\n                                       longitude=slice(lon_min, lon_max)\n                                       )\nviirsAVG = viirs_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del viirs_subset \n\nearliest date = 2012-01-02T12:00:00.000000000\nlatest date = 2023-08-01T12:00:00.000000000 \n\nvariables: KeysView(Data variables:\n    chlor_a  (time, altitude, latitude, longitude) float32 ...) \n\nIs the first latitude value --&gt; 89.75625\ngreater than the last latitude value --&gt; -89.75625\nTrue"
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#plot-the-time-series",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#plot-the-time-series",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Plot the time series",
    "text": "Plot the time series\n\nPlot the result for three datasets\n\nplt.figure(figsize=(10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(swAVG.time, swAVG, \n              'o', markersize=3, \n              label='SeaWiFS', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(modisAVG.time, modisAVG, \n              'o', markersize=3, \n              label='MODIS', c='blue', \n              linestyle='-', linewidth=1) \n\n# Add VIIRS data\nplt.plot_date(viirsAVG.time, viirsAVG, \n              'o', markersize=3, \n              label='VIIRS', c='green', \n              linestyle='-', linewidth=1) \n\nplt.ylim([0, 3])\nplt.ylabel('Chl-a (mg m-3)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#get-oc-cci-data",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#get-oc-cci-data",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Get OC-CCI data",
    "text": "Get OC-CCI data\nIf you needed a single time series from 1997 to present, you would have to use the plot above to devise some method to reconcile the difference in values where two datasets overlap. Alternatively, you could use the ESA OC-CCI (Ocean Color Climate Change Initiative) dataset, which blends data from many satellite missions into a single dataset, including data from SeaWiFS, MODIS, and VIIRS.\nAdd the ESA OC-CCI dataset to the plot above to see how it compares with data from the individual satellite missions.\n### Repeat the steps above to get data from the ESA OC-CCI chlorophyll dataset\n\nurl_cci = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                    'erddap',\n                    'griddap',\n                    'pmlEsaCCI60OceanColorMonthly'\n                    ])\ncci_ds = xr.open_dataset(url_cci)\ncci_ds\n\nprint('earliest date =', cci_ds.time.values[0])\nprint('latest date =', cci_ds.time.values[-1])\n\n# From the 93 variables in the dataset, \n# display only those with chl in the name\nsubset_variables = [ln for ln in list(cci_ds.data_vars.keys()) if 'chl' in ln]\n\nprint('variables with chl in name:', subset_variables, '\\n')\n\n\nprint('Is the first latitude value --&gt;', cci_ds.latitude[0].item())\nprint('greater than the last latitude value --&gt;', cci_ds.latitude[-1].item())\n\nprint(cci_ds.latitude[0].item() &gt; cci_ds.latitude[-1].item())\n\nlat1 = lat_min\nlat2 = lat_max\n\nif cci_ds.latitude[0].item() &gt; cci_ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\ncci_subset = cci_ds['chlor_a'].sel(time=slice(cci_ds.time[0], cci_ds.time[-1]),\n                                   latitude=slice(lat1, lat2),\n                                   longitude=slice(lon_min, lon_max)\n                                   )\ncciAVG = cci_subset.mean(dim=['latitude', 'longitude'])\n\n# If you are running low on memory, uncomment the next line\n# del cci_subset \n\nearliest date = 1997-09-04T00:00:00.000000000\nlatest date = 2023-03-01T00:00:00.000000000\nvariables with chl in name: ['chlor_a', 'chlor_a_log10_bias', 'chlor_a_log10_rmsd'] \n\nIs the first latitude value --&gt; 89.97916666666667\ngreater than the last latitude value --&gt; -89.97916666666666\nTrue"
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#replot-the-results-using-data-from-all-four-datasets",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#replot-the-results-using-data-from-all-four-datasets",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "Replot the results using data from all four datasets",
    "text": "Replot the results using data from all four datasets\n\nplt.figure(figsize=(10, 5)) \n\n# Add SeaWiFS data\nplt.plot_date(swAVG.time, swAVG, \n              'o', markersize=0, \n              label='SeaWiFS', c='red', \n              linestyle='-', linewidth=1) \n\n# Add MODIS data\nplt.plot_date(modisAVG.time, modisAVG, \n              's', markersize=0, \n              label='MODIS', c='blue', \n              linestyle='-', linewidth=1) \n\n# Add VIIRS data\nplt.plot_date(viirsAVG.time, viirsAVG, \n              '^', markersize=0, \n              label='VIIRS', c='green', \n              linestyle='-', linewidth=1) \n\n# Add CCI data\nplt.plot_date(cciAVG.time, cciAVG, \n              'o', markersize=3,\n              label='OC-CCI', c='black', \n              linestyle='-', linewidth=1) \n\nplt.ylim([0, 3])\nplt.ylabel('Chl-a (mg m-3)') \nplt.legend()"
  },
  {
    "objectID": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#references",
    "href": "tutorials/python/Tutorial2-timeseries-compare-sensors.html#references",
    "title": "Tutorial 2. Compare time series from different sensors",
    "section": "References",
    "text": "References\n\nCoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html\nhttps://polarwatch.noaa.gov/catalog/"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html",
    "title": "Working with data that crosses the antimeridian",
    "section": "",
    "text": "History | Updated Sep 2023"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#background",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#background",
    "title": "Working with data that crosses the antimeridian",
    "section": "Background",
    "text": "Background\nMany datasets use a system where longitude is numbered from -180 to +180 degrees east (see example below). This numbering system presents a problem for researchers working in a region that spans the antimeridian, because the parts of the data end up on the opposite ends of the map.\n\n\n\nmap_-180to180_500px.png\n\n\n\nFigure. Global map on -180/+180 longitude showing data region crossing the antimeridian."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#objectives",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#objectives",
    "title": "Working with data that crosses the antimeridian",
    "section": "Objectives",
    "text": "Objectives\nThis tutorial will demonstrate how to use datasets with -180 to +180 longitude values to work within regions that cross the antimeridian."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Working with data that crosses the antimeridian",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data that crosses the antimeridian from a dataset with -180 to +180 longitude values\n\nConvert the data to a 0-360 longitude values\nReordering the longitude axis so that the longitude values are in ascending order\nVisualizing data on a map"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#datasets-used",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#datasets-used",
    "title": "Working with data that crosses the antimeridian",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Chlorophyll Gap-filled, Blended NOAA-20 and S-NPP VIIRS, Science Quality, Global, 9km, 2018- recent, Daily\nThis NOAA dataset blends chlorophyll data from the Visible and Infrared Imager/Radiometer Suite (VIIRS) sensors aboard the Suomi-NPP and NOAA-20 spacecraft. The gaps in the data are then filled using an empirical orthogonal function (DINEOF). The dataset is available from the CoastWatch Central ERDDAP: https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily\n\nImport packages\n\nimport xarray as xr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#define-the-area-to-extract",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#define-the-area-to-extract",
    "title": "Working with data that crosses the antimeridian",
    "section": "Define the area to extract",
    "text": "Define the area to extract\nWe will extract data for an area in the Bering Sea between Russia and the United States at 176°E to -152°E longitude and 50°N to 70°N latitude.\n\n\n\ninterest_area_500px.png\n\n\n\nSet up variables\n\nDate to extract\nMinimum and maximum values for the longitude and latitude ranges.\n\n\nmy_date = '2023-08-18'\nlon_min = -152.\nlon_max = 176.\nlat_min = 50.\nlat_max = 70."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#get-the-seawifs-data",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#get-the-seawifs-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Get the SeaWiFS data",
    "text": "Get the SeaWiFS data\n\nOpen an xarray dataset object\n\n#url = 'https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily'\n\nurl = '/'.join(['https://coastwatch.noaa.gov',\n                'erddap',\n                'griddap',\n                'noaacwNPPN20VIIRSSCIDINEOFDaily'\n                ])\n\nds = xr.open_dataset(url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:    (time: 1874, altitude: 1, latitude: 2160, longitude: 4320)\nCoordinates:\n  * time       (time) datetime64[ns] 2018-05-30T12:00:00 ... 2023-08-24T12:00:00\n  * altitude   (altitude) float64 0.0\n  * latitude   (latitude) float32 89.96 89.88 89.79 ... -89.79 -89.88 -89.96\n  * longitude  (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nData variables:\n    chlor_a    (time, altitude, latitude, longitude) float32 ...\nAttributes: (12/77)\n    _lastModified:                    2023-09-04T21:15:13.000Z\n    _NCProperties:                    version=2,netcdf=4.7.3,hdf5=1.12.0,\n    cdm_data_type:                    Grid\n    Conventions:                      CF-1.6, COARDS, ACDD-1.3\n    creator_email:                    coastwatch.info@noaa.gov\n    creator_name:                     NOAA CoastWatch\n    ...                               ...\n    testOutOfDate:                    now-4days\n    time_coverage_end:                2023-08-24T12:00:00Z\n    time_coverage_start:              2018-05-30T12:00:00Z\n    title:                            Chlorophyll (Gap-filled DINEOF), NOAA S...\n    Westernmost_Easting:              -179.9583\n    westernmost_longitude:            -180.0xarray.DatasetDimensions:time: 1874altitude: 1latitude: 2160longitude: 4320Coordinates: (4)time(time)datetime64[ns]2018-05-30T12:00:00 ... 2023-08-..._CoordinateAxisType :Timeactual_range :[1.5276816e+09 1.6928784e+09]axis :Tioos_category :Timelong_name :Timesource_name :timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2018-05-30T12:00:00.000000000', '2018-05-31T12:00:00.000000000',\n       '2018-06-01T12:00:00.000000000', ..., '2023-08-22T12:00:00.000000000',\n       '2023-08-23T12:00:00.000000000', '2023-08-24T12:00:00.000000000'],\n      dtype='datetime64[ns]')altitude(altitude)float640.0_CoordinateAxisType :Height_CoordinateZisPositive :upactual_range :[0. 0.]axis :Zioos_category :Locationlong_name :Altitudepositive :upstandard_name :altitudeunits :marray([0.])latitude(latitude)float3289.96 89.88 89.79 ... -89.88 -89.96_ChunkSizes :2160_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudesource_name :latstandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([ 89.958336,  89.875   ,  89.791664, ..., -89.79167 , -89.87501 ,\n       -89.958336], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_ChunkSizes :4320_CoordinateAxisType :Lonactual_range :[-179.9583  179.9583]axis :Xioos_category :Locationlong_name :Longitudesource_name :lonstandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79167, ...,  179.79167,  179.87502,\n        179.95834], dtype=float32)Data variables: (1)chlor_a(time, altitude, latitude, longitude)float32...C_format :%.4gcell_methods :time:mean(interval:1 day)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logcoverage_content_type :physicalMeasurementgrid_mapping :coord_refioos_category :Ocean Colorlong_name :Chlorophyll Concentration, DINEOF Gap-Filledstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001[17486668800 values with dtype=float32]Indexes: (4)timePandasIndexPandasIndex(DatetimeIndex(['2018-05-30 12:00:00', '2018-05-31 12:00:00',\n               '2018-06-01 12:00:00', '2018-06-02 12:00:00',\n               '2018-06-03 12:00:00', '2018-06-04 12:00:00',\n               '2018-06-05 12:00:00', '2018-06-06 12:00:00',\n               '2018-06-07 12:00:00', '2018-06-08 12:00:00',\n               ...\n               '2023-08-15 12:00:00', '2023-08-16 12:00:00',\n               '2023-08-17 12:00:00', '2023-08-18 12:00:00',\n               '2023-08-19 12:00:00', '2023-08-20 12:00:00',\n               '2023-08-21 12:00:00', '2023-08-22 12:00:00',\n               '2023-08-23 12:00:00', '2023-08-24 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=1874, freq=None))altitudePandasIndexPandasIndex(Index([0.0], dtype='float64', name='altitude'))latitudePandasIndexPandasIndex(Index([ 89.95833587646484,             89.875,  89.79166412353516,\n        89.70833587646484,             89.625,  89.54166412353516,\n        89.45833587646484,             89.375,  89.29166412353516,\n        89.20833587646484,\n       ...\n       -89.20833587646484, -89.29167175292969, -89.37500762939453,\n       -89.45833587646484, -89.54167175292969, -89.62500762939453,\n       -89.70833587646484, -89.79167175292969, -89.87500762939453,\n       -89.95833587646484],\n      dtype='float32', name='latitude', length=2160))longitudePandasIndexPandasIndex(Index([-179.9583282470703,           -179.875, -179.7916717529297,\n       -179.7083282470703,           -179.625, -179.5416717529297,\n       -179.4583282470703,           -179.375, -179.2916717529297,\n       -179.2083282470703,\n       ...\n       179.20834350585938,  179.2916717529297, 179.37501525878906,\n       179.45834350585938,  179.5416717529297, 179.62501525878906,\n       179.70834350585938,  179.7916717529297, 179.87501525878906,\n       179.95834350585938],\n      dtype='float32', name='longitude', length=4320))Attributes: (77)_lastModified :2023-09-04T21:15:13.000Z_NCProperties :version=2,netcdf=4.7.3,hdf5=1.12.0,cdm_data_type :GridConventions :CF-1.6, COARDS, ACDD-1.3creator_email :coastwatch.info@noaa.govcreator_name :NOAA CoastWatchcreator_type :groupcreator_url :https://coastwatch.noaa.gov/data_bins :4466138.0data_maximum :301.4826data_minimum :0.0022108806date_created :2023-09-04T21:15:13.000ZEasternmost_Easting :179.9583easternmost_longitude :180.0end_orbit_number :0geospatial_lat_max :89.95834geospatial_lat_min :-89.95834geospatial_lat_resolution :0.08333333950903196geospatial_lat_units :degrees_northgeospatial_lon_max :179.9583geospatial_lon_min :-179.9583geospatial_lon_resolution :0.0833333178976615geospatial_lon_units :degrees_eastgeospatial_vertical_max :0.0geospatial_vertical_min :0.0geospatial_vertical_positive :upgeospatial_vertical_units :mhistory :/data/data369/hgu/ocssw/bin/l3mapgen par=/data/data652/coastwatch/oc/L3/scripts/bin/../config/l3mapgen_par_dineof_chlor_a ifile=/data/data652/coastwatch/oc/L3/scripts/bin/../temp/Config_dineof/V2023236_oci_L3.nc ofile=/data/data369/viirs/L3_dineof/236/V2023236_A1_WW00_chlor_a.nc   Mon Sep  4 21:15:16 2023\n: /data/data652/coastwatch/oc/L3/scripts/bin/l3cnvtr -b -s Suomi-NPP,NOAA-20 /data/data369/viirs/L3_dineof/236/V2023236_A1_WW00_chlor_a.nc /data/aftp/socd1/mecb/coastwatch/viirs/science/L3/global/chlora/dineof/2023/V2023236_A1_WW00_chlora.nc\n2023-09-05T23:55:50Z (local files)\n2023-09-05T23:55:50Z https://coastwatch.noaa.gov/erddap/griddap/noaacwNPPN20VIIRSSCIDINEOFDaily.dasid :L3//data/data540/DINEOF/EOF-global-daily4/reconstructed_mix_nsw/V2023236_oci_L3.ncinfoUrl :https://coastwatch.noaa.gov/institution :NOAA NESDIS CoastWatchinstrument :VIIRSkeywords :altitude, applications, baseline, center, chlorophyll, data, environmental, graphics, imager, imager/radiometer, imaging, information, infrared, latitude, leaving, longitude, mean, merged, n20, national, nesdis, noaa, NOAA-20, normalized, npp, optical, optical properties, orbiting, overlay, partnership, planes, polar, polar-orbiting, properties, radiance, radiometer, research, satellite, service, suite, time, viirs, visible, water, water-leaving, ww00l2_flag_names :ATMFAIL,LAND,HIGLINT,HILT,HISATZEN,CLOUD,HISOLZEN,LOWLW,CHLFAIL,NAVWARN,CLDSHDSTL,MAXAERITER,CHLWARN,ALGICE,SEAICE,NAVFAIL,FILTERlatitude_step :0.083333336latitude_units :degrees_northlicense :These data were produced by NOAA and are not subject to copyright protection in the United States. \nNOAA waives any potential copyright and related rights in these data worldwide through the Creative \nCommons Zero 1.0 Universal Public Domain Dedication (CC0-1.0). \nThe data may be used and redistributed for free but is not intended\n for legal use, since it may contain inaccuracies. Neither the data\n Contributor, ERD, NOAA, nor the United States Government, nor any\n of their employees or contractors, makes any warranty, express or\n implied, including warranties of merchantability and fitness for a\n particular purpose, or assumes any legal liability for the accuracy,\n completeness, or usefulness, of this information.longitude_step :0.083333336longitude_units :degrees_eastmap_projection :geographicmeasure :Meannaming_authority :gov.noaa.coastwatchnorthernmost_latitude :90.0Northernmost_Northing :89.95834number_of_columns :4320number_of_lines :2160platform :Suomi-NPP, NOAA-20processing_level :L3 Mappedprocessing_version :Unspecifiedproduct_name :V2023236_A1_WW00_chlora.ncproj4_string :+proj=eqc +lat_ts=0 +lat_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +lon_0=0.000000project :Ocean Color Science Team (NOAA/NESDIS/STAR/OCST)publisher_email :coastwatch.info@noaa.gov;ncei.info@noaa.govpublisher_name :NOAA CoastWatch;National Centers for Environmental Information (NCEI)publisher_url :https://coastwatch.noaa.gov;https://www.ncei.noaa.gov/Satellite :Suomi-NPP\n NOAA-20Sensor :VIIRSsourceUrl :(local files)southernmost_latitude :-90.0Southernmost_Northing :-89.95834spatialResolution :9.28 kmstandard_name_vocabulary :CF Standard Name Table v29start_orbit_number :0suggested_image_scaling_applied :Nosuggested_image_scaling_maximum :20.0suggested_image_scaling_minimum :0.01suggested_image_scaling_type :LOGsummary :Visible and Infrared Imager/Radiometer Suite/Suomi-NPP NOAA-20 (VIIRS) Level-3 (WW00), Chlorophyll, DINEOF, Gap filled, MSL12,  Science Quality,Global, Daily, processed by NOAA.  EXPERIMENTAL.sw_point_latitude :-89.958336sw_point_longitude :-179.95833temporal_range :dailytestOutOfDate :now-4daystime_coverage_end :2023-08-24T12:00:00Ztime_coverage_start :2018-05-30T12:00:00Ztitle :Chlorophyll (Gap-filled DINEOF), NOAA S-NPP NOAA-20, VIIRS, Science Quality, Global 9km, 2018-recent,  DailyWesternmost_Easting :-179.9583westernmost_longitude :-180.0\n\n\n\n\nSubset the data\nWe will do this in two steps to make the process easier to follow. 1. Subset the data for date and latitude range 2. Subset the area around the antimeridian * Request data &lt; the limit (-152) on the US side of the antimeridian, i.e. -180 to -152 * Request data &gt; the limit (176) on the Russian side of the antimeridian, i.e. 176 to 180\n\n# The lat1 and lat2 values are used in the slice function\n# At first we set them as if the dataset is compliant with standards\nlat1 = lat_min\nlat2 = lat_max\n\n# Then switch them if latitude values are descending\nif ds.latitude[0].item() &gt; ds.latitude[-1].item():\n    lat1 = lat_max\n    lat2 = lat_min\n\n# Subset the data in two steps to make it easier to understand\n# 1. Subset the date and latitude range\nds_subset = ds['chlor_a'].sel(time=my_date, \n                              method='nearest').sel(latitude=slice(lat1, lat2))\n\n# 2. Subset the around the antimeridian\nds_subset = ds_subset.sel(longitude=(ds.longitude &lt; lon_min) \n                          | (ds.longitude &gt; lon_max)\n                          )\n\nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'chlor_a' (altitude: 1, latitude: 240, longitude: 384)&gt;\n[92160 values with dtype=float32]\nCoordinates:\n    time       datetime64[ns] 2023-08-18T12:00:00\n  * altitude   (altitude) float64 0.0\n  * latitude   (latitude) float32 69.96 69.88 69.79 69.71 ... 50.21 50.12 50.04\n  * longitude  (longitude) float32 -180.0 -179.9 -179.8 ... 179.8 179.9 180.0\nAttributes: (12/13)\n    C_format:               %.4g\n    cell_methods:           time:mean(interval:1 day)\n    colorBarMaximum:        30.0\n    colorBarMinimum:        0.03\n    colorBarScale:          Log\n    coverage_content_type:  physicalMeasurement\n    ...                     ...\n    ioos_category:          Ocean Color\n    long_name:              Chlorophyll Concentration, DINEOF Gap-Filled\n    standard_name:          mass_concentration_of_chlorophyll_a_in_sea_water\n    units:                  mg m^-3\n    valid_max:              100.0\n    valid_min:              0.001xarray.DataArray'chlor_a'altitude: 1latitude: 240longitude: 384...[92160 values with dtype=float32]Coordinates: (4)time()datetime64[ns]2023-08-18T12:00:00_CoordinateAxisType :Timeactual_range :[1.5276816e+09 1.6928784e+09]axis :Tioos_category :Timelong_name :Timesource_name :timestandard_name :timetime_origin :01-JAN-1970 00:00:00array('2023-08-18T12:00:00.000000000', dtype='datetime64[ns]')altitude(altitude)float640.0_CoordinateAxisType :Height_CoordinateZisPositive :upactual_range :[0. 0.]axis :Zioos_category :Locationlong_name :Altitudepositive :upstandard_name :altitudeunits :marray([0.])latitude(latitude)float3269.96 69.88 69.79 ... 50.12 50.04_ChunkSizes :2160_CoordinateAxisType :Latactual_range :[-89.95834  89.95834]axis :Yioos_category :Locationlong_name :Latitudesource_name :latstandard_name :latitudeunits :degrees_northvalid_max :90.0valid_min :-90.0array([69.958336, 69.875   , 69.791664, ..., 50.208332, 50.125   , 50.041664],\n      dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_ChunkSizes :4320_CoordinateAxisType :Lonactual_range :[-179.9583  179.9583]axis :Xioos_category :Locationlong_name :Longitudesource_name :lonstandard_name :longitudeunits :degrees_eastvalid_max :180.0valid_min :-180.0array([-179.95833, -179.875  , -179.79167, ...,  179.79167,  179.87502,\n        179.95834], dtype=float32)Indexes: (3)altitudePandasIndexPandasIndex(Index([0.0], dtype='float64', name='altitude'))latitudePandasIndexPandasIndex(Index([ 69.95833587646484,             69.875,  69.79166412353516,\n        69.70833587646484,             69.625,  69.54166412353516,\n        69.45833587646484,             69.375,  69.29166412353516,\n        69.20833587646484,\n       ...\n       50.791664123535156,  50.70833206176758,             50.625,\n       50.541664123535156,  50.45833206176758,             50.375,\n       50.291664123535156,  50.20833206176758,             50.125,\n       50.041664123535156],\n      dtype='float32', name='latitude', length=240))longitudePandasIndexPandasIndex(Index([-179.9583282470703,           -179.875, -179.7916717529297,\n       -179.7083282470703,           -179.625, -179.5416717529297,\n       -179.4583282470703,           -179.375, -179.2916717529297,\n       -179.2083282470703,\n       ...\n       179.20834350585938,  179.2916717529297, 179.37501525878906,\n       179.45834350585938,  179.5416717529297, 179.62501525878906,\n       179.70834350585938,  179.7916717529297, 179.87501525878906,\n       179.95834350585938],\n      dtype='float32', name='longitude', length=384))Attributes: (13)C_format :%.4gcell_methods :time:mean(interval:1 day)colorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logcoverage_content_type :physicalMeasurementgrid_mapping :coord_refioos_category :Ocean Colorlong_name :Chlorophyll Concentration, DINEOF Gap-Filledstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m^-3valid_max :100.0valid_min :0.001"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-downloaded-data",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-downloaded-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Plot the downloaded data",
    "text": "Plot the downloaded data\n\n# Make plot area\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Set the color palette\ncmap = mpl.cm.get_cmap(\"jet\").copy()\ncmap.set_bad(color='gray')\n\n# Show image\nshw = ax.imshow(np.log10(ds_subset.squeeze()), cmap=cmap, vmin=-1, vmax=2)\n\nbar = plt.colorbar(shw, shrink=0.65)\n  \n# Show plot with labels\nbar.set_label('Chlorophyll (log mg m-3)')\nplt.show()\n\n\n\n\n\n\n\n\n\nThe plot of the data shows a discontinuity\nThe plot of subsetted data (above) shows that we downloaded the data we requested, but there is a discontinuity on the right side of the map. The data from the Russian side (west of the antimeridian) is mapped to the east of the data on the US side.\nTo fix the discontinuity, we need to:\n* Change the longitude values on the US side of the antimeridian (-180 to -152) to values on the 0-360 longitude indexing system (180-208). * Rearrange the longitude values so that the data on the Russian side is moved to the west of the data on the US side."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#change-to-0-360-longitude-numbering",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#change-to-0-360-longitude-numbering",
    "title": "Working with data that crosses the antimeridian",
    "section": "Change to 0-360 longitude numbering",
    "text": "Change to 0-360 longitude numbering\n\nds_360 = ds_subset.assign_coords(longitude=(ds_subset.longitude % 360))\n\nprint('minimum lon value =', ds_360.longitude.min().item())\nprint('minimum lon value =', ds_360.longitude.max().item(), end='\\n\\n')\n\nprint('first value in lon array =', ds_360.longitude[0].item())\nprint('last value in lon array =', ds_360.longitude[-1].item())\n\nminimum lat value = 176.0416717529297\nminimum lat value = 207.9583282470703\n\nfirst value in lat array = 180.0416717529297\nlast value in lat array = 179.95834350585938"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#reorder-the-longitude-axis",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#reorder-the-longitude-axis",
    "title": "Working with data that crosses the antimeridian",
    "section": "Reorder the longitude axis",
    "text": "Reorder the longitude axis\nThe output from the cell above shows that the longitude values have been converted to 0-360. However, the lowest longitude value is not at the beginning of the array and the highest longitude value is not at the end of the array.\nTo rearrange the longitude values, use the roll function of xarray. The roll function will push values along an axis by the number of steps you enter. The values that are “pushed off” of the end of the array will be put at the beginning of the array.\n\nFirst we need to find the position where the longitude discontinuity happens, i.e. where the most easterly longitude (208.0) abruptly meets the most easterly longitude value (176.0)\nNext, use the discontinuity position to determine how many positions to roll the longitude array to the right. Apply the number to the roll function.\n\n\n# This code finds the index where the absolute value between each longitude value \n# and the largest longitude value is maximal\ndiscont_index = max(range(len(ds_360.longitude)), \n                    key=lambda i: abs(ds_360.longitude[i] -\n                                      ds_360.longitude.max())\n                    )\nprint('the index marking the discontinuity is:', discont_index, end='\\n\\n')\n\n# Substract the discontinuity position from the length of the array \n# to obtain the number of positions to roll the longitude axis\npostions_to_roll = len(ds_360.longitude) - discont_index\n\n# Roll the dataset\nds_rolled = ds_360.roll(longitude=postions_to_roll, roll_coords=True)\n\nprint('minimum lon value =', ds_rolled.longitude.min().item())\nprint('minimum lon value =', ds_rolled.longitude.max().item(), end='\\n\\n')\n\nprint('first value in lon array =', ds_rolled.longitude[0].item())\nprint('last value in lon array =', ds_rolled.longitude[-1].item())\n\nthe index marking the discontinuity is: 336\n\nminimum lon value = 176.0416717529297\nminimum lon value = 207.9583282470703\n\nfirst value in lon array = 176.0416717529297\nlast value in lon array = 207.9583282470703\n\n\nThe output from the cell above shows that the longitude values have been converted to 0-360, and that the lowest longitude value is at the beginning of the array and the highest longitude value is at the end of the array."
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-data",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#plot-the-data",
    "title": "Working with data that crosses the antimeridian",
    "section": "Plot the data",
    "text": "Plot the data\n\nThe discontinuity has been corrected!\n\n# Make plot area\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Set the color palette\ncmap = mpl.cm.get_cmap(\"jet\").copy()\ncmap.set_bad(color='gray')\n\n# show image\nshw = ax.imshow(np.log10(ds_rolled.squeeze()), \n                cmap=cmap,\n                vmin=-1, \n                vmax=2)\n\nbar = plt.colorbar(shw, shrink=0.65)\n  \n# show plot with labels\nbar.set_label('Chlorophyll (log mg m-3)')\nplt.show()"
  },
  {
    "objectID": "tutorials/python/convert-180+180-to-0-360-longitude.html#save-the-corrected-dataset-as-a-netcdf-file",
    "href": "tutorials/python/convert-180+180-to-0-360-longitude.html#save-the-corrected-dataset-as-a-netcdf-file",
    "title": "Working with data that crosses the antimeridian",
    "section": "Save the corrected dataset as a netCDF file",
    "text": "Save the corrected dataset as a netCDF file\n\nds_rolled.to_netcdf('data_corrected_0_to_360.nc')"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html",
    "href": "tutorials/python/define_marine_habitat.html",
    "title": "Define a marine habitat",
    "section": "",
    "text": "History | Updated Sep 2023 ## Background The TurtleWatch project investigated the overlap between loggerhead sea turtles habitat and fishing effort of the Hawaii-based shallow-set longline fishery in the Pacific Ocean north of the Hawaiian Islands. That fishery, which targets swordfish, used to experience high levels of bycatch of loggerhead turtles. Considerable changes in gear and operations lowered bycatch rate and TurtleWatch was designed as a tool to advise fishermen on areas to avoid to limit bycatch.\nResearch results indicated that 50% of interactions occurred between 17.5°C and 18.5°C."
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#objective",
    "href": "tutorials/python/define_marine_habitat.html#objective",
    "title": "Define a marine habitat",
    "section": "Objective",
    "text": "Objective\nHere we will draw the 17.5 and 18.5ºC temperature contours on a map of satellite sea surface temperature."
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#the-exercise-demonstrates-the-following-techniques",
    "href": "tutorials/python/define_marine_habitat.html#the-exercise-demonstrates-the-following-techniques",
    "title": "Define a marine habitat",
    "section": "The exercise demonstrates the following techniques:",
    "text": "The exercise demonstrates the following techniques:\n\nSubsetting and loading data from an ERDDAP server using xarray\n\nSet flag values for features of interest\n\nPlotting maps"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#datasets-used",
    "href": "tutorials/python/define_marine_habitat.html#datasets-used",
    "title": "Define a marine habitat",
    "section": "Datasets used",
    "text": "Datasets used\nCoralTemp Sea Surface Temperature product from the NOAA Coral Reef Watch program. The NOAA Coral Reef Watch (CRW) daily global 5km Sea Surface Temperature (SST) product, also known as CoralTemp, shows the nighttime ocean temperature measured at the surface. The SST scale ranges from -2 to 35 °C. The CoralTemp SST data product was developed from two related reanalysis (reprocessed) SST products and a near real-time SST product. Spanning January 1, 1985 to the present, the CoralTemp SST is one of the best and most internally consistent daily global 5km SST products available. More information about the product: https://coralreefwatch.noaa.gov/product/5km/index_5km_sst.php"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#install-required-packages",
    "href": "tutorials/python/define_marine_habitat.html#install-required-packages",
    "title": "Define a marine habitat",
    "section": "Install required packages",
    "text": "Install required packages\n\nimport xarray as xr    \nimport matplotlib.pyplot as plt\nimport matplotlib as mpl"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#download-the-sst-data",
    "href": "tutorials/python/define_marine_habitat.html#download-the-sst-data",
    "title": "Define a marine habitat",
    "section": "Download the SST data",
    "text": "Download the SST data\n\nSelect a geographical range\n\nSelect an area of the central North Pacific where the fishery operates: longitude range of 185 to 235 east and latitude range of 20 to 45 north\n\n\n\nSelect a date\n\nSelect a date in the first quarter of the year when bycatch typically occurs: 2023-01-06\n\n\n\nSet variables for the habitat temperature range\n\n# Longitude range\nlon_min = 185\nlon_max = 235\n\n# Latitude range\nlat_min = 20\nlat_max = 45\n\ndate_for_sat_data = '2023-01-06'\n\n# Turtle habitat temperature range\nhab_temp_min = 17.5\nhab_temp_max = 18.5"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#open-the-netcdf-file-to-create-an-xarray-dataset-object",
    "href": "tutorials/python/define_marine_habitat.html#open-the-netcdf-file-to-create-an-xarray-dataset-object",
    "title": "Define a marine habitat",
    "section": "Open the netCDF file to create an xarray dataset object",
    "text": "Open the netCDF file to create an xarray dataset object\n\nurl = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1\"\nds = xr.open_dataset(url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (time: 14130, latitude: 3600, longitude: 7200)\nCoordinates:\n  * time              (time) datetime64[ns] 1985-01-01T12:00:00 ... 2023-09-0...\n  * latitude          (latitude) float32 -89.97 -89.93 -89.88 ... 89.93 89.97\n  * longitude         (longitude) float32 0.025 0.075 0.125 ... 359.9 360.0\nData variables:\n    analysed_sst      (time, latitude, longitude) float64 ...\n    sea_ice_fraction  (time, latitude, longitude) float64 ...\nAttributes: (12/68)\n    acknowledgement:                  NOAA Coral Reef Watch Program\n    cdm_data_type:                    Grid\n    comment:                          This product is designed to improve on ...\n    contributor_name:                 NOAA Coral Reef Watch Program\n    contributor_role:                 Collecting source data and deriving pro...\n    Conventions:                      CF-1.6, ACDD-1.3, COARDS\n    ...                               ...\n    time_coverage_duration:           P1D\n    time_coverage_end:                2023-09-09T12:00:00Z\n    time_coverage_resolution:         P1D\n    time_coverage_start:              1985-01-01T12:00:00Z\n    title:                            Sea Surface Temperature, Coral Reef Wat...\n    Westernmost_Easting:              0.025xarray.DatasetDimensions:time: 14130latitude: 3600longitude: 7200Coordinates: (3)time(time)datetime64[ns]1985-01-01T12:00:00 ... 2023-09-..._CoordinateAxisType :Timeactual_range :[4.7342880e+08 1.6942608e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the sst fieldstandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1985-01-01T12:00:00.000000000', '1985-01-02T12:00:00.000000000',\n       '1985-01-03T12:00:00.000000000', ..., '2023-09-07T12:00:00.000000000',\n       '2023-09-08T12:00:00.000000000', '2023-09-09T12:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float32-89.97 -89.93 ... 89.93 89.97_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([-89.975, -89.925, -89.875, ...,  89.875,  89.925,  89.975],\n      dtype=float32)longitude(longitude)float320.025 0.075 0.125 ... 359.9 360.0_CoordinateAxisType :Lonactual_range :[2.50000e-02 3.59975e+02]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :359.975valid_min :0.025array([2.50000e-02, 7.50000e-02, 1.25000e-01, ..., 3.59875e+02, 3.59925e+02,\n       3.59975e+02], dtype=float32)Data variables: (2)analysed_sst(time, latitude, longitude)float64...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[366249600000 values with dtype=float64]sea_ice_fraction(time, latitude, longitude)float64...colorBarMaximum :1.0colorBarMinimum :0.0comment :0 is 0% ice, 1 is 100% icecoverage_content_type :physicalMeasurementioos_category :Ice Distributionlong_name :Sea Ice Fractionstandard_name :sea_ice_area_fractionunits :1valid_max :1.0valid_min :0.0[366249600000 values with dtype=float64]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1985-01-01 12:00:00', '1985-01-02 12:00:00',\n               '1985-01-03 12:00:00', '1985-01-04 12:00:00',\n               '1985-01-05 12:00:00', '1985-01-06 12:00:00',\n               '1985-01-07 12:00:00', '1985-01-08 12:00:00',\n               '1985-01-09 12:00:00', '1985-01-10 12:00:00',\n               ...\n               '2023-08-31 12:00:00', '2023-09-01 12:00:00',\n               '2023-09-02 12:00:00', '2023-09-03 12:00:00',\n               '2023-09-04 12:00:00', '2023-09-05 12:00:00',\n               '2023-09-06 12:00:00', '2023-09-07 12:00:00',\n               '2023-09-08 12:00:00', '2023-09-09 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=14130, freq=None))latitudePandasIndexPandasIndex(Float64Index([ -89.9749984741211, -89.92500305175781,            -89.875,\n              -89.82499694824219,  -89.7750015258789,  -89.7249984741211,\n              -89.67500305175781,            -89.625, -89.57499694824219,\n               -89.5250015258789,\n              ...\n                89.5250015258789,  89.57499694824219,             89.625,\n               89.67500305175781,   89.7249984741211,   89.7750015258789,\n               89.82499694824219,             89.875,  89.92500305175781,\n                89.9749984741211],\n             dtype='float64', name='latitude', length=3600))longitudePandasIndexPandasIndex(Float64Index([0.02500000037252903, 0.07500000298023224,               0.125,\n              0.17499999701976776, 0.22499999403953552,  0.2750000059604645,\n              0.32499998807907104,               0.375, 0.42500001192092896,\n               0.4749999940395355,\n              ...\n                359.5249938964844,  359.57501220703125,             359.625,\n               359.67498779296875,   359.7250061035156,   359.7749938964844,\n               359.82501220703125,             359.875,  359.92498779296875,\n                359.9750061035156],\n             dtype='float64', name='longitude', length=7200))Attributes: (68)acknowledgement :NOAA Coral Reef Watch Programcdm_data_type :Gridcomment :This product is designed to improve on and replace the use of AVHRR Pathfinder SST for use within the Coral Reef Watch Program.contributor_name :NOAA Coral Reef Watch Programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archiveConventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch Programcreator_name :NOAA Coral Reef Watch Programcreator_type :groupcreator_url :https://coralreefwatch.noaa.gov/data_source :NOAA Daily Global 5km Geo-Polar Blended Night-only Sea Surface Temperature Analysis from the date specified in the global attribute time_coverage_start. Note, if the text of this global attribute begins with \"Due to ...\", one of the following situations occurred: (1) the source data file for the CoralTemp of data file for the CoralTemp of the day was missing; (2) the sea_ice_fraction data array in the source data was missing, (3) some alternation was made on the source data to derive the CoralTemp data of the day.date_created :2018-01-01T00:00:00Zdate_issued :2021-04-04T13:40:08Zdate_metadata_modified :2020-11-18T00:00:00Zdate_modified :2018-01-01T00:00:00ZEasternmost_Easting :359.975geospatial_bounds :\"POLYGON((-90.0 360.0, 90.0 360.0, 90.0 0.0, -90.0 0.0, -90.0 360.0))\"geospatial_bounds_crs :EPSG:4326geospatial_lat_max :89.975geospatial_lat_min :-89.975geospatial_lat_resolution :0.049999999999999996geospatial_lat_units :degrees_northgeospatial_lon_max :359.975geospatial_lon_min :0.025geospatial_lon_resolution :0.05000000000000001geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:4326grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Sat Sep  9 06:30:11 2023: ncatted -O -a geospatial_bounds,global,o,c,\"POLYGON((-90.0 360.0, 90.0 360.0, 90.0 0.0, -90.0 0.0, -90.0 360.0))\" coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a geospatial_lon_max,global,o,f,359.975 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a geospatial_lon_min,global,o,f,0.025 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a valid_max,lon,o,f,359.975 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:11 2023: ncatted -O -a valid_min,lon,o,f,0.025 coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:10 2023: ncap2 -O -s where(lon&lt;0) lon=lon+360 coraltemp_v3.1_20230908-0-360.nc coraltemp_v3.1_20230908-0-360.nc\nSat Sep  9 06:30:08 2023: ncks -O --msa_usr_rdr -d lon,0.0,180.0 -d lon,-180.0,0.0 coraltemp_v3.1_20230908.nc coraltemp_v3.1_20230908-0-360.nc\nThis is the first version of CoralTemp. It was originally called v1.0 and then renamed to v3.1 with no change to the overall product)\n2023-09-11T14:46:38Z (local files)\n2023-09-11T14:46:38Z https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v3_1.dasid :CoralTemp-v3.1infoUrl :https://coralreefwatch.noaa.gov/satellite/bleaching5kminstitution :NOAA/NESDIS/STAR Coral Reef Watch Programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, analysed_sst, analysis, area, coral, coraltemp, crw, cryosphere, daily, data, day, distribution, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, extent, fraction, global, ice, ice distribution, information, infrared, national, near, nesdis, noaa, nrt, ocean, oceans, operational, ostia, program, real, reef, satellite, science, sea, sea_ice_area_fraction, sea_ice_fraction, sea_surface_temperature, seawater, service, spectral, spectral/engineering, sst, star, surface, temperature, thermal, time, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :OSTIA Usage Statement (1985-2002): IMPORTANT usage statement. Unless otherwise agreed in writing, these data may be used for pure academic research only, with no commercial or other application and all usage must meet the Met Office Standard Terms and Conditions, which may be found here: https://www.metoffice.gov.uk/corporate/legal/tandc.html. The data may be used for a maximum period of 5 years. Reproduction of the data is permitted provided the following copyright statement is included: (C) Crown Copyright 2010, published by the Met Office. You must submit a completed reproduction license application form (here https://www.metoffice.gov.uk/corporate/legal/repro_licence.html) before using the data. This only needs to be completed once for each user. WARNING Some applications are unable to properly handle signed byte values. If values are encountered &gt; 127, please subtract 256 from this reported value. GHRSST statement (2002-present): GHRSST protocol describes data use as free and open. Coral Reef Watch program statement: The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of Coral Reef Watch's website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/satellite/bleaching5kmnaming_authority :gov.noaa.coralreefwatchNCO :netCDF Operators version 4.7.5 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)nco_openmp_thread_number :1Northernmost_Northing :89.975platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :L4product_version :3.1program :NOAA Coral Reef Watch Programproject :NOAA Coral Reef Watch Programpublisher_email :coralreefwatch@noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch Programpublisher_name :NOAA Coral Reef Watch Programpublisher_type :grouppublisher_url :https://coralreefwatch.noaa.gov/references :Donlon, et al., 2011. The Operational Sea Surface Temperature and Sea Ice analysis (OSTIA). Maturi, et al., 2017. A new high-resolution sea surface temperature analysis. https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :OSTIA Sea Surface Temperature Reanalysis (night-only), NOAA Geo-Polar Blended Night-only Sea Surface Temperature Reanalysis, NOAA Geo-Polar Blended Night-only Sea Surface Temperature (near real-time)sourceUrl :(local files)Southernmost_Northing :-89.975standard_name_vocabulary :CF Standard Name Table v27summary :NOAA Coral Reef Watch Daily Global 5km Satellite Sea Surface Temperature (CoralTemp). CoralTemp is derived from three different but related 5km daily gap-free SST data sets and provides an internally consistent SST product that stretches from 1985 to present: Operational Sea Surface Temperature and Sea Ice Analysis (OSTIA) Sea Surface Temperature Reanalysis (1985-2002), Geo-Polar Blended Night-only Sea Surface Temperature Reanalysis (2002-2016), Geo-Polar Blended Night-only Sea Surface Temperature Near Real-Time (2017 to present).time_coverage_duration :P1Dtime_coverage_end :2023-09-09T12:00:00Ztime_coverage_resolution :P1Dtime_coverage_start :1985-01-01T12:00:00Ztitle :Sea Surface Temperature, Coral Reef Watch, CoralTemp, v3.1 - Daily, 1985-presentWesternmost_Easting :0.025"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#subset-the-erddap-dataset",
    "href": "tutorials/python/define_marine_habitat.html#subset-the-erddap-dataset",
    "title": "Define a marine habitat",
    "section": "Subset the ERDDAP dataset",
    "text": "Subset the ERDDAP dataset\nThe code below does the following: * Trims the data to include only SST data\n* Selects the date. To avoid the need to match the exact date found in the dataset, include method='nearest'. * Slices within the latitude and longitude ranges\n\nds_subset = ds['analysed_sst'].sel(time=date_for_sat_data, \n                          method='nearest'\n                          ).sel(latitude=slice(lat_min, lat_max),\n                                longitude=slice(lon_min, lon_max)\n                                )"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#make-a-plot-to-view-the-data",
    "href": "tutorials/python/define_marine_habitat.html#make-a-plot-to-view-the-data",
    "title": "Define a marine habitat",
    "section": "Make a plot to view the data",
    "text": "Make a plot to view the data\nThis may take a few seconds. So far you have only set the parameters for download but not requested that the data be downloaded. However, downloading will be necessary to plot the data, so xarray will download it.\n\nds_subset.plot.pcolormesh(cmap=\"gist_rainbow_r\",\n                          vmin=5,\n                          vmax=30,\n                          aspect=2,\n                          size=4\n                          )"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#define-and-mask-the-turtlewatch-band",
    "href": "tutorials/python/define_marine_habitat.html#define-and-mask-the-turtlewatch-band",
    "title": "Define a marine habitat",
    "section": "Define and mask the TurtleWatch band",
    "text": "Define and mask the TurtleWatch band\n\nThe band is between 17.5°C and 18.5°C.\nUse the “where” function of xarray to flag all pixels in the habitat range by replacing their values with a value that is much smaller than the data range minimum.\n\n\nds_masked = xr.where((ds_subset &gt; hab_temp_min) & (ds_subset &lt; hab_temp_max), \n                     -999,  # Set flag value\n                     ds_subset  \n                     )"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#map-the-masked-data",
    "href": "tutorials/python/define_marine_habitat.html#map-the-masked-data",
    "title": "Define a marine habitat",
    "section": "Map the masked data",
    "text": "Map the masked data\nMake some adjustments to the color map:\n* Set the palette to be the reverse of the gist_rainbow\n* Set missing values (like land..) to gray\n* Set the flag value color\n\n# Create the color palette\ncmap = mpl.cm.get_cmap(\"gist_rainbow_r\").copy()\n\n# Set the color of the missing or masked data \ncmap.set_bad(color='gray')  # missing values color (like land..)\n\n# Set the color of flag value (-999)\ncmap.set_under(color='firebrick')  # flag value color\n\n# Plot the data\nds_masked.plot.pcolormesh(cmap=cmap,\n                          vmin=5,\n                          vmax=30,\n                          aspect=2,\n                          size=4\n                          )\n\n# Add plot annotation\nplt.title('TurtleWatch band - ' + date_for_sat_data)\nplt.ylabel('Latitude')\nplt.xlabel('Longitude')\n\nText(0.5, 0, 'Longitude')"
  },
  {
    "objectID": "tutorials/python/define_marine_habitat.html#references",
    "href": "tutorials/python/define_marine_habitat.html#references",
    "title": "Define a marine habitat",
    "section": "References",
    "text": "References\n\nTurtleWatch: https://oceanwatch.pifsc.noaa.gov/turtlewatch.html\nSeveral CoastWatch Node websites have data catalogs containing documentation and links to all the datasets available:\n\nhttps://oceanwatch.pifsc.noaa.gov/doc.html\nhttps://coastwatch.pfeg.noaa.gov/data.html\nhttps://polarwatch.noaa.gov/catalog/"
  },
  {
    "objectID": "tutorials/python/gl-access-sat-surface-temp-data.html",
    "href": "tutorials/python/gl-access-sat-surface-temp-data.html",
    "title": "Python Tutorial - How to work with CoastWatch data in Python",
    "section": "",
    "text": "This tutorial is based on the OceanWatch tutorial meterial edited with Great Lakes data. This tutorial will show the steps to grab data in ERDDAP from Python, how to work with NetCDF files in Python and how to make some maps and time-series water surface temperature (sst) in Lake Erie."
  },
  {
    "objectID": "tutorials/python/gl-access-sat-surface-temp-data.html#downlading-data-from-python",
    "href": "tutorials/python/gl-access-sat-surface-temp-data.html#downlading-data-from-python",
    "title": "Python Tutorial - How to work with CoastWatch data in Python",
    "section": "1. Downlading data from Python",
    "text": "1. Downlading data from Python\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure. For example, the following page allows you to subset daily water surface temperature data from the dataset GLSEA_ACSPO_GCS\nIn this specific example, the URL we generated is :\nhttps://apps.glerl.noaa.gov/erddap/griddap/GLSEA_ACSPO_GCS.nc?sst%5B(2023-06-01T12:00:00Z):1:(2023-06-30T12:00:00Z)%5D%5B(41):1:(43)%5D%5B(-83.5):1:(-78.5)%5D\nIn Python, run the following to download the data using the generated URL. Note: replace coastwatch.glerl.noaa.gov with apps.glerl.noaa.gov) :\n\nimport urllib.request\n\nurl=\"https://apps.glerl.noaa.gov/erddap/griddap/GLSEA_ACSPO_GCS.nc?sst%5B(2023-06-01T12:00:00Z):1:(2023-06-30T12:00:00Z)%5D%5B(41):1:(43)%5D%5B(-83.5):1:(-78.5)%5D\"\nurllib.request.urlretrieve(url, \"e_sst.nc\")\n\n('e_sst.nc', &lt;http.client.HTTPMessage at 0x1b7d5152610&gt;)"
  },
  {
    "objectID": "tutorials/python/gl-access-sat-surface-temp-data.html#working-with-the-extracted-data",
    "href": "tutorials/python/gl-access-sat-surface-temp-data.html#working-with-the-extracted-data",
    "title": "Python Tutorial - How to work with CoastWatch data in Python",
    "section": "Working with the extracted data",
    "text": "Working with the extracted data\n\nCreating a map for one time step\nLet’s create a map of SST for June 1, 2021 (our first time step).\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n#np.warnings.filterwarnings('ignore')\n\n\n- Examine the values of sst:\n\nds.sst.values\n\narray([[[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       ...,\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]],\n\n       [[-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        ...,\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.],\n        [-99999., -99999., -99999., ..., -99999., -99999., -99999.]]],\n      dtype=float32)\n\n\n\nds.sst.attrs\n\n{'_FillValue': -99999.0,\n 'colorBarMaximum': 32.0,\n 'colorBarMinimum': 0.0,\n 'ioos_category': 'Temperature',\n 'long_name': 'Temperature',\n 'standard_name': 'sea_water_temperature',\n 'units': 'degree_C'}\n\n\n\nds.sst.attrs['_FillValue']\n\n-99999.0\n\n\n\n#ds.sst.dims\n#ds.sst.coords\n\n\n\n- Make a new sst DataArray and replace _fillValue with NaN\n\n#nan_sst = ds.sst.where(ds.sst.values != -99999.0)\nnan_sst = ds.sst.where(ds.sst.values != ds.sst.attrs['_FillValue'])\n\n# nan_sst[time][latitude][longitude]\n#print(nan_sst[10][100][200])\n\nprint(nan_sst)\n\n\n&lt;xarray.DataArray 'sst' (time: 30, latitude: 143, longitude: 358)&gt;\narray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)\nCoordinates:\n  * time       (time) float64 1.686e+09 1.686e+09 ... 1.688e+09 1.688e+09\n  * latitude   (latitude) float64 41.01 41.02 41.03 41.05 ... 42.97 42.98 43.0\n  * longitude  (longitude) float64 -83.51 -83.49 -83.48 ... -78.53 -78.52 -78.5\nAttributes:\n    _FillValue:       -99999.0\n    colorBarMaximum:  32.0\n    colorBarMinimum:  0.0\n    ioos_category:    Temperature\n    long_name:        Temperature\n    standard_name:    sea_water_temperature\n    units:            degree_C\n\n\n\n\n- Set some color breaks\n\nnp.nanmin(ds.sst)\n\n-99999.0\n\n\n\n# find min value in man_sst\nnp.nanmin(nan_sst)\n\n13.25\n\n\n\nnp.nanmax(nan_sst)\n\n23.35\n\n\n\nlevs = np.arange(13.25, 23.35, 0.05)\nlen(levs)\n\n203\n\n\n\n\n- Define a color palette\n\n# init a color list\njet=[\"blue\", \"#007FFF\", \"cyan\",\"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"]\n\n\n\n- Set color scale using the jet palette\n\ncm = LinearSegmentedColormap.from_list('my_jet', jet, N=len(levs))\n\n#https://www.youtube.com/watch?v=qk0n-YaKIkY\n\n\n\n- plot the SST map\n\nnp.linspace(-82.5,-80,num=4)\n\narray([-82.5       , -81.66666667, -80.83333333, -80.        ])\n\n\n\nplt.subplots(figsize=(10, 5))\n\n#plot first sst image: nan_sst[0,:,:]\nplt.contourf(nan_sst.longitude, nan_sst.latitude, nan_sst[0,:,:], levs,cmap=cm)\n\n#plot the color scale\nplt.colorbar()\n\n#example of how to add points to the map\nplt.scatter(np.linspace(-82,-80.5,num=4),np.repeat(42,4),c='black')\n\n#example of how to add a contour line\nstep = np.arange(9,26, 1)\n\nplt.contour(ds.longitude, ds.latitude, ds.sst[0,:,:],levels=step,linewidths=1)\n\n#plot title\nplt.title(\"Lake Erie Water Surface Temperature - \" + dates[0].strftime('%b %d, %Y'))\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPlotting a time series\nLet’s pick the following box : 41.75-42.0N, 83.0-83.5W. We are going to generate a time series of mean SST within that box.\n\n- first, let’s subset our data:\n\nlat_bnds, lon_bnds = [41.75, 42.0], [-83.5, -83.0]\na_sst=nan_sst.sel(latitude=slice(*lat_bnds), longitude=slice(*lon_bnds))\nprint(a_sst)\n\n&lt;xarray.DataArray 'sst' (time: 30, latitude: 17, longitude: 36)&gt;\narray([[[  nan,   nan,   nan, ..., 18.86, 18.84, 18.84],\n        [  nan,   nan,   nan, ..., 18.82, 18.8 , 18.8 ],\n        [  nan,   nan,   nan, ..., 18.78, 18.76, 18.76],\n        ...,\n        [  nan,   nan,   nan, ..., 18.5 , 18.46, 18.46],\n        [  nan,   nan,   nan, ..., 18.5 , 18.46, 18.46],\n        [  nan,   nan,   nan, ..., 18.53, 18.49, 18.49]],\n\n       [[  nan,   nan,   nan, ..., 19.45, 19.44, 19.44],\n        [  nan,   nan,   nan, ..., 19.42, 19.41, 19.41],\n        [  nan,   nan,   nan, ..., 19.39, 19.38, 19.38],\n        ...,\n        [  nan,   nan,   nan, ..., 19.13, 19.1 , 19.1 ],\n        [  nan,   nan,   nan, ..., 19.07, 19.06, 19.06],\n        [  nan,   nan,   nan, ..., 19.06, 19.04, 19.04]],\n\n       [[  nan,   nan,   nan, ..., 19.63, 19.61, 19.61],\n        [  nan,   nan,   nan, ..., 19.6 , 19.58, 19.58],\n        [  nan,   nan,   nan, ..., 19.56, 19.54, 19.54],\n        ...,\n...\n        ...,\n        [  nan,   nan,   nan, ..., 21.24, 21.31, 21.31],\n        [  nan,   nan,   nan, ..., 21.24, 21.34, 21.34],\n        [  nan,   nan,   nan, ..., 21.29, 21.42, 21.42]],\n\n       [[  nan,   nan,   nan, ..., 21.8 , 21.75, 21.75],\n        [  nan,   nan,   nan, ..., 21.7 , 21.67, 21.67],\n        [  nan,   nan,   nan, ..., 21.6 , 21.59, 21.59],\n        ...,\n        [  nan,   nan,   nan, ..., 21.36, 21.41, 21.41],\n        [  nan,   nan,   nan, ..., 21.36, 21.44, 21.44],\n        [  nan,   nan,   nan, ..., 21.44, 21.53, 21.53]],\n\n       [[  nan,   nan,   nan, ..., 21.93, 21.82, 21.82],\n        [  nan,   nan,   nan, ..., 21.86, 21.79, 21.79],\n        [  nan,   nan,   nan, ..., 21.78, 21.75, 21.75],\n        ...,\n        [  nan,   nan,   nan, ..., 21.49, 21.52, 21.52],\n        [  nan,   nan,   nan, ..., 21.51, 21.55, 21.55],\n        [  nan,   nan,   nan, ..., 21.63, 21.66, 21.66]]], dtype=float32)\nCoordinates:\n  * time       (time) float64 1.686e+09 1.686e+09 ... 1.688e+09 1.688e+09\n  * latitude   (latitude) float64 41.76 41.78 41.79 41.8 ... 41.96 41.97 41.99\n  * longitude  (longitude) float64 -83.49 -83.48 -83.46 ... -83.03 -83.02 -83.0\nAttributes:\n    _FillValue:       -99999.0\n    colorBarMaximum:  32.0\n    colorBarMinimum:  0.0\n    ioos_category:    Temperature\n    long_name:        Temperature\n    standard_name:    sea_water_temperature\n    units:            degree_C\n\n\n\n\n- let’s plot the subset:\n\n#plot first image of the a_sst array\nplt.contourf(a_sst.longitude, a_sst.latitude, a_sst[0,:,:], levs,cmap=cm)\nplt.colorbar()\nplt.title(\"Subset of Lake Erie Water Surface Temperature \" + dates[0].strftime('%b %d, %Y'))\nplt.show()\n\n\n\n\n\n\n\n\n\n\n- let’s compute the daily mean over the bounding region:\n\nres=np.nanmean(a_sst,axis=(1,2))\nres\n\narray([19.252283, 19.84715 , 20.109388, 20.06981 , 20.01454 , 20.00379 ,\n       19.958447, 19.921082, 19.963646, 19.956564, 19.885717, 19.525248,\n       19.253717, 19.179811, 19.149954, 19.190142, 19.41266 , 19.634283,\n       19.90713 , 20.220236, 20.525293, 20.747812, 21.015364, 21.460989,\n       21.71833 , 21.710024, 21.643694, 21.593224, 21.749012, 22.0068  ],\n      dtype=float32)\n\n\n\n\n- let’s plot the time-series:\n\nplt.figure(figsize=(8,4))\n\nplt.scatter(dates,res)\n\ndegree_sign = u\"\\N{DEGREE SIGN}\"\nplt.ylabel('SST (' + degree_sign + 'C)')\n\nplt.xlim(dates[0], dates[-1])\n\nplt.xticks(dates,rotation=70, fontsize=10 )\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCreating a map of average SST over a month\n\n- let’s compute the monthly mean for the region:\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\nmean_sst=np.nanmean(nan_sst,axis=0)\n\n\nmean_sst.shape\n\n(143, 358)\n\n\n\n\n- let’s plot the map of the average SST in the region for 2021 June:\n\nplt.subplots(figsize=(10, 5))\n\nplt.contourf(ds.longitude, ds.latitude, mean_sst, levs,cmap=cm)\n\ncbar = plt.colorbar()\ncbar.set_label('SST')\n\nplt.title(\"Mean SST \" + dates[0].strftime('%Y-%m-%d')+' - '+dates[-1].strftime('%Y-%m-%d'))\nplt.show()\n\n\n\n\n\n\n\n\n\n!jupyter nbconvert --to html GL_python_tutorial1.ipynb\n\n[NbConvertApp] Converting notebook GL_python_tutorial1.ipynb to html\n[NbConvertApp] Writing 974120 bytes to GL_python_tutorial1.html"
  },
  {
    "objectID": "tutorials/python/gl-timeseries-chloro-from-diff-sensors.html",
    "href": "tutorials/python/gl-timeseries-chloro-from-diff-sensors.html",
    "title": "Time series of chlorophyll data from different sensors",
    "section": "",
    "text": "Great Lakes color producing agents (CPA) are derived from two different sensors.\nAs an example, we are going to plot time-series of mean chlorophyll a concentration from different sensors from 2002 to 2023. We are going to download MODIS data (2002-2017) and VIIRS data (2018-2023).\nFirst, let’s load all the packages needed:\nimport urllib.request \nimport xarray as xr \nimport netCDF4 as nc\n\nimport pandas as pd \nimport numpy as np \nfrom matplotlib import pyplot as plt \nfrom matplotlib.colors import LinearSegmentedColormap \n\nimport warnings\n\nwarnings.filterwarnings('ignore')\n##Get Lake Erie Monthly Average MODIS data\nGo to ERDDAP to find the name of the dataset for dailly MODIS data: LE_CHL_MODIS_Daily\nYou should always examine the dataset in ERDDAP to check the date range, names of the variables and dataset ID, to make sure your griddap calls are correct:\nhttps://apps.glerl.noaa.gov/erddap/griddap/LE_CHL_MODIS_Daily.graph\n# in Python code replace coastwatch.glerl.noaa.gov with apps.glerl.noaa.gov\n\nurl='https://apps.glerl.noaa.gov/erddap/griddap/LE_CHL_MODIS_Daily.nc?chlorophyll%5B(2002-08-07T19:05:00Z):1:(2017-10-22T18:00:00Z)%5D%5B(41.0051550293714):1:(42.9950003885447)%5D%5B(-83.4950003885448):1:(-78.505388156246)%5D'\nurllib.request.urlretrieve(url, \"e_chl_modis.nc\")\n\n('e_chl_modis.nc', &lt;http.client.HTTPMessage at 0x1a2705704d0&gt;)"
  },
  {
    "objectID": "tutorials/python/gl-timeseries-chloro-from-diff-sensors.html#get-lake-erie-dailly-average-viirs-data",
    "href": "tutorials/python/gl-timeseries-chloro-from-diff-sensors.html#get-lake-erie-dailly-average-viirs-data",
    "title": "Time series of chlorophyll data from different sensors",
    "section": "Get Lake Erie Dailly Average VIIRS data",
    "text": "Get Lake Erie Dailly Average VIIRS data\n\nurl2='https://apps.glerl.noaa.gov/erddap/griddap/LE_CHL_VIIRS_Daily.nc?Chlorophyll%5B(2023-01-04T18:47:05Z):1:(2023-12-28T18:32:33Z)%5D%5B(41.2690208353804):1:(43.017997272827)%5D%5B(-83.6574899492178):1:(-78.4429490894234)%5D'\nurllib.request.urlretrieve(url2, \"e_viirs_chl.nc\")\n\n('e_viirs_chl.nc', &lt;http.client.HTTPMessage at 0x1a20d832610&gt;)\n\n\n\ne_v_ds = xr.open_dataset('e_viirs_chl.nc',decode_cf=False)\n\n\nprint(e_v_ds)\n\n&lt;xarray.Dataset&gt;\nDimensions:      (time: 544, latitude: 271, longitude: 806)\nCoordinates:\n  * time         (time) float64 1.673e+09 1.673e+09 ... 1.704e+09 1.704e+09\n  * latitude     (latitude) float64 41.27 41.28 41.28 ... 43.01 43.01 43.02\n  * longitude    (longitude) float64 -83.66 -83.65 -83.64 ... -78.45 -78.44\nData variables:\n    Chlorophyll  (time, latitude, longitude) float32 ...\nAttributes: (12/34)\n    cdm_data_type:                  Grid\n    colorBarMaximum:                30.0\n    colorBarMinimum:                1.0\n    colorBarScale:                  Log\n    Conventions:                    CF-1.6, COARDS, ACDD-1.3\n    Easternmost_Easting:            -78.4429490894234\n    ...                             ...\n    summary:                        Color Producing Agent (CPA) Chlorophyll, ...\n    testOutOfDate:                  now-18days\n    time_coverage_end:              2023-12-28T18:32:33Z\n    time_coverage_start:            2023-01-04T18:47:05Z\n    title:                          Color Producing Agent (CPA) Chlorophyll, ...\n    Westernmost_Easting:            -83.6574899492178\n\n\n\nnan_e_v_ds_chlorophyll = e_v_ds.Chlorophyll.where(e_v_ds.Chlorophyll.values != e_v_ds.Chlorophyll.attrs['_FillValue'])\n\nv_chl_avg = np.nanmean(nan_e_v_ds_chlorophyll,axis=(1,2))\n#print(v_chl_avg)\n#print(len(v_chl_avg))\n\n\ne_v_dates=nc.num2date(e_v_ds.time,e_v_ds.time.units, only_use_cftime_datetimes=False, \n                        only_use_python_datetimes=True )\ne_v_dates\n\narray([real_datetime(2023, 1, 4, 18, 47, 5),\n       real_datetime(2023, 1, 5, 18, 28, 10),\n       real_datetime(2023, 1, 7, 17, 50, 19),\n       real_datetime(2023, 1, 7, 19, 31, 19),\n       real_datetime(2023, 1, 8, 19, 12, 23),\n       real_datetime(2023, 1, 9, 17, 12, 27),\n       real_datetime(2023, 1, 9, 17, 13, 53),\n       real_datetime(2023, 1, 9, 18, 53, 28),\n       real_datetime(2023, 1, 10, 18, 34, 32),\n       real_datetime(2023, 1, 11, 18, 15, 36),\n       real_datetime(2023, 1, 14, 17, 18, 51),\n       real_datetime(2023, 1, 14, 18, 59, 52),\n       real_datetime(2023, 1, 15, 16, 59, 56),\n       real_datetime(2023, 1, 15, 17, 1, 21),\n       real_datetime(2023, 1, 15, 18, 40, 56),\n       real_datetime(2023, 1, 16, 18, 22),\n       real_datetime(2023, 1, 17, 18, 3, 5),\n       real_datetime(2023, 1, 19, 17, 25, 14),\n       real_datetime(2023, 1, 19, 19, 6, 14),\n       real_datetime(2023, 1, 24, 17, 31, 37),\n       real_datetime(2023, 1, 24, 19, 12, 38),\n       real_datetime(2023, 1, 31, 18, 41, 10),\n       real_datetime(2023, 2, 1, 18, 22, 15),\n       real_datetime(2023, 2, 2, 18, 3, 19),\n       real_datetime(2023, 2, 3, 17, 44, 23),\n       real_datetime(2023, 2, 3, 19, 25, 24),\n       real_datetime(2023, 2, 4, 17, 25, 28),\n       real_datetime(2023, 2, 4, 19, 6, 28),\n       real_datetime(2023, 2, 6, 18, 28, 37),\n       real_datetime(2023, 2, 7, 18, 9, 41),\n       real_datetime(2023, 2, 8, 17, 50, 47),\n       real_datetime(2023, 2, 8, 19, 31, 46),\n       real_datetime(2023, 2, 9, 17, 31, 52),\n       real_datetime(2023, 2, 9, 19, 12, 52),\n       real_datetime(2023, 2, 10, 18, 52, 31),\n       real_datetime(2023, 2, 10, 18, 53, 56),\n       real_datetime(2023, 2, 11, 18, 33, 35),\n       real_datetime(2023, 2, 11, 18, 35, 1),\n       real_datetime(2023, 2, 12, 18, 14, 40),\n       real_datetime(2023, 2, 12, 18, 16, 5),\n       real_datetime(2023, 2, 13, 17, 57, 9),\n       real_datetime(2023, 2, 13, 19, 36, 44),\n       real_datetime(2023, 2, 13, 19, 38, 10),\n       real_datetime(2023, 2, 14, 17, 38, 14),\n       real_datetime(2023, 2, 14, 19, 19, 14),\n       real_datetime(2023, 2, 15, 17, 19, 18),\n       real_datetime(2023, 2, 15, 18, 58, 53),\n       real_datetime(2023, 2, 15, 19, 0, 18),\n       real_datetime(2023, 2, 17, 18, 22, 29),\n       real_datetime(2023, 2, 18, 18, 2, 8),\n       real_datetime(2023, 2, 18, 18, 3, 33),\n       real_datetime(2023, 2, 19, 17, 44, 38),\n       real_datetime(2023, 2, 19, 19, 24, 12),\n       real_datetime(2023, 2, 19, 19, 25, 38),\n       real_datetime(2023, 2, 20, 17, 25, 42),\n       real_datetime(2023, 2, 20, 19, 5, 17),\n       real_datetime(2023, 2, 20, 19, 6, 42),\n       real_datetime(2023, 2, 21, 17, 6, 46),\n       real_datetime(2023, 2, 21, 18, 46, 21),\n       real_datetime(2023, 2, 21, 18, 47, 47),\n       real_datetime(2023, 2, 23, 18, 8, 30),\n       real_datetime(2023, 2, 24, 17, 51),\n       real_datetime(2023, 2, 24, 19, 30, 34),\n       real_datetime(2023, 2, 24, 19, 32),\n       real_datetime(2023, 2, 25, 19, 13, 4),\n       real_datetime(2023, 2, 26, 17, 13, 10),\n       real_datetime(2023, 2, 26, 18, 52, 45),\n       real_datetime(2023, 2, 28, 18, 14, 54),\n       real_datetime(2023, 3, 1, 17, 57, 23),\n       real_datetime(2023, 3, 1, 19, 38, 24),\n       real_datetime(2023, 3, 2, 17, 38, 28),\n       real_datetime(2023, 3, 2, 19, 18, 3),\n       real_datetime(2023, 3, 5, 18, 21, 17),\n       real_datetime(2023, 3, 5, 18, 22, 43),\n       real_datetime(2023, 3, 6, 18, 2, 22),\n       real_datetime(2023, 3, 7, 17, 44, 52),\n       real_datetime(2023, 3, 7, 19, 24, 26),\n       real_datetime(2023, 3, 7, 19, 25, 52),\n       real_datetime(2023, 3, 8, 17, 25, 56),\n       real_datetime(2023, 3, 11, 18, 10, 9),\n       real_datetime(2023, 3, 15, 16, 54, 28),\n       real_datetime(2023, 3, 15, 18, 35, 29),\n       real_datetime(2023, 3, 16, 18, 15, 8),\n       real_datetime(2023, 3, 16, 18, 16, 33),\n       real_datetime(2023, 3, 18, 19, 18, 16),\n       real_datetime(2023, 3, 19, 17, 19, 46),\n       real_datetime(2023, 3, 19, 18, 59, 21),\n       real_datetime(2023, 3, 20, 17, 0, 52),\n       real_datetime(2023, 3, 20, 18, 40, 25),\n       real_datetime(2023, 3, 21, 18, 21, 31),\n       real_datetime(2023, 3, 21, 18, 22, 57),\n       real_datetime(2023, 3, 24, 17, 26, 10),\n       real_datetime(2023, 3, 25, 17, 7, 14),\n       real_datetime(2023, 3, 25, 18, 46, 49),\n       real_datetime(2023, 3, 25, 18, 48, 14),\n       real_datetime(2023, 3, 26, 18, 27, 53),\n       real_datetime(2023, 3, 26, 18, 29, 19),\n       real_datetime(2023, 3, 27, 18, 10, 23),\n       real_datetime(2023, 3, 28, 17, 51, 29),\n       real_datetime(2023, 3, 29, 17, 32, 33),\n       real_datetime(2023, 3, 29, 19, 13, 34),\n       real_datetime(2023, 3, 30, 17, 13, 38),\n       real_datetime(2023, 3, 30, 18, 53, 13),\n       real_datetime(2023, 3, 30, 18, 54, 38),\n       real_datetime(2023, 4, 1, 18, 16, 47),\n       real_datetime(2023, 4, 2, 17, 57, 51),\n       real_datetime(2023, 4, 2, 19, 37, 26),\n       real_datetime(2023, 4, 2, 19, 38, 51),\n       real_datetime(2023, 4, 4, 17, 20, 2),\n       real_datetime(2023, 4, 4, 19, 1),\n       real_datetime(2023, 4, 6, 18, 23, 10),\n       real_datetime(2023, 4, 7, 18, 4, 15),\n       real_datetime(2023, 4, 8, 17, 45, 19),\n       real_datetime(2023, 4, 8, 19, 24, 54),\n       real_datetime(2023, 4, 8, 19, 26, 19),\n       real_datetime(2023, 4, 9, 17, 26, 23),\n       real_datetime(2023, 4, 9, 19, 5, 58),\n       real_datetime(2023, 4, 9, 19, 7, 24),\n       real_datetime(2023, 4, 10, 17, 7, 28),\n       real_datetime(2023, 4, 10, 18, 47, 3),\n       real_datetime(2023, 4, 10, 18, 48, 28),\n       real_datetime(2023, 4, 11, 18, 28, 7),\n       real_datetime(2023, 4, 11, 18, 29, 32),\n       real_datetime(2023, 4, 12, 18, 9, 13),\n       real_datetime(2023, 4, 12, 18, 10, 38),\n       real_datetime(2023, 4, 13, 17, 51, 43),\n       real_datetime(2023, 4, 13, 19, 31, 18),\n       real_datetime(2023, 4, 13, 19, 32, 43),\n       real_datetime(2023, 4, 14, 17, 32, 47),\n       real_datetime(2023, 4, 14, 19, 12, 22),\n       real_datetime(2023, 4, 14, 19, 13, 47),\n       real_datetime(2023, 4, 15, 17, 13, 52),\n       real_datetime(2023, 4, 15, 18, 53, 26),\n       real_datetime(2023, 4, 15, 18, 54, 52),\n       real_datetime(2023, 4, 16, 16, 54, 56),\n       real_datetime(2023, 4, 16, 18, 34, 31),\n       real_datetime(2023, 4, 16, 18, 35, 56),\n       real_datetime(2023, 4, 18, 17, 58, 5),\n       real_datetime(2023, 4, 19, 17, 39, 11),\n       real_datetime(2023, 4, 19, 19, 18, 44),\n       real_datetime(2023, 4, 19, 19, 20, 9),\n       real_datetime(2023, 4, 20, 18, 59, 50),\n       real_datetime(2023, 4, 21, 17, 1, 20),\n       real_datetime(2023, 4, 22, 18, 21, 59),\n       real_datetime(2023, 4, 23, 18, 3, 3),\n       real_datetime(2023, 4, 23, 18, 4, 28),\n       real_datetime(2023, 4, 24, 17, 44, 7),\n       real_datetime(2023, 4, 24, 17, 45, 33),\n       real_datetime(2023, 4, 24, 19, 25, 8),\n       real_datetime(2023, 4, 25, 17, 26, 37),\n       real_datetime(2023, 4, 26, 17, 7, 43),\n       real_datetime(2023, 4, 26, 18, 47, 16),\n       real_datetime(2023, 4, 27, 18, 28, 23),\n       real_datetime(2023, 4, 30, 17, 31, 36),\n       real_datetime(2023, 4, 30, 17, 33, 1),\n       real_datetime(2023, 4, 30, 19, 12, 36),\n       real_datetime(2023, 5, 1, 17, 14, 5),\n       real_datetime(2023, 5, 1, 18, 53, 40),\n       real_datetime(2023, 5, 3, 18, 15, 49),\n       real_datetime(2023, 5, 4, 17, 56, 53),\n       real_datetime(2023, 5, 4, 19, 37, 53),\n       real_datetime(2023, 5, 5, 17, 37, 59),\n       real_datetime(2023, 5, 5, 17, 39, 25),\n       real_datetime(2023, 5, 5, 19, 18, 58),\n       real_datetime(2023, 5, 6, 17, 19, 4),\n       real_datetime(2023, 5, 6, 17, 20, 29),\n       real_datetime(2023, 5, 6, 19, 0, 4),\n       real_datetime(2023, 5, 7, 18, 41, 8),\n       real_datetime(2023, 5, 8, 18, 22, 13),\n       real_datetime(2023, 5, 10, 17, 44, 21),\n       real_datetime(2023, 5, 10, 19, 25, 22),\n       real_datetime(2023, 5, 11, 17, 25, 26),\n       real_datetime(2023, 5, 11, 19, 6, 26),\n       real_datetime(2023, 5, 12, 17, 6, 32),\n       real_datetime(2023, 5, 12, 17, 7, 57),\n       real_datetime(2023, 5, 12, 18, 47, 30),\n       real_datetime(2023, 5, 13, 18, 28, 36),\n       real_datetime(2023, 5, 15, 17, 50, 45),\n       real_datetime(2023, 5, 15, 19, 31, 45),\n       real_datetime(2023, 5, 16, 19, 12, 50),\n       real_datetime(2023, 5, 17, 17, 12, 54),\n       real_datetime(2023, 5, 17, 18, 53, 54),\n       real_datetime(2023, 5, 18, 18, 34, 58),\n       real_datetime(2023, 5, 19, 18, 16, 3),\n       real_datetime(2023, 5, 20, 17, 57, 9),\n       real_datetime(2023, 5, 21, 17, 38, 13),\n       real_datetime(2023, 5, 23, 18, 41, 22),\n       real_datetime(2023, 5, 24, 18, 22, 27),\n       real_datetime(2023, 5, 25, 18, 3, 31),\n       real_datetime(2023, 5, 26, 17, 44, 35),\n       real_datetime(2023, 5, 26, 19, 24, 10),\n       real_datetime(2023, 5, 26, 19, 25, 35),\n       real_datetime(2023, 5, 27, 17, 25, 40),\n       real_datetime(2023, 5, 27, 19, 5, 14),\n       real_datetime(2023, 5, 27, 19, 6, 40),\n       real_datetime(2023, 5, 28, 18, 46, 19),\n       real_datetime(2023, 5, 28, 18, 47, 44),\n       real_datetime(2023, 5, 29, 18, 27, 25),\n       real_datetime(2023, 5, 29, 18, 28, 50),\n       real_datetime(2023, 5, 30, 18, 8, 29),\n       real_datetime(2023, 5, 30, 18, 9, 55),\n       real_datetime(2023, 5, 31, 17, 50, 59),\n       real_datetime(2023, 5, 31, 19, 30, 34),\n       real_datetime(2023, 5, 31, 19, 31, 59),\n       real_datetime(2023, 6, 1, 17, 32, 3),\n       real_datetime(2023, 6, 1, 19, 11, 38),\n       real_datetime(2023, 6, 1, 19, 13, 4),\n       real_datetime(2023, 6, 2, 17, 13, 8),\n       real_datetime(2023, 6, 2, 18, 52, 43),\n       real_datetime(2023, 6, 2, 18, 54, 8),\n       real_datetime(2023, 6, 3, 18, 33, 47),\n       real_datetime(2023, 6, 3, 18, 35, 12),\n       real_datetime(2023, 6, 4, 18, 14, 51),\n       real_datetime(2023, 6, 4, 18, 16, 17),\n       real_datetime(2023, 6, 5, 17, 57, 23),\n       real_datetime(2023, 6, 6, 17, 38, 27),\n       real_datetime(2023, 6, 6, 19, 18, 2),\n       real_datetime(2023, 6, 7, 17, 19, 32),\n       real_datetime(2023, 6, 7, 18, 59, 6),\n       real_datetime(2023, 6, 8, 18, 40, 11),\n       real_datetime(2023, 6, 9, 18, 21, 15),\n       real_datetime(2023, 6, 9, 18, 22, 40),\n       real_datetime(2023, 6, 10, 18, 2, 19),\n       real_datetime(2023, 6, 10, 18, 3, 45),\n       real_datetime(2023, 6, 11, 17, 44, 49),\n       real_datetime(2023, 6, 12, 19, 5, 28),\n       real_datetime(2023, 6, 13, 17, 7),\n       real_datetime(2023, 6, 13, 18, 46, 33),\n       real_datetime(2023, 6, 14, 18, 27, 39),\n       real_datetime(2023, 6, 15, 18, 8, 43),\n       real_datetime(2023, 6, 16, 17, 49, 48),\n       real_datetime(2023, 6, 17, 17, 30, 52),\n       real_datetime(2023, 6, 17, 17, 32, 17),\n       real_datetime(2023, 6, 17, 19, 11, 52),\n       real_datetime(2023, 6, 18, 17, 13, 22),\n       real_datetime(2023, 6, 18, 18, 52, 57),\n       real_datetime(2023, 6, 19, 18, 34, 1),\n       real_datetime(2023, 6, 20, 18, 15, 5),\n       real_datetime(2023, 6, 21, 17, 56, 10),\n       real_datetime(2023, 6, 21, 19, 37, 10),\n       real_datetime(2023, 6, 22, 17, 37, 16),\n       real_datetime(2023, 6, 22, 19, 18, 14),\n       real_datetime(2023, 6, 23, 18, 59, 20),\n       real_datetime(2023, 6, 24, 17, 0, 50),\n       real_datetime(2023, 6, 24, 18, 40, 25),\n       real_datetime(2023, 6, 25, 18, 21, 29),\n       real_datetime(2023, 6, 26, 18, 2, 34),\n       real_datetime(2023, 6, 27, 17, 43, 38),\n       real_datetime(2023, 6, 27, 19, 24, 38),\n       real_datetime(2023, 6, 28, 17, 24, 42),\n       real_datetime(2023, 6, 28, 17, 26, 8),\n       real_datetime(2023, 6, 28, 19, 5, 43),\n       real_datetime(2023, 6, 29, 17, 7, 14),\n       real_datetime(2023, 6, 29, 18, 46, 47),\n       real_datetime(2023, 6, 30, 18, 27, 53),\n       real_datetime(2023, 7, 2, 17, 50, 2),\n       real_datetime(2023, 7, 2, 19, 31, 2),\n       real_datetime(2023, 7, 3, 17, 31, 6),\n       real_datetime(2023, 7, 3, 17, 32, 32),\n       real_datetime(2023, 7, 3, 19, 12, 6),\n       real_datetime(2023, 7, 4, 17, 12, 10),\n       real_datetime(2023, 7, 4, 17, 13, 36),\n       real_datetime(2023, 7, 4, 18, 53, 11),\n       real_datetime(2023, 7, 5, 16, 54, 40),\n       real_datetime(2023, 7, 5, 18, 34, 15),\n       real_datetime(2023, 7, 6, 18, 15, 19),\n       real_datetime(2023, 7, 7, 17, 56, 24),\n       real_datetime(2023, 7, 7, 19, 37, 24),\n       real_datetime(2023, 7, 8, 17, 37, 30),\n       real_datetime(2023, 7, 8, 19, 18, 28),\n       real_datetime(2023, 7, 9, 17, 18, 34),\n       real_datetime(2023, 7, 9, 18, 59, 35),\n       real_datetime(2023, 7, 10, 17, 1, 4),\n       real_datetime(2023, 7, 10, 18, 40, 39),\n       real_datetime(2023, 7, 11, 18, 21, 43),\n       real_datetime(2023, 7, 12, 18, 2, 48),\n       real_datetime(2023, 7, 13, 17, 43, 52),\n       real_datetime(2023, 7, 13, 19, 24, 52),\n       real_datetime(2023, 7, 14, 17, 24, 56),\n       real_datetime(2023, 7, 14, 19, 5, 57),\n       real_datetime(2023, 7, 16, 18, 28, 5),\n       real_datetime(2023, 7, 17, 18, 9, 11),\n       real_datetime(2023, 7, 18, 17, 50, 16),\n       real_datetime(2023, 7, 18, 19, 31, 16),\n       real_datetime(2023, 7, 19, 17, 31, 20),\n       real_datetime(2023, 7, 19, 19, 12, 20),\n       real_datetime(2023, 7, 20, 17, 12, 25),\n       real_datetime(2023, 7, 20, 17, 13, 50),\n       real_datetime(2023, 7, 20, 18, 53, 25),\n       real_datetime(2023, 7, 21, 16, 54, 54),\n       real_datetime(2023, 7, 21, 18, 34, 29),\n       real_datetime(2023, 7, 22, 18, 15, 33),\n       real_datetime(2023, 7, 23, 17, 56, 38),\n       real_datetime(2023, 7, 24, 17, 37, 44),\n       real_datetime(2023, 7, 24, 19, 18, 42),\n       real_datetime(2023, 7, 25, 18, 59, 47),\n       real_datetime(2023, 7, 27, 18, 21, 56),\n       real_datetime(2023, 7, 28, 18, 3, 1),\n       real_datetime(2023, 7, 29, 17, 44, 7),\n       real_datetime(2023, 7, 29, 19, 25, 5),\n       real_datetime(2023, 7, 30, 17, 25, 11),\n       real_datetime(2023, 7, 30, 19, 6, 11),\n       real_datetime(2023, 7, 31, 17, 6, 16),\n       real_datetime(2023, 7, 31, 18, 47, 16),\n       real_datetime(2023, 8, 1, 18, 28, 20),\n       real_datetime(2023, 8, 2, 18, 9, 25),\n       real_datetime(2023, 8, 3, 17, 50, 29),\n       real_datetime(2023, 8, 3, 19, 31, 29),\n       real_datetime(2023, 8, 4, 17, 31, 33),\n       real_datetime(2023, 8, 4, 19, 12, 33),\n       real_datetime(2023, 8, 5, 18, 53, 38),\n       real_datetime(2023, 8, 6, 16, 53, 44),\n       real_datetime(2023, 8, 6, 18, 34, 44),\n       real_datetime(2023, 8, 7, 18, 15, 48),\n       real_datetime(2023, 8, 8, 17, 56, 53),\n       real_datetime(2023, 8, 8, 19, 37, 53),\n       real_datetime(2023, 8, 9, 17, 37, 57),\n       real_datetime(2023, 8, 10, 17, 19, 1),\n       real_datetime(2023, 8, 10, 18, 58, 36),\n       real_datetime(2023, 8, 10, 19, 0, 2),\n       real_datetime(2023, 8, 11, 17, 0, 6),\n       real_datetime(2023, 8, 11, 18, 39, 41),\n       real_datetime(2023, 8, 11, 18, 41, 6),\n       real_datetime(2023, 8, 12, 18, 20, 45),\n       real_datetime(2023, 8, 12, 18, 22, 10),\n       real_datetime(2023, 8, 13, 18, 3, 15),\n       real_datetime(2023, 8, 15, 17, 25, 25),\n       real_datetime(2023, 8, 15, 19, 5),\n       real_datetime(2023, 8, 15, 19, 6, 25),\n       real_datetime(2023, 8, 16, 17, 6, 30),\n       real_datetime(2023, 8, 16, 18, 46, 4),\n       real_datetime(2023, 8, 16, 18, 47, 30),\n       real_datetime(2023, 8, 17, 18, 27, 9),\n       real_datetime(2023, 8, 17, 18, 28, 34),\n       real_datetime(2023, 8, 18, 18, 8, 13),\n       real_datetime(2023, 8, 18, 18, 9, 39),\n       real_datetime(2023, 8, 19, 17, 50, 43),\n       real_datetime(2023, 8, 19, 19, 30, 18),\n       real_datetime(2023, 8, 19, 19, 31, 43),\n       real_datetime(2023, 8, 20, 17, 31, 47),\n       real_datetime(2023, 8, 20, 19, 11, 22),\n       real_datetime(2023, 8, 20, 19, 12, 47),\n       real_datetime(2023, 8, 21, 18, 52, 26),\n       real_datetime(2023, 8, 22, 16, 53, 58),\n       real_datetime(2023, 8, 22, 18, 33, 33),\n       real_datetime(2023, 8, 22, 18, 34, 56),\n       real_datetime(2023, 8, 24, 17, 55, 41),\n       real_datetime(2023, 8, 24, 17, 57, 7),\n       real_datetime(2023, 8, 25, 17, 38, 11),\n       real_datetime(2023, 8, 25, 19, 17, 46),\n       real_datetime(2023, 8, 26, 17, 19, 15),\n       real_datetime(2023, 8, 26, 18, 58, 50),\n       real_datetime(2023, 8, 26, 19, 0, 16),\n       real_datetime(2023, 8, 27, 17, 0, 20),\n       real_datetime(2023, 8, 27, 18, 39, 55),\n       real_datetime(2023, 8, 27, 18, 41, 20),\n       real_datetime(2023, 8, 28, 18, 20, 59),\n       real_datetime(2023, 8, 28, 18, 22, 24),\n       real_datetime(2023, 8, 29, 18, 2, 3),\n       real_datetime(2023, 8, 29, 18, 3, 29),\n       real_datetime(2023, 8, 30, 17, 44, 35),\n       real_datetime(2023, 8, 30, 19, 24, 8),\n       real_datetime(2023, 8, 31, 17, 25, 39),\n       real_datetime(2023, 8, 31, 19, 5, 14),\n       real_datetime(2023, 9, 1, 17, 6, 44),\n       real_datetime(2023, 9, 1, 18, 46, 18),\n       real_datetime(2023, 9, 2, 18, 27, 23),\n       real_datetime(2023, 9, 3, 18, 8, 27),\n       real_datetime(2023, 9, 4, 17, 49, 31),\n       real_datetime(2023, 9, 4, 17, 50, 57),\n       real_datetime(2023, 9, 4, 19, 30, 32),\n       real_datetime(2023, 9, 5, 17, 30, 36),\n       real_datetime(2023, 9, 5, 17, 32, 1),\n       real_datetime(2023, 9, 5, 19, 11, 36),\n       real_datetime(2023, 9, 6, 17, 13, 7),\n       real_datetime(2023, 9, 6, 18, 52, 40),\n       real_datetime(2023, 9, 7, 16, 54, 12),\n       real_datetime(2023, 9, 7, 18, 33, 47),\n       real_datetime(2023, 9, 8, 18, 14, 51),\n       real_datetime(2023, 9, 9, 17, 55, 55),\n       real_datetime(2023, 9, 10, 17, 37),\n       real_datetime(2023, 9, 10, 17, 38, 25),\n       real_datetime(2023, 9, 10, 19, 18),\n       real_datetime(2023, 9, 11, 17, 18, 4),\n       real_datetime(2023, 9, 11, 17, 19, 29),\n       real_datetime(2023, 9, 11, 18, 59, 4),\n       real_datetime(2023, 9, 12, 18, 40, 9),\n       real_datetime(2023, 9, 13, 18, 21, 13),\n       real_datetime(2023, 9, 14, 18, 2, 17),\n       real_datetime(2023, 9, 15, 17, 43, 23),\n       real_datetime(2023, 9, 15, 19, 24, 22),\n       real_datetime(2023, 9, 16, 17, 24, 28),\n       real_datetime(2023, 9, 16, 19, 5, 28),\n       real_datetime(2023, 9, 17, 17, 5, 32),\n       real_datetime(2023, 9, 17, 17, 6, 58),\n       real_datetime(2023, 9, 17, 18, 46, 32),\n       real_datetime(2023, 9, 18, 18, 27, 37),\n       real_datetime(2023, 9, 19, 18, 8, 41),\n       real_datetime(2023, 9, 20, 17, 49, 46),\n       real_datetime(2023, 9, 20, 19, 30, 46),\n       real_datetime(2023, 9, 21, 17, 30, 50),\n       real_datetime(2023, 9, 21, 19, 11, 50),\n       real_datetime(2023, 9, 22, 17, 11, 54),\n       real_datetime(2023, 9, 22, 18, 52, 54),\n       real_datetime(2023, 9, 23, 18, 33, 59),\n       real_datetime(2023, 9, 24, 18, 15, 5),\n       real_datetime(2023, 9, 25, 17, 56, 9),\n       real_datetime(2023, 9, 26, 17, 37, 14),\n       real_datetime(2023, 9, 26, 19, 18, 14),\n       real_datetime(2023, 9, 27, 18, 59, 18),\n       real_datetime(2023, 9, 28, 18, 40, 23),\n       real_datetime(2023, 9, 29, 18, 21, 27),\n       real_datetime(2023, 9, 30, 18, 2, 32),\n       real_datetime(2023, 10, 1, 17, 43, 36),\n       real_datetime(2023, 10, 1, 19, 23, 11),\n       real_datetime(2023, 10, 1, 19, 24, 36),\n       real_datetime(2023, 10, 2, 17, 24, 42),\n       real_datetime(2023, 10, 2, 19, 4, 15),\n       real_datetime(2023, 10, 2, 19, 5, 41),\n       real_datetime(2023, 10, 3, 17, 5, 46),\n       real_datetime(2023, 10, 3, 18, 45, 21),\n       real_datetime(2023, 10, 3, 18, 46, 47),\n       real_datetime(2023, 10, 4, 18, 26, 26),\n       real_datetime(2023, 10, 4, 18, 27, 51),\n       real_datetime(2023, 10, 5, 18, 8, 55),\n       real_datetime(2023, 10, 6, 17, 50),\n       real_datetime(2023, 10, 6, 19, 29, 35),\n       real_datetime(2023, 10, 6, 19, 31),\n       real_datetime(2023, 10, 7, 17, 31, 4),\n       real_datetime(2023, 10, 7, 19, 10, 39),\n       real_datetime(2023, 10, 7, 19, 12, 4),\n       real_datetime(2023, 10, 8, 17, 12, 9),\n       real_datetime(2023, 10, 8, 18, 51, 43),\n       real_datetime(2023, 10, 8, 18, 53, 9),\n       real_datetime(2023, 10, 9, 16, 53, 13),\n       real_datetime(2023, 10, 9, 18, 32, 48),\n       real_datetime(2023, 10, 9, 18, 34, 13),\n       real_datetime(2023, 10, 11, 17, 54, 57),\n       real_datetime(2023, 10, 11, 17, 56, 22),\n       real_datetime(2023, 10, 11, 19, 35, 57),\n       real_datetime(2023, 10, 12, 17, 37, 28),\n       real_datetime(2023, 10, 12, 19, 17, 1),\n       real_datetime(2023, 10, 13, 17, 18, 33),\n       real_datetime(2023, 10, 15, 18, 20, 16),\n       real_datetime(2023, 10, 16, 18, 1, 21),\n       real_datetime(2023, 10, 17, 17, 43, 50),\n       real_datetime(2023, 10, 18, 17, 24, 55),\n       real_datetime(2023, 10, 18, 19, 4, 30),\n       real_datetime(2023, 10, 20, 18, 26, 38),\n       real_datetime(2023, 10, 21, 18, 7, 43),\n       real_datetime(2023, 10, 21, 18, 9, 8),\n       real_datetime(2023, 10, 22, 17, 48, 49),\n       real_datetime(2023, 10, 22, 17, 50, 14),\n       real_datetime(2023, 10, 22, 19, 29, 47),\n       real_datetime(2023, 10, 23, 17, 29, 53),\n       real_datetime(2023, 10, 23, 17, 31, 19),\n       real_datetime(2023, 10, 23, 19, 10, 54),\n       real_datetime(2023, 10, 24, 17, 12, 23),\n       real_datetime(2023, 10, 24, 18, 51, 58),\n       real_datetime(2023, 10, 26, 18, 14, 7),\n       real_datetime(2023, 10, 27, 17, 55, 11),\n       real_datetime(2023, 10, 27, 17, 56, 37),\n       real_datetime(2023, 10, 27, 19, 36, 11),\n       real_datetime(2023, 10, 28, 17, 37, 41),\n       real_datetime(2023, 10, 28, 19, 17, 16),\n       real_datetime(2023, 10, 30, 18, 39, 25),\n       real_datetime(2023, 10, 31, 18, 20, 29),\n       real_datetime(2023, 11, 2, 17, 44, 4),\n       real_datetime(2023, 11, 2, 19, 23, 39),\n       real_datetime(2023, 11, 3, 17, 23, 45),\n       real_datetime(2023, 11, 3, 17, 25, 10),\n       real_datetime(2023, 11, 3, 19, 4, 43),\n       real_datetime(2023, 11, 4, 18, 45, 49),\n       real_datetime(2023, 11, 5, 18, 26, 54),\n       real_datetime(2023, 11, 6, 18, 7, 58),\n       real_datetime(2023, 11, 7, 17, 49, 2),\n       real_datetime(2023, 11, 7, 17, 50, 28),\n       real_datetime(2023, 11, 7, 19, 30, 3),\n       real_datetime(2023, 11, 9, 17, 12, 37),\n       real_datetime(2023, 11, 9, 18, 52, 11),\n       real_datetime(2023, 11, 10, 18, 33, 16),\n       real_datetime(2023, 11, 11, 18, 14, 20),\n       real_datetime(2023, 11, 12, 17, 55, 25),\n       real_datetime(2023, 11, 12, 17, 56, 50),\n       real_datetime(2023, 11, 12, 19, 36, 25),\n       real_datetime(2023, 11, 13, 17, 36, 31),\n       real_datetime(2023, 11, 13, 17, 37, 56),\n       real_datetime(2023, 11, 13, 19, 17, 29),\n       real_datetime(2023, 11, 14, 17, 17, 35),\n       real_datetime(2023, 11, 14, 17, 19, 1),\n       real_datetime(2023, 11, 14, 18, 58, 35),\n       real_datetime(2023, 11, 15, 17, 0, 5),\n       real_datetime(2023, 11, 15, 18, 39, 40),\n       real_datetime(2023, 11, 16, 18, 20, 44),\n       real_datetime(2023, 11, 18, 17, 42, 53),\n       real_datetime(2023, 11, 18, 17, 44, 19),\n       real_datetime(2023, 11, 18, 19, 23, 53),\n       real_datetime(2023, 11, 19, 17, 23, 58),\n       real_datetime(2023, 11, 19, 17, 25, 23),\n       real_datetime(2023, 11, 19, 19, 4, 58),\n       real_datetime(2023, 11, 20, 18, 46, 2),\n       real_datetime(2023, 11, 23, 17, 49, 15),\n       real_datetime(2023, 11, 23, 19, 30, 16),\n       real_datetime(2023, 11, 24, 17, 30, 22),\n       real_datetime(2023, 11, 24, 17, 31, 47),\n       real_datetime(2023, 11, 24, 19, 11, 20),\n       real_datetime(2023, 11, 25, 17, 11, 26),\n       real_datetime(2023, 11, 25, 17, 12, 51),\n       real_datetime(2023, 11, 25, 18, 52, 26),\n       real_datetime(2023, 11, 27, 18, 14, 35),\n       real_datetime(2023, 11, 28, 17, 55, 40),\n       real_datetime(2023, 11, 28, 19, 36, 40),\n       real_datetime(2023, 11, 29, 17, 36, 44),\n       real_datetime(2023, 11, 29, 19, 17, 44),\n       real_datetime(2023, 11, 30, 17, 17, 48),\n       real_datetime(2023, 11, 30, 18, 58, 49),\n       real_datetime(2023, 12, 3, 18, 2, 2),\n       real_datetime(2023, 12, 4, 17, 43, 6),\n       real_datetime(2023, 12, 6, 17, 5, 17),\n       real_datetime(2023, 12, 6, 18, 46, 17),\n       real_datetime(2023, 12, 7, 18, 27, 21),\n       real_datetime(2023, 12, 8, 18, 8, 26),\n       real_datetime(2023, 12, 9, 17, 49, 30),\n       real_datetime(2023, 12, 10, 17, 30, 35),\n       real_datetime(2023, 12, 11, 18, 52, 39),\n       real_datetime(2023, 12, 12, 18, 33, 44),\n       real_datetime(2023, 12, 13, 18, 14, 48),\n       real_datetime(2023, 12, 14, 17, 55, 53),\n       real_datetime(2023, 12, 15, 17, 36, 57),\n       real_datetime(2023, 12, 15, 19, 16, 32),\n       real_datetime(2023, 12, 15, 19, 17, 57),\n       real_datetime(2023, 12, 16, 17, 18, 3),\n       real_datetime(2023, 12, 16, 18, 57, 36),\n       real_datetime(2023, 12, 16, 18, 59, 2),\n       real_datetime(2023, 12, 19, 18, 2, 17),\n       real_datetime(2023, 12, 20, 17, 43, 21),\n       real_datetime(2023, 12, 20, 19, 22, 56),\n       real_datetime(2023, 12, 20, 19, 24, 21),\n       real_datetime(2023, 12, 21, 17, 24, 26),\n       real_datetime(2023, 12, 21, 19, 4),\n       real_datetime(2023, 12, 21, 19, 5, 26),\n       real_datetime(2023, 12, 25, 17, 49, 43),\n       real_datetime(2023, 12, 26, 19, 10, 23),\n       real_datetime(2023, 12, 28, 18, 32, 33)], dtype=object)\n\n\n\nv_chl_avg = np.nanmean(nan_e_v_ds_chlorophyll.values,axis=(1,2))\nv_chl_avg\n\narray([ 3.8245378 , 17.05229   ,  0.77159315,  1.6202371 ,  2.068805  ,\n        1.7207391 ,  2.0681734 ,  9.915978  , 12.000377  , 60.60568   ,\n        2.9275532 , 15.261721  ,  2.1003587 ,  2.5391452 , 15.000816  ,\n       18.150581  ,  4.041805  ,  5.558531  , 14.340515  ,  7.0143795 ,\n       24.486782  , 10.351516  ,  9.925964  ,  8.393265  ,  7.0230336 ,\n       19.298477  , 13.378698  , 17.380596  ,  8.412001  , 18.604963  ,\n        9.874779  , 34.36881   ,  2.2588596 ,  3.6034255 ,  2.506503  ,\n        7.9039016 , 28.500935  , 15.452688  , 18.463425  , 11.424103  ,\n        8.926837  , 29.18119   , 15.104329  ,  7.305774  , 12.944991  ,\n       28.979595  , 31.491842  , 17.951267  ,  4.4605803 , 14.379     ,\n       28.11916   ,  9.264345  , 26.880186  , 46.661022  , 14.642408  ,\n       13.05799   , 13.633649  ,  1.418521  , 13.829434  ,  5.444851  ,\n       16.703632  , 20.848345  ,  5.0073376 , 43.061474  ,  4.4501486 ,\n       10.821825  , 13.9933815 , 31.618942  , 18.309826  ,  0.626642  ,\n        1.3072004 ,  0.5550653 , 18.288877  ,  8.388084  , 84.72084   ,\n       21.264292  , 30.243666  ,  8.217334  , 26.758741  , 12.297731  ,\n        1.0648437 ,  7.8218217 ,  6.743732  ,  8.725778  ,  0.37988   ,\n       20.73484   , 37.852497  , 23.765854  , 36.893124  , 43.02589   ,\n       21.644255  ,  7.4811535 ,  0.56276786, 21.756771  ,  8.571441  ,\n       34.194794  , 24.734491  , 20.891743  , 19.614132  , 20.337917  ,\n        0.89833146, 15.468415  , 23.633438  , 12.742027  , 10.469747  ,\n       19.536373  , 63.70876   , 31.262995  , 12.08394   ,  6.5038023 ,\n       23.642673  , 15.831917  ,  9.192328  , 18.234331  , 18.983482  ,\n       12.585856  , 19.876034  , 10.024232  ,  6.4187565 , 11.187998  ,\n        5.847157  , 15.026388  , 13.55039   , 57.649048  , 10.104386  ,\n       10.101064  , 25.943897  ,  9.368579  ,  6.515471  , 10.244264  ,\n        1.1295458 ,  7.0011516 , 10.233358  ,  6.5892057 ,  5.111359  ,\n        5.5639024 ,  4.002067  ,  2.6186795 , 20.945406  , 22.75246   ,\n       22.861576  , 26.649107  ,  3.9389431 ,  6.8372855 ,  4.1539216 ,\n        7.945154  ,  2.4636204 ,  2.8101442 ,  2.9989738 ,  3.761499  ,\n        4.040188  ,  6.779965  ,  4.0392694 ,  5.058976  ,  3.642377  ,\n        5.0899043 ,  1.535409  ,  5.489851  , 12.624435  , 14.986074  ,\n       19.135656  ,  8.674835  ,  1.8120102 ,  6.0505404 ,  4.0770435 ,\n        4.2323365 ,  4.5445585 ,  6.407044  ,  4.4135103 , 10.111502  ,\n        2.559734  ,  6.3161306 ,  4.1022396 ,  5.3999968 ,  5.693675  ,\n        4.2225466 ,  4.975449  ,  5.87973   ,  1.8912128 ,  4.844044  ,\n        8.326566  , 21.682102  ,  5.796414  ,  4.81131   ,  1.6386082 ,\n        4.858289  ,  1.0573728 ,  5.3810554 , 19.722094  , 12.00176   ,\n       23.595955  , 31.021114  ,  6.9326816 ,  5.9504557 ,  3.3385806 ,\n        4.8724666 ,  2.2861915 , 12.186277  ,  3.0852036 , 30.52236   ,\n        4.891082  ,  4.0605354 , 27.45894   , 12.472047  ,  3.3337376 ,\n        3.500256  ,  0.65000206,  1.3446043 ,  5.6772294 ,  2.0434697 ,\n        6.4364944 ,  3.82695   , 26.283665  ,  6.5254254 ,  0.35209   ,\n        1.7417568 ,  0.323401  ,  1.3526874 , 19.266989  , 16.352032  ,\n        4.9344935 ,  4.533328  ,  1.8704015 ,  1.9660938 ,  2.0816095 ,\n        0.31560874,  2.6231666 ,  6.254045  ,  3.8463306 ,  1.3136346 ,\n        2.3147666 ,  3.226815  ,  3.4912894 ,  9.928331  ,  5.029834  ,\n        7.1034536 ,  2.6826584 ,  3.407092  ,  5.1383185 ,  4.0941634 ,\n        3.3249714 ,  2.8196743 ,  1.0019007 ,  0.4673027 ,  6.095398  ,\n        2.4684315 ,  2.894028  ,  1.7736832 ,  0.53535175,  2.3534393 ,\n        5.9133415 ,  1.4854542 ,  0.98389864,  2.8314965 ,  3.388785  ,\n        1.7273644 ,  1.4295217 ,  3.9137824 ,  0.8343511 ,  5.592705  ,\n        4.1189713 ,  4.519481  ,  4.514461  ,  1.216034  ,  4.9332423 ,\n        4.501184  ,  5.48342   ,  5.1219296 ,  1.8448588 ,  1.8978752 ,\n        2.399244  ,  4.452588  ,  2.9473898 ,  4.242     ,  5.101925  ,\n        3.4773014 ,  4.1459665 ,  3.9358723 ,  4.571998  ,  4.4941797 ,\n        1.8119017 ,  1.184782  ,  3.4886737 ,  1.7374743 ,  5.519011  ,\n        4.1905513 ,  2.60639   ,  0.7090206 ,  4.3053236 ,  0.48008502,\n        4.8589377 ,  5.2264676 ,  4.044144  ,  3.4191263 ,  1.1011882 ,\n        3.1120796 ,  6.7359877 ,  2.9646623 ,  2.554451  ,  2.4505644 ,\n        2.142144  ,  4.9301887 ,  1.2831734 ,  2.7954278 ,  1.5539587 ,\n        5.100337  ,  3.3232377 ,  1.7723247 ,  4.5153937 ,  3.388878  ,\n        6.257826  ,  1.1053416 ,  3.9824939 ,  0.76826215,  4.1770864 ,\n        5.84404   ,  3.564656  ,  4.186695  ,  3.18334   ,  4.3410416 ,\n        2.4948015 ,  5.7432327 ,  3.2015507 ,  4.697011  ,  8.011776  ,\n        6.00471   ,  1.4959276 ,  3.4044938 ,  2.7345881 ,  3.1861002 ,\n        6.807063  ,  3.672278  ,  4.4842434 ,  4.369128  , 10.34134   ,\n        7.659503  ,  4.640015  ,  2.260385  ,  2.9616964 ,  5.770283  ,\n        5.8344135 ,  3.0287185 ,  4.6171303 ,  1.8015864 ,  3.3256059 ,\n        4.025933  , 15.307446  , 24.68179   ,  5.1921005 ,  0.95913076,\n        2.531541  ,  3.3621345 ,  5.42665   ,  2.610918  ,  7.0007544 ,\n        4.5238733 ,  6.4797854 ,  7.7474403 ,  8.129336  ,  6.065284  ,\n        6.313556  , 23.959946  ,  6.9332256 ,  7.346444  ,  3.9448545 ,\n        7.4828005 ,  9.371148  ,  6.901665  ,  6.0786414 ,  7.611087  ,\n        4.072118  ,  5.4114847 ,  5.8930087 ,  6.2145314 ,  3.5961418 ,\n        3.5599902 ,  0.31376082,  4.7233195 ,  1.835947  ,  1.3035926 ,\n        3.0226147 ,  0.4981069 ,  6.3224025 ,  3.036155  ,  2.8434775 ,\n        4.545952  , 18.239357  ,  6.450544  ,  6.273684  ,  6.03156   ,\n        3.223308  ,  3.63122   ,  2.694837  ,  2.6652293 ,  1.1407009 ,\n        4.5644073 ,  6.183016  ,  4.285992  ,  4.728611  ,  1.2699568 ,\n        3.6176095 ,  2.5436394 ,  2.7925599 ,  3.8075545 ,  8.981911  ,\n       22.87494   ,  7.5639124 ,  1.6238711 ,  0.5307012 ,  6.469891  ,\n        3.0692794 ,  4.6451344 ,  7.6391034 ,  6.2791705 ,  7.3014994 ,\n        4.254345  ,  6.4056168 ,  7.458692  ,  3.457129  ,  5.2672634 ,\n        9.947004  ,  4.4163375 , 10.526679  ,  4.949929  ,  1.9953364 ,\n        8.43534   ,  8.067071  ,  5.2787495 ,  3.2672718 , 14.374089  ,\n        1.9808887 , 36.714443  , 25.423502  , 10.191787  ,  2.9083974 ,\n       13.615338  ,  7.3216214 , 16.14564   ,  7.027708  ,  8.500385  ,\n        4.132675  ,  3.6679573 ,  1.4386141 , 35.34755   , 27.14011   ,\n        0.611455  ,  9.363178  , 12.209044  ,  7.530161  ,  8.551426  ,\n        1.8653786 ,  4.8010054 ,  5.6198926 , 35.149426  , 30.55753   ,\n        5.9123573 ,  2.7006626 ,  3.9975345 ,  6.327705  ,  5.3463564 ,\n        6.5932918 ,  6.520323  ,  3.5866342 ,  0.6119649 ,  0.34683716,\n        4.459534  ,  5.4071994 ,  6.77416   , 20.245544  ,  1.24846   ,\n       16.727642  , 34.44699   ,  3.2000692 ,  6.9570527 ,  4.8707566 ,\n        0.85470015,  1.5286115 ,  1.4164749 , 16.511541  , 23.00998   ,\n       11.719736  , 10.880672  ,  6.8268065 ,  1.6250918 ,  8.308749  ,\n       11.111537  , 24.678076  , 11.334251  ,  3.5857413 ,  6.996021  ,\n        4.5214167 ,  8.312405  ,  7.4295473 ,  7.6591887 , 10.038146  ,\n        1.7212489 ,  8.699176  ,  8.796391  ,  9.621361  ,  9.075598  ,\n        0.19450001, 14.5820675 , 18.2731    , 15.891861  ,  5.1796503 ,\n       23.901497  ,  6.602838  ,  8.11695   ,  5.7776127 ,  0.9575611 ,\n       19.564034  , 44.46723   ,  6.194875  , 20.724203  , 18.15552   ,\n       36.427177  ,  3.437948  ,  0.62041324,  0.78566986,  7.326401  ,\n       13.820853  ,  4.118893  ,  0.77267   ,  0.74762917,  0.88341135,\n       20.338709  , 18.454927  , 13.954808  , 11.78991   , 11.854942  ,\n       14.00589   ,  9.306969  ,  9.987267  ,  6.9419265 , 10.148791  ,\n        8.151923  , 18.923534  , 18.946314  ,  1.1267239 ,  1.1251845 ,\n        1.3136889 , 71.61      ,  1.9791391 ,  0.40409204], dtype=float32)\n\n\n\nplt.figure(figsize=(12,5)) \nplt.plot(e_v_dates,v_chl_avg,label='VIIRS CHL',c='red',marker='.',linestyle='-')\nplt.ylabel('Chl-a (mg/m^3)')\nplt.title(\"Lake Erie Daily Average CHL - 2023\")\nplt.legend()\nprint(type(v_chl_avg))\nprint(v_chl_avg.shape)\nprint(e_v_dates.shape)\n\n&lt;class 'numpy.ndarray'&gt;\n(544,)\n(544,)\n\n\n\n\n\n\n\n\n\n\n#e_v_ds.close()\n!jupyter nbconvert --to html GL_python_tutorial2.ipynb\n\n[NbConvertApp] Converting notebook GL_python_tutorial2.ipynb to html\n[NbConvertApp] Writing 878306 bytes to GL_python_tutorial2.html"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html",
    "href": "tutorials/python/lis-chlora-dynamics.html",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "",
    "text": "History | Updated March 2025"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#objective",
    "href": "tutorials/python/lis-chlora-dynamics.html#objective",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Objective",
    "text": "Objective\nThis tutorial will show the steps to grab daily chlorophyll-a data hosted on an ERDDAP server from Python, how to make temporal composites in Python and how to make some maps and time-series of chlorophyll-a"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/lis-chlora-dynamics.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nLocating a satellite product in ERDDAP, manually changing the constraints and copying the URL defining the data request\nDownloading the resulting netCDF file\nOpening and examining the netCDF file\nCalculate temporal composites (8Day and monthly)\nSpatially subset the dataset\nMaking basic maps and time series plots"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#datasets-used",
    "href": "tutorials/python/lis-chlora-dynamics.html#datasets-used",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Datasets used",
    "text": "Datasets used\nLong Island Sound Optimized water quailty datasets from OLCI Products developed by academic collaborators that have partnered with NOAA CoastWatch through a Sea Grant project titled “Actionable satellite water-quality data products in Long Island Sound for improved management and societal benefits”. The dataset includes daily Sentinal-3 OLCI (300 m) water quality indicators: - Chlorophyll-a (Chla “chlor_a”) - Absorption coefficient of Chromophoric Dissolved Organic Material at 300 nm (aCDOM(300) “cdom”) - Dissolved Organic Carbon (DOC “doc”) - Suspended Particulate Matter (SPM “spm”). Chlor_a, cdom and doc are based on Long Island Sound optimized algorithms. Spm retrieved using the Nechad Algorithm.\nThis dataset covers the Long Island Sound region between 40.2° N - 41.5° N and 74° W - 71.8° W\nIn this tutorial we will use the daily Chlorophyll-a dataset The data will be downloaded from the CoastWatch ERRDAP server: https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.html\nfor more information on each product refer to: - Chla: https://www.sciencedirect.com/science/article/pii/S1569843223000456 - CDOM and DOC: https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2023JG007767 - SPM: https://www.sciencedirect.com/science/article/abs/pii/S0034425709003617"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#import-python-modules",
    "href": "tutorials/python/lis-chlora-dynamics.html#import-python-modules",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Import Python modules",
    "text": "Import Python modules\n\nimport urllib.request\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#download-data-from-erddap-using-python",
    "href": "tutorials/python/lis-chlora-dynamics.html#download-data-from-erddap-using-python",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "1. Download data from ERDDAP using Python",
    "text": "1. Download data from ERDDAP using Python\nBecause ERDDAP includes RESTful services, you can download data listed on any ERDDAP platform from Python using the URL structure.\nFor example, the following page allows you to download daily chlorophyll-a (chlor_a) https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.html\n\n\n\nimage.png\n\n\n\nSelect the date range of interest, then select the ‘.nc’ (NetCDF) file type and click on “Just Generate the URL”.\nIn this specific example, the URL we generated is :\nhttps://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.nc?chlor_a%5B(2022-01-01T00:00:00Z):1:(2022-12-31T00:00:00Z)%5D%5B(41.5):1:(40.204)%5D%5B(-74.0):1:(-71.8049)%5D\n\n\nWith Python, run the following to download the data using the generated URL .\n\nurl = ''.join(['https://coastwatch.noaa.gov/erddap/griddap/noaacwappsS3ABcolorLISDaily.nc?',\n               'chlor_a',\n               '%5B(2022-01-01T00:00:00Z):1:(2022-12-31T00:00:00Z)%5D',\n               '%5B(41.5):1:(40.204)%5D',\n               '%5B(-74.0):1:(-71.8049)%5D'\n               ])\n\nurllib.request.urlretrieve(url, \"chlor_a_2022_LIS_tutorial.nc\")\n\n('chlor_a_2022_LIS_tutorial.nc', &lt;http.client.HTTPMessage at 0x7f0c9c31b220&gt;)"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#loading-netcdf4-data-into-python",
    "href": "tutorials/python/lis-chlora-dynamics.html#loading-netcdf4-data-into-python",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "2. Loading netCDF4 data into Python",
    "text": "2. Loading netCDF4 data into Python\nNow that we’ve downloaded the data locally, we can load it into Python and extract the variables of interest.\nThe xarray package makes it very convenient to work with NetCDF files. Documentation is available here: http://xarray.pydata.org/en/stable/why-xarray.html\n\nOpen the netCDF file as an xarray dataset object and examine the data structure.\n\nds = xr.open_dataset('chlor_a_2022_LIS_tutorial.nc', decode_cf=True)\n\n\n\nExamine which coordinates and variables are included in the dataset.\n\n# List the coordinates\nprint('The coordinates variables:', list(ds.coords), '\\n')\n\n# List the data variables\nprint('The data variables:', list(ds.data_vars))\n\nThe coordinates variables: ['time', 'latitude', 'longitude'] \n\nThe data variables: ['chlor_a']\n\n\n\n\nExamine the structure of chlor_a.\n\nds.chlor_a.shape\n\n(365, 481, 814)\n\n\nThe dataset is a 3-D array with 365 time steps, each with 481 rows corresponding to latitudes and 814 columns corresponding to longitudes.\n\n\nList the dates for each time step.\nThe dataset has 365 time steps, one for each day between January 2022 and December 2022.\n\nds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 365)&gt; Size: 3kB\narray(['2022-01-01T00:00:00.000000000', '2022-01-02T00:00:00.000000000',\n       '2022-01-03T00:00:00.000000000', ..., '2022-12-29T00:00:00.000000000',\n       '2022-12-30T00:00:00.000000000', '2022-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 3kB 2022-01-01 2022-01-02 ... 2022-12-31\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [1.6409952e+09 1.6724448e+09]\n    axis:                 T\n    ioos_category:        Time\n    long_name:            Start Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00xarray.DataArray'time'time: 3652022-01-01 2022-01-02 2022-01-03 ... 2022-12-29 2022-12-30 2022-12-31array(['2022-01-01T00:00:00.000000000', '2022-01-02T00:00:00.000000000',\n       '2022-01-03T00:00:00.000000000', ..., '2022-12-29T00:00:00.000000000',\n       '2022-12-30T00:00:00.000000000', '2022-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2022-01-01 ... 2022-12-31_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-01T00:00:00.000000000', '2022-01-02T00:00:00.000000000',\n       '2022-01-03T00:00:00.000000000', ..., '2022-12-29T00:00:00.000000000',\n       '2022-12-30T00:00:00.000000000', '2022-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04',\n               '2022-01-05', '2022-01-06', '2022-01-07', '2022-01-08',\n               '2022-01-09', '2022-01-10',\n               ...\n               '2022-12-22', '2022-12-23', '2022-12-24', '2022-12-25',\n               '2022-12-26', '2022-12-27', '2022-12-28', '2022-12-29',\n               '2022-12-30', '2022-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))Attributes: (7)_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00\n\n\n\n\nResample daily data monthly.\nUse Xarray’s resample function to group the data into a monthly dataset (“MS” = Month Start). You can then apply aggregation functions like .mean(), .median(), .sum(), .cumsum(), etc., to compute statistics for each month.\n\nds_mon = ds.resample(time=\"MS\").mean()\n\n\n\nList the dates for each time step after resampling\nThe dataset now has 12 time steps, one for each month between January 2022 and December 2022.\n\nds_mon.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 12)&gt; Size: 96B\narray(['2022-01-01T00:00:00.000000000', '2022-02-01T00:00:00.000000000',\n       '2022-03-01T00:00:00.000000000', '2022-04-01T00:00:00.000000000',\n       '2022-05-01T00:00:00.000000000', '2022-06-01T00:00:00.000000000',\n       '2022-07-01T00:00:00.000000000', '2022-08-01T00:00:00.000000000',\n       '2022-09-01T00:00:00.000000000', '2022-10-01T00:00:00.000000000',\n       '2022-11-01T00:00:00.000000000', '2022-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 96B 2022-01-01 2022-02-01 ... 2022-12-01\nAttributes:\n    _CoordinateAxisType:  Time\n    actual_range:         [1.6409952e+09 1.6724448e+09]\n    axis:                 T\n    ioos_category:        Time\n    long_name:            Start Time\n    standard_name:        time\n    time_origin:          01-JAN-1970 00:00:00xarray.DataArray'time'time: 122022-01-01 2022-02-01 2022-03-01 ... 2022-10-01 2022-11-01 2022-12-01array(['2022-01-01T00:00:00.000000000', '2022-02-01T00:00:00.000000000',\n       '2022-03-01T00:00:00.000000000', '2022-04-01T00:00:00.000000000',\n       '2022-05-01T00:00:00.000000000', '2022-06-01T00:00:00.000000000',\n       '2022-07-01T00:00:00.000000000', '2022-08-01T00:00:00.000000000',\n       '2022-09-01T00:00:00.000000000', '2022-10-01T00:00:00.000000000',\n       '2022-11-01T00:00:00.000000000', '2022-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2022-01-01 ... 2022-12-01_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2022-01-01T00:00:00.000000000', '2022-02-01T00:00:00.000000000',\n       '2022-03-01T00:00:00.000000000', '2022-04-01T00:00:00.000000000',\n       '2022-05-01T00:00:00.000000000', '2022-06-01T00:00:00.000000000',\n       '2022-07-01T00:00:00.000000000', '2022-08-01T00:00:00.000000000',\n       '2022-09-01T00:00:00.000000000', '2022-10-01T00:00:00.000000000',\n       '2022-11-01T00:00:00.000000000', '2022-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2022-01-01', '2022-02-01', '2022-03-01', '2022-04-01',\n               '2022-05-01', '2022-06-01', '2022-07-01', '2022-08-01',\n               '2022-09-01', '2022-10-01', '2022-11-01', '2022-12-01'],\n              dtype='datetime64[ns]', name='time', freq='MS'))Attributes: (7)_CoordinateAxisType :Timeactual_range :[1.6409952e+09 1.6724448e+09]axis :Tioos_category :Timelong_name :Start Timestandard_name :timetime_origin :01-JAN-1970 00:00:00\n\n\n\n\nExamine the latitude coordinate variable\nTypically, the latitude coordinate variable will be in ascending order. However, in some datasets the order is reversed, i.e the order is descending.\nBy examining the first and last values on our latitude array (below), we can see that the values are descending.\n* In practice what this means is that when you slice (subset) using latitude later in this tutorial, you will put the largest latitude value first.\n\nprint('First latitude value', ds.latitude[0].item())\nprint('Last latitude value', ds.latitude[-1].item())\n\nFirst latitude value 41.5\nLast latitude value 40.204"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#working-with-the-data",
    "href": "tutorials/python/lis-chlora-dynamics.html#working-with-the-data",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "3. Working with the data",
    "text": "3. Working with the data\n\nCreating a Faceted Plot of Monthly Mean Chlorophyll-a for 2022\nIn this example, we plot directly from an xarray object using its built-in .plot() method. This is a quick and convenient way to create faceted maps, though it offers limited control over layout and map styling compared to using matplotlib or cartopy directly.\nThe col and col_wrap arguments define which dimension to facet over (in this case, “time”) and how many panels to display per row. The cbar_kwargs dictionary gives access to colorbar customization, such as setting the label and size.\n\nds_mon.chlor_a.plot(col=\"time\",\n                    col_wrap=4,\n                    cmap=\"turbo\",\n                    vmin=0, vmax=20,\n                    figsize=(15, 10),\n                    aspect=1.5,\n                    cbar_kwargs={\n                        'label': 'Chlorophyll-a (mg m$^{-3}$)',\n                        'shrink': 0.7,\n                        }\n                        )"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#creating-a-map-of-average-chlorophyll-a-over-the-year",
    "href": "tutorials/python/lis-chlora-dynamics.html#creating-a-map-of-average-chlorophyll-a-over-the-year",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Creating a Map of Average Chlorophyll-a Over the Year",
    "text": "Creating a Map of Average Chlorophyll-a Over the Year\n\nCompute the yearly mean for the region\nHere we use NumPy’s mean function to calculate the average chlorophyll-a across the time dimension (axis 0), resulting in a xarray dataarray of yearly mean values.\n\nds_yearly = np.mean(ds_mon.chlor_a, axis=0)\n\n\n\nPlot the map of the 2022 average SST in the region\n\nplt.pcolormesh(ds_yearly.longitude, ds_yearly.latitude, ds_yearly, cmap=\"turbo\", vmin=0, vmax=20)\nplt.colorbar()\nplt.title(\"Mean Chl-a \" \n          + ds_mon.time[0].dt.strftime('%b %Y').item() \n          + ' - '\n          + ds_mon.time[11].dt.strftime('%b %Y').item())\n\nplt.show()"
  },
  {
    "objectID": "tutorials/python/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "href": "tutorials/python/lis-chlora-dynamics.html#spatial-subset-and-time-series-comparing-chlorophyll-a-seasonal-cycles-in-western-and-eastern-long-island-sound",
    "title": "Long Island Sound Chlorophyll-a Dynamics Tutorial",
    "section": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound",
    "text": "Spatial Subset and Time Series Comparing Chlorophyll-a Seasonal Cycles in Western and Eastern Long Island Sound\nSubset the data - West Long Island Ssound bewteen -73.9o to -73.1o W longitude - East Long Island Ssound bewteen -72.9o to -71.8o W longitude\nWe are going to generate a time series of mean SST within each box.\n\nda_west = ds.sel(longitude=slice(-73.9, -73.1))\nda_east = ds.sel(longitude=slice(-72.9, -71.8))\n\n\nExamine the structure of the subsetted data.\nThe subsets are 3D arrays with 365 time steps, each with 481 rows corresponding to latitudes (full LIS latitudinal extent) and 296 / 406 columns corresponding to longitudes in the West and East, respectively.\n\nprint(f\"West shape: {da_west.chlor_a.shape}\")\nprint(f\"West shape: {da_east.chlor_a.shape}\")\n\nWest shape: (365, 481, 296)\nWest shape: (365, 481, 406)\n\n\n\n\nResmaple each subset to an 8-Day means\nPlotting a daily time series can often be messy, so we compute 8-day averages to smooth the data and highlight seasonal patterns.\n\nda_west = da_west.resample(time=\"8D\").mean()\nda_east = da_east.resample(time=\"8D\").mean()\n\n\n\nCompute a time series\nNow, we will average all data within each subset across the latitude and longitude dimensions to produce a single time series.\n\nwest_TS = da_west.chlor_a.mean(dim=(\"latitude\",\"longitude\"))\neast_TS = da_east.chlor_a.mean(dim=(\"latitude\",\"longitude\"))\n\n\n\nPlot the time-series\n\nplt.figure(figsize=(8, 4))\nplt.plot(west_TS.time, west_TS, label=\"West LIS\", marker=\"o\", c=\"tab:blue\")\nplt.plot(east_TS.time, east_TS, label=\"East LIS\", marker=\"o\", c=\"tab:red\")\n\n\nplt.ylabel('Chlorophyll-a (mg m$^{-3}$)')\nplt.legend()"
  },
  {
    "objectID": "tutorials/python/matchup-polar-data-to-animal-track-locations.html",
    "href": "tutorials/python/matchup-polar-data-to-animal-track-locations.html",
    "title": "Tracking Penguin in Antarctica",
    "section": "",
    "text": "Modified October 2024"
  },
  {
    "objectID": "tutorials/python/matchup-polar-data-to-animal-track-locations.html#import-the-required-python-modules",
    "href": "tutorials/python/matchup-polar-data-to-animal-track-locations.html#import-the-required-python-modules",
    "title": "Tracking Penguin in Antarctica",
    "section": "Import the required Python modules",
    "text": "Import the required Python modules"
  },
  {
    "objectID": "tutorials/python/matchup-polar-data-to-animal-track-locations.html#packages",
    "href": "tutorials/python/matchup-polar-data-to-animal-track-locations.html#packages",
    "title": "Tracking Penguin in Antarctica",
    "section": "Packages",
    "text": "Packages\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport xarray as xr\nimport cartopy.crs as ccrs  \nimport cartopy.feature as cfeature\nimport warnings\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nwarnings.filterwarnings(\"ignore\")\n\n\nLoading the sea ice data from PolarWatch ERDDAP\n\n# Get sea ice data by sending data request using xarray to ERDDAP using its unique ID 'nsidcG02202v4shmday'\nds = xr.open_dataset(\"https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday\")\n\n\n\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1GB\nDimensions:                           (time: 545, ygrid: 332, xgrid: 316)\nCoordinates:\n  * time                              (time) datetime64[ns] 4kB 1978-11-01 .....\n  * ygrid                             (ygrid) float32 1kB 4.338e+06 ... -3.93...\n  * xgrid                             (xgrid) float32 1kB -3.938e+06 ... 3.93...\nData variables:\n    cdr_seaice_conc_monthly           (time, ygrid, xgrid) float32 229MB ...\n    nsidc_bt_seaice_conc_monthly      (time, ygrid, xgrid) float32 229MB ...\n    nsidc_nt_seaice_conc_monthly      (time, ygrid, xgrid) float32 229MB ...\n    qa_of_cdr_seaice_conc_monthly     (time, ygrid, xgrid) float32 229MB ...\n    stdev_of_cdr_seaice_conc_monthly  (time, ygrid, xgrid) float32 229MB ...\nAttributes: (12/66)\n    _NCProperties:                                       version=2,netcdf=4.8...\n    acknowledgement:                                     This project was sup...\n    cdm_data_type:                                       Grid\n    cdr_variable:                                        cdr_seaice_conc_monthly\n    contributor_name:                                    Walter N. Meier, Flo...\n    contributor_role:                                    principal investigat...\n    ...                                                  ...\n    summary:                                             This data set provid...\n    time_coverage_duration:                              P1M\n    time_coverage_end:                                   2024-03-01T00:00:00Z\n    time_coverage_resolution:                            P1M\n    time_coverage_start:                                 1978-11-01T00:00:00Z\n    title:                                               Sea Ice Concentratio...xarray.DatasetDimensions:time: 545ygrid: 332xgrid: 316Coordinates: (3)time(time)datetime64[ns]1978-11-01 ... 2024-03-01_ChunkSizes :1024_CoordinateAxisType :Timeactual_range :[2.7872640e+08 1.7092512e+09]axis :Tioos_category :Timelong_name :ANSI datestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1978-11-01T00:00:00.000000000', '1978-12-01T00:00:00.000000000',\n       '1979-01-01T00:00:00.000000000', ..., '2024-01-01T00:00:00.000000000',\n       '2024-02-01T00:00:00.000000000', '2024-03-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')ygrid(ygrid)float324.338e+06 4.312e+06 ... -3.938e+06_ChunkSizes :332actual_range :[-3937500.  4337500.]axis :Yioos_category :Locationlong_name :projection_grid_y_centersstandard_name :projection_y_coordinateunits :metersvalid_range :[-3950000.  4350000.]array([ 4337500.,  4312500.,  4287500., ..., -3887500., -3912500., -3937500.],\n      dtype=float32)xgrid(xgrid)float32-3.938e+06 -3.912e+06 ... 3.938e+06_ChunkSizes :316actual_range :[-3937500.  3937500.]axis :Xioos_category :Locationlong_name :projection_grid_x_centersstandard_name :projection_x_coordinateunits :metersvalid_range :[-3950000.  3950000.]array([-3937500., -3912500., -3887500., ...,  3887500.,  3912500.,  3937500.],\n      dtype=float32)Data variables: (5)cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...ancillary_variables :stdev_of_cdr_seaice_conc_monthly qa_of_cdr_seaice_conc_monthlycolorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole lakes coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :NOAA/NSIDC Climate Data Record of Passive Microwave Monthly Southern Hemisphere Sea Ice Concentrationreferences :https://nsidc.org/data/g02202/versions/4/standard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][57177040 values with dtype=float32]nsidc_bt_seaice_conc_monthly(time, ygrid, xgrid)float32...colorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole unused coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration by Bootstrap algorithm processed by NSIDCstandard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][57177040 values with dtype=float32]nsidc_nt_seaice_conc_monthly(time, ygrid, xgrid)float32...colorBarMaximum :1.0colorBarMinimum :0.0colorBarPalette :KT_icedatum :+ellps=urn:ogc:def:crs:EPSG::4326flag_meanings :pole_hole unused coastal land_mask missing_dataflag_values :[-5 -4 -3 -2 -1]ioos_category :Ice Distributionlong_name :Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration by NASA Team algorithm processed by NSIDCstandard_name :sea_ice_area_fractionunits :1valid_range :[0. 1.][57177040 values with dtype=float32]qa_of_cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...colorBarMaximum :120.0colorBarMinimum :0.0datum :+ellps=urn:ogc:def:crs:EPSG::4326flag_masks :[  1.   2.   4.   8.  32.  64. 128.]flag_meanings :Average_concentration_exceeds_0.15 Average_concentration_exceeds_0.30 At_least_half_the_days_have_sea_ice_conc_exceeds_0.15 At_least_half_the_days_have_sea_ice_conc_exceeds_0.30 Region_masked_by_ocean_climatology At_least_one_day_during_month_has_spatial_interpolation At_least_one_day_during_month_has_temporal_interpolationioos_category :Qualitylong_name :Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration QC flagsstandard_name :sea_ice_area_fraction status_flagvalid_range :[ 1 -1][57177040 values with dtype=float32]stdev_of_cdr_seaice_conc_monthly(time, ygrid, xgrid)float32...colorBarMaximum :5.0colorBarMinimum :0.0datum :+ellps=urn:ogc:def:crs:EPSG::4326ioos_category :Statisticslong_name :Passive Microwave Monthly Southern Hemisphere Sea Ice Concentration Source Estimated Standard Deviationvalid_range :[0. 1.][57177040 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1978-11-01', '1978-12-01', '1979-01-01', '1979-02-01',\n               '1979-03-01', '1979-04-01', '1979-05-01', '1979-06-01',\n               '1979-07-01', '1979-08-01',\n               ...\n               '2023-06-01', '2023-07-01', '2023-08-01', '2023-09-01',\n               '2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01',\n               '2024-02-01', '2024-03-01'],\n              dtype='datetime64[ns]', name='time', length=545, freq=None))ygridPandasIndexPandasIndex(Index([ 4337500.0,  4312500.0,  4287500.0,  4262500.0,  4237500.0,  4212500.0,\n        4187500.0,  4162500.0,  4137500.0,  4112500.0,\n       ...\n       -3712500.0, -3737500.0, -3762500.0, -3787500.0, -3812500.0, -3837500.0,\n       -3862500.0, -3887500.0, -3912500.0, -3937500.0],\n      dtype='float32', name='ygrid', length=332))xgridPandasIndexPandasIndex(Index([-3937500.0, -3912500.0, -3887500.0, -3862500.0, -3837500.0, -3812500.0,\n       -3787500.0, -3762500.0, -3737500.0, -3712500.0,\n       ...\n        3712500.0,  3737500.0,  3762500.0,  3787500.0,  3812500.0,  3837500.0,\n        3862500.0,  3887500.0,  3912500.0,  3937500.0],\n      dtype='float32', name='xgrid', length=316))Attributes: (66)_NCProperties :version=2,netcdf=4.8.1,hdf5=1.10.6acknowledgement :This project was supported in part by a grant from the NOAA Climate Data Record Program. Production of original NASA Team and Bootstrap algorithm estimates supported by the NASA Polar Distributed Active Archive Center. The sea ice concentration algorithms were developed by Donald J. Cavalieri, Josefino C. Comiso, Claire L. Parkinson, and others at the NASA Goddard Space Flight Center in Greenbelt, MD.cdm_data_type :Gridcdr_variable :cdr_seaice_conc_monthlycontributor_name :Walter N. Meier, Florence Fetterer, Ann Windnagel, J. Scott Stewart, Trey Stafford, Matt Fishercontributor_role :principal investigator, author, author, software developer, software developer, software developerConventions :CF-1.6, ACDD-1.3, COARDScreator_email :nsidc@nsidc.orgcreator_name :NSIDCcreator_type :institutioncreator_url :https://nsidc.org/date_created :2024-08-05T20:55:49ZdefaultGraphQuery :cdr_seaice_conc_monthly%5Blast%5D%5B(4337500.0):(-3937500.0)%5D%5B(-3937500.0):(3937500.0)%5D&.draw=surfacegrid_mapping_false_easting :0.0grid_mapping_false_northing :0.0grid_mapping_GeoTransform :-3950000.0 25000.0 0 4350000.0 0 -25000.0grid_mapping_grid_boundary_bottom_projected_y :-3950000.0grid_mapping_grid_boundary_left_projected_x :-3950000.0grid_mapping_grid_boundary_right_projected_x :3950000.0grid_mapping_grid_boundary_top_projected_y :4350000.0grid_mapping_latitude_of_projection_origin :-90.0grid_mapping_longitude_of_projection_origin :0.0grid_mapping_name :polar_stereographicgrid_mapping_parent_grid_cell_column_subset_end :316.0grid_mapping_parent_grid_cell_column_subset_start :0.0grid_mapping_parent_grid_cell_row_subset_end :332.0grid_mapping_parent_grid_cell_row_subset_start :0.0grid_mapping_proj4text :+proj=stere +lat_0=-90 +lat_ts=-70 +lon_0=0 +k=1 +x_0=0 +y_0=0 +a=6378273 +b=6356889.449 +units=m +no_defsgrid_mapping_scaling_factor :1.0grid_mapping_semimajor_radius :6378273.0grid_mapping_semiminor_radius :6356889.449grid_mapping_spatial_ref :PROJCS[\"NSIDC Sea Ice Polar Stereographic South\",GEOGCS[\"Unspecified datum based upon the Hughes 1980 ellipsoid\",DATUM[\"Not_specified_based_on_Hughes_1980_ellipsoid\",SPHEROID[\"Hughes 1980\",6378273,298.279411123061,AUTHORITY[\"EPSG\",\"7058\"]],AUTHORITY[\"EPSG\",\"6054\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4054\"]],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",-70],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],AUTHORITY[\"EPSG\",\"3412\"],AXIS[\"X\",UNKNOWN],AXIS[\"Y\",UNKNOWN]]grid_mapping_srid :urn:ogc:def:crs:EPSG::3412grid_mapping_standard_parallel :-70.0grid_mapping_straight_vertical_longitude_from_pole :180.0grid_mapping_units :metershistory :Tue Jan  5 13:40:25 2021: ncks -x -v goddard_merged_seaice_conc_monthly ./previous_blank_ncs/S_monthly_blank.nc ./S_monthly_blank.nc\n2024-10-01T21:47:42Z (local files)\n2024-10-01T21:47:42Z https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4shmday.dasid :https://doi.org/10.7265/sr8p-kc62infoUrl :https://nsidc.org/data/g02202/versions/4/institution :NSIDC &gt; National Snow and Ice Data Centerkeywords :algorithm, area, bellingshausen, bootstrap, cdr_seaice_conc_monthly, center, climate, common, concentration, cryosphere, data, defense, deviation, distribution, dmsp, earth, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Extent, Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Sea Ice Concentration, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Extent, estimated, extent, flag, flags, flight, format, fraction, geographic, Geographic Region &gt; Polar, Geographic Region &gt; Southern Hemisphere, goddard, gsfc, hemisphere, ice, ice distribution, meteorological, microwave, month, monthly, nasa, national, network, noaa, noaa/nsidc, nsidc, nsidc_bt_seaice_conc_monthly, nsidc_nt_seaice_conc_monthly, ocean, Ocean &gt; Southern Ocean, Ocean &gt; Southern Ocean &gt; Bellingshausen Sea, Ocean &gt; Southern Ocean &gt; Ross Sea, Ocean &gt; Southern Ocean &gt; Weddell Sea, oceans, passive, polar, processed, program, qa_of_cdr_seaice_conc_monthly, quality, record, region, ross, satellite, science, sea, sea_ice_area_fraction, sea_ice_area_fraction status_flag, snow, source, southern, space, standard, statistics, status, stdev_of_cdr_seaice_conc_monthly, tdim, team, version, weddellkeywords_vocabulary :GCMD Science Keywordslicense :No constraints on data access or usemetadata_link :https://nsidc.org/data/g02202/versions/4/naming_authority :org.doi.dxNCO :\"4.5.4\"platform :DMSP 5D-3/F17 &gt; Defense Meteorological Satellite Program-F17processing_level :NOAA Level 3product_version :v04r00program :NOAA Climate Data Record Programproj_crs_code :EPSG:3412proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.project :NOAA/NSIDC passive microwave sea ice concentration climate data recordreferences :Comiso, J. C., and F. Nishio. 2008. Trends in the Sea Ice Cover Using Enhanced and Compatible AMSR-E, SSM/I, and SMMR Data. Journal of Geophysical Research 113, C02S07, doi:10.1029/2007JC0043257. ; Comiso, J. C., D. Cavalieri, C. Parkinson, and P. Gloersen. 1997. Passive Microwave Algorithms for Sea Ice Concentrations: A Comparison of Two Techniques. Remote Sensing of the Environment 60(3):357-84. ; Comiso, J. C. 1984. Characteristics of Winter Sea Ice from Satellite Multispectral Microwave Observations. Journal of Geophysical Research 91(C1):975-94. ; Cavalieri, D. J., P. Gloersen, and W. J. Campbell. 1984. Determination of Sea Ice Parameters with the NIMBUS-7 SMMR. Journal of Geophysical Research 89(D4):5355-5369. ; Cavalieri, D. J., C. l. Parkinson, P. Gloersen, J. C. Comiso, and H. J. Zwally. 1999. Deriving Long-term Time Series of Sea Ice Cover from Satellite Passive-Microwave Multisensor Data Sets. Journal of Geophysical Research 104(7):  15,803-15,814. ; Comiso, J.C., R.A. Gersten, L.V. Stock, J. Turner, G.J. Perez, and K. Cho. 2017. Positive Trend in the Antarctic Sea Ice Cover and Associated Changes in Surface Temperature. J. Climate, 30, 2251?2267, https://doi.org/10.1175/JCLI-D-16-0408.1sensor :SSMI/S &gt; Special Sensor Microwave Imager/Soundersoftware_version_id :git@bitbucket.org:nsidc/seaice_cdr.git@a11f275ee7ada7a9cdadada1b3d252de674d624fsource :ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240301_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240302_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240303_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240304_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240305_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240306_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240307_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240308_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240309_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240310_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240311_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240312_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240313_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240314_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240315_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240316_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240317_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240318_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240319_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240320_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240321_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240322_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240323_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240324_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240325_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240326_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240327_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240328_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240329_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240330_f17_v04r00.nc, ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02202_V4/south/daily/2024/seaice_conc_daily_sh_20240331_f17_v04r00.ncsourceUrl :(local files)spatial_resolution :25kmstandard_name_vocabulary :CF Standard Name Table v70summary :This data set provides a passive microwave sea ice concentration climate data record (CDR) based on gridded brightness temperatures (TBs) from the Defense Meteorological Satellite Program (DMSP) series of passive microwave radiometers: the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR), the Special Sensor Microwave Imager (SSM/I) and the Special Sensor Microwave Imager/Sounder (SSMIS). The sea ice concentration CDR is an estimate of sea ice concentration that is produced by combining concentration estimates from two algorithms developed at the NASA Goddard Space Flight Center (GSFC): the NASA Team algorithm and the Bootstrap algorithm. The individual algorithms are used to process and combine brightness temperature data at National Snow and Ice Data Center (NSIDC).  This product is designed to provide a consistent time series of sea ice concentrations (the fraction, or percentage, of ocean area covered by sea ice) from November 1978 to the present which spans the coverage of several passive microwave instruments. The data are gridded on the NSIDC polar stereographic grid with 25 x 25 km grid cells, and are available in Network Common Data Format (NetCDF) file format. Each file contains a variable with the CDR concentration values as well as variables that hold the NASA Team and Bootstrap concentrations for reference. Variables containing standard deviation, quality flags, and projection information are also included. Data are available from NSIDC via FTP see https://nsidc.org/data/G02202/versions/4/. Data are also distributed via the PolarWatch ERDDAP at https://polarwatch.noaa.gov/erddap. Note that the data format available through PolarWatch is different from the NSIDC FTP NetCDF files. The PolarWatch data server stores projection information as global attributes (with the prefix grid_mapping) instead of as a variable; and the timestamp is served in different units (seconds since 1970).time_coverage_duration :P1Mtime_coverage_end :2024-03-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :1978-11-01T00:00:00Ztitle :Sea Ice Concentration, NOAA/NSIDC Climate Data Record V4, Southern Hemisphere, 25km, Science Quality, 1978-Present, Monthly\n\n\n\n\nPlotting Sea Ice Data on a Map\n\n# Select sea ice concentration variable of first timestep\nsic = ds['cdr_seaice_conc_monthly'][0]\n\n# Based on the metadata, values above 1 represent variouag flags, therefore we will \n# remove the values greater than 1.\nsic = sic.where(sic &lt;=1, np.nan)\n\n# Set coordinate reference system (crs) based on the projection attribute from ds\npolar_crs = ccrs.SouthPolarStereo(central_longitude=0.0, true_scale_latitude=-70)\n\n# Set figure size\nplt.figure(figsize=(5,5))\n\n# Set the map projection and associated boundaries based on the metadata\nax = plt.axes(projection = polar_crs)\nax.set_extent([-3950000.0, 3950000.0, -3950000.0, 4350000.0], polar_crs)  \nax.coastlines()\nax.add_feature(cfeature.LAND)\n\n# Plot first time-step\ncs = ax.pcolormesh(ds['xgrid'], ds['ygrid'], sic,\n                   cmap=plt.cm.Blues,  transform= polar_crs) #transform default is basemap specs\nplt.colorbar(cs, ax=ax, location='right', shrink =0.8)\nax.set_title('Ice Concentration of timestep 1')\n\nText(0.5, 1.0, 'Ice Concentration of timestep 1')\n\n\n\n\n\n\n\n\n\n\n\nLoading penguin telemetry data in csv\n\n# Load penguin data into pandas data frame\npenguin = pd.read_csv('../data/copa_adpe_ncei.csv')\npenguin.head()\n\n\n\n\n\n\n\n\nBirdId\nSex\nAge\nBreed Stage\nDateGMT\nTimeGMT\nLatitude\nLongitude\nArgosQuality\n\n\n\n\n0\nADPE1\nfemale\nadult\nincubation\n28/10/1997\n7:54:00\n-62.171667\n-58.445000\n2\n\n\n1\nADPE1\nfemale\nadult\nincubation\n28/10/1997\n9:32:00\n-62.173333\n-58.463333\n2\n\n\n2\nADPE1\nfemale\nadult\nincubation\n28/10/1997\n18:15:00\n-62.158333\n-58.426667\n1\n\n\n3\nADPE1\nfemale\nadult\nincubation\n28/10/1997\n19:57:00\n-62.175000\n-58.441667\n2\n\n\n4\nADPE1\nfemale\nadult\nincubation\n28/10/1997\n21:37:00\n-62.171667\n-58.445000\n2\n\n\n\n\n\n\n\n\n\nProcessing Penguin Data\nFor this exercise, we will select ADPE24, female penguin whose track records are highest within the female group, and will follow her journey in the Arctic.\n\n# Find BirdID with the most count by sex\npenguin.groupby('Sex')['BirdId'].apply(lambda x: x.value_counts().idxmax())\n\n# Extract ADPE24 track data\nadpe24 = penguin[penguin['BirdId']=='ADPE24']\n\n# Format Date\nadpe24['DateGMT'] = pd.to_datetime(adpe24['DateGMT'], format='%d/%m/%Y')\nadpe24['Year_Month'] = adpe24['DateGMT'].dt.strftime('%Y-%m')\n\n# unique penguin dates\nadpe_dates = adpe24['Year_Month'].unique()\n\nprint(f\"Date Range: {adpe24['DateGMT'].min()}, {adpe24['DateGMT'].max()}\")\nprint(f\"Unique Month: {adpe24['Year_Month'].unique()}\")\n\nDate Range: 2003-01-16 00:00:00, 2003-03-09 00:00:00\nUnique Month: ['2003-01' '2003-02' '2003-03']\n\n\n\n\nVisualize penguin tracks on sea ice concentration map\n\nadpe_dates\n\narray(['2003-01', '2003-02', '2003-03'], dtype=object)\n\n\n\n# Subset sea ice data based on ADPE24 unique dates\nds_penguin = ds.sel(time=adpe_dates, method='nearest')\n# Process sea ice data\nsic_penguin = ds_penguin['cdr_seaice_conc_monthly']\nsic_penguin = sic_penguin.where(sic_penguin &lt;=1, np.nan)\n\n\n# Penguin Data for Each Month\nadpe24_jan = adpe24[adpe24['DateGMT'].dt.month == 1]\nadpe24_feb = adpe24[adpe24['DateGMT'].dt.month == 2]\nadpe24_mar = adpe24[adpe24['DateGMT'].dt.month == 3]\n\nadpe24_data = [adpe24_jan, adpe24_feb, adpe24_mar]\ntitles = ['January', 'February', 'March']\n\n# set mapping crs to Cartopy's South Polar Stereo graphic\ncrs_epsg = ccrs.SouthPolarStereo(central_longitude=-45)\n\n# Assuming your setup is the same\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 8), subplot_kw={'projection': crs_epsg})\n\nfor i, ax in enumerate(axes):\n    # set basemap with Cartopy PlateCarree() projection\n    ax.add_feature(cfeature.LAND)\n    ax.coastlines(resolution='50m')\n    ax.set_extent([-1500000.0, 500000.0, 2000000.0, 3500000.0], crs_epsg)\n    ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=True)\n\n    cs = ax.pcolormesh(ds_penguin['xgrid'], ds_penguin['ygrid'], sic_penguin[i],\n                       cmap=plt.cm.Blues, transform=ccrs.SouthPolarStereo(true_scale_latitude=-70, central_longitude=0))\n\n    # set the data crs\n    ax.scatter(\n        y=adpe24_data[i][\"Latitude\"],\n        x=adpe24_data[i][\"Longitude\"],\n        color=\"red\",\n        s=3,\n        alpha=1,\n        transform=ccrs.PlateCarree()\n    )\n\n    ax.set_title(titles[i])\n\n #Create a colorbar\ncbar_ax = fig.add_axes([1, 0.15, 0.02, 0.7])  # [left, bottom, width, height]  \nfig.colorbar(cs, cax=cbar_ax, orientation='vertical', label='Sea Ice Concentration')\n\nplt.tight_layout()\nplt.show()\n     \n\n\n\n\n\n\n\n\n\n\nResampling Penguin data to match satellite Date\n\n\nadpe24 = adpe24[[\"DateGMT\", \"Latitude\", \"Longitude\"]]\nadpe24['DateGMT'] = pd.to_datetime(adpe24['DateGMT'], format='%d/%m/%Y')\nadpe24_df = adpe24.resample('D', on='DateGMT').mean()\n\n\n\nTransforming CRS of the penguin locations\n\n\nlatlon_crs = ccrs.PlateCarree() # lat and lon\npolar_crs = ccrs.epsg('3412') # South pole\n\ntransformed_coords = polar_crs.transform_points(latlon_crs, adpe24_df['Longitude'].values, adpe24_df['Latitude'].values)\n\nadpe24_df['xgrid'] = transformed_coords[:, 0]\nadpe24_df['ygrid'] = transformed_coords[:, 1]\n\nadpe24_df.head()\n\n\n\n\n\n\n\n\nLatitude\nLongitude\nerddap_date\nmatched_ygrid\nmatched_xgrid\nmatched_sea_ice_concen\nxgrid\nygrid\n\n\nDateGMT\n\n\n\n\n\n\n\n\n\n\n\n\n2003-01-16\n-62.177000\n-58.452600\nNaN\nNaN\nNaN\nNaN\n-2.618256e+06\n1.607450e+06\n\n\n2003-01-17\n-62.176370\n-58.425000\nNaN\nNaN\nNaN\nNaN\n-2.617543e+06\n1.608749e+06\n\n\n2003-01-18\n-62.339500\n-57.683400\nNaN\nNaN\nNaN\nNaN\n-2.580691e+06\n1.632492e+06\n\n\n2003-01-19\n-62.547353\n-57.539765\nNaN\nNaN\nNaN\nNaN\n-2.556494e+06\n1.626173e+06\n\n\n2003-01-20\n-62.163853\n-58.457471\nNaN\nNaN\nNaN\nNaN\n-2.619678e+06\n1.608017e+06\n\n\n\n\n\n\n\n\n\nExtracting Satellite Data to match penguin track and date\n\n\n# Add new columns to the dataframe\nadpe24_df[[\"erddap_date\", \"matched_ygrid\", \"matched_xgrid\", \"matched_sea_ice_concen\"]] = np.nan\n\n# Subset the satellite data\nfor i in range(0, len(adpe24_df)):\n    # Download the satellite data\n    temp_ds = ds['cdr_seaice_conc_monthly'].sel(time='{0:%Y-%m-%d}'.format(adpe24_df.index[i]),\n                                ygrid=adpe24_df.iloc[i]['ygrid'],\n                                xgrid=adpe24_df.iloc[i]['xgrid'],\n                                method='nearest'\n                                )\n    \n    # Add to the dataframe\n    adpe24_df.loc[adpe24_df.index[i], [\"erddap_date\", \"matched_ygrid\",\n                                 \"matched_xgrid\", \"matched_sea_ice_concen\"]\n          ] = [temp_ds.time.values,\n               np.round(temp_ds.ygrid.values, 5),  # round 5 dec\n               np.round(temp_ds.xgrid.values, 5), # round 5 dec\n               np.round(temp_ds.values, 2)  # round 2 decimals\n               ]\n\n\n\nPlotting Penguin Tracks with Matched Sea Ice Concentration Data\n\nplt.figure(figsize=(14, 10))\n\n\n# set the projection\nax1 = plt.subplot(211, projection=crs_epsg)\n\n# Use the lon and lat ranges to set the extent of the map\nax1.set_extent([-90, -30, -75, -55], ccrs.PlateCarree()) # South Pole\n\n# Add grid line\ngl = ax1.gridlines(draw_labels=True, crs=ccrs.PlateCarree(), linestyle='--')\ngl.xlabels_top = False\ngl.ylabels_right = False\ngl.xformatter = LongitudeFormatter()\ngl.yformatter = LatitudeFormatter()\n\n# Add geographical features\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# build and plot coordinates onto map\nx,y = list(adpe24_df.Longitude), list(adpe24_df.Latitude)\nax1 = plt.scatter(x, y, transform=ccrs.PlateCarree(),\n                  marker='o',\n                  c=adpe24_df.matched_sea_ice_concen,\n                  cmap=plt.get_cmap('Blues'),\n                  edgecolor='Black',\n                  linewidth=0.25\n                  )\nax1=plt.plot(x[0],y[0],marker='*', label='start', color='red', transform=ccrs.PlateCarree(), markersize=10)\nax1=plt.plot(x[-1],y[-1],marker='X', label='end',color='orange', transform=ccrs.PlateCarree(), markersize=10)\n\n\n\n# control color bar values spacing\nlevs2 = np.arange(0, 1, 0.1)\n\ncbar=plt.colorbar()\ncbar.set_label(\"Sea Ice Concentration\", size=12, labelpad=20)\n\n# set the labels to be exp(levs2) so the label reflect values of chl-a, not log(chl-a)\ncbar.ax.set_yticklabels(np.round(levs2, 1), size=10)\n\nplt.legend()\nplt.title(\"Sea Ice Concen Matchup to Penguin Track\", size=15)\nplt.show()"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray.html",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray.html",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "",
    "text": "History | Updated Mar 2024\n\nIn this exercise you will extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like that produced by an animal telemetry tag, and ship track, or a glider tract.\nPlease note that there may be more efficient ways, more Pythonic ways, to accomplish the tasks in this tutorial. The tutorial was developed to be easier to follow for less experienced users of Python.\n\n\n\nLoading data from a tab- or comma-separated file\nPlotting the latitude/longitude points onto a map\nExtracting satellite data along a track\nSaving results as a CSV file\nPlotting the satellite data onto a map\n\n\n\n\n\nChlorophyll a concentration from the European Space Agency’s Ocean Colour Climate Change Initiative Monthly dataset v6.0\nA loggerhead turtle telemetry track that has been subsample to reduce the data requests needed for this tutorial from over 1200 to 25. The turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. The track data can be downloaded from data folder in this project folder.\n\n\n\n\n\npandas (reading and analyzing data)\n\nnumpy (data analysis, manipulation)\nxarray (multi-dimensional data analysis, manipulation)\nmatplotlib (mapping)\ncartopy (mapping)\ndatetime (date manipulation)"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#overview",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#overview",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "",
    "text": "History | Updated Mar 2024\n\nIn this exercise you will extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like that produced by an animal telemetry tag, and ship track, or a glider tract.\nPlease note that there may be more efficient ways, more Pythonic ways, to accomplish the tasks in this tutorial. The tutorial was developed to be easier to follow for less experienced users of Python.\n\n\n\nLoading data from a tab- or comma-separated file\nPlotting the latitude/longitude points onto a map\nExtracting satellite data along a track\nSaving results as a CSV file\nPlotting the satellite data onto a map\n\n\n\n\n\nChlorophyll a concentration from the European Space Agency’s Ocean Colour Climate Change Initiative Monthly dataset v6.0\nA loggerhead turtle telemetry track that has been subsample to reduce the data requests needed for this tutorial from over 1200 to 25. The turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. The track data can be downloaded from data folder in this project folder.\n\n\n\n\n\npandas (reading and analyzing data)\n\nnumpy (data analysis, manipulation)\nxarray (multi-dimensional data analysis, manipulation)\nmatplotlib (mapping)\ncartopy (mapping)\ndatetime (date manipulation)"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#import-the-required-python-modules",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#import-the-required-python-modules",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Import the required Python modules",
    "text": "Import the required Python modules\n\nfrom IPython.display import clear_output\nimport pandas as pd\nimport numpy as np\nimport os\nimport warnings\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport matplotlib.pyplot as plt\nimport xarray as xr\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#load-the-track-data-into-a-pandas-data-frame",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#load-the-track-data-into-a-pandas-data-frame",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Load the track data into a Pandas data frame",
    "text": "Load the track data into a Pandas data frame\nBelow, the track data will load using the Pandas “read_csv” method. * Then use the “.head()” method to view the column names and the first few rows of data.\n\ntrack_path = os.path.join('..',\n                          'data',\n                          '25317_05_subsampled.dat')\n\ndf = pd.read_csv(track_path)\nprint(df.head(2))\n\n     mean_lon   mean_lat  year  month  day\n0  176.619433  32.678728  2005      5    4\n1  175.860895  35.057734  2005      6   23"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#plot-the-track-on-a-map",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#plot-the-track-on-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot the track on a map",
    "text": "Plot the track on a map\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([120, 260, 15, 55], ccrs.PlateCarree())\n\n# Set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(125, 255, 20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(20, 60, 10), crs=ccrs.PlateCarree())\n\n# Add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# Format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# Bring the lon and lat data into a numpy array \nx, y = df.mean_lon.to_numpy(), df.mean_lat.to_numpy()\nax1 = plt.plot(x, y, transform=ccrs.PlateCarree(), color='k')\n# start point in green star\nax1 = plt.plot(x[0], y[0],\n               marker='*',\n               color='g',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\n# end point in red X\nax1 = plt.plot(x[-1], y[-1],\n               marker='X',\n               color='r',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\nplt.title('Animal Track for Turtle #25317', fontsize=20)\n\nplt.show()"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#prepare-track-data-for-use-to-extract-satellite-data",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#prepare-track-data-for-use-to-extract-satellite-data",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Prepare track data for use to extract satellite data",
    "text": "Prepare track data for use to extract satellite data\n\nCreate a column with Pandas date objects\nReload the “25317_05_subsampled.dat”. This time we will use the “parse_dates” option to create a Pandas date object column (year_month_day) from the ‘year’, ‘month’, and ‘day’ columns.\n\ndf = pd.read_csv(track_path,\n                 parse_dates=[['year', 'month', 'day']]\n                 )\n\nprint('The new year_month_day column contains the Pandas date objects')\nprint(df.head(2))\nprint(df.dtypes)\n\nThe new year_month_day column contains the Pandas date objects\n  year_month_day    mean_lon   mean_lat\n0     2005-05-04  176.619433  32.678728\n1     2005-06-23  175.860895  35.057734\nyear_month_day    datetime64[ns]\nmean_lon                 float64\nmean_lat                 float64\ndtype: object"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Extract data from a satellite dataset corresponding to points on the track",
    "text": "Extract data from a satellite dataset corresponding to points on the track\nWe are going to download data from an ERDDAP server using the following steps: * Select a dataset on an ERDDAP server * Open the dataset using the Xarray module * Loop though the track data and pull out the date, latitude and longitude coordinates from each row * Insert these coordinates into the Xarray open-dataset object to select and download the satellite data that corresponds to the coordinates. * Store the satellite data in a temporary Pandas data frame * Once all the satellite data has been added to the temporary data frame, merge it with the track data frame.\n\nSelect a dataset\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product that blends data from many ocean color sensors to create a long time series (1997-present) with better spatial coverage than any single sensor.\nIdeally we would use a daily dataset, selecting the day that corresponds to the track data date. However, chlorophyll measurements can have a lot of missing data, primarily due to cloud cover. To reduce data gaps and improve the likelihood of data for our matchups, we can use a dataset that combines all of the data from each month into the monthly average.\nThe ERDDAP URL to the monthly version of the OC-CCI product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\n\n\nOpen the satellite data in Xarray\n\nUse the ERDDAP URL with no extension (e.g. without .html or .graph…). This is the OPeNDAP URL, which allows viewing the dataset metadata and, when you select the data you want, downloading the data.\nUse the Xarray “open_dataset” function then view the metadata\n\n\nerddap_url = '/'.join(['https://oceanwatch.pifsc.noaa.gov',\n                       'erddap',\n                       'griddap',\n                       'esa-cci-chla-monthly-v6-0'])\n\nds = xr.open_dataset(erddap_url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 472GB\nDimensions:             (time: 316, latitude: 4320, longitude: 8640)\nCoordinates:\n  * time                (time) datetime64[ns] 3kB 1997-09-04 ... 2023-12-01\n  * latitude            (latitude) float64 35kB 89.98 89.94 ... -89.94 -89.98\n  * longitude           (longitude) float64 69kB 0.02083 0.0625 ... 359.9 360.0\nData variables:\n    chlor_a             (time, latitude, longitude) float32 47GB ...\n    MERIS_nobs_sum      (time, latitude, longitude) float32 47GB ...\n    MODISA_nobs_sum     (time, latitude, longitude) float32 47GB ...\n    OLCI_A_nobs_sum     (time, latitude, longitude) float32 47GB ...\n    OLCI_B_nobs_sum     (time, latitude, longitude) float32 47GB ...\n    SeaWiFS_nobs_sum    (time, latitude, longitude) float32 47GB ...\n    VIIRS_nobs_sum      (time, latitude, longitude) float32 47GB ...\n    chlor_a_log10_bias  (time, latitude, longitude) float32 47GB ...\n    chlor_a_log10_rmsd  (time, latitude, longitude) float32 47GB ...\n    total_nobs_sum      (time, latitude, longitude) float32 47GB ...\nAttributes: (12/53)\n    cdm_data_type:                     Grid\n    comment:                           See summary attribute\n    Conventions:                       CF-1.7, COARDS, ACDD-1.3\n    creation_date:                     Thu Jan 18 09:04:18 2024\n    creator_email:                     help@esa-oceancolour-cci.org\n    creator_name:                      Plymouth Marine Laboratory\n    ...                                ...\n    time_coverage_end:                 2023-12-01T00:00:00Z\n    time_coverage_resolution:          P1M\n    time_coverage_start:               1997-09-04T00:00:00Z\n    title:                             Chlorophyll a concentration, ESA OC CC...\n    tracking_id:                       abd52a4c-7009-464f-b1eb-958f7d333a1d\n    Westernmost_Easting:               0.020833333333314386xarray.DatasetDimensions:time: 316latitude: 4320longitude: 8640Coordinates: (3)time(time)datetime64[ns]1997-09-04 ... 2023-12-01_CoordinateAxisType :Timeactual_range :[8.7333120e+08 1.7013888e+09]axis :Tioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1997-09-04T00:00:00.000000000', '1997-10-01T00:00:00.000000000',\n       '1997-11-01T00:00:00.000000000', ..., '2023-10-01T00:00:00.000000000',\n       '2023-11-01T00:00:00.000000000', '2023-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float6489.98 89.94 89.9 ... -89.94 -89.98_CoordinateAxisType :Latactual_range :[-89.97916667  89.97916667]axis :Yioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.97916666666667valid_min :-89.97916666666666array([ 89.979167,  89.9375  ,  89.895833, ..., -89.895833, -89.9375  ,\n       -89.979167])longitude(longitude)float640.02083 0.0625 ... 359.9 360.0_CoordinateAxisType :Lonactual_range :[2.08333333e-02 3.59979167e+02]axis :Xioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :359.97918701171875valid_min :0.020829999819397926array([2.083333e-02, 6.250000e-02, 1.041667e-01, ..., 3.598958e+02,\n       3.599375e+02, 3.599792e+02])Data variables: (10)chlor_a(time, latitude, longitude)float32...ancillary_variables :chlor_a_log10_rmsd chlor_a_log10_biascolorBarMaximum :30.0colorBarMinimum :0.03colorBarScale :Logioos_category :Ocean Colorlong_name :Chlorophyll-a concentration in seawater (not log-transformed), generated by as a blended combination of OCI, OCI2, OC2 and OCx algorithms, depending on water class membershipsparameter_vocab_uri :http://vocab.ndg.nerc.ac.uk/term/P011/current/CHLTVOLUstandard_name :mass_concentration_of_chlorophyll_a_in_sea_waterunits :mg m-3units_nonstandard :mg m^-3[11794636800 values with dtype=float32]MERIS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the MERIS sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]MODISA_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the MODIS (Aqua) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]OLCI_A_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the OLCI (Sentinel-3a) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]OLCI_B_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the OLCI (Sentinel-3b) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]SeaWiFS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the SeaWiFS (GAC and LAC) sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]VIIRS_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the number of observations from the VIIRS sensor contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]chlor_a_log10_bias(time, latitude, longitude)float32...colorBarMaximum :0.1colorBarMinimum :-0.1comment :Uncertainty lookups derived from file: /data/datasets/CCI/v6.0-production/stage09b-uncertainty_tables/chlor_a/cci_chla_bias.datioos_category :Statisticslong_name :Bias of log10-transformed chlorophyll-a concentration in seawater.references :https://esa-oceancolour-cci.org/?q=webfm_send/581rel :uncertainty[11794636800 values with dtype=float32]chlor_a_log10_rmsd(time, latitude, longitude)float32...colorBarMaximum :0.002colorBarMinimum :0.0comment :Uncertainty lookups derived from file: /data/datasets/CCI/v6.0-production/stage09b-uncertainty_tables/chlor_a/cci_chla_rmsd.datioos_category :Statisticslong_name :Root-mean-square-difference of log10-transformed chlorophyll-a concentration in seawater.references :https://esa-oceancolour-cci.org/?q=webfm_send/581rel :uncertainty[11794636800 values with dtype=float32]total_nobs_sum(time, latitude, longitude)float32...colorBarMaximum :100.0colorBarMinimum :0.0ioos_category :Statisticslong_name :Count of the total number of observations contributing to this bin cellnumber_of_files_composited :31[11794636800 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1997-09-04', '1997-10-01', '1997-11-01', '1997-12-01',\n               '1998-01-01', '1998-02-01', '1998-03-01', '1998-04-01',\n               '1998-05-01', '1998-06-01',\n               ...\n               '2023-03-01', '2023-04-01', '2023-05-01', '2023-06-01',\n               '2023-07-01', '2023-08-01', '2023-09-01', '2023-10-01',\n               '2023-11-01', '2023-12-01'],\n              dtype='datetime64[ns]', name='time', length=316, freq=None))latitudePandasIndexPandasIndex(Index([ 89.97916666666667,            89.9375,  89.89583333333333,\n        89.85416666666667,            89.8125,  89.77083333333333,\n        89.72916666666667,            89.6875,  89.64583333333333,\n        89.60416666666667,\n       ...\n       -89.60416666666666, -89.64583333333331,           -89.6875,\n       -89.72916666666666, -89.77083333333331,           -89.8125,\n       -89.85416666666666, -89.89583333333331,           -89.9375,\n       -89.97916666666666],\n      dtype='float64', name='latitude', length=4320))longitudePandasIndexPandasIndex(Index([0.020833333333314386,               0.0625,  0.10416666666665719,\n        0.14583333333331439,               0.1875,   0.2291666666666572,\n         0.2708333333333144,               0.3125,   0.3541666666666572,\n         0.3958333333333144,\n       ...\n         359.60416666666663,    359.6458333333333,             359.6875,\n         359.72916666666663,    359.7708333333333,             359.8125,\n         359.85416666666663,    359.8958333333333,             359.9375,\n         359.97916666666663],\n      dtype='float64', name='longitude', length=8640))Attributes: (53)cdm_data_type :Gridcomment :See summary attributeConventions :CF-1.7, COARDS, ACDD-1.3creation_date :Thu Jan 18 09:04:18 2024creator_email :help@esa-oceancolour-cci.orgcreator_name :Plymouth Marine Laboratorycreator_url :https://esa-oceancolour-cci.orgdate_created :2022-08-15T22:03:48ZEasternmost_Easting :359.97916666666663geospatial_lat_max :89.97916666666667geospatial_lat_min :-89.97916666666666geospatial_lat_resolution :0.041666666666666664geospatial_lat_units :degrees_northgeospatial_lon_max :359.97916666666663geospatial_lon_min :0.020833333333314386geospatial_lon_resolution :0.041666666666666664geospatial_lon_units :degrees_eastgit_commit_hash :27964270df6ae0b9bdd0af5672529dbebb4e7bd9history :Thu Jan 18 08:21:00 2024: ncatted -O -a geospatial_lon_max,global,o,f,360.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a geospatial_lon_min,global,o,f,0.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a valid_max,lon,o,f,359.9792 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:21:00 2024: ncatted -O -a valid_min,lon,o,f,0.02083 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:20:41 2024: ncap2 -O -s where(lon&lt;0) lon=lon+360 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nThu Jan 18 08:20:20 2024: ncks -O --msa_usr_rdr -d lon,0.0,180.0 -d lon,-180.0,0.0 ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0.nc ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0-0-360.nc\nSource data were: ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231201-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231202-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231203-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231204-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231205-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231206-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231207-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231208-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231209-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231210-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231211-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231212-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231213-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231214-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231215-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231216-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231217-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231218-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231219-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231220-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231221-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231222-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231223-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231224-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231225-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231226-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231227-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231228-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231229-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231230-fv6.0.nc, ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_OCx_QAA-20231231-fv6.0.nc; netcdf_compositor_cci composites  Rrs_412, Rrs_412_bias, Rrs_443, Rrs_443_bias, Rrs_490, Rrs_490_bias, Rrs_510, Rrs_510_bias, Rrs_560, Rrs_560_bias, Rrs_665, Rrs_665_bias, adg_412, adg_412_bias, adg_443, adg_443_bias, adg_490, adg_490_bias, adg_510, adg_510_bias, adg_560, adg_560_bias, adg_665, adg_665_bias, aph_412, aph_412_bias, aph_443, aph_443_bias, aph_490, aph_490_bias, aph_510, aph_510_bias, aph_560, aph_560_bias, aph_665, aph_665_bias, atot_412, atot_443, atot_490, atot_510, atot_560, atot_665, bbp_412, bbp_443, bbp_490, bbp_510, bbp_560, bbp_665, chlor_a, chlor_a_log10_bias, kd_490, kd_490_bias, water_class1, water_class10, water_class11, water_class12, water_class13, water_class14, water_class2, water_class3, water_class4, water_class5, water_class6, water_class7, water_class8, water_class9 with --mean,  Rrs_412_rmsd, Rrs_443_rmsd, Rrs_490_rmsd, Rrs_510_rmsd, Rrs_560_rmsd, Rrs_665_rmsd, adg_412_rmsd, adg_443_rmsd, adg_490_rmsd, adg_510_rmsd, adg_560_rmsd, adg_665_rmsd, aph_412_rmsd, aph_443_rmsd, aph_490_rmsd, aph_510_rmsd, aph_560_rmsd, aph_665_rmsd, chlor_a_log10_rmsd, kd_490_rmsd with --root-mean-square, and  MERIS_nobs, MODISA_nobs, OLCI-A_nobs, OLCI-B_nobs, SeaWiFS_nobs, VIIRS_nobs, total_nobs - with --total\n1705571341 Subsetted from standardised_geo/ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1M_MONTHLY_4km_GEO_PML_OCx_QAA-202312-fv6.0.nc to only include variables MERIS_nobs_sum,MODISA_nobs_sum,OLCI-A_nobs_sum,OLCI-B_nobs_sum,SeaWiFS_nobs_sum,VIIRS_nobs_sum,chlor_a,chlor_a_log10_bias,chlor_a_log10_rmsd,crs,lat,lon,time,total_nobs_sum\n2024-03-15T14:27:48Z (local files)\n2024-03-15T14:27:48Z https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.dasid :ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-202312-fv6.0.ncinfoUrl :https://esa-oceancolour-cci.org/institution :Plymouth Marine Laboratorykeywords :algorithms, aqua, area, array, array-data, bias, bin, blended, cci, cell, chemistry, chlor_a, chlor_a_log10_bias, chlor_a_log10_rmsd, chlorophyll, chlorophyll-a, class, color, colour, combination, comprehensive, concentration, contributing, count, coverage, data, depending, difference, earth, Earth Science &gt; Oceans &gt; Ocean Chemistry &gt; Chlorophyll, esa, field, field-of-view, gac, generated, global, imager, imager/radiometer, imaging, infrared, laboratory, lac, large, local, log, log-transformed, log10, log10-transformed, marine, mass, mass_concentration_of_chlorophyll_a_in_sea_water, mean, memberships, meris, MERIS_nobs_sum, moderate, modis, MODISA_nobs_sum, not, number, observation, observations, oc2, ocean, ocean color, ocean colour, oceans, oci, oci2, ocx, olci, OLCI-A_nobs_sum, OLCI-B_nobs_sum, plymouth, product, radiometer, resolution, root, root-mean-square-difference, satellite, science, sea, sea-wide, seawater, seawifs, SeaWiFS_nobs_sum, sensor, sentinel, sentinel-3a, sentinel-3b, spectroradiometer, square, statistics, stewardship, suite, system, time, total, total_nobs_sum, transformed, view, viirs, VIIRS_nobs_sum, visible, water, widekeywords_vocabulary :GCMD Science Keywordslicense :ESA CCI Data Policy: free and open access.  When referencing, please use: Ocean Colour Climate Change Initiative dataset, Version &lt;Version Number&gt;, European Space Agency, available online at https://esa-oceancolour-cci.org.  We would also appreciate being notified of publications so that we can list them on the project website at https://esa-oceancolour-cci.org/?q=publicationsnaming_authority :uk.ac.pmlNCO :netCDF Operators version 4.7.5 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)nco_openmp_thread_number :1netcdf_file_type :NETCDF4_CLASSICNorthernmost_Northing :89.97916666666667number_of_bands_used_to_classify :4number_of_files_composited :31number_of_optical_water_types :14platform :Orbview-2,Aqua,Envisat,Suomi-NPP, Sentinel-3a, Sentinel-3bprocessing_level :Level-3product_version :6.0project :Climate Change Initiative - European Space Agencyreferences :https://esa-oceancolour-cci.org/sensor :SeaWiFS,MODIS,MERIS,VIIRS,OLCIsensors_present :OLCIa OLCIbsource :NASA SeaWiFS  L1A and L2 R2018.0 LAC and GAC, MODIS-Aqua L1A and L2 R2018.0, MERIS L1B 3rd reprocessing inc OCL corrections, NASA VIIRS L1A and L2 R2018.0, OLCI L1BsourceUrl :(local files)Southernmost_Northing :-89.97916666666666spatial_resolution :4km nominal at equatorstandard_name_vocabulary :CF Standard Name Table v70summary :Data products generated by the Ocean Colour component of the European Space Agency Climate Change Initiative project. These files are monthly composites of merged sensor (MERIS, Moderate Resolution Imaging Spectroradiometer (MODIS) Aqua, Sea-Wide Field-of-View Sensor (SeaWiFS) Local Area Coverage (LAC) & Global Area Coverage (GAC), Visible and Infrared Imager/Radiometer Suite (VIIRS), OLCI) products.  MODIS Aqua and SeaWiFS were band-shifted and bias-corrected to MERIS bands and values using a temporally and spatially varying scheme based on the overlap years of 2003-2007.  VIIRS was band-shifted and bias-corrected in a second stage against the MODIS Rrs that had already been corrected to MERIS levels, for the overlap period 2012-2014; at the third stage Sentinel-3A OLCI was bias corrected against already corrected MODIS, for overlap period 2016-07-01 to 2019-06-30;  at the fourth stage Sentinel-3B OLCI was bias corrected against already corrected Sentinel-3A OLCI, for overlap period 2018-07-01 to 2021-06-30.  VIIRS, MODIS, SeaWiFS and MERIS Rrs were derived from a combination of NASA's l2gen (for basic sensor geometry corrections, etc) and HYGEOS POLYMER (for atmospheric correction). OLCI Rrs were sourced at L1b (already geometrically corrected) and processed with POLYMER.  The Rrs were binned to a sinusoidal 4km level-3 grid, and later to 4km geographic projection, by Brockmann Consult's SNAP.  Derived products were generally computed with the standard algorithms through SeaDAS.  QAA IOPs were derived using the standard SeaDAS algorithm but with a modified backscattering table to match that used in the bandshifting.  The final chlorophyll is a combination of OCI, OCI2, OC2 and OCx, depending on the water class memberships.  Uncertainty estimates were added using the fuzzy water classifier and uncertainty estimation algorithm of Tim Moore as documented in Jackson et al (2017). and updated according to Jackson et al. (in prep).time_coverage_duration :P1Mtime_coverage_end :2023-12-01T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :1997-09-04T00:00:00Ztitle :Chlorophyll a concentration, ESA OC CCI - Monthly, 1997-present. v6.0tracking_id :abd52a4c-7009-464f-b1eb-958f7d333a1dWesternmost_Easting :0.020833333333314386\n\n\nOpening the dataset in Xarray lets you look at the dataset metadata.\n* The metadata are listed above. * No data is downloaded until you request it.\nFrom the metadata you can view: * The coordinates (time, latitude and longitude) that you will use to select the data to download. * A list of ten data variables. For this exercise, we want the “chlor_a” variable. If you want, you can find out about each variable with clicking the page icon to the right of each variable name.\nA note on dataset selection\nWe have preselected the OC-CCI monthly dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application.\nYou can find that information above by clicking the right arrow next to “Attribute”. Then look through the list to find: * ‘time_coverage_start’ and ‘time_coverage_end’: the time range * ‘geospatial_lat_min’ and ‘geospatial_lat_max’: the latitude range * ‘geospatial_lon_min’ and ‘geospatial_lon_max’: the longitude range\nThere are a lot of metadata attributes to look through. We can make it easier with a little code to print out the metadata of interest. Then compare these ranges to those found in your track data.\n\nprint('Temporal and spatial ranges of the satellite dataset')\nprint('time range', ds.attrs['time_coverage_start'], \n      ds.attrs['time_coverage_end'])\nprint('latitude range', ds.attrs['geospatial_lat_min'], \n      ds.attrs['geospatial_lat_max'])\nprint('longitude range', ds.attrs['geospatial_lon_min'], \n      ds.attrs['geospatial_lon_max'])\nprint(' ')\nprint('Temporal and spatial ranges of the track data')\nprint('time range', df.year_month_day.min(), df.year_month_day.max())\nprint('latitude range', \n      round(df.mean_lat.min(), 2), round(df.mean_lat.max(), 2))\nprint('longitude range', \n      round(df.mean_lon.min(), 2), round(df.mean_lon.max(), 2))\n\nTemporal and spatial ranges of the satellite dataset\ntime range 1997-09-04T00:00:00Z 2023-12-01T00:00:00Z\nlatitude range -89.97916666666666 89.97916666666667\nlongitude range 0.020833333333314386 359.97916666666663\n \nTemporal and spatial ranges of the track data\ntime range 2005-05-04 00:00:00 2008-08-16 00:00:00\nlatitude range 23.72 41.77\nlongitude range 175.86 248.57\n\n\n\n\nDownload the satellite data that corresponds to each track location\n\n# Create a temporary Pandas data frame to hold the downloaded satellite data\ncol_names = [\"erddap_date\", \"matched_lat\", \"matched_lon\", \"matched_chla\"]\ntot = pd.DataFrame(columns=col_names)\n\n# Finish each URL and download\nfor i in range(0, len(df)):\n    clear_output(wait=True)\n    print(i+1, 'of', len(df))\n    \n    # Crop the dataset to include data that corresponds to track locations\n    cropped_ds = ds['chlor_a'].sel(time=df.year_month_day[i],\n                                   latitude=df.mean_lat[i],\n                                   longitude=df.mean_lon[i],\n                                   method='nearest'\n                                   )\n     \n    # Downloaded the data and add it to a new line in the tot data frame\n    tot.loc[len(tot.index)] = [cropped_ds.time.values,\n                               np.round(cropped_ds.latitude.values, 5),  # round 5 dec\n                               np.round(cropped_ds.longitude.values, 5), # round 5 dec\n                               np.round(cropped_ds.values, 2)  # round 2 decimals\n                               ]\n    \n    print(tot.loc[[len(tot)-1]])\n\ntot.head(2)\n\n25 of 25\n   erddap_date  matched_lat  matched_lon  matched_chla\n24  2008-08-01     26.77083    245.77083          0.71\n\n\n\n\n\n\n\n\n\nerddap_date\nmatched_lat\nmatched_lon\nmatched_chla\n\n\n\n\n0\n2005-05-01\n32.6875\n176.60417\n0.29\n\n\n1\n2005-07-01\n35.0625\n175.85417\n0.11\n\n\n\n\n\n\n\n\n\nConsolidate the downloaded satellite data into the track data frame\n\n\ndf[['matched_lat', \n    'matched_lon', \n    'matched_chla', \n    'erddap_date']] = tot[['matched_lat',\n                           'matched_lon',\n                           'matched_chla',\n                           'erddap_date']]\n\ndf.head(2)\n\n\n\n\n\n\n\n\nyear_month_day\nmean_lon\nmean_lat\nmatched_lat\nmatched_lon\nmatched_chla\nerddap_date\n\n\n\n\n0\n2005-05-04\n176.619433\n32.678728\n32.6875\n176.60417\n0.29\n2005-05-01\n\n\n1\n2005-06-23\n175.860895\n35.057734\n35.0625\n175.85417\n0.11\n2005-07-01\n\n\n\n\n\n\n\n\n\nSave your work\n\ndf.to_csv('chl_matchup_turtle25327.csv', index=False, encoding='utf-8')"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#plot-chlorophyll-matchup-data-onto-a-map",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#plot-chlorophyll-matchup-data-onto-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot chlorophyll matchup data onto a map",
    "text": "Plot chlorophyll matchup data onto a map\n\nFirst plot a histogram of the chlorophyll data\n\nprint('Range:', df.matched_chla.min(), df.matched_chla.max())\n_ = df.matched_chla.hist(bins=40)\n\nRange: 0.06 0.71\n\n\n\n\n\n\n\n\n\nThe range of chlorophyll values can be large, with lots of very low values and a few very high values. Using a linear color bar, most of the lower values would have the same color. * To better visualize the data, we often plot the log or log10 of chlorophyll.\n\n\nPlot a histogram of the log of the chlorophyll data\n\nprint('Range:', np.log(df.matched_chla.min()), np.log(df.matched_chla.max()))\n_ = np.log(df.matched_chla).hist(bins=40)\n\nRange: -2.8134108 -0.34249032\n\n\n\n\n\n\n\n\n\n\nThe logarithmic transformation displays the range of values across the color bar range (above).\n\n\n\nMap the chlorophyll data\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\n\n# set the projection\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([120,255, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(120,255,20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(20,50,10), crs=ccrs.PlateCarree())\n\n# Add geographical features\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# build and plot coordinates onto map\nx,y = list(df.mean_lon),list(df.mean_lat)\nax1 = plt.scatter(x, y, transform=ccrs.PlateCarree(),\n                  marker='o',\n                  c=np.log(df.matched_chla),\n                  cmap=plt.get_cmap('jet')\n                  )\nax1=plt.plot(x[0],y[0],marker='*', transform=ccrs.PlateCarree(), markersize=10)\nax1=plt.plot(x[-1],y[-1],marker='X', transform=ccrs.PlateCarree(), markersize=10)\n\n\n\n# control color bar values spacing\nlevs2 = np.arange(-2.5, 0, 0.5)\ncbar=plt.colorbar(ticks=levs2, shrink=0.75, aspect=10)\ncbar.set_label(\"Chl a (mg/m^3)\", size=15, labelpad=20)\n\n# set the labels to be exp(levs2) so the label reflect values of chl-a, not log(chl-a)\ncbar.ax.set_yticklabels(np.around(np.exp(levs2), 2), size=10)\n\nplt.title(\"Chlorophyll Matchup to Animal Track #25317\", size=15)\nplt.show()"
  },
  {
    "objectID": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#on-your-own",
    "href": "tutorials/python/satellite_matchups_to_track_locations_xarray.html#on-your-own",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "On your own!",
    "text": "On your own!\n\nExercise 1:\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the NOAA Geo-polar Blended Analysis SST, GHRSST dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html\n* This dataset is a different ERDDAP; It has a different base URL and dataset ID and variable name. * Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nExercise 2:\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/\n* This dataset will likely be on a different base URL and dataset ID and variable name. * Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nOptional\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v1_0.html"
  },
  {
    "objectID": "tutorials/python/seaice-thickness-climatology.html",
    "href": "tutorials/python/seaice-thickness-climatology.html",
    "title": "Calculating anomaly and trend with sea ice thickness time series",
    "section": "",
    "text": "In this exercise, we will use the sea ice thickness data in the Arctic region, available through the PolarWatch data server, to study changes in monthly average sea ice thickness values. We will compare the current state of sea ice thickness to the historical mean and also evaluate the long-term trend from the data.\n\nThe exercise demonstrates the following techniques:\n\nLoading twice daily sea ice thickness data of the year 2023 from ERDDAP using xarray and compute monthly average\nLoading multi-year monthly average sea ice thickness data from netCDF file\nCalculating the historical sea ice thickness monthly means\nCalculating anomalies (departures from the historical means)\nCalculating the trend of monthly sea ice thickness means for the climatological reference period of 2006 to 2020 (15 years)\nVisualizing the data\n\n\n\nDatasets used:\n\nSea ice thickness for the Arctic from the NOAA Climate Data Record (CDR) of the Extended Polar Pathfinder cryosphere dataset from NCEI. Twice daily data are available from 1982 to present. https://polarwatch.noaa.gov/catalog/ice-thick-sq-nh-appx/preview/?dataset=daily&var=cdr_sea_ice_thickness&time_min=2024-08-28T14:00:00Z&time_max=2024-08-28T14:00:00Z&proj=epsg3413&colorBar=KT_amp|||0|3|\n25-km sea ice thickess monthly average data from 2006 to 2020.\n\nIn this exercise, monthly means were computed from the 25-km sea ice thickness dataset under the assumption of equal sampling and no missing data. Therefore, no weights were applied in this instance. In cases where data gaps or uneven sampling occur, applying appropriate weights is recommended for more accurate climatological calculations.\n\n\nImport Python packages\n\n# Load packages\nimport xarray as xr\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport pymannkendall as mk\n\n\n\nLoad data from PolarWatch ERDDAP data server\nWe will begin by obtaining the current sea ice thickness data from the PolarWatch ERDDAP data server. The data request is made using a URL that includes the ERDDAP address and a unique dataset ID.\n\n# Define the URL for the PolarWatch sea ice thickness dataset on the ERDDAP server\nerddap_url = \"https://polarwatch.noaa.gov/erddap/griddap/ncei_polarAPPX20_nhem\"  \n\n# Use xarray function to load the dtaset from the EREDDAP URL\nds = xr.open_dataset(erddap_url)   \n\n# Display the dataset metadata \nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 310GB\nDimensions:                                    (time: 29729, rows: 361,\n                                                columns: 361)\nCoordinates:\n  * time                                       (time) datetime64[ns] 238kB 19...\n  * rows                                       (rows) float32 1kB -4.5e+06 .....\n  * columns                                    (columns) float32 1kB -4.525e+...\nData variables: (12/20)\n    cdr_sea_ice_thickness                      (time, rows, columns) float32 15GB ...\n    cdr_surface_temperature                    (time, rows, columns) float32 15GB ...\n    cdr_surface_albedo                         (time, rows, columns) float32 15GB ...\n    cdr_surface_downwelling_shortwave_flux     (time, rows, columns) float32 15GB ...\n    cdr_surface_downwelling_longwave_flux      (time, rows, columns) float32 15GB ...\n    cdr_surface_upwelling_shortwave_flux       (time, rows, columns) float32 15GB ...\n    ...                                         ...\n    cloud_optical_depth                        (time, rows, columns) float32 15GB ...\n    cloud_top_pressure                         (time, rows, columns) float32 15GB ...\n    cloud_top_temperature                      (time, rows, columns) float32 15GB ...\n    cloud_type                                 (time, rows, columns) float32 15GB ...\n    surface_shortwave_cloud_radiative_forcing  (time, rows, columns) float32 15GB ...\n    surface_longwave_cloud_radiative_forcing   (time, rows, columns) float32 15GB ...\nAttributes: (12/44)\n    _NCProperties:              version=2,netcdf=4.8.1,hdf5=1.10.6\n    acknowledgement:            Please acknowledge NCEI, CoastWatch West Coas...\n    cdm_data_type:              Grid\n    cdr_program:                NOAA Climate Data Record Program for satellites\n    cdr_variable:               cdr_surface_temperature, cdr_surface_albedo, ...\n    comment:                    In order to be compliant with the EASE Grid s...\n    ...                         ...\n    spatial_resolution:         25 km\n    standard_name_vocabulary:   CF Standard Name Table (v26, 08 November 2013)\n    summary:                    summary\n    time_coverage_end:          2024-09-19T14:00:00Z\n    time_coverage_start:        1982-01-01T04:00:00Z\n    title:                      Sea Ice Thickness and Multi-variable Extended...xarray.DatasetDimensions:time: 29729rows: 361columns: 361Coordinates: (3)time(time)datetime64[ns]1982-01-01T04:00:00 ... 2024-09-..._ChunkSizes :512_CoordinateAxisType :Timeactual_range :[3.7870560e+08 1.7267544e+09]axis :Tioos_category :Timelong_name :Timestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1982-01-01T04:00:00.000000000', '1982-01-01T14:00:00.000000000',\n       '1982-01-02T04:00:00.000000000', ..., '2024-09-16T14:00:00.000000000',\n       '2024-09-19T04:00:00.000000000', '2024-09-19T14:00:00.000000000'],\n      dtype='datetime64[ns]')rows(rows)float32-4.5e+06 -4.475e+06 ... 4.525e+06_ChunkSizes :361_CoordinateAxisType :GeoYactual_range :[-4499620.  4524689.]axis :Ycomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid Y Coordinatesstandard_name :projection_y_coordinateunits :metersarray([-4499620.5, -4474553. , -4449485.5, ...,  4474553. ,  4499620.5,\n        4524688.5], dtype=float32)columns(columns)float32-4.525e+06 -4.5e+06 ... 4.5e+06_ChunkSizes :361_CoordinateAxisType :GeoXactual_range :[-4524688.  4499621.]axis :Xcomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid X Coordinatesstandard_name :projection_x_coordinateunits :metersarray([-4524688.5, -4499620.5, -4474553. , ...,  4449485.5,  4474553. ,\n        4499620.5], dtype=float32)Data variables: (20)cdr_sea_ice_thickness(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_icecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Ice Distributionlong_name :NOAA CDR of sea ice thicknessstandard_name :sea_ice_thicknessunits :mvalid_range :[ 0. 10.][3874313009 values with dtype=float32]cdr_surface_temperature(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_thermalcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Temperaturelong_name :NOAA CDR of surface skin temperaturestandard_name :surface_temperatureunits :degree_Kvalid_range :[   0. 1000.][3874313009 values with dtype=float32]cdr_surface_albedo(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of surface broadband albedostandard_name :surface_albedounits :1valid_range :[0. 1.][3874313009 values with dtype=float32]cdr_surface_downwelling_shortwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of surface downwelling shortwave radiative fluxstandard_name :surface_downwelling_shortwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_surface_downwelling_longwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of surface downwelling longwave radiative fluxstandard_name :surface_downwelling_longwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_surface_upwelling_shortwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of surface upwelling shortwave radiative fluxstandard_name :surface_upwelling_shortwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_surface_upwelling_longwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of surface upwelling longwave radiative fluxstandard_name :surface_upwelling_longwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_cloud_binary_mask(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarContinuous :falsecolorBarMaximum :1.5colorBarMinimum :-0.5colorBarNSections :2colorBarPalette :BlackWhitecoverage_content_type :referenceInformationflag_meanings :clear cloudyflag_values :[0 1]grid_mapping :crsioos_category :Identifierlong_name :NOAA CDR of cloud maskunits :1valid_range :[0. 1.][3874313009 values with dtype=float32]cdr_toa_net_downward_shortwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of TOA net downward shortwave radiative fluxstandard_name :toa_net_downward_shortwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_toa_outgoing_shortwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of TOA outgoing shortwave radiative fluxstandard_name :toa_outgoing_shortwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]cdr_toa_outgoing_longwave_flux(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_solarcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :NOAA CDR of TOA outgoing longwave radiative fluxstandard_name :toa_outgoing_longwave_fluxunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]surface_type(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarContinuous :falsecolorBarMaximum :5.5colorBarMinimum :-0.5colorBarNSections :6colorBarPalette :KT_graycoverage_content_type :physicalMeasurementflag_meanings :not_land ice snow landflag_values :[  0   3   4 254]grid_mapping :crsioos_category :Meteorologylong_name :surface typeunits :1valid_range :[  0 254][3874313009 values with dtype=float32]cloud_particle_phase(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarContinuous :falsecolorBarMaximum :1.5colorBarMinimum :-0.5colorBarNSections :2colorBarPalette :KT_halinecoverage_content_type :physicalMeasurementflag_meanings :liquid solidflag_values :[0 1]grid_mapping :crsioos_category :Meteorologylong_name :cloud particle phaseunits :1valid_range :[0 1][3874313009 values with dtype=float32]cloud_particle_radius(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_halinecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :cloud particle radiusunits :micronsvalid_range :[  0. 300.][3874313009 values with dtype=float32]cloud_optical_depth(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_deepcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :cloud optical depthunits :1valid_range :[  0. 300.][3874313009 values with dtype=float32]cloud_top_pressure(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_densecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :cloud top pressureunits :hPavalid_range :[   0. 1000.][3874313009 values with dtype=float32]cloud_top_temperature(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_thermalcoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :cloud top temperatureunits :Kvalid_range :[   0. 1000.][3874313009 values with dtype=float32]cloud_type(time, rows, columns)float32..._ChunkSizes :[  1 361 361]coverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :cloud typemeanings :Cloud type value has two digits, i.e. XX, the ones place X (the first X from left), representing cloud type from CASPR algorithm, and the tenth place X representing cloud type from CLAVR algorithm. For CLAVR algorithm the tenth place X meanings: 0=clear or partly cloudy,1=fogs,2=liquid,3=mixed phase,4=glaciated,5=cirrus6=cirrus over lower,7=unused,8=unused,9=missing. For CASPR algorithm the ones place X meanings: 0=clear,1=cirrus,2=low stratus,3=warm,4=cold,5=water6=ice,7=Polar stratospheric cloud (PSC),8=unknown,9=missing.units :1valid_range :[ 0 99][3874313009 values with dtype=float32]surface_shortwave_cloud_radiative_forcing(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_densecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :surface shortwave cloud radiative forcingunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]surface_longwave_cloud_radiative_forcing(time, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_densecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Meteorologylong_name :surface longwave cloud radiative forcingunits :W m-2valid_range :[   0. 1800.][3874313009 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1982-01-01 04:00:00', '1982-01-01 14:00:00',\n               '1982-01-02 04:00:00', '1982-01-02 14:00:00',\n               '1982-01-03 04:00:00', '1982-01-03 14:00:00',\n               '1982-01-04 04:00:00', '1982-01-04 14:00:00',\n               '1982-01-05 04:00:00', '1982-01-05 14:00:00',\n               ...\n               '2024-09-13 04:00:00', '2024-09-13 14:00:00',\n               '2024-09-14 04:00:00', '2024-09-14 14:00:00',\n               '2024-09-15 04:00:00', '2024-09-15 14:00:00',\n               '2024-09-16 04:00:00', '2024-09-16 14:00:00',\n               '2024-09-19 04:00:00', '2024-09-19 14:00:00'],\n              dtype='datetime64[ns]', name='time', length=29729, freq=None))rowsPandasIndexPandasIndex(Index([-4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5, -4374283.0,\n       -4349215.5, -4324148.0, -4299080.5, -4274013.0,\n       ...\n        4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,  4424418.0,\n        4449485.5,  4474553.0,  4499620.5,  4524688.5],\n      dtype='float32', name='rows', length=361))columnsPandasIndexPandasIndex(Index([-4524688.5, -4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5,\n       -4374283.0, -4349215.5, -4324148.0, -4299080.5,\n       ...\n        4274013.0,  4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,\n        4424418.0,  4449485.5,  4474553.0,  4499620.5],\n      dtype='float32', name='columns', length=361))Attributes: (44)_NCProperties :version=2,netcdf=4.8.1,hdf5=1.10.6acknowledgement :Please acknowledge NCEI, CoastWatch West Coast Node, and this dataset (doi:10.25921/AE96-0E57).cdm_data_type :Gridcdr_program :NOAA Climate Data Record Program for satellitescdr_variable :cdr_surface_temperature, cdr_surface_albedo, cdr_surface_downwelling_shortwave_flux, cdr_surface_downwelling_longwave_flux, cdr_surface_upwelling_shortwave_flux, cdr_surface_upwelling_longwave_flux, cdr_cloud_binary_mask, cdr_sea_ice_thickness, cdr_toa_net_downward_shortwave_flux, cdr_toa_outgoing_shortwave_flux, cdr_toa_outgoing_longwave_flux,surface_type, cloud_particle_phase, cloud_particle_radius, cloud_optical_depth, cloud_top_pressure, cloud_top_temperature, Cloud_type, surface_shortwave_cloud_radiative_forcing, surface_longwave_cloud_radiative_forcingcomment :In order to be compliant with the EASE Grid specifications, the following modifications were made to the source files: 1) For each data variable plus the latitude and longitude variables, the two dimensional x-y grid was rotated clockwise by 90 degrees, resulting in geographical orientation where the Greenwich Meridian runs parallel to the y (rows)-axis from the North Pole at the grid center to the middle of the x (columns)-axis at the bottom edge of the grid and -90 degree E meridian runs parallel to the x (columns)-axis from the North Pole at the grid center to the middle of the y (rows)-axis at the left edge of the grid.: 2) two coordinate variables (columns and rows) were added that correspond to the columns and rows dimensions (units of m). In addition, the time variable was modified to put all of the files in the dataset on the same base time (seconds since 1970-01-01T00:00:00Z).Conventions :COARDS, CF-1.4, Unidata Dataset Discovery v1.0creator_email :erd.data@noaa.govcreator_name :NOAA/NMFS/SWFSC/ERD and NOAA/NESDIS/CoastWatch West Coast Nodecreator_type :institutiondate_created :2024-09-23defaultGraphQuery :cdr_sea_ice_thickness[(last)][(-4499620.5):(4524688.5)][(-4524688.5):(4499620.5)]&.draw=surfacedoi :doi.org/10.25921/AE96-0E57EPSG :http://epsg.io/3408history :Data files were obtained from NCEI at https://www.ncei.noaa.gov/data/avhrr-polar-pathfinder-extended/access/. For each data variable plus the latitude and longitude variables, the two dimensional x-y grid was rotated clockwise by 90 degrees, resulting in geographical orientation where the Greenwich Meridian runs parallel to the y (rows)-axis from the North Pole at the grid center to the middle of the x (columns)-axis at the bottom edge of the grid and -90 degree E meridian runs parallel to the x (columns)-axis from the North Pole at the grid center to the middle of the y (rows)-axis at the left edge of the grid. To coordinate variables (columns and rows) were added that correspond to the columns and rows dimensions. The coordinate variables have units of meters. The timestamp was made consistent across all files by converting to seconds since 1970-01-01T00:00:00Z. Metadata were alter to be in compliance with CF and ACDD standards.\n2024-10-02T16:55:11Z https://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.ncdc:C00941/html\n2024-10-02T16:55:11Z https://polarwatch.noaa.gov/erddap/griddap/ncei_polarAPPX20_nhem.dasid :Polar-APP-X_v02r00_NheminfoUrl :https://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.ncdc:C00941/htmlinstitution :NOAA/NCEIkeywords :Earth Science &gt; Atmosphere &gt; Atmospheric Radiation &gt; Longwave Radiation, Earth Science &gt; Atmosphere &gt; Atmospheric Radiation &gt; Radiative Flux, Earth Science &gt; Atmosphere &gt; Atmospheric Radiation &gt; Solar Radiation, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Microphysics &gt; Cloud Droplet Concentration(Size), Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Microphysics &gt; Cloud Droplet Phase, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Microphysics &gt; Cloud Optical Depth(Thickness), Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Properties &gt; Cloud Fraction, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Properties &gt; Cloud Top Pressure, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Properties &gt; Cloud Top Temperature, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Properties &gt; Cloud Type, Earth Science &gt; Atmosphere &gt; Clouds &gt; Cloud Radiative Transfer &gt; Cloud Radiative Forcing, Earth Science &gt; Climate Indicators &gt; Cryospheric Indicators &gt; Ice Depth(Thickness), Earth Science &gt; Cryosphere &gt; Sea Ice &gt; Ice Depth(Thickness), Earth Science &gt; Cryosphere &gt; Snow And Ice &gt; Albedo, Earth Science &gt; Cryosphere &gt; Snow And Ice &gt; Snow And Ice Temperature, Earth Science &gt; Land Surface &gt; Land Albedo, Earth Science &gt; Land Surface &gt; Land Temperature, Earth Science &gt; Oceans &gt; Sea Ice &gt; Ice Depth(Thickness), Earth Science &gt; Terrestrial Hydrosphere &gt; Snow And Ice &gt; Albedo, Earth Science &gt; Terrestrial Hydrosphere &gt; Snow And Ice &gt; Ice Depth(Thickness)keywords_vocabulary :NASA Global Change Master Directory (GCMD) Earth Science Keywords, Version 8license :The data may be used and redistributed for free but is not intended\nfor legal use, since it may contain inaccuracies. Neither the data\nContributor, ERD, NOAA, nor the United States Government, nor any\nof their employees or contractors, makes any warranty, express or\nimplied, including warranties of merchantability and fitness for a\nparticular purpose, or assumes any legal liability for the accuracy,\ncompleteness, or usefulness, of this information.Metadata_Conventions :COARDS, CF-1.6, Unidata Dataset Discovery v1.0metadata_link :https://doi.org/10.25921/AE96-0E57naming_authority :gov.noaa.nceiNCO :netCDF Operators version 5.0.6 (Homepage = http://nco.sf.net, Code = https://github.com/nco/nco)platform : NOAA polar orbiting satellite 19product_version :V2.0PROJ4 :+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +a=6371228 +b=6371228 +units=m +no_defsproj_crs_code :EPSG:3408proj_crs_code_description :The proj_crs_code attribute references a registered projection identifier (i.e. EPSG) when available. If the projection is not registered, non-standard then this attribute references a PolarWatch assigned internal identifier.proj_units :meterspublisher_email :erd.data@noaa.govpublisher_name :NOAA/NMFS/SWFSC/ERD and NOAA/NESDIS/CoastWatch West Coast Nodepublisher_type :institutionreferences :doi.org/10.25921/AE96-0E57sensor :Advanced Very High Resolution Radiometer (AVHRR)/3source :individual twice daily APP-x datasourceUrl :https://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.ncdc:C00941/htmlspatial_resolution :25 kmstandard_name_vocabulary :CF Standard Name Table (v26, 08 November 2013)summary :summarytime_coverage_end :2024-09-19T14:00:00Ztime_coverage_start :1982-01-01T04:00:00Ztitle :Sea Ice Thickness and Multi-variable Extended AVHRR Polar Pathfinder APP-X NCEI Climate Data Record V2, Arctic, 1982-Present, Twice Daily\n\n\n\n\nLoad 2021 data and compute monthly average\nNote: Running this code snippet may take some time (about 10 minutes), depending on the available resources of your computer. If you encounter any issues running the code, you can load the final dataset, ds_23_monthly.nc, located in the data/ folder to continue with the exercise.\n# Load data from year 2021\nds21 = ds.sel(time=slice('2023-01-01', '2023-12-31'))\n\n# Compute montly average\nds_monthly_mean21 = ds21.groupby(\"time.month\").mean()\n\n# Close dataset to free up memory\nds21.close()\n\n# Load data from year 2021\nds23 = ds['cdr_sea_ice_thickness'].sel(time=slice('2023-01-01', '2023-12-31'))\n\n# Compute montly average\nds_monthly_mean23_2 = ds23.groupby(\"time.month\").mean()\n\n# Close dataset to free up memory\nds23.close()\n\n\n\n# Load already computed monthly mean for 2021\nds_monthly_mean23 = xr.open_dataset('../data/sit_monthly_mean23.nc')\nds_monthly_mean23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 6MB\nDimensions:                (rows: 361, columns: 361, month: 12)\nCoordinates:\n  * rows                   (rows) float32 1kB -4.5e+06 -4.475e+06 ... 4.525e+06\n  * columns                (columns) float32 1kB -4.525e+06 -4.5e+06 ... 4.5e+06\n  * month                  (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\nData variables:\n    cdr_sea_ice_thickness  (month, rows, columns) float32 6MB ...xarray.DatasetDimensions:rows: 361columns: 361month: 12Coordinates: (3)rows(rows)float32-4.5e+06 -4.475e+06 ... 4.525e+06_ChunkSizes :361_CoordinateAxisType :GeoYactual_range :[-4499620.  4524689.]axis :Ycomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid Y Coordinatesstandard_name :projection_y_coordinateunits :metersarray([-4499620.5, -4474553. , -4449485.5, ...,  4474553. ,  4499620.5,\n        4524688.5], dtype=float32)columns(columns)float32-4.525e+06 -4.5e+06 ... 4.5e+06_ChunkSizes :361_CoordinateAxisType :GeoXactual_range :[-4524688.  4499621.]axis :Xcomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid X Coordinatesstandard_name :projection_x_coordinateunits :metersarray([-4524688.5, -4499620.5, -4474553. , ...,  4449485.5,  4474553. ,\n        4499620.5], dtype=float32)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])Data variables: (1)cdr_sea_ice_thickness(month, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_icecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Ice Distributionlong_name :NOAA CDR of sea ice thicknessstandard_name :sea_ice_thicknessunits :mvalid_range :[ 0. 10.][1563852 values with dtype=float32]Indexes: (3)rowsPandasIndexPandasIndex(Index([-4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5, -4374283.0,\n       -4349215.5, -4324148.0, -4299080.5, -4274013.0,\n       ...\n        4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,  4424418.0,\n        4449485.5,  4474553.0,  4499620.5,  4524688.5],\n      dtype='float32', name='rows', length=361))columnsPandasIndexPandasIndex(Index([-4524688.5, -4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5,\n       -4374283.0, -4349215.5, -4324148.0, -4299080.5,\n       ...\n        4274013.0,  4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,\n        4424418.0,  4449485.5,  4474553.0,  4499620.5],\n      dtype='float32', name='columns', length=361))monthPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))Attributes: (0)\n\n\n\n\nVisualizing 2023 January Monthly Average on the Map\n\n# Visualize the January sea ice thickness mean (first time step: index[0])\nds_monthly_mean23['cdr_sea_ice_thickness'][0].plot()\nplt.title(\"2023 Sea ice thickness January Average\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nLoading Monthly Average from 2006 to 2020\nTo do climate analysis such as computing climatology and trend analysis, we will use sea ice thickness monthly average from 2005 to 2020. The monthly averages are already computed and are available in netcdf file.\n\n# Load monthly average data from 2006-2020\nds_monthly = xr.open_dataset('../data/seaice-thickness-monthly2006_2020.nc')\nds_monthly\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 94MB\nDimensions:                (year: 15, month: 12, rows: 361, columns: 361)\nCoordinates:\n  * rows                   (rows) float32 1kB -4.5e+06 -4.475e+06 ... 4.525e+06\n  * columns                (columns) float32 1kB -4.525e+06 -4.5e+06 ... 4.5e+06\n  * month                  (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\n  * year                   (year) int64 120B 2006 2007 2008 ... 2018 2019 2020\nData variables:\n    cdr_sea_ice_thickness  (year, month, rows, columns) float32 94MB ...xarray.DatasetDimensions:year: 15month: 12rows: 361columns: 361Coordinates: (4)rows(rows)float32-4.5e+06 -4.475e+06 ... 4.525e+06_ChunkSizes :361_CoordinateAxisType :GeoYactual_range :[-4499620.  4524689.]axis :Ycomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid Y Coordinatesstandard_name :projection_y_coordinateunits :metersarray([-4499620.5, -4474553. , -4449485.5, ...,  4474553. ,  4499620.5,\n        4524688.5], dtype=float32)columns(columns)float32-4.525e+06 -4.5e+06 ... 4.5e+06_ChunkSizes :361_CoordinateAxisType :GeoXactual_range :[-4524688.  4499621.]axis :Xcomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid X Coordinatesstandard_name :projection_x_coordinateunits :metersarray([-4524688.5, -4499620.5, -4474553. , ...,  4449485.5,  4474553. ,\n        4499620.5], dtype=float32)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])year(year)int642006 2007 2008 ... 2018 2019 2020array([2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n       2018, 2019, 2020])Data variables: (1)cdr_sea_ice_thickness(year, month, rows, columns)float32..._ChunkSizes :[  1 361 361]colorBarPalette :KT_icecoverage_content_type :physicalMeasurementgrid_mapping :crsioos_category :Ice Distributionlong_name :NOAA CDR of sea ice thicknessstandard_name :sea_ice_thicknessunits :mvalid_range :[ 0. 10.][23457780 values with dtype=float32]Indexes: (4)rowsPandasIndexPandasIndex(Index([-4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5, -4374283.0,\n       -4349215.5, -4324148.0, -4299080.5, -4274013.0,\n       ...\n        4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,  4424418.0,\n        4449485.5,  4474553.0,  4499620.5,  4524688.5],\n      dtype='float32', name='rows', length=361))columnsPandasIndexPandasIndex(Index([-4524688.5, -4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5,\n       -4374283.0, -4349215.5, -4324148.0, -4299080.5,\n       ...\n        4274013.0,  4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,\n        4424418.0,  4449485.5,  4474553.0,  4499620.5],\n      dtype='float32', name='columns', length=361))monthPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))yearPandasIndexPandasIndex(Index([2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n       2018, 2019, 2020],\n      dtype='int64', name='year'))Attributes: (0)\n\n\n\n\nCompute the 15 year historical mean\nUsing ds_monthly dataset, we will compute 15 year historical monthly means.\n\n# Compute monthly mean from annualized data\nhistorical_mean = ds_monthly.mean(dim='year')\nds_monthly.close()\nhistorical_mean\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 6MB\nDimensions:                (month: 12, rows: 361, columns: 361)\nCoordinates:\n  * rows                   (rows) float32 1kB -4.5e+06 -4.475e+06 ... 4.525e+06\n  * columns                (columns) float32 1kB -4.525e+06 -4.5e+06 ... 4.5e+06\n  * month                  (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\nData variables:\n    cdr_sea_ice_thickness  (month, rows, columns) float32 6MB 0.0 0.0 ... 0.0xarray.DatasetDimensions:month: 12rows: 361columns: 361Coordinates: (3)rows(rows)float32-4.5e+06 -4.475e+06 ... 4.525e+06_ChunkSizes :361_CoordinateAxisType :GeoYactual_range :[-4499620.  4524689.]axis :Ycomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid Y Coordinatesstandard_name :projection_y_coordinateunits :metersarray([-4499620.5, -4474553. , -4449485.5, ...,  4474553. ,  4499620.5,\n        4524688.5], dtype=float32)columns(columns)float32-4.525e+06 -4.5e+06 ... 4.5e+06_ChunkSizes :361_CoordinateAxisType :GeoXactual_range :[-4524688.  4499621.]axis :Xcomment :columns values are the upper left of the grid cellsioos_category :Locationlong_name :Projection Grid X Coordinatesstandard_name :projection_x_coordinateunits :metersarray([-4524688.5, -4499620.5, -4474553. , ...,  4449485.5,  4474553. ,\n        4499620.5], dtype=float32)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])Data variables: (1)cdr_sea_ice_thickness(month, rows, columns)float320.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0array([[[ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        ...,\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        ...,\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        ...,\n...\n        ...,\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        ...,\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        [ 0.,  0.,  0., ..., nan, nan, nan],\n        ...,\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32)Indexes: (3)rowsPandasIndexPandasIndex(Index([-4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5, -4374283.0,\n       -4349215.5, -4324148.0, -4299080.5, -4274013.0,\n       ...\n        4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,  4424418.0,\n        4449485.5,  4474553.0,  4499620.5,  4524688.5],\n      dtype='float32', name='rows', length=361))columnsPandasIndexPandasIndex(Index([-4524688.5, -4499620.5, -4474553.0, -4449485.5, -4424418.0, -4399350.5,\n       -4374283.0, -4349215.5, -4324148.0, -4299080.5,\n       ...\n        4274013.0,  4299080.5,  4324148.0,  4349215.5,  4374283.0,  4399350.5,\n        4424418.0,  4449485.5,  4474553.0,  4499620.5],\n      dtype='float32', name='columns', length=361))monthPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))Attributes: (0)\n\n\n\n\nVisualizing monthly historical mean\n\n# Plot the first time step of the sea ice thickness\nhistorical_mean['cdr_sea_ice_thickness'][1].plot()\nplt.title(\"Sea Ice Thickness Historical Month Mean (Feb)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nComputing Anomalies\nTo assess recent changes in sea ice thickness, we can compare the current sea ice thickness for the year 2023 to the 15-year historical mean. An anaomaly is a commonly used metric that represents the difference (or departure) between the current value and the historical average.\n\n# Compute anomaly of 2021 from the mean data\nanom_mean = ds_monthly_mean23['cdr_sea_ice_thickness'] - historical_mean['cdr_sea_ice_thickness']\n\n# Plot Feb and Sep anomaly\nfig, axs = plt.subplots(1, 2, figsize=(12, 5))\nanom_mean[1].plot(ax=axs[0])\nanom_mean[8].plot(ax=axs[1])\n\n# Set the title\nfig.suptitle('2021 Monthly Sea ice thickness Anomalies from 2005-2020 means', fontsize=13)\n\n# Adjust the layout\nplt.tight_layout()\n\n# Display the plots\nplt.show()\n\n\n\n\n\n\n\n\n\n\nComputing Trends\nhttps://www.geeksforgeeks.org/how-to-perform-a-mann-kendall-trend-test-in-python/\nA trend in climatology refers to long-term changes over an extended period. There are several methods to estimate the trends in the time series data. In this exercise, we will use Mann-Kendall regression with mk_slope() function to compute the slope. Mann-Kendall test is a non-parametric method that does not assume data normality, making it suitable for various data distributions.\nNote: The code may take some time to process (approximately 3 minutes).\n\n\n# Define a function to apply the Mann-Kendall test and return the slope\ndef mk_slope(data):\n\n# remove NaN data points\n    clean_data = data[~np.isnan(data)]\n# if data points not enough, return Nan \n    if len(clean_data) &lt; 2:\n            return np.nan     \n    # Apply MK analysis\n    result = mk.original_test(data)\n    # Return only slope\n    return result.slope\n\n# Using xarray.apply_ufunc(), we will apply mk_slope across the 'time' (monthly)  dimension for each grid\n# Apply the function across the 'time' dimension for each pixel\nslopes = xr.apply_ufunc(\n    mk_slope,                # The function to apply\n    ds_monthly,                    # The data \n    input_core_dims=[['year']],  # The dimension over which to apply the function\n    vectorize=True,          # Vectorize to apply across all grid\n    dask='parallelized',     # Enable parallel processing if using Dask\n    output_dtypes=[float]    # The output type (float for slope)\n)\n\n\n\n\nVisualizing the Trends (Slopes) for Each Grid\nThe slopes are calculated for each month and grid over the 15-year-period (2005-2020).\nFor this visualization, we will display the results from the month of September across the grid.\n\nslopes['cdr_sea_ice_thickness'].sel(month=9).plot()\n\nplt.title('Sea Ice Thickness Trend for September')\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "tutorials/python/subset-polar-data-with-shapefile.html",
    "href": "tutorials/python/subset-polar-data-with-shapefile.html",
    "title": "Subset data in polar stereographic projection using a shape file fr",
    "section": "",
    "text": "Updated September 2024\n\n\nBackground\nRemote sensing data in polar regions commonly use a polar stereographic projection, where the georeferencing is in x and y coordinates instead of the more widely used latitudes and longitudes. Working with data from different projections can be challenging.\n\n\nObjectives\nIn this tutorial, we will demonstrate how to download remote sensing data in polar stereographic projection from PolarWatch and subset it within the boundaries of Lake Iliamna in Alaska, where the lake shape data is presented in a different projection.\nAs this tutorial focuses on satellite data transformation, a basic understanding of satellite data, map projections, and the ERDDAP data server is recommended. For additional learning, you can explore satellite data tutorials and video lectures available through introductory video lectures and tutorials hosted on the CoastWatch Learning Portal and GitHub repository.\n\nThe tutorial demonstrates the following techniques\n\nDownload sea ice satellite data from the PolarWatch ERDDAP data server\nImport geographical features of Lake Iliamna from a shapefile\nTransform data from one projection to another\nSubset the satellite data for Lake Iliamna\nVisualize data in different projection\n\n\n\n\nData Used\nWorld Lake shape data\nThe world lake shapefile can be downloaded from ArcGIS Hub at https://hub.arcgis.com, and is also available in the resource/ directory of this tutorial folder. The file includes geographical features of all world lakes. For this exercise, only the features of Lake Illemna will be used.\nIMS Snow and Ice Analysis, Arctic, 4km, 2004 - Present, Daily (PolarWatch Preview)\nThe IMS dataset includes daily snow and ice coverage data for the Arctic with a 4-km resolution, available starting from 2004. The values in the dataset are categorical, representing five categories: 0 for areas outside the coverage zone, 1 for open water, 2 for land without snow, 3 for sea ice or lake ice, and 4 for snow-covered land. Data with a 1-km resolution are also available. Please contact us for more information.\n\nLoad python packages\nFor this exercise, the following packages are required. The complete list of required packages for all CoastWatch tutorials is provided in the environment.yml located in the Python-setup/ folder.\n\n# Load packages\nimport xarray as xr\nimport geopandas as gpd\nimport pandas as pd\nimport rioxarray\nfrom shapely.geometry import mapping\n\n\n\nLoad Lake Illemna data\n\n# Load lake shape file into geopanda data frame\nshapefile_path = '../resources/Iliamna/Iliamna.shp'\nlakes_shp = gpd.read_file(shapefile_path)\n\n\n# Check column names\nprint(\"Lake Data Columns:\")\nprint(lakes_shp.columns)\nlakes_shp[\"Lake_name\"].unique()\n\nLake Data Columns:\nIndex(['Hylak_id', 'Lake_name', 'Country', 'Continent', 'Poly_src',\n       'Lake_type', 'Grand_id', 'Lake_area', 'Shore_len', 'Shore_dev',\n       'Vol_total', 'Vol_res', 'Vol_src', 'Depth_avg', 'Dis_avg', 'Res_time',\n       'Elevation', 'Slope_100', 'Wshd_area', 'Pour_long', 'Pour_lat',\n       'geometry'],\n      dtype='object')\n\n\narray([None, 'Iliamna'], dtype=object)\n\n\n\n# Look up Iliamna lake\nprint(\"Row(s) that contain lake name: Iliamna\")\nlakes_shp[lakes_shp['Lake_name'].str.contains('iliamna', case=False, na=False)]\n\nRow(s) that contain lake name: Iliamna\n\n\n\n\n\n\n\n\n\nHylak_id\nLake_name\nCountry\nContinent\nPoly_src\nLake_type\nGrand_id\nLake_area\nShore_len\nShore_dev\n...\nVol_src\nDepth_avg\nDis_avg\nRes_time\nElevation\nSlope_100\nWshd_area\nPour_long\nPour_lat\ngeometry\n\n\n\n\n287\n31\nIliamna\nUnited States of America\nNorth America\nNHD\n1\n0\n2634.62\n1006.79\n5.53\n...\n1\n43.8\n354.811\n3761.5\n13\n-1.0\n16869.4\n-155.884538\n59.331889\nPOLYGON ((-17336380.000 8247763.000, -17336837...\n\n\n\n\n1 rows × 22 columns\n\n\n\n\n# Extract Iliamna shape\niliamna_shp = lakes_shp[lakes_shp['Hylak_id'] == 31]\n\n# Examine coordinate referernce system (crs)\niliamna_shp.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n# Visualize the lake \niliamna_shp.plot()\n\n\n\n\n\n\n\n\n\n\nLoad IMS data from PolarWatch ERDDAP\n\n# Load IMS data from ERDDAP\nerddap_url = \"https://polarwatch.noaa.gov/erddap/griddap/usnic_ims_4km\"\nds = xr.open_dataset(erddap_url)\n\n# Select one day data\nds_date = '2024-07-30'\nds = ds.sel(time=ds_date)\n\n# Visualize the IMS data\nds[\"IMS_Surface_Values\"].plot()\n\n\n\n\n\n\n\n\n\n# Check the IMS data projection\nds.attrs['grid_mapping_proj4']\n\n'+proj=stere +lat_0=90 +lat_ts=60 +lon_0=-80 +k=1 +x_0=0 +y_0=0 +a=6378137 +b=6356257 +units=m +no_defs'\n\n\n\n\n\nTransform the lake data crs to match the satellite data crs\nThe helper functions are provided for the projection transformation process\n\n# from PolarWatch helper functions\n\ndef set_geo_specs(dat: xr.DataArray, xdim: str, ydim: str, crs: str) -&gt; xr.DataArray:\n    \"\"\"Update the spatial dimensions and coordinate reference system (CRS) of an xarray DataArray.\n\n    Args:\n        dat (xr.DataArray): The data array to modify.\n        xdim (str): Name of the dimension representing the x-coordinate.\n        ydim (str): Name of the dimension representing the y-coordinate.\n        crs (str): String representation of the coordinate reference system to assign.\n\n    Returns:\n        xr.DataArray: The updated data array with specified spatial dimensions and CRS.\n    \"\"\"\n    dat = dat.rio.set_spatial_dims(x_dim=xdim, y_dim=ydim)\n    try:\n        dat = dat.rio.write_crs(crs)\n        print('CRS setup successful')\n    except Exception as e:\n        print(f'Error during crs setup: {e}')\n\n    return dat\n\n\ndef clip_data_to_shapefile(data_array: xr.DataArray, shapefile_geom, crs: str)-&gt; xr.DataArray:\n    \"\"\"Clip data array to the specified shapefile geometry with CRS.\n    \n    Args:\n        data_array (xr.DataArray): The data array to modify.\n        shapefile_geom : Shapefile geometry.\n        crs (str): CRS of the data.\n\n    Returns:\n        xr.DataArray: The updated data array with specified spatial dimensions and CRS.  \n    \n    \"\"\"\n    try:\n        clipped_data = data_array.rio.clip(shapefile_geom.apply(mapping), crs)\n        print(\"Clipping successful\")\n        return clipped_data\n    except Exception as e:\n        print(f\"Error during clipping: {e}\")\n        raise\n\ndef transform_shapes(shp: gpd.GeoDataFrame, crs:str)-&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Transforms the projection of a GeoDataFrame to a specified coordinate reference system (CRS).\n    \n    This function takes a GeoDataFrame and transforms its projection to the specified CRS, typically used\n    for reprojecting geometries to match satellite data or other spatial datasets that require a specific CRS.\n    For example, transforming the shape to a Polar Stereographic Projection.\n    \n    Parameters:\n    shp : gpd.GeoDataFrame\n        The input GeoDataFrame containing geometries (e.g., shapes, boundaries) that need to be transformed.\n    crs : str\n        The target coordinate reference system (CRS) in string format (e.g., \"EPSG:3413\" for the Polar Stereographic Projection).\n    \n    Returns:\n    gpd.GeoDataFrame\n        A GeoDataFrame with geometries transformed to the specified CRS.\n\n    \"\"\"\n    try:\n        shp_proj_transformed = shp.to_crs(crs)\n        print(f\"Projection transformed to {crs}\")\n        return shp_proj_transformed\n    except Exception as e:\n        print(f\"Error transforming CRS: {e}\")\n        raise\n\n\n# Set crs_project as the data crs (based on xarray.Dataset.attrs)\ncrs_project = \"+proj=stere +lat_0=90 +lat_ts=60 +lon_0=-80 +k=1 +x_0=0 +y_0=0 +a=6378137 +b=6356257 +units=m +no_defs\"\n\n# Set data crs\nds = set_geo_specs(ds, xdim=\"x\", ydim=\"y\", crs=crs_project)\n\n# Transform the shape into the data crs\niliamna_transformed = transform_shapes(iliamna_shp, crs_project)\n\nCRS setup successful\nProjection transformed to +proj=stere +lat_0=90 +lat_ts=60 +lon_0=-80 +k=1 +x_0=0 +y_0=0 +a=6378137 +b=6356257 +units=m +no_defs\n\n\n\n# Examine lake shape crs\niliamna_transformed.crs\n\n&lt;Projected CRS: +proj=stere +lat_0=90 +lat_ts=60 +lon_0=-80 +k=1 + ...&gt;\nName: unknown\nAxis Info [cartesian]:\n- E[south]: Easting (metre)\n- N[south]: Northing (metre)\nArea of Use:\n- undefined\nCoordinate Operation:\n- name: unknown\n- method: Polar Stereographic (variant B)\nDatum: unknown\n- Ellipsoid: unknown\n- Prime Meridian: Greenwich\n\n\n\n# Visualized transformed iliamna shape\niliamna_transformed.plot()\n\n\n\n\n\n\n\n\n\nSubset the satellite data using the Lake shape\n\n# Clip data to the shape\nds_clipped = clip_data_to_shapefile(ds, iliamna_transformed.geometry, iliamna_transformed.crs)\n\nClipping successful\n\n\n\n# Visualized clipped data\nds_clipped[\"IMS_Surface_Values\"].plot()\n\n\n\n\n\n\n\n\n\n\n\nResources\n\nCoastWatch Learning Portal - Lectures, Videos, Other learning resources\nCoastWatch Tutorials on Github - Tutorial notebooks and code samples\nPolarWatch ERDDAP - Complete list of data available on PolarWatch ERDDAP Server\nPolarWatch Catalog - Preview data on polar map"
  }
]